"""
AI ë¶„ì„ ì˜ˆì¸¡ ì—”ì§„
ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ì„ ë¶„ì„í•˜ì—¬ ë¬¸ì œì ê³¼ ê¶Œì¥ì‚¬í•­ì„ ì œê³µ
"""

from typing import Dict, List, Optional, Any
from datetime import datetime
import json
import numpy as np
import pandas as pd
import psutil
import os
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings('ignore')

class MetricsPredictor:
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë¶„ì„ ë° ì˜ˆì¸¡ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.confidence_threshold = 0.8
        self.critical_cpu_threshold = 90
        self.critical_memory_threshold = 85
        self.critical_disk_threshold = 90
        
    def analyze_metrics(self, query: Optional[str] = None, 
                       metrics: Optional[List[Dict[str, Any]]] = None,
                       data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë¬¸ì œì ê³¼ ê¶Œì¥ì‚¬í•­ì„ ë°˜í™˜
        
        Args:
            query: ë¶„ì„ ìš”ì²­ ì¿¼ë¦¬
            metrics: ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë¦¬ìŠ¤íŠ¸
            data: ì¶”ê°€ ë°ì´í„°
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        
        # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼
        analysis_result = {
            "summary": "ì •ìƒì ì¸ ì‹œìŠ¤í…œ ìƒíƒœì…ë‹ˆë‹¤",
            "confidence": 0.95,
            "recommendations": ["ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ ì§€ì†"],
            "analysis_data": {
                "query": query,
                "metrics_count": len(metrics) if metrics else 0,
                "timestamp": datetime.now().isoformat(),
                "analysis_type": "general"
            }
        }
        
        # ì¿¼ë¦¬ ê¸°ë°˜ ë¶„ì„
        if query:
            analysis_result.update(self._analyze_by_query(query))
            
        # ë©”íŠ¸ë¦­ ê¸°ë°˜ ë¶„ì„
        if metrics and len(metrics) > 0:
            metric_analysis = self._analyze_metrics_data(metrics)
            analysis_result.update(metric_analysis)
            
        return analysis_result
    
    def _analyze_by_query(self, query: str) -> Dict[str, Any]:
        """ì¿¼ë¦¬ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„"""
        
        query_lower = query.lower()
        
        # CPU ê´€ë ¨ ë¶„ì„
        if any(keyword in query_lower for keyword in ['cpu', 'í”„ë¡œì„¸ì„œ', 'ì²˜ë¦¬ìœ¨', 'ì‚¬ìš©ë¥ ']):
            if any(keyword in query_lower for keyword in ['ê¸‰ì¦', 'ì¦ê°€', 'ë†’ìŒ', 'ê³¼ë¶€í•˜']):
                return {
                    "summary": "CPU ë¶€í•˜ ì¦ê°€ë¡œ ì¸í•œ ì‘ë‹µ ì§€ì—° ê°€ëŠ¥ì„±",
                    "confidence": 0.92,
                    "recommendations": [
                        "nginx ìƒíƒœ í™•ì¸",
                        "DB ì»¤ë„¥ì…˜ ìˆ˜ ì ê²€",
                        "ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸",
                        "CPU ì§‘ì•½ì  ì‘ì—… ìµœì í™” ê²€í† "
                    ],
                    "analysis_data": {
                        "analysis_type": "cpu_performance",
                        "severity": "high"
                    }
                }
        
        # ë©”ëª¨ë¦¬ ê´€ë ¨ ë¶„ì„
        elif any(keyword in query_lower for keyword in ['ë©”ëª¨ë¦¬', 'ë¨', 'memory', 'ram']):
            return {
                "summary": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤",
                "confidence": 0.88,
                "recommendations": [
                    "ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì ê²€",
                    "ìºì‹œ ì •ë¦¬ ì‹¤í–‰",
                    "ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ"
                ],
                "analysis_data": {
                    "analysis_type": "memory_optimization",
                    "severity": "medium"
                }
            }
        
        # ë””ìŠ¤í¬ ê´€ë ¨ ë¶„ì„
        elif any(keyword in query_lower for keyword in ['ë””ìŠ¤í¬', 'ì €ì¥ì†Œ', 'disk', 'storage']):
            return {
                "summary": "ë””ìŠ¤í¬ ê³µê°„ ë˜ëŠ” I/O ì„±ëŠ¥ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "confidence": 0.85,
                "recommendations": [
                    "ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸",
                    "ë¡œê·¸ íŒŒì¼ ì •ë¦¬",
                    "ë””ìŠ¤í¬ ì¡°ê° ëª¨ìŒ ì‹¤í–‰"
                ],
                "analysis_data": {
                    "analysis_type": "disk_performance",
                    "severity": "medium"
                }
            }
        
        # ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ë¶„ì„
        elif any(keyword in query_lower for keyword in ['ë„¤íŠ¸ì›Œí¬', 'ì—°ê²°', 'network', 'ì§€ì—°']):
            return {
                "summary": "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "confidence": 0.80,
                "recommendations": [
                    "ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ í™•ì¸",
                    "ë°©í™”ë²½ ê·œì¹™ ì ê²€",
                    "DNS í•´ì„ ì†ë„ í™•ì¸"
                ],
                "analysis_data": {
                    "analysis_type": "network_analysis",
                    "severity": "medium"
                }
            }
        
        return {}
    
    def _analyze_metrics_data(self, metrics: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì‹¤ì œ ë©”íŠ¸ë¦­ ë°ì´í„° ë¶„ì„"""
        
        # ê°€ì¥ ìµœê·¼ ë©”íŠ¸ë¦­ ë¶„ì„
        latest_metric = metrics[-1] if metrics else {}
        
        cpu_usage = latest_metric.get('cpu', 0)
        memory_usage = latest_metric.get('memory', 0)
        disk_usage = latest_metric.get('disk', 0)
        
        issues = []
        recommendations = []
        severity = "low"
        confidence = 0.95
        
        # CPU ë¶„ì„
        if cpu_usage >= self.critical_cpu_threshold:
            issues.append(f"CPU ì‚¬ìš©ë¥ ì´ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤ ({cpu_usage}%)")
            recommendations.extend([
                "CPU ì§‘ì•½ì  í”„ë¡œì„¸ìŠ¤ í™•ì¸",
                "ë¡œë“œ ë°¸ëŸ°ì‹± ê²€í† ",
                "ì„œë²„ ìŠ¤ì¼€ì¼ë§ ê³ ë ¤"
            ])
            severity = "critical"
            
        elif cpu_usage >= 70:
            issues.append(f"CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({cpu_usage}%)")
            recommendations.append("CPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ê°•í™”")
            severity = "high" if severity == "low" else severity
        
        # ë©”ëª¨ë¦¬ ë¶„ì„
        if memory_usage >= self.critical_memory_threshold:
            issues.append(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤ ({memory_usage}%)")
            recommendations.extend([
                "ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì ê²€",
                "ìºì‹œ ìµœì í™”",
                "ë©”ëª¨ë¦¬ ì¦ì„¤ ê²€í† "
            ])
            severity = "critical"
            
        elif memory_usage >= 70:
            issues.append(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({memory_usage}%)")
            recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§")
            severity = "high" if severity == "low" else severity
        
        # ë””ìŠ¤í¬ ë¶„ì„
        if disk_usage >= self.critical_disk_threshold:
            issues.append(f"ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ì´ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤ ({disk_usage}%)")
            recommendations.extend([
                "ë””ìŠ¤í¬ ì •ë¦¬ ì¦‰ì‹œ ì‹¤í–‰",
                "ë¡œê·¸ íŒŒì¼ ì•„ì¹´ì´ë¸Œ",
                "ë””ìŠ¤í¬ ìš©ëŸ‰ ì¦ì„¤"
            ])
            severity = "critical"
        
        # ë¶„ì„ ê²°ê³¼ ìƒì„±
        if issues:
            summary = "; ".join(issues)
            if severity == "critical":
                confidence = 0.95
            elif severity == "high":
                confidence = 0.88
            else:
                confidence = 0.75
        else:
            summary = "ëª¨ë“  ë©”íŠ¸ë¦­ì´ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤"
            recommendations = ["í˜„ì¬ ìƒíƒœ ìœ ì§€", "ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ ì§€ì†"]
        
        return {
            "summary": summary,
            "confidence": confidence,
            "recommendations": recommendations,
            "analysis_data": {
                "analysis_type": "metrics_analysis",
                "severity": severity,
                "metrics_analyzed": {
                    "cpu": cpu_usage,
                    "memory": memory_usage,
                    "disk": disk_usage
                }
            }
        }

class RealTimePredictor:
    """ğŸ”® ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì˜ˆì¸¡ ë° ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.system_info = None
        self.baseline_metrics = None
        self.initialized = False
        self.analysis_history = []
        
    def initialize(self):
        """ğŸš€ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”"""
        print("ğŸ”® RealTimePredictor ì´ˆê¸°í™” ì¤‘...")
        
        # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
        self.system_info = self._collect_system_info()
        
        # ML ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_models()
        
        # ë² ì´ìŠ¤ë¼ì¸ ë©”íŠ¸ë¦­ ì„¤ì •
        self.baseline_metrics = self._collect_baseline_metrics()
        
        self.initialized = True
        print("âœ… RealTimePredictor ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def _collect_system_info(self) -> Dict[str, Any]:
        """ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
        try:
            cpu_info = {
                'count': psutil.cpu_count(),
                'freq': psutil.cpu_freq()._asdict() if psutil.cpu_freq() else None,
                'model': 'Unknown'
            }
            
            memory_info = psutil.virtual_memory()._asdict()
            disk_info = psutil.disk_usage('/')._asdict()
            
            # ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤
            network_info = {
                'interfaces': list(psutil.net_if_addrs().keys()),
                'stats': psutil.net_io_counters()._asdict()
            }
            
            return {
                'cpu': cpu_info,
                'memory': memory_info,
                'disk': disk_info,
                'network': network_info,
                'boot_time': psutil.boot_time(),
                'platform': os.name,
                'collected_at': datetime.now().isoformat()
            }
        except Exception as e:
            print(f"âš ï¸ ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {'error': str(e), 'collected_at': datetime.now().isoformat()}
    
    def _initialize_models(self):
        """ğŸ¤– ML ëª¨ë¸ ì´ˆê¸°í™”"""
        # ì´ìƒ íƒì§€ ëª¨ë¸
        self.models['anomaly_detector'] = IsolationForest(
            contamination=0.1,
            random_state=42,
            n_estimators=100
        )
        
        # í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ (ì •ìƒ/ê²½ê³ /ìœ„í—˜ ìƒíƒœ ë¶„ë¥˜)
        self.models['state_classifier'] = KMeans(
            n_clusters=3,
            random_state=42,
            n_init=10
        )
        
        # íŠ¸ë Œë“œ ì˜ˆì¸¡ ëª¨ë¸
        self.models['trend_predictor'] = LinearRegression()
        
        # ìŠ¤ì¼€ì¼ëŸ¬
        self.scalers['metrics'] = StandardScaler()
        self.scalers['features'] = StandardScaler()
        
        print("ğŸ¤– ML ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _collect_baseline_metrics(self) -> Dict[str, float]:
        """ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # í˜„ì¬ ì‹œì ì˜ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ì„ ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ ì„¤ì •
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            baseline = {
                'cpu_normal': min(cpu_percent + 10, 70),  # ì •ìƒ ë²”ìœ„ ìƒí•œ
                'memory_normal': min(memory.percent + 15, 80),
                'disk_normal': min((disk.used / disk.total * 100) + 10, 85),
                'cpu_warning': 80,
                'memory_warning': 85,
                'disk_warning': 90,
                'cpu_critical': 95,
                'memory_critical': 95,
                'disk_critical': 98
            }
            
            print(f"ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ë©”íŠ¸ë¦­ ì„¤ì •: CPU {baseline['cpu_normal']:.1f}%, ë©”ëª¨ë¦¬ {baseline['memory_normal']:.1f}%")
            return baseline
            
        except Exception as e:
            print(f"âš ï¸ ë² ì´ìŠ¤ë¼ì¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {
                'cpu_normal': 70, 'cpu_warning': 80, 'cpu_critical': 95,
                'memory_normal': 80, 'memory_warning': 85, 'memory_critical': 95,
                'disk_normal': 85, 'disk_warning': 90, 'disk_critical': 98
            }
    
    def analyze_metrics(self, query: str, metrics: List[Dict], data: Dict) -> Dict[str, Any]:
        """ğŸ§  ë©”ì¸ ë¶„ì„ ì—”ì§„"""
        if not self.initialized:
            self.initialize()
        
        start_time = datetime.now()
        
        try:
            # 1. ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            current_metrics = self._collect_current_metrics()
            
            # 2. ë°ì´í„° ì „ì²˜ë¦¬
            processed_data = self._preprocess_metrics(metrics, current_metrics)
            
            # 3. ë‹¤ì¤‘ ë¶„ì„ ìˆ˜í–‰
            analysis_results = {
                'anomaly_detection': self._detect_anomalies(processed_data),
                'performance_analysis': self._analyze_performance(processed_data),
                'trend_prediction': self._predict_trends(processed_data),
                'system_health': self._assess_system_health(current_metrics),
                'recommendations': self._generate_recommendations(processed_data, current_metrics)
            }
            
            # 4. ê²°ê³¼ í†µí•© ë° í•œêµ­ì–´ í•´ì„
            final_result = self._synthesize_results(analysis_results, query, current_metrics)
            
            # 5. ë¶„ì„ ê¸°ë¡ ì €ì¥
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            final_result['processing_time'] = processing_time
            
            self._record_analysis(query, final_result)
            
            return final_result
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_error_response(str(e), query)
    
    def _collect_current_metrics(self) -> Dict[str, Any]:
        """ğŸ“Š í˜„ì¬ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì‹¤ì‹œê°„ ìˆ˜ì§‘"""
        try:
            # CPU ì •ë³´
            cpu_percent = psutil.cpu_percent(interval=0.1)
            cpu_count = psutil.cpu_count()
            cpu_freq = psutil.cpu_freq()
            
            # ë©”ëª¨ë¦¬ ì •ë³´
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()
            
            # ë””ìŠ¤í¬ ì •ë³´
            disk = psutil.disk_usage('/')
            disk_io = psutil.disk_io_counters()
            
            # ë„¤íŠ¸ì›Œí¬ ì •ë³´
            network = psutil.net_io_counters()
            
            # í”„ë¡œì„¸ìŠ¤ ì •ë³´
            processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
                try:
                    pinfo = proc.info
                    if pinfo['cpu_percent'] > 0 or pinfo['memory_percent'] > 1:
                        processes.append(pinfo)
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
            
            # ìƒìœ„ 10ê°œ í”„ë¡œì„¸ìŠ¤ë§Œ ì„ íƒ
            processes = sorted(processes, key=lambda x: x['cpu_percent'], reverse=True)[:10]
            
            return {
                'timestamp': datetime.now().isoformat(),
                'cpu': {
                    'percent': cpu_percent,
                    'count': cpu_count,
                    'freq': cpu_freq._asdict() if cpu_freq else None
                },
                'memory': {
                    'total': memory.total,
                    'available': memory.available,
                    'percent': memory.percent,
                    'used': memory.used,
                    'free': memory.free,
                    'swap_total': swap.total,
                    'swap_used': swap.used,
                    'swap_percent': swap.percent
                },
                'disk': {
                    'total': disk.total,
                    'used': disk.used,
                    'free': disk.free,
                    'percent': (disk.used / disk.total) * 100,
                    'read_bytes': disk_io.read_bytes if disk_io else 0,
                    'write_bytes': disk_io.write_bytes if disk_io else 0
                },
                'network': {
                    'bytes_sent': network.bytes_sent,
                    'bytes_recv': network.bytes_recv,
                    'packets_sent': network.packets_sent,
                    'packets_recv': network.packets_recv
                },
                'processes': processes,
                'uptime': datetime.now().timestamp() - psutil.boot_time()
            }
            
        except Exception as e:
            print(f"âš ï¸ í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'error': str(e),
                'fallback': True
            }
    
    def _preprocess_metrics(self, historical_metrics: List[Dict], current_metrics: Dict) -> Dict[str, Any]:
        """ğŸ”§ ë©”íŠ¸ë¦­ ë°ì´í„° ì „ì²˜ë¦¬"""
        try:
            # íˆìŠ¤í† ë¦¬ì»¬ ë°ì´í„° ì •ê·œí™”
            if historical_metrics:
                df = pd.DataFrame(historical_metrics)
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ì¶”ê°€
                required_cols = ['cpu', 'memory', 'disk']
                for col in required_cols:
                    if col not in df.columns:
                        df[col] = np.random.normal(50, 15, len(df))
                
                # ì´ìƒê°’ ì œê±°
                for col in required_cols:
                    df[col] = df[col].clip(0, 100)
                
                # íŠ¸ë Œë“œ ê³„ì‚°
                trends = {}
                for col in required_cols:
                    if len(df) > 1:
                        x = np.arange(len(df)).reshape(-1, 1)
                        y = df[col].values
                        model = LinearRegression().fit(x, y)
                        trends[f'{col}_trend'] = model.coef_[0]
                    else:
                        trends[f'{col}_trend'] = 0
            else:
                df = pd.DataFrame()
                trends = {'cpu_trend': 0, 'memory_trend': 0, 'disk_trend': 0}
            
            # í˜„ì¬ ë©”íŠ¸ë¦­ ì •ê·œí™”
            current_normalized = {
                'cpu': current_metrics.get('cpu', {}).get('percent', 0),
                'memory': current_metrics.get('memory', {}).get('percent', 0),
                'disk': current_metrics.get('disk', {}).get('percent', 0)
            }
            
            return {
                'historical_df': df,
                'current_metrics': current_normalized,
                'trends': trends,
                'data_quality': len(df) if not df.empty else 0,
                'has_sufficient_data': len(df) >= 5
            }
            
        except Exception as e:
            print(f"âš ï¸ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'historical_df': pd.DataFrame(),
                'current_metrics': {'cpu': 0, 'memory': 0, 'disk': 0},
                'trends': {'cpu_trend': 0, 'memory_trend': 0, 'disk_trend': 0},
                'data_quality': 0,
                'has_sufficient_data': False,
                'error': str(e)
            }
    
    def _detect_anomalies(self, processed_data: Dict) -> Dict[str, Any]:
        """ğŸš¨ ì´ìƒ íƒì§€"""
        try:
            current = processed_data['current_metrics']
            baseline = self.baseline_metrics
            
            anomalies = []
            severity_score = 0
            
            # CPU ì´ìƒ íƒì§€
            if current['cpu'] > baseline['cpu_critical']:
                anomalies.append({
                    'type': 'cpu_critical',
                    'value': current['cpu'],
                    'threshold': baseline['cpu_critical'],
                    'severity': 'critical',
                    'message': f'CPU ì‚¬ìš©ë¥ ì´ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤ ({current["cpu"]:.1f}%)'
                })
                severity_score += 3
            elif current['cpu'] > baseline['cpu_warning']:
                anomalies.append({
                    'type': 'cpu_warning',
                    'value': current['cpu'],
                    'threshold': baseline['cpu_warning'],
                    'severity': 'warning',
                    'message': f'CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({current["cpu"]:.1f}%)'
                })
                severity_score += 1
            
            # ë©”ëª¨ë¦¬ ì´ìƒ íƒì§€
            if current['memory'] > baseline['memory_critical']:
                anomalies.append({
                    'type': 'memory_critical',
                    'value': current['memory'],
                    'threshold': baseline['memory_critical'],
                    'severity': 'critical',
                    'message': f'ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤ ({current["memory"]:.1f}%)'
                })
                severity_score += 3
            elif current['memory'] > baseline['memory_warning']:
                anomalies.append({
                    'type': 'memory_warning',
                    'value': current['memory'],
                    'threshold': baseline['memory_warning'],
                    'severity': 'warning',
                    'message': f'ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({current["memory"]:.1f}%)'
                })
                severity_score += 1
            
            # ë””ìŠ¤í¬ ì´ìƒ íƒì§€
            if current['disk'] > baseline['disk_critical']:
                anomalies.append({
                    'type': 'disk_critical',
                    'value': current['disk'],
                    'threshold': baseline['disk_critical'],
                    'severity': 'critical',
                    'message': f'ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ì´ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤ ({current["disk"]:.1f}%)'
                })
                severity_score += 3
            elif current['disk'] > baseline['disk_warning']:
                anomalies.append({
                    'type': 'disk_warning',
                    'value': current['disk'],
                    'threshold': baseline['disk_warning'],
                    'severity': 'warning',
                    'message': f'ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({current["disk"]:.1f}%)'
                })
                severity_score += 1
            
            # íŠ¸ë Œë“œ ê¸°ë°˜ ì´ìƒ íƒì§€
            trends = processed_data['trends']
            if trends['cpu_trend'] > 2:
                anomalies.append({
                    'type': 'cpu_trend',
                    'value': trends['cpu_trend'],
                    'severity': 'warning',
                    'message': f'CPU ì‚¬ìš©ë¥ ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤ (ì¶”ì„¸: +{trends["cpu_trend"]:.1f}%)'
                })
                severity_score += 1
            
            overall_status = 'normal'
            if severity_score >= 6:
                overall_status = 'critical'
            elif severity_score >= 3:
                overall_status = 'warning'
            elif severity_score >= 1:
                overall_status = 'caution'
            
            return {
                'anomalies_detected': len(anomalies),
                'anomalies': anomalies,
                'severity_score': severity_score,
                'overall_status': overall_status,
                'confidence': min(0.9, 0.6 + (len(anomalies) * 0.1))
            }
            
        except Exception as e:
            print(f"âš ï¸ ì´ìƒ íƒì§€ ì‹¤íŒ¨: {e}")
            return {
                'anomalies_detected': 0,
                'anomalies': [],
                'severity_score': 0,
                'overall_status': 'unknown',
                'confidence': 0.3,
                'error': str(e)
            }
    
    def _analyze_performance(self, processed_data: Dict) -> Dict[str, Any]:
        """âš¡ ì„±ëŠ¥ ë¶„ì„"""
        try:
            current = processed_data['current_metrics']
            trends = processed_data['trends']
            
            # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (0-100)
            cpu_score = max(0, 100 - current['cpu'])
            memory_score = max(0, 100 - current['memory'])
            disk_score = max(0, 100 - current['disk'])
            
            overall_score = (cpu_score + memory_score + disk_score) / 3
            
            # ì„±ëŠ¥ ë“±ê¸‰
            if overall_score >= 80:
                performance_grade = 'excellent'
                grade_text = 'ìš°ìˆ˜'
            elif overall_score >= 60:
                performance_grade = 'good'
                grade_text = 'ì–‘í˜¸'
            elif overall_score >= 40:
                performance_grade = 'average'
                grade_text = 'ë³´í†µ'
            elif overall_score >= 20:
                performance_grade = 'poor'
                grade_text = 'ì €ì¡°'
            else:
                performance_grade = 'critical'
                grade_text = 'ìœ„í—˜'
            
            # ë³‘ëª© í˜„ìƒ ë¶„ì„
            bottlenecks = []
            if current['cpu'] > 80:
                bottlenecks.append('CPU')
            if current['memory'] > 85:
                bottlenecks.append('ë©”ëª¨ë¦¬')
            if current['disk'] > 90:
                bottlenecks.append('ë””ìŠ¤í¬')
            
            return {
                'overall_score': round(overall_score, 1),
                'performance_grade': performance_grade,
                'grade_text': grade_text,
                'component_scores': {
                    'cpu': round(cpu_score, 1),
                    'memory': round(memory_score, 1),
                    'disk': round(disk_score, 1)
                },
                'bottlenecks': bottlenecks,
                'trends': {
                    'cpu_direction': 'improving' if trends['cpu_trend'] < 0 else 'degrading' if trends['cpu_trend'] > 1 else 'stable',
                    'memory_direction': 'improving' if trends['memory_trend'] < 0 else 'degrading' if trends['memory_trend'] > 1 else 'stable',
                    'disk_direction': 'improving' if trends['disk_trend'] < 0 else 'degrading' if trends['disk_trend'] > 1 else 'stable'
                }
            }
            
        except Exception as e:
            print(f"âš ï¸ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'overall_score': 50,
                'performance_grade': 'unknown',
                'grade_text': 'ì•Œ ìˆ˜ ì—†ìŒ',
                'error': str(e)
            }
    
    def _predict_trends(self, processed_data: Dict) -> Dict[str, Any]:
        """ğŸ“ˆ íŠ¸ë Œë“œ ì˜ˆì¸¡"""
        try:
            trends = processed_data['trends']
            current = processed_data['current_metrics']
            
            # 1ì‹œê°„ í›„ ì˜ˆì¸¡ê°’
            predictions_1h = {
                'cpu': max(0, min(100, current['cpu'] + trends['cpu_trend'] * 6)),  # 10ë¶„ * 6 = 1ì‹œê°„
                'memory': max(0, min(100, current['memory'] + trends['memory_trend'] * 6)),
                'disk': max(0, min(100, current['disk'] + trends['disk_trend'] * 6))
            }
            
            # 24ì‹œê°„ í›„ ì˜ˆì¸¡ê°’
            predictions_24h = {
                'cpu': max(0, min(100, current['cpu'] + trends['cpu_trend'] * 144)),  # 10ë¶„ * 144 = 24ì‹œê°„
                'memory': max(0, min(100, current['memory'] + trends['memory_trend'] * 144)),
                'disk': max(0, min(100, current['disk'] + trends['disk_trend'] * 144))
            }
            
            # ê²½ê³  ì˜ˆì¸¡
            warnings = []
            for metric in ['cpu', 'memory', 'disk']:
                if predictions_1h[metric] > 85:
                    warnings.append(f'{metric.upper()}ì´ 1ì‹œê°„ ë‚´ì— ìœ„í—˜ ìˆ˜ì¤€ì— ë„ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤')
                elif predictions_24h[metric] > 90:
                    warnings.append(f'{metric.upper()}ì´ 24ì‹œê°„ ë‚´ì— ìœ„í—˜ ìˆ˜ì¤€ì— ë„ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤')
            
            return {
                'predictions_1h': predictions_1h,
                'predictions_24h': predictions_24h,
                'trends': trends,
                'warnings': warnings,
                'confidence': 0.7 if processed_data['has_sufficient_data'] else 0.4
            }
            
        except Exception as e:
            print(f"âš ï¸ íŠ¸ë Œë“œ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {
                'predictions_1h': {'cpu': 0, 'memory': 0, 'disk': 0},
                'predictions_24h': {'cpu': 0, 'memory': 0, 'disk': 0},
                'warnings': [],
                'confidence': 0.2,
                'error': str(e)
            }
    
    def _assess_system_health(self, current_metrics: Dict) -> Dict[str, Any]:
        """ğŸ¥ ì‹œìŠ¤í…œ ê±´ê°•ë„ í‰ê°€"""
        try:
            cpu = current_metrics.get('cpu', {}).get('percent', 0)
            memory = current_metrics.get('memory', {}).get('percent', 0)
            disk = current_metrics.get('disk', {}).get('percent', 0)
            uptime = current_metrics.get('uptime', 0)
            
            # ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚°
            health_score = 100
            issues = []
            
            if cpu > 90:
                health_score -= 30
                issues.append('CPU ê³¼ë¶€í•˜')
            elif cpu > 70:
                health_score -= 15
                issues.append('CPU ì‚¬ìš©ë¥  ë†’ìŒ')
            
            if memory > 90:
                health_score -= 25
                issues.append('ë©”ëª¨ë¦¬ ë¶€ì¡±')
            elif memory > 75:
                health_score -= 10
                issues.append('ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ')
            
            if disk > 95:
                health_score -= 20
                issues.append('ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±')
            elif disk > 85:
                health_score -= 10
                issues.append('ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ìœ„í—˜')
            
            # ê±´ê°•ë„ ë“±ê¸‰
            if health_score >= 80:
                health_status = 'healthy'
                status_text = 'ê±´ê°•í•¨'
                status_color = 'green'
            elif health_score >= 60:
                health_status = 'warning'
                status_text = 'ì£¼ì˜ í•„ìš”'
                status_color = 'yellow'
            elif health_score >= 40:
                health_status = 'poor'
                status_text = 'ë¶ˆëŸ‰'
                status_color = 'orange'
            else:
                health_status = 'critical'
                status_text = 'ìœ„í—˜'
                status_color = 'red'
            
            return {
                'health_score': max(0, health_score),
                'health_status': health_status,
                'status_text': status_text,
                'status_color': status_color,
                'issues': issues,
                'uptime_hours': round(uptime / 3600, 1),
                'system_stability': 'stable' if not issues else 'unstable'
            }
            
        except Exception as e:
            print(f"âš ï¸ ì‹œìŠ¤í…œ ê±´ê°•ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                'health_score': 50,
                'health_status': 'unknown',
                'status_text': 'ì•Œ ìˆ˜ ì—†ìŒ',
                'error': str(e)
            }
    
    def _generate_recommendations(self, processed_data: Dict, current_metrics: Dict) -> List[str]:
        """ğŸ’¡ ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        try:
            current = processed_data['current_metrics']
            trends = processed_data['trends']
            
            # CPU ì¶”ì²œì‚¬í•­
            if current['cpu'] > 90:
                recommendations.append('ğŸ”¥ ê¸´ê¸‰: CPU ì‚¬ìš©ë¥ ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•˜ì„¸ìš”.')
            elif current['cpu'] > 75:
                recommendations.append('âš ï¸ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ì„¸ìš”.')
            elif trends['cpu_trend'] > 2:
                recommendations.append('ğŸ“ˆ CPU ì‚¬ìš©ë¥ ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.')
            
            # ë©”ëª¨ë¦¬ ì¶”ì²œì‚¬í•­
            if current['memory'] > 90:
                recommendations.append('ğŸ’¾ ê¸´ê¸‰: ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ì •ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
            elif current['memory'] > 80:
                recommendations.append('ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¢…ë£Œí•˜ì„¸ìš”.')
            elif trends['memory_trend'] > 1:
                recommendations.append('ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ì ê²€í•˜ì„¸ìš”.')
            
            # ë””ìŠ¤í¬ ì¶”ì²œì‚¬í•­
            if current['disk'] > 95:
                recommendations.append('ğŸ’¿ ê¸´ê¸‰: ë””ìŠ¤í¬ ê³µê°„ì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì •ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
            elif current['disk'] > 85:
                recommendations.append('ğŸ—‚ï¸ ë””ìŠ¤í¬ ê³µê°„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ íŒŒì¼ì„ ì‚­ì œí•˜ì„¸ìš”.')
            
            # ì „ë°˜ì ì¸ ì¶”ì²œì‚¬í•­
            if not recommendations:
                recommendations.append('âœ… ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê³„ì†í•˜ì„¸ìš”.')
            
            # ì˜ˆë°©ì  ì¶”ì²œì‚¬í•­ ì¶”ê°€
            recommendations.append('ğŸ“‹ ì •ê¸°ì ì¸ ì‹œìŠ¤í…œ ë°±ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”.')
            recommendations.append('ğŸ”„ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ë¥¼ í™•ì¸í•˜ê³  ì ìš©í•˜ì„¸ìš”.')
            
        except Exception as e:
            print(f"âš ï¸ ì¶”ì²œì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")
            recommendations.append('âš ï¸ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì ê²€í•˜ê³  ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.')
        
        return recommendations[:5]  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ë°˜í™˜
    
    def _synthesize_results(self, analysis_results: Dict, query: str, current_metrics: Dict) -> Dict[str, Any]:
        """ğŸ”® ê²°ê³¼ í†µí•© ë° í•œêµ­ì–´ í•´ì„"""
        try:
            anomaly = analysis_results['anomaly_detection']
            performance = analysis_results['performance_analysis']
            trends = analysis_results['trend_prediction']
            health = analysis_results['system_health']
            recommendations = analysis_results['recommendations']
            
            # ì „ì²´ ìš”ì•½ ìƒì„±
            summary_parts = []
            
            if health['health_status'] == 'healthy':
                summary_parts.append('ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤')
            elif health['health_status'] == 'warning':
                summary_parts.append('ì‹œìŠ¤í…œì— ì£¼ì˜ê°€ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤')
            else:
                summary_parts.append('ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤')
            
            summary_parts.append(f"ì„±ëŠ¥ ì ìˆ˜ëŠ” {performance['overall_score']:.1f}ì ({performance['grade_text']})ì…ë‹ˆë‹¤")
            
            if anomaly['anomalies_detected'] > 0:
                summary_parts.append(f"{anomaly['anomalies_detected']}ê°œì˜ ì´ìƒì§•í›„ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤")
            
            # í•œêµ­ì–´ ì‘ë‹µ ìƒì„±
            korean_response = {
                'success': True,
                'analysis_type': 'comprehensive_system_analysis',
                'query': query,
                'summary': '. '.join(summary_parts) + '.',
                'details': {
                    'current_status': {
                        'cpu': f"{current_metrics.get('cpu', {}).get('percent', 0):.1f}%",
                        'memory': f"{current_metrics.get('memory', {}).get('percent', 0):.1f}%",
                        'disk': f"{current_metrics.get('disk', {}).get('percent', 0):.1f}%",
                        'health_score': health['health_score'],
                        'health_status': health['status_text']
                    },
                    'performance': performance,
                    'anomalies': anomaly,
                    'trends': trends,
                    'system_health': health
                },
                'recommendations': recommendations,
                'confidence': min(0.9, (
                    anomaly.get('confidence', 0.5) + 
                    trends.get('confidence', 0.5) + 
                    0.8  # ê¸°ë³¸ ë¶„ì„ ì‹ ë¢°ë„
                ) / 3),
                'metadata': {
                    'analysis_timestamp': datetime.now().isoformat(),
                    'data_quality': 'good' if current_metrics.get('timestamp') else 'limited',
                    'model_version': '2.0.0',
                    'features_analyzed': ['cpu', 'memory', 'disk', 'trends', 'anomalies']
                }
            }
            
            return korean_response
            
        except Exception as e:
            print(f"âŒ ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {e}")
            return self._create_error_response(str(e), query)
    
    def _create_error_response(self, error_msg: str, query: str) -> Dict[str, Any]:
        """âŒ ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            'success': False,
            'error': error_msg,
            'query': query,
            'summary': 'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
            'fallback_analysis': {
                'message': 'ê¸°ë³¸ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.',
                'timestamp': datetime.now().isoformat()
            },
            'recommendations': [
                'ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”',
                'ì„œë¹„ìŠ¤ë¥¼ ì¬ì‹œì‘í•´ë³´ì„¸ìš”',
                'ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”'
            ],
            'confidence': 0.1
        }
    
    def _record_analysis(self, query: str, result: Dict):
        """ğŸ“ ë¶„ì„ ê¸°ë¡ ì €ì¥"""
        try:
            record = {
                'timestamp': datetime.now().isoformat(),
                'query': query[:100],  # ì¿¼ë¦¬ ê¸¸ì´ ì œí•œ
                'success': result.get('success', False),
                'confidence': result.get('confidence', 0),
                'processing_time': result.get('processing_time', 0)
            }
            
            self.analysis_history.append(record)
            
            # ìµœëŒ€ 100ê°œ ê¸°ë¡ë§Œ ìœ ì§€
            if len(self.analysis_history) > 100:
                self.analysis_history = self.analysis_history[-100:]
                
        except Exception as e:
            print(f"âš ï¸ ë¶„ì„ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_analysis_stats(self) -> Dict[str, Any]:
        """ğŸ“Š ë¶„ì„ í†µê³„"""
        if not self.analysis_history:
            return {'message': 'ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤'}
        
        total_analyses = len(self.analysis_history)
        successful_analyses = sum(1 for record in self.analysis_history if record['success'])
        avg_processing_time = np.mean([record['processing_time'] for record in self.analysis_history])
        avg_confidence = np.mean([record['confidence'] for record in self.analysis_history])
        
        return {
            'total_analyses': total_analyses,
            'success_rate': (successful_analyses / total_analyses) * 100,
            'avg_processing_time_ms': round(avg_processing_time, 2),
            'avg_confidence': round(avg_confidence, 3),
            'last_analysis': self.analysis_history[-1]['timestamp']
        }

# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
predictor = RealTimePredictor() 