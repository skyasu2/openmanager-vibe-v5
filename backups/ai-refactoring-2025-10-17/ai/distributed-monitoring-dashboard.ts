/**
 * ğŸŒ Distributed AI Services Monitoring Dashboard
 *
 * ëª©í‘œ: ë¶„ì‚° AI ì„œë¹„ìŠ¤ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
 * - Vercel Edge Runtime ìƒíƒœ
 * - Supabase pgvector ì„±ëŠ¥
 * - GCP Functions ì‘ë‹µ ì‹œê°„
 * - Redis ìºì‹œ ì ì¤‘ë¥ 
 * - ì„œë¹„ìŠ¤ ê°„ í†µì‹  ì§€ì—°
 */

interface ServiceMetrics {
  name: string;
  status: 'healthy' | 'degraded' | 'unhealthy';
  responseTime: number;
  successRate: number;
  lastCheck: string;
  errorCount: number;
  throughput: number; // requests per minute
}

interface DistributedMetrics {
  vercelEdge: ServiceMetrics;
  supabaseRAG: ServiceMetrics;
  gcpKoreanNLP: ServiceMetrics;
  gcpMLAnalytics: ServiceMetrics;
  memoryCache: ServiceMetrics;
  interServiceLatency: {
    vercelToSupabase: number;
    vercelToGCP: number;
    supabaseToCache: number;
  };
}

interface AlertRule {
  id: string;
  service: string;
  metric: 'responseTime' | 'successRate' | 'errorCount';
  threshold: number;
  operator: 'gt' | 'lt' | 'eq';
  severity: 'warning' | 'critical';
  enabled: boolean;
}

interface Alert {
  id: string;
  ruleId: string;
  service: string;
  message: string;
  severity: 'warning' | 'critical';
  timestamp: number;
  acknowledged: boolean;
}

export class DistributedMonitoringDashboard {
  private metrics: DistributedMetrics;
  private metricsHistory: Array<{
    timestamp: number;
    metrics: DistributedMetrics;
  }> = [];
  private alerts: Alert[] = [];
  private alertRules: AlertRule[] = [];
  private monitoringInterval: NodeJS.Timeout | null = null;

  constructor() {
    this.metrics = this.initializeMetrics();
    this.setupDefaultAlertRules();
    this.startMonitoring();
  }

  /**
   * ğŸ“Š ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
   */
  private initializeMetrics(): DistributedMetrics {
    const defaultServiceMetrics: ServiceMetrics = {
      name: '',
      status: 'healthy',
      responseTime: 0,
      successRate: 1.0,
      lastCheck: new Date().toISOString(),
      errorCount: 0,
      throughput: 0,
    };

    return {
      vercelEdge: { ...defaultServiceMetrics, name: 'Vercel Edge Runtime' },
      supabaseRAG: { ...defaultServiceMetrics, name: 'Supabase RAG Engine' },
      gcpKoreanNLP: { ...defaultServiceMetrics, name: 'GCP Korean NLP' },
      gcpMLAnalytics: { ...defaultServiceMetrics, name: 'GCP ML Analytics' },
      memoryCache: { ...defaultServiceMetrics, name: 'Memory Cache System' },
      interServiceLatency: {
        vercelToSupabase: 0,
        vercelToGCP: 0,
        supabaseToCache: 0,
      },
    };
  }

  /**
   * ğŸš¨ ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •
   */
  private setupDefaultAlertRules(): void {
    this.alertRules = [
      // ì‘ë‹µ ì‹œê°„ ì•Œë¦¼
      {
        id: 'vercel_response_time',
        service: 'vercelEdge',
        metric: 'responseTime',
        threshold: 500,
        operator: 'gt',
        severity: 'warning',
        enabled: true,
      },
      {
        id: 'supabase_response_time',
        service: 'supabaseRAG',
        metric: 'responseTime',
        threshold: 1000,
        operator: 'gt',
        severity: 'critical',
        enabled: true,
      },
      {
        id: 'gcp_response_time',
        service: 'gcpKoreanNLP',
        metric: 'responseTime',
        threshold: 3000,
        operator: 'gt',
        severity: 'warning',
        enabled: true,
      },
      // ì„±ê³µë¥  ì•Œë¦¼
      {
        id: 'vercel_success_rate',
        service: 'vercelEdge',
        metric: 'successRate',
        threshold: 0.95,
        operator: 'lt',
        severity: 'critical',
        enabled: true,
      },
      {
        id: 'supabase_success_rate',
        service: 'supabaseRAG',
        metric: 'successRate',
        threshold: 0.9,
        operator: 'lt',
        severity: 'warning',
        enabled: true,
      },
      // ì—ëŸ¬ ìˆ˜ ì•Œë¦¼
      {
        id: 'error_count_critical',
        service: 'vercelEdge',
        metric: 'errorCount',
        threshold: 10,
        operator: 'gt',
        severity: 'critical',
        enabled: true,
      },
    ];
  }

  /**
   * ğŸ”„ ëª¨ë‹ˆí„°ë§ ì‹œì‘
   */
  private startMonitoring(): void {
    // 30ì´ˆë§ˆë‹¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    this.monitoringInterval = setInterval(() => {
      this.collectMetrics();
    }, 30000);

    console.log('ğŸŒ ë¶„ì‚° ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘');
  }

  /**
   * ğŸ“Š ë©”íŠ¸ë¦­ ìˆ˜ì§‘
   */
  private async collectMetrics(): Promise<void> {
    const timestamp = Date.now();

    try {
      // ë³‘ë ¬ë¡œ ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
      const [
        vercelMetrics,
        supabaseMetrics,
        gcpNlpMetrics,
        gcpMlMetrics,
        cacheMetrics,
        latencyMetrics,
      ] = await Promise.allSettled([
        this.checkVercelEdgeHealth(),
        this.checkSupabaseRAGHealth(),
        this.checkGCPKoreanNLPHealth(),
        this.checkGCPMLAnalyticsHealth(),
        this.checkMemoryCacheHealth(),
        this.measureInterServiceLatency(),
      ]);

      // ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
      if (vercelMetrics.status === 'fulfilled') {
        this.metrics.vercelEdge = vercelMetrics.value;
      }
      if (supabaseMetrics.status === 'fulfilled') {
        this.metrics.supabaseRAG = supabaseMetrics.value;
      }
      if (gcpNlpMetrics.status === 'fulfilled') {
        this.metrics.gcpKoreanNLP = gcpNlpMetrics.value;
      }
      if (gcpMlMetrics.status === 'fulfilled') {
        this.metrics.gcpMLAnalytics = gcpMlMetrics.value;
      }
      if (cacheMetrics.status === 'fulfilled') {
        this.metrics.memoryCache = cacheMetrics.value;
      }
      if (latencyMetrics.status === 'fulfilled') {
        this.metrics.interServiceLatency = latencyMetrics.value;
      }

      // ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì €ì¥ (ìµœê·¼ 100ê°œ)
      this.metricsHistory.push({ timestamp, metrics: { ...this.metrics } });
      if (this.metricsHistory.length > 100) {
        this.metricsHistory.shift();
      }

      // ì•Œë¦¼ ê·œì¹™ í™•ì¸
      this.checkAlertRules();
    } catch (error) {
      console.error('ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨:', error);
    }
  }

  /**
   * âš¡ Vercel Edge ìƒíƒœ í™•ì¸
   */
  private async checkVercelEdgeHealth(): Promise<ServiceMetrics> {
    const startTime = Date.now();

    try {
      // Edge Runtime í—¬ìŠ¤ì²´í¬ (ì‹¤ì œë¡œëŠ” /api/health ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ)
      const response = await fetch('/api/health', {
        method: 'HEAD',
        headers: { 'x-health-check': 'true' },
      });

      const responseTime = Date.now() - startTime;
      const isHealthy = response.ok;

      return {
        name: 'Vercel Edge Runtime',
        status: isHealthy ? 'healthy' : 'unhealthy',
        responseTime,
        successRate: isHealthy ? 1.0 : 0.0,
        lastCheck: new Date().toISOString(),
        errorCount: isHealthy ? 0 : 1,
        throughput: this.calculateThroughput('vercelEdge'),
      };
    } catch (error) {
      return {
        name: 'Vercel Edge Runtime',
        status: 'unhealthy',
        responseTime: Date.now() - startTime,
        successRate: 0.0,
        lastCheck: new Date().toISOString(),
        errorCount: 1,
        throughput: 0,
      };
    }
  }

  /**
   * ğŸ§  Supabase RAG ìƒíƒœ í™•ì¸
   */
  private async checkSupabaseRAGHealth(): Promise<ServiceMetrics> {
    const startTime = Date.now();

    try {
      // RAG ì—”ì§„ í—¬ìŠ¤ì²´í¬ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” RAG ì—”ì§„ healthCheck í˜¸ì¶œ)
      const testQuery = 'í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬';

      // ì‹œë®¬ë ˆì´ì…˜ëœ RAG ê²€ìƒ‰
      const isHealthy = Math.random() > 0.1; // 90% ì„±ê³µë¥ 
      const responseTime = Date.now() - startTime + Math.random() * 200;

      return {
        name: 'Supabase RAG Engine',
        status: responseTime < 1000 ? 'healthy' : 'degraded',
        responseTime,
        successRate: isHealthy ? 0.95 : 0.8,
        lastCheck: new Date().toISOString(),
        errorCount: isHealthy ? 0 : 1,
        throughput: this.calculateThroughput('supabaseRAG'),
      };
    } catch (error) {
      return {
        name: 'Supabase RAG Engine',
        status: 'unhealthy',
        responseTime: Date.now() - startTime,
        successRate: 0.0,
        lastCheck: new Date().toISOString(),
        errorCount: 1,
        throughput: 0,
      };
    }
  }

  /**
   * ğŸ‡°ğŸ‡· GCP Korean NLP ìƒíƒœ í™•ì¸
   */
  private async checkGCPKoreanNLPHealth(): Promise<ServiceMetrics> {
    const startTime = Date.now();

    try {
      // GCP Function í—¬ìŠ¤ì²´í¬ (ì‹¤ì œë¡œëŠ” Function URL í˜¸ì¶œ)
      const healthCheckPayload = {
        query: 'í—¬ìŠ¤ì²´í¬',
        type: 'health_check',
      };

      // ì‹œë®¬ë ˆì´ì…˜ëœ ì‘ë‹µ
      const responseTime = Math.random() * 2000 + 500; // 0.5-2.5ì´ˆ
      const isHealthy = Math.random() > 0.05; // 95% ì„±ê³µë¥ 

      return {
        name: 'GCP Korean NLP',
        status: responseTime < 3000 && isHealthy ? 'healthy' : 'degraded',
        responseTime,
        successRate: isHealthy ? 0.95 : 0.7,
        lastCheck: new Date().toISOString(),
        errorCount: isHealthy ? 0 : 1,
        throughput: this.calculateThroughput('gcpKoreanNLP'),
      };
    } catch (error) {
      return {
        name: 'GCP Korean NLP',
        status: 'unhealthy',
        responseTime: Date.now() - startTime,
        successRate: 0.0,
        lastCheck: new Date().toISOString(),
        errorCount: 1,
        throughput: 0,
      };
    }
  }

  /**
   * ğŸ“Š GCP ML Analytics ìƒíƒœ í™•ì¸
   */
  private async checkGCPMLAnalyticsHealth(): Promise<ServiceMetrics> {
    const startTime = Date.now();

    try {
      // ML Analytics Function í—¬ìŠ¤ì²´í¬
      const responseTime = Math.random() * 1500 + 300; // 0.3-1.8ì´ˆ
      const isHealthy = Math.random() > 0.08; // 92% ì„±ê³µë¥ 

      return {
        name: 'GCP ML Analytics',
        status: isHealthy ? 'healthy' : 'degraded',
        responseTime,
        successRate: isHealthy ? 0.92 : 0.75,
        lastCheck: new Date().toISOString(),
        errorCount: isHealthy ? 0 : 1,
        throughput: this.calculateThroughput('gcpMLAnalytics'),
      };
    } catch (error) {
      return {
        name: 'GCP ML Analytics',
        status: 'unhealthy',
        responseTime: Date.now() - startTime,
        successRate: 0.0,
        lastCheck: new Date().toISOString(),
        errorCount: 1,
        throughput: 0,
      };
    }
  }

  /**
   * ğŸ’¾ Memory Cache ìƒíƒœ í™•ì¸
   */
  private async checkMemoryCacheHealth(): Promise<ServiceMetrics> {
    try {
      // ë©”ëª¨ë¦¬ ìºì‹œ í†µê³„ (ì‹¤ì œë¡œëŠ” ìºì‹œ í—¬í¼ì—ì„œ ê°€ì ¸ì˜´)
      const cacheStats = {
        hitRate: Math.random() * 0.4 + 0.6, // 60-100%
        size: Math.floor(Math.random() * 500) + 100, // 100-600ê°œ
        memoryUsage: Math.random() * 50 + 20, // 20-70MB
      };

      const responseTime = Math.random() * 5 + 1; // 1-6ms

      return {
        name: 'Memory Cache System',
        status: cacheStats.hitRate > 0.7 ? 'healthy' : 'degraded',
        responseTime,
        successRate: 0.99,
        lastCheck: new Date().toISOString(),
        errorCount: 0,
        throughput: cacheStats.size * 2, // ìºì‹œ ì•„ì´í…œ ìˆ˜ * 2
      };
    } catch (error) {
      return {
        name: 'Memory Cache System',
        status: 'unhealthy',
        responseTime: 0,
        successRate: 0.0,
        lastCheck: new Date().toISOString(),
        errorCount: 1,
        throughput: 0,
      };
    }
  }

  /**
   * ğŸ“¡ ì„œë¹„ìŠ¤ ê°„ ì§€ì—° ì‹œê°„ ì¸¡ì •
   */
  private async measureInterServiceLatency(): Promise<
    DistributedMetrics['interServiceLatency']
  > {
    try {
      // ì‹¤ì œë¡œëŠ” ê° ì„œë¹„ìŠ¤ ê°„ ping í…ŒìŠ¤íŠ¸
      return {
        vercelToSupabase: Math.random() * 50 + 20, // 20-70ms
        vercelToGCP: Math.random() * 100 + 50, // 50-150ms
        supabaseToCache: Math.random() * 10 + 1, // 1-11ms
      };
    } catch (error) {
      return {
        vercelToSupabase: 999,
        vercelToGCP: 999,
        supabaseToCache: 999,
      };
    }
  }

  /**
   * ğŸ“ˆ ì²˜ë¦¬ëŸ‰ ê³„ì‚°
   */
  private calculateThroughput(serviceName: string): number {
    // ì‹¤ì œë¡œëŠ” ì§€ë‚œ 1ë¶„ê°„ì˜ ìš”ì²­ ìˆ˜ë¥¼ ê³„ì‚°
    // ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    const baseRate = {
      vercelEdge: 120, // ë¶„ë‹¹ 120ê°œ
      supabaseRAG: 80, // ë¶„ë‹¹ 80ê°œ
      gcpKoreanNLP: 40, // ë¶„ë‹¹ 40ê°œ
      gcpMLAnalytics: 30, // ë¶„ë‹¹ 30ê°œ
      memoryCache: 200, // ë¶„ë‹¹ 200ê°œ (ìºì‹œ ì•¡ì„¸ìŠ¤)
    };

    return Math.floor(
      (baseRate[serviceName as keyof typeof baseRate] || 50) *
        (0.8 + Math.random() * 0.4)
    );
  }

  /**
   * ğŸš¨ ì•Œë¦¼ ê·œì¹™ í™•ì¸
   */
  private checkAlertRules(): void {
    const currentTime = Date.now();

    for (const rule of this.alertRules) {
      if (!rule.enabled) continue;

      const service = this.metrics[
        rule.service as keyof DistributedMetrics
      ] as ServiceMetrics;
      if (!service || typeof service !== 'object' || !('name' in service))
        continue;

      const metricValue = service[rule.metric];
      let shouldAlert = false;

      switch (rule.operator) {
        case 'gt':
          shouldAlert = metricValue > rule.threshold;
          break;
        case 'lt':
          shouldAlert = metricValue < rule.threshold;
          break;
        case 'eq':
          shouldAlert = metricValue === rule.threshold;
          break;
      }

      if (shouldAlert) {
        // ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (ìµœê·¼ 5ë¶„ ë‚´ ë™ì¼ ì•Œë¦¼ ì²´í¬)
        const recentAlert = this.alerts.find(
          (alert) =>
            alert.ruleId === rule.id &&
            currentTime - alert.timestamp < 5 * 60 * 1000
        );

        if (!recentAlert) {
          const alert: Alert = {
            id: `alert_${currentTime}_${Math.random().toString(36).substr(2, 9)}`,
            ruleId: rule.id,
            service: service.name,
            message: `${service.name}: ${rule.metric} ${rule.operator} ${rule.threshold} (í˜„ì¬: ${metricValue})`,
            severity: rule.severity,
            timestamp: currentTime,
            acknowledged: false,
          };

          this.alerts.push(alert);
          console.warn(`ğŸš¨ ì•Œë¦¼ ë°œìƒ: ${alert.message}`);
        }
      }
    }
  }

  /**
   * ğŸ“Š ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ
   */
  getDashboardData() {
    const currentMetrics = this.metrics;
    const recentHistory = this.metricsHistory.slice(-20); // ìµœê·¼ 20ê°œ
    const activeAlerts = this.alerts.filter((alert) => !alert.acknowledged);

    // ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ê³„ì‚°
    const serviceStatuses = [
      currentMetrics.vercelEdge,
      currentMetrics.supabaseRAG,
      currentMetrics.gcpKoreanNLP,
      currentMetrics.gcpMLAnalytics,
      currentMetrics.memoryCache,
    ];

    const healthyServices = serviceStatuses.filter(
      (s) => s.status === 'healthy'
    ).length;
    const totalServices = serviceStatuses.length;

    let overallStatus: 'healthy' | 'degraded' | 'unhealthy';
    if (healthyServices === totalServices) {
      overallStatus = 'healthy';
    } else if (healthyServices >= totalServices * 0.6) {
      overallStatus = 'degraded';
    } else {
      overallStatus = 'unhealthy';
    }

    return {
      // í˜„ì¬ ìƒíƒœ
      current: {
        overallStatus,
        healthyServices,
        totalServices,
        services: currentMetrics,
        interServiceLatency: currentMetrics.interServiceLatency,
      },

      // íˆìŠ¤í† ë¦¬ ì°¨íŠ¸ ë°ì´í„°
      history: recentHistory.map((h) => ({
        timestamp: h.timestamp,
        vercelResponseTime: h.metrics.vercelEdge.responseTime,
        supabaseResponseTime: h.metrics.supabaseRAG.responseTime,
        gcpKoreanNLPResponseTime: h.metrics.gcpKoreanNLP.responseTime,
        overallSuccessRate:
          serviceStatuses.reduce((sum, s) => sum + s.successRate, 0) /
          serviceStatuses.length,
      })),

      // í™œì„± ì•Œë¦¼
      alerts: {
        active: activeAlerts.length,
        critical: activeAlerts.filter((a) => a.severity === 'critical').length,
        warning: activeAlerts.filter((a) => a.severity === 'warning').length,
        list: activeAlerts.slice(0, 10), // ìµœì‹  10ê°œ
      },

      // ì„±ëŠ¥ ìš”ì•½
      performance: {
        averageResponseTime:
          serviceStatuses.reduce((sum, s) => sum + s.responseTime, 0) /
          serviceStatuses.length,
        totalThroughput: serviceStatuses.reduce(
          (sum, s) => sum + s.throughput,
          0
        ),
        cacheHitRate: currentMetrics.memoryCache.successRate,
        systemLoad: this.calculateSystemLoad(),
      },

      // SLA ì¤€ìˆ˜ìœ¨
      sla: {
        uptime: healthyServices / totalServices,
        responseTime:
          serviceStatuses.filter((s) => s.responseTime < 1000).length /
          totalServices,
        errorRate:
          1 -
          serviceStatuses.reduce((sum, s) => sum + s.successRate, 0) /
            serviceStatuses.length,
      },
    };
  }

  /**
   * ğŸ“Š ì‹œìŠ¤í…œ ë¶€í•˜ ê³„ì‚°
   */
  private calculateSystemLoad(): number {
    const services = [
      this.metrics.vercelEdge,
      this.metrics.supabaseRAG,
      this.metrics.gcpKoreanNLP,
      this.metrics.gcpMLAnalytics,
      this.metrics.memoryCache,
    ];

    // ì‘ë‹µ ì‹œê°„ ê¸°ë°˜ ë¶€í•˜ ê³„ì‚°
    const avgResponseTime =
      services.reduce((sum, s) => sum + s.responseTime, 0) / services.length;
    const errorRate =
      1 - services.reduce((sum, s) => sum + s.successRate, 0) / services.length;

    // 0-1 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™” (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    const timeLoad = Math.min(avgResponseTime / 2000, 1); // 2ì´ˆë¥¼ 100%ë¡œ
    const errorLoad = errorRate; // ì´ë¯¸ 0-1 ìŠ¤ì¼€ì¼

    return Math.min((timeLoad + errorLoad) / 2, 1);
  }

  /**
   * âœ… ì•Œë¦¼ í™•ì¸ ì²˜ë¦¬
   */
  acknowledgeAlert(alertId: string): boolean {
    const alert = this.alerts.find((a) => a.id === alertId);
    if (alert) {
      alert.acknowledged = true;
      console.log(`âœ… ì•Œë¦¼ í™•ì¸: ${alert.message}`);
      return true;
    }
    return false;
  }

  /**
   * ğŸ”§ ì•Œë¦¼ ê·œì¹™ ì¶”ê°€
   */
  addAlertRule(rule: Omit<AlertRule, 'id'>): string {
    const id = `rule_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    this.alertRules.push({ ...rule, id });
    return id;
  }

  /**
   * ğŸ¥ ì „ì²´ ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬
   */
  async performHealthCheck(): Promise<{
    status: 'healthy' | 'degraded' | 'unhealthy';
    services: Record<string, ServiceMetrics>;
    summary: string;
  }> {
    await this.collectMetrics();

    const services = {
      vercelEdge: this.metrics.vercelEdge,
      supabaseRAG: this.metrics.supabaseRAG,
      gcpKoreanNLP: this.metrics.gcpKoreanNLP,
      gcpMLAnalytics: this.metrics.gcpMLAnalytics,
      memoryCache: this.metrics.memoryCache,
    };

    const healthyCount = Object.values(services).filter(
      (s) => s.status === 'healthy'
    ).length;
    const totalCount = Object.values(services).length;

    let status: 'healthy' | 'degraded' | 'unhealthy';
    let summary: string;

    if (healthyCount === totalCount) {
      status = 'healthy';
      summary = 'ëª¨ë“  ë¶„ì‚° AI ì„œë¹„ìŠ¤ê°€ ì •ìƒ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤.';
    } else if (healthyCount >= totalCount * 0.6) {
      status = 'degraded';
      summary = `${totalCount}ê°œ ì„œë¹„ìŠ¤ ì¤‘ ${healthyCount}ê°œê°€ ì •ìƒì…ë‹ˆë‹¤. ì¼ë¶€ ì„œë¹„ìŠ¤ ì„±ëŠ¥ ì €í•˜ ê°ì§€.`;
    } else {
      status = 'unhealthy';
      summary = `ì‹¬ê°í•œ ì„œë¹„ìŠ¤ ì¥ì•  ê°ì§€. ${totalCount}ê°œ ì„œë¹„ìŠ¤ ì¤‘ ${totalCount - healthyCount}ê°œ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.`;
    }

    return { status, services, summary };
  }

  /**
   * ğŸ›‘ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
   */
  stopMonitoring(): void {
    if (this.monitoringInterval) {
      clearInterval(this.monitoringInterval);
      this.monitoringInterval = null;
      console.log('ğŸ›‘ ë¶„ì‚° ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€');
    }
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let dashboardInstance: DistributedMonitoringDashboard | null = null;

export function getDistributedMonitoringDashboard(): DistributedMonitoringDashboard {
  if (!dashboardInstance) {
    dashboardInstance = new DistributedMonitoringDashboard();
  }
  return dashboardInstance;
}
