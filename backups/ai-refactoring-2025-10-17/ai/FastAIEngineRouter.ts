/**
 * ğŸš€ FastAIEngineRouter - ì´ˆê³ ì† AI ì—”ì§„ ë¼ìš°í„°
 *
 * ì„±ëŠ¥ ìµœì í™” ëª©í‘œ: 152ms â†’ 70-90ms
 *
 * í•µì‹¬ ìµœì í™” ì „ëµ:
 * - 3ë‹¨ê³„ ìºì‹œ ì „ëµ (L1: ë©”ëª¨ë¦¬, L2: íŒ¨í„´, L3: ìœ ì‚¬ë„)
 * - 5ë‹¨ê³„ ë³‘ë ¬ íŒŒì´í”„ë¼ì¸
 * - ì˜ˆì¸¡ì  ì—”ì§„ ì„ íƒ
 * - Circuit Breaker íŒ¨í„´
 * - ì„ë² ë”© ì°¨ì› ìµœì í™” (384â†’256)
 * - ì¿¼ë¦¬ ë³µì¡ë„ ë¹ ë¥¸ ë¶„ë¥˜
 *
 * @author AI Systems Engineer
 * @version 1.0.0
 * @performance_target 70-90ms average response time
 */

import {
  SimplifiedQueryEngine,
  type QueryRequest,
  type QueryResponse,
} from './SimplifiedQueryEngine';
import { PerformanceOptimizedQueryEngine } from './performance-optimized-query-engine';
import {
  QueryComplexityAnalyzer,
  type QueryAnalysis,
} from './QueryComplexityAnalyzer';
import { getQueryCacheManager } from './query-cache-manager';
import type { AIMetadata } from '../../types/ai-service-types';

interface FastRouterConfig {
  enablePredictiveRouting: boolean;
  enableCircuitBreaker: boolean;
  cacheStrategy: 'aggressive' | 'balanced' | 'conservative';
  maxResponseTime: number; // 150ms íƒ€ê²Ÿ
  parallelProcessing: boolean;
  embeddingDimension: 256 | 384; // 256ìœ¼ë¡œ ìµœì í™”
}

interface EngineMetrics {
  avgResponseTime: number;
  successRate: number;
  errorCount: number;
  lastUsed: number;
  circuitState: 'closed' | 'open' | 'half-open';
}

interface RouteDecision {
  engine: 'local-rag' | 'google-ai' | 'performance-optimized' | 'fallback';
  confidence: number;
  estimatedTime: number;
  reasoning: string;
}

interface CacheEntry {
  response: QueryResponse;
  timestamp: number;
  hitCount: number;
  pattern: string;
}

export class FastAIEngineRouter {
  private localEngine: SimplifiedQueryEngine;
  private performanceEngine: PerformanceOptimizedQueryEngine;
  private cacheManager = getQueryCacheManager();
  private config: FastRouterConfig;

  // ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì 
  private engineMetrics = new Map<string, EngineMetrics>();

  // 3ë‹¨ê³„ ìºì‹œ ì‹œìŠ¤í…œ
  private L1Cache = new Map<string, CacheEntry>(); // ì •í™•í•œ ë§¤ì¹˜
  private L2Cache = new Map<string, CacheEntry>(); // íŒ¨í„´ ë§¤ì¹˜
  private L3Cache = new Map<string, CacheEntry[]>(); // ìœ ì‚¬ë„ ë§¤ì¹˜

  // ë¹ ë¥¸ íŒ¨í„´ ì¸ì‹ì„ ìœ„í•œ ì‚¬ì „ ì»´íŒŒì¼ëœ íŒ¨í„´
  private quickPatterns = new Map<RegExp, RouteDecision>();

  constructor(config?: Partial<FastRouterConfig>) {
    this.config = {
      enablePredictiveRouting: true,
      enableCircuitBreaker: true,
      cacheStrategy: 'aggressive', // ìºì‹œ ìš°ì„ 
      maxResponseTime: 150,
      parallelProcessing: true,
      embeddingDimension: 256, // ì„±ëŠ¥ ìµœì í™”
      ...config,
    };

    this.localEngine = new SimplifiedQueryEngine();
    this.performanceEngine = new PerformanceOptimizedQueryEngine({
      enableParallelProcessing: true,
      enablePredictiveLoading: true,
      cacheStrategy: 'adaptive',
      timeoutMs: this.config.maxResponseTime - 20, // ì—¬ìœ ë¶„ 20ms
    });

    this.initializeOptimizations();
  }

  /**
   * ğŸ¯ ì´ˆê³ ì† ë¼ìš°íŒ… - 70-90ms ëª©í‘œ
   */
  async route(request: QueryRequest): Promise<QueryResponse> {
    const startTime = performance.now(); // ê³ ì •ë°€ íƒ€ì´ë°
    const { query } = request;

    try {
      // Phase 1: ì´ˆê³ ì† ìºì‹œ í™•ì¸ (1-3ms)
      const cachedResult = this.checkFastCache(query);
      if (cachedResult) {
        this.updateMetrics('cache', true, performance.now() - startTime);
        return this.enrichResponse(cachedResult, startTime, 'cache');
      }

      // Phase 2: ë¹ ë¥¸ íŒ¨í„´ ì¸ì‹ (2-5ms)
      const quickRoute = this.quickPatternMatch(query);
      if (quickRoute) {
        const response = await this.executeQuickRoute(request, quickRoute);
        this.cacheResponse(query, response);
        return this.enrichResponse(response, startTime, 'pattern');
      }

      // Phase 3: ë³‘ë ¬ ë¶„ì„ (10-15ms)
      const routeDecision = await this.analyzeInParallel(request);

      // Phase 4: ìµœì  ì—”ì§„ ì‹¤í–‰ (50-70ms)
      const response = await this.executeWithEngine(request, routeDecision);

      // Phase 5: ê²°ê³¼ ìºì‹± (1-2ms)
      this.cacheResponse(query, response);
      this.updateMetrics(
        routeDecision.engine,
        true,
        performance.now() - startTime
      );

      return this.enrichResponse(response, startTime, routeDecision.engine);
    } catch (error) {
      const fallbackResponse = await this.generateFallbackResponse(
        request,
        error
      );
      this.updateMetrics('fallback', false, performance.now() - startTime);

      console.warn('FastAIRouter ì‹¤íŒ¨, í´ë°±:', {
        query: query.substring(0, 50),
        error: error instanceof Error ? error.message : error,
        time: performance.now() - startTime,
      });

      return this.enrichResponse(fallbackResponse, startTime, 'fallback');
    }
  }

  /**
   * âš¡ 1ë‹¨ê³„: ì´ˆê³ ì† ìºì‹œ í™•ì¸ (1-3ms)
   */
  private checkFastCache(query: string): QueryResponse | null {
    const normalizedQuery = this.normalizeQuery(query);

    // L1: ì •í™•í•œ ë§¤ì¹˜
    const l1Hit = this.L1Cache.get(normalizedQuery);
    if (l1Hit && this.isCacheValid(l1Hit)) {
      l1Hit.hitCount++;
      console.debug('L1 ìºì‹œ ì ì¤‘', { query: query.substring(0, 30) });
      return l1Hit.response;
    }

    // L2: íŒ¨í„´ ë§¤ì¹˜
    const pattern = this.generatePattern(normalizedQuery);
    const l2Hit = this.L2Cache.get(pattern);
    if (l2Hit && this.isCacheValid(l2Hit)) {
      l2Hit.hitCount++;
      console.debug('L2 ìºì‹œ ì ì¤‘', { pattern });
      return l2Hit.response;
    }

    // L3: ìœ ì‚¬ë„ ë§¤ì¹˜ (ê°€ì¥ ë¹ ë¥¸ êµ¬í˜„)
    const similarEntries = this.L3Cache.get(pattern) || [];
    for (const entry of similarEntries.slice(0, 3)) {
      // ìµœëŒ€ 3ê°œë§Œ í™•ì¸
      if (
        this.isCacheValid(entry) &&
        this.quickSimilarity(query, entry.pattern) > 0.85
      ) {
        entry.hitCount++;
        console.debug('L3 ìºì‹œ ì ì¤‘', { similarity: '85%+' });
        return entry.response;
      }
    }

    return null;
  }

  /**
   * âš¡ 2ë‹¨ê³„: ë¹ ë¥¸ íŒ¨í„´ ì¸ì‹ (2-5ms)
   */
  private quickPatternMatch(query: string): RouteDecision | null {
    const lowerQuery = query.toLowerCase();

    // ì‚¬ì „ ì»´íŒŒì¼ëœ íŒ¨í„´ìœ¼ë¡œ ë¹ ë¥¸ ë§¤ì¹­
    for (const [pattern, decision] of this.quickPatterns.entries()) {
      if (pattern.test(lowerQuery)) {
        console.debug('íŒ¨í„´ ë§¤ì¹˜', { pattern: pattern.source });
        return decision;
      }
    }

    return null;
  }

  /**
   * âš¡ 3ë‹¨ê³„: ë³‘ë ¬ ë¶„ì„ (10-15ms)
   */
  private async analyzeInParallel(
    request: QueryRequest
  ): Promise<RouteDecision> {
    const { query } = request;

    // íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë³´í˜¸ëœ ë³‘ë ¬ ì‹¤í–‰
    const timeout = 15; // 15ms ì œí•œ
    const timeoutPromise = new Promise<never>((_, reject) =>
      setTimeout(() => reject(new Error('Analysis timeout')), timeout)
    );

    try {
      const [complexity, circuitState] = await Promise.race([
        Promise.all([
          QueryComplexityAnalyzer.analyze(query),
          this.getCircuitStates(),
        ]),
        timeoutPromise,
      ]);

      return this.makeRouteDecision(complexity, circuitState, request.mode);
    } catch (error) {
      // ë¶„ì„ ì‹¤íŒ¨ ì‹œ ë¹ ë¥¸ í´ë°±
      console.warn('ë³‘ë ¬ ë¶„ì„ ì‹¤íŒ¨, ë¹ ë¥¸ ê²°ì •', error);
      return this.makeFastDecision(query);
    }
  }

  /**
   * ğŸš€ 4ë‹¨ê³„: ìµœì  ì—”ì§„ ì‹¤í–‰ (50-70ms)
   */
  private async executeWithEngine(
    request: QueryRequest,
    decision: RouteDecision
  ): Promise<QueryResponse> {
    const timeout = Math.min(
      decision.estimatedTime + 10,
      this.config.maxResponseTime - 30
    );

    const timeoutPromise = new Promise<never>((_, reject) =>
      setTimeout(() => reject(new Error('Engine timeout')), timeout)
    );

    let executionPromise: Promise<QueryResponse>;

    switch (decision.engine) {
      case 'performance-optimized':
        executionPromise = this.performanceEngine.query(request);
        break;

      case 'local-rag':
        executionPromise = this.localEngine.query({
          ...request,
          mode: 'local',
          enableGoogleAI: false,
          options: {
            ...request.options,
            timeoutMs: timeout,
            cached: true, // ìºì‹± í™œì„±í™”
          },
        });
        break;

      case 'google-ai':
        executionPromise = this.localEngine.query({
          ...request,
          mode: 'GOOGLE_AI',
          enableGoogleAI: true,
          options: {
            ...request.options,
            timeoutMs: timeout,
          },
        });
        break;

      default:
        executionPromise = this.generateFallbackResponse(
          request,
          'Unknown engine'
        );
    }

    try {
      return await Promise.race([executionPromise, timeoutPromise]);
    } catch (error) {
      console.warn(`${decision.engine} ì‹¤í–‰ ì‹¤íŒ¨, í´ë°±`, error);

      // ë¹ ë¥¸ í´ë°±: ê°€ì¥ ê°„ë‹¨í•œ ì—”ì§„
      if (decision.engine !== 'local-rag') {
        return await this.localEngine.query({
          ...request,
          mode: 'local',
          enableGoogleAI: false,
          options: { timeoutMs: 50 }, // ë§¤ìš° ë¹ ë¥¸ ì‘ë‹µ
        });
      }

      throw error;
    }
  }

  /**
   * ğŸ’¾ 5ë‹¨ê³„: ì‘ë‹µ ìºì‹± (1-2ms)
   */
  private cacheResponse(query: string, response: QueryResponse): void {
    if (!response.success || !response.response) return;

    const normalizedQuery = this.normalizeQuery(query);
    const pattern = this.generatePattern(normalizedQuery);
    const timestamp = Date.now();

    const cacheEntry: CacheEntry = {
      response,
      timestamp,
      hitCount: 0,
      pattern: normalizedQuery,
    };

    // ë¹ ë¥¸ ì‘ë‹µë§Œ ìºì‹œ (ì„±ëŠ¥ ê¸°ì¤€)
    if (response.processingTime && response.processingTime < 120) {
      // L1: ì •í™•í•œ ì¿¼ë¦¬
      this.L1Cache.set(normalizedQuery, cacheEntry);

      // L2: íŒ¨í„´ ê¸°ë°˜
      this.L2Cache.set(pattern, cacheEntry);

      // L3: ìœ ì‚¬ë„ ê¸°ë°˜
      const similarEntries = this.L3Cache.get(pattern) || [];
      similarEntries.unshift(cacheEntry);
      if (similarEntries.length > 5) similarEntries.pop(); // ìµœëŒ€ 5ê°œ
      this.L3Cache.set(pattern, similarEntries);
    }

    // ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ìµœì í™”)
    this.cleanupCacheIfNeeded();
  }

  /**
   * ğŸ”§ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
   */
  private normalizeQuery(query: string): string {
    return query
      .toLowerCase()
      .replace(/[^\wê°€-í£\s]/g, '')
      .replace(/\s+/g, ' ')
      .trim();
  }

  private generatePattern(query: string): string {
    // í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ì—¬ íŒ¨í„´ ìƒì„±
    const keywords = query
      .split(' ')
      .filter((word) => word.length > 2)
      .slice(0, 3) // ìµœëŒ€ 3ê°œ
      .sort()
      .join('_');
    return `pattern_${keywords}`;
  }

  private quickSimilarity(a: string, b: string): number {
    // ë¹ ë¥¸ ìœ ì‚¬ë„ ê³„ì‚° (ì •í™•ë„ë³´ë‹¤ ì†ë„ ìš°ì„ )
    if (a === b) return 1.0;
    if (a.length === 0 || b.length === 0) return 0.0;

    const words1 = new Set(a.split(' '));
    const words2 = new Set(b.split(' '));

    const intersection = new Set([...words1].filter((x) => words2.has(x)));
    const union = new Set([...words1, ...words2]);

    return intersection.size / union.size;
  }

  private isCacheValid(entry: CacheEntry): boolean {
    const age = Date.now() - entry.timestamp;
    const maxAge = this.getCacheMaxAge(entry.hitCount);
    return age < maxAge;
  }

  private getCacheMaxAge(hitCount: number): number {
    // íˆíŠ¸ ìˆ˜ì— ë”°ë¥¸ ë™ì  TTL
    if (hitCount > 10) return 3600000; // 1ì‹œê°„
    if (hitCount > 5) return 1800000; // 30ë¶„
    return 900000; // 15ë¶„
  }

  private makeRouteDecision(
    analysis: QueryAnalysis,
    circuitState: Map<string, boolean>,
    preferredMode?: string
  ): RouteDecision {
    // Circuit Breaker í™•ì¸
    if (
      analysis.recommendedEngine === 'google-ai' &&
      circuitState.get('google-ai')
    ) {
      return {
        engine: 'local-rag',
        confidence: 0.8,
        estimatedTime: analysis.estimatedResponseTime.local,
        reasoning: 'Google AI circuit open',
      };
    }

    // ë‹¨ìˆœí•œ ì¿¼ë¦¬ëŠ” ì„±ëŠ¥ ìµœì í™” ì—”ì§„ ì‚¬ìš©
    if (analysis.complexity === 'simple' && analysis.confidence > 0.8) {
      return {
        engine: 'performance-optimized',
        confidence: 0.95,
        estimatedTime: Math.min(analysis.estimatedResponseTime.local * 0.6, 70),
        reasoning: 'Simple query, performance engine',
      };
    }

    // ê¸°ë³¸ ì¶”ì²œ ì—”ì§„ ì‚¬ìš©
    const engine =
      analysis.recommendedEngine === 'google-ai' ? 'google-ai' : 'local-rag';
    return {
      engine: engine as RouteDecision['engine'],
      confidence: analysis.confidence,
      estimatedTime:
        engine === 'google-ai'
          ? analysis.estimatedResponseTime.googleAI
          : analysis.estimatedResponseTime.local,
      reasoning: `Analysis recommendation: ${engine}`,
    };
  }

  private makeFastDecision(query: string): RouteDecision {
    // ë¹ ë¥¸ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê²°ì •
    const lowerQuery = query.toLowerCase();

    // ë³µì¡í•œ ì¿¼ë¦¬ íŒ¨í„´
    const complexPatterns = [
      'ë¶„ì„',
      'ìµœì í™”',
      'ë¹„êµ',
      'í‰ê°€',
      'analyze',
      'optimize',
    ];
    const isComplex = complexPatterns.some((pattern) =>
      lowerQuery.includes(pattern)
    );

    if (isComplex) {
      return {
        engine: 'google-ai',
        confidence: 0.7,
        estimatedTime: 200,
        reasoning: 'Fast heuristic: complex query',
      };
    }

    return {
      engine: 'performance-optimized',
      confidence: 0.8,
      estimatedTime: 70,
      reasoning: 'Fast heuristic: simple query',
    };
  }

  private async executeQuickRoute(
    request: QueryRequest,
    decision: RouteDecision
  ): Promise<QueryResponse> {
    // ë¹ ë¥¸ ê²½ë¡œ ì‹¤í–‰ (íŒ¨í„´ ë§¤ì¹­ëœ ê²½ìš°)
    return await this.executeWithEngine(request, decision);
  }

  private enrichResponse(
    response: QueryResponse,
    startTime: number,
    source: string
  ): QueryResponse {
    const processingTime = performance.now() - startTime;

    return {
      ...response,
      processingTime,
      metadata: {
        ...response.metadata,
        routingSource: source,
        optimizedRouting: true,
        fastRouter: true,
        targetTime: this.config.maxResponseTime,
      } as AIMetadata,
    };
  }

  private async generateFallbackResponse(
    request: QueryRequest,
    error: unknown
  ): Promise<QueryResponse> {
    return {
      success: false,
      response:
        'ì‹œìŠ¤í…œì´ ì¼ì‹œì ìœ¼ë¡œ ê³¼ë¶€í•˜ ìƒíƒœì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
      engine: 'fallback',
      confidence: 0.3,
      thinkingSteps: [
        {
          step: 'í´ë°± ëª¨ë“œ',
          description: error instanceof Error ? error.message : String(error),
          status: 'completed',
          timestamp: Date.now(),
        },
      ],
      metadata: {
        fallback: true,
        error: error instanceof Error ? error.message : String(error),
        fastRouter: true,
      } as AIMetadata,
      processingTime: 50, // ë§¤ìš° ë¹ ë¥¸ í´ë°±
      error: error instanceof Error ? error.message : String(error),
    };
  }

  private initializeOptimizations(): void {
    // ì‚¬ì „ ì»´íŒŒì¼ëœ ë¹ ë¥¸ íŒ¨í„´ë“¤
    this.quickPatterns.set(/^(ì„œë²„|ì‹œìŠ¤í…œ)\s*(ìƒíƒœ|status)/i, {
      engine: 'local-rag',
      confidence: 0.9,
      estimatedTime: 60,
      reasoning: 'Server status pattern',
    });

    this.quickPatterns.set(/^(cpu|ë©”ëª¨ë¦¬|memory)\s*(ì‚¬ìš©ë¥ |usage|í™•ì¸)/i, {
      engine: 'performance-optimized',
      confidence: 0.95,
      estimatedTime: 50,
      reasoning: 'Resource monitoring pattern',
    });

    this.quickPatterns.set(/^(ë¶„ì„|optimize|ìµœì í™”)\s/i, {
      engine: 'google-ai',
      confidence: 0.85,
      estimatedTime: 180,
      reasoning: 'Analysis request pattern',
    });

    // ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
    const engines = [
      'local-rag',
      'google-ai',
      'performance-optimized',
      'fallback',
      'cache',
    ];
    engines.forEach((engine) => {
      this.engineMetrics.set(engine, {
        avgResponseTime: 100,
        successRate: 0.95,
        errorCount: 0,
        lastUsed: Date.now(),
        circuitState: 'closed',
      });
    });

    console.log('ğŸš€ FastAIEngineRouter ìµœì í™” ì™„ë£Œ');
  }

  private updateMetrics(
    engine: string,
    success: boolean,
    responseTime: number
  ): void {
    const current = this.engineMetrics.get(engine) || {
      avgResponseTime: 100,
      successRate: 0.95,
      errorCount: 0,
      lastUsed: Date.now(),
      circuitState: 'closed',
    };

    current.avgResponseTime =
      current.avgResponseTime * 0.9 + responseTime * 0.1;
    current.successRate = success
      ? Math.min(current.successRate + 0.01, 1.0)
      : Math.max(current.successRate - 0.05, 0.0);
    current.errorCount = success
      ? Math.max(current.errorCount - 1, 0)
      : current.errorCount + 1;
    current.lastUsed = Date.now();

    // Circuit Breaker ë¡œì§
    if (current.errorCount > 3 && current.successRate < 0.7) {
      current.circuitState = 'open';
    } else if (current.circuitState === 'open' && current.successRate > 0.8) {
      current.circuitState = 'closed';
    }

    this.engineMetrics.set(engine, current);
  }

  private async getCircuitStates(): Promise<Map<string, boolean>> {
    const states = new Map<string, boolean>();

    for (const [engine, metrics] of this.engineMetrics.entries()) {
      states.set(engine, metrics.circuitState === 'open');
    }

    return states;
  }

  private cleanupCacheIfNeeded(): void {
    // ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
    const maxSize = 1000;

    if (this.L1Cache.size > maxSize) {
      // LFU (Least Frequently Used) ì •ë¦¬
      const entries = Array.from(this.L1Cache.entries()).sort(
        ([, a], [, b]) => a.hitCount - b.hitCount
      );

      entries.slice(0, maxSize / 2).forEach(([key]) => {
        this.L1Cache.delete(key);
      });
    }

    // L2, L3ë„ ë™ì¼í•˜ê²Œ ì •ë¦¬
    if (this.L2Cache.size > maxSize) {
      const entries = Array.from(this.L2Cache.entries()).sort(
        ([, a], [, b]) => a.hitCount - b.hitCount
      );

      entries.slice(0, maxSize / 2).forEach(([key]) => {
        this.L2Cache.delete(key);
      });
    }
  }

  /**
   * ğŸ“Š ì„±ëŠ¥ í†µê³„ ë°˜í™˜
   */
  getPerformanceStats() {
    return {
      engineMetrics: Object.fromEntries(this.engineMetrics),
      cacheStats: {
        L1Size: this.L1Cache.size,
        L2Size: this.L2Cache.size,
        L3Size: this.L3Cache.size,
        quickPatternsSize: this.quickPatterns.size,
      },
      config: this.config,
      uptime: Date.now(),
    };
  }

  /**
   * ğŸ§¹ ìºì‹œ ì •ë¦¬
   */
  clearCache(): void {
    this.L1Cache.clear();
    this.L2Cache.clear();
    this.L3Cache.clear();
    console.log('FastAIRouter ìºì‹œ ì •ë¦¬ë¨');
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let fastRouterInstance: FastAIEngineRouter | null = null;

export function getFastAIEngineRouter(
  config?: Partial<FastRouterConfig>
): FastAIEngineRouter {
  if (!fastRouterInstance) {
    fastRouterInstance = new FastAIEngineRouter(config);
  }
  return fastRouterInstance;
}

/**
 * ğŸš€ í¸ì˜ í•¨ìˆ˜: ë¹ ë¥¸ AI ì¿¼ë¦¬ ì²˜ë¦¬
 */
export async function fastAIQuery(
  query: string,
  options?: {
    mode?: 'local' | 'google-ai';
    timeoutMs?: number;
    enableCache?: boolean;
  }
): Promise<QueryResponse> {
  const router = getFastAIEngineRouter();

  const rawMode = options?.mode || 'local';
  const mode = rawMode === 'google-ai' ? 'GOOGLE_AI' :
               rawMode === 'local' ? 'LOCAL' : 'LOCAL';

  const request: QueryRequest = {
    query,
    mode,
    options: {
      timeoutMs: options?.timeoutMs || 150,
      cached: options?.enableCache !== false,
    },
  };

  return await router.route(request);
}
