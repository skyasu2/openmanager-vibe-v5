#!/usr/bin/env node

/**
 * ğŸš€ Cursor â†” ë°°í¬í™˜ê²½ í†µì‹  ì±„ë„
 * 
 * ì»¤ì„œê°€ ë°°í¬ëœ OpenManager Vibe v5ì™€ ì§ì ‘ í†µì‹ í•˜ì—¬
 * AI ì—”ì§„ ìƒíƒœ, ì„±ëŠ¥ ë©”íŠ¸ë¦­, ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
 * 
 * ì‚¬ìš©ë²•:
 * node scripts/cursor-deployment-communicator.js --action=status
 * node scripts/cursor-deployment-communicator.js --action=performance
 * node scripts/cursor-deployment-communicator.js --action=ai-engines
 */

const https = require('https');
const http = require('http');

class CursorDeploymentCommunicator {
    constructor() {
        // ë°°í¬ í™˜ê²½ ì„¤ì •
        this.deploymentConfig = {
            // Vercel ë°°í¬ URL
            vercel: 'https://openmanager-vibe-v5.vercel.app',
            // Render MCP ì„œë²„ (ë°±ì—…)
            render: 'https://openmanager-vibe-v5.onrender.com',
            // ë¡œì»¬ ê°œë°œ í™˜ê²½ (í…ŒìŠ¤íŠ¸ìš©)
            local: 'http://localhost:3001'
        };

        // í˜„ì¬ í™œì„± í™˜ê²½ ê°ì§€
        this.activeEnvironment = 'vercel';

        // API ì—”ë“œí¬ì¸íŠ¸ ë§¤í•‘
        this.endpoints = {
            // AI ì—”ì§„ ìƒíƒœ
            aiStatus: '/api/ai-chat?action=status',
            aiEngines: '/api/ai/engines/status',

            // ì‹œìŠ¤í…œ ì„±ëŠ¥
            health: '/api/health',
            metrics: '/api/metrics/performance',

            // AI ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            aiContext: '/api/ai/unified/status',
            systemContext: '/api/system/unified/status',

            // ì‹¤ì‹œê°„ ë°ì´í„°
            realtime: '/api/realtime/connect',
            logs: '/api/logs'
        };

        // Google AI API ë¶€í•˜ ë³´í˜¸
        this.rateLimiter = {
            lastRequest: 0,
            minInterval: 2000, // 2ì´ˆ ê°„ê²©
            requestCount: 0,
            maxRequestsPerMinute: 15 // ë¶„ë‹¹ 15íšŒ ì œí•œ
        };
    }

    /**
     * ë°°í¬í™˜ê²½ ì—°ê²° ìƒíƒœ í™•ì¸
     */
    async checkDeploymentHealth() {
        console.log('ğŸ” ë°°í¬í™˜ê²½ ì—°ê²° ìƒíƒœ í™•ì¸ ì¤‘...');

        const environments = ['vercel', 'local', 'render'];
        const results = {};

        for (const env of environments) {
            try {
                const url = this.deploymentConfig[env];
                const response = await this.makeRequest(`${url}/api/health`);

                results[env] = {
                    status: 'online',
                    responseTime: response.responseTime,
                    data: response.data
                };

                console.log(`âœ… ${env.toUpperCase()}: ì˜¨ë¼ì¸ (${response.responseTime}ms)`);

                // ì²« ë²ˆì§¸ ì‘ë‹µí•˜ëŠ” í™˜ê²½ì„ í™œì„± í™˜ê²½ìœ¼ë¡œ ì„¤ì •
                if (!this.activeEnvironment || this.activeEnvironment === 'vercel') {
                    this.activeEnvironment = env;
                }

            } catch (error) {
                results[env] = {
                    status: 'offline',
                    error: error.message
                };
                console.log(`âŒ ${env.toUpperCase()}: ì˜¤í”„ë¼ì¸ (${error.message})`);
            }
        }

        return results;
    }

    /**
     * AI ì—”ì§„ ìƒíƒœ ì¡°íšŒ
     */
    async getAIEngineStatus() {
        console.log('ğŸ¤– AI ì—”ì§„ ìƒíƒœ ì¡°íšŒ ì¤‘...');

        try {
            // Rate limiting ì²´í¬
            await this.checkRateLimit();

            const baseUrl = this.deploymentConfig[this.activeEnvironment];
            const response = await this.makeRequest(`${baseUrl}${this.endpoints.aiStatus}`);

            console.log('ğŸ“Š AI ì—”ì§„ ìƒíƒœ:');
            console.log(JSON.stringify(response.data, null, 2));

            return response.data;

        } catch (error) {
            console.error('âŒ AI ì—”ì§„ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨:', error.message);
            throw error;
        }
    }

    /**
     * ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ
     */
    async getPerformanceMetrics() {
        console.log('ğŸ“ˆ ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì¤‘...');

        try {
            const baseUrl = this.deploymentConfig[this.activeEnvironment];

            // ì—¬ëŸ¬ ë©”íŠ¸ë¦­ì„ ë³‘ë ¬ë¡œ ì¡°íšŒ
            const [health, metrics] = await Promise.all([
                this.makeRequest(`${baseUrl}${this.endpoints.health}`),
                this.makeRequest(`${baseUrl}${this.endpoints.metrics}`).catch(() => ({ data: null }))
            ]);

            const performanceData = {
                health: health.data,
                metrics: metrics.data,
                responseTime: health.responseTime,
                timestamp: new Date().toISOString()
            };

            console.log('ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­:');
            console.log(JSON.stringify(performanceData, null, 2));

            return performanceData;

        } catch (error) {
            console.error('âŒ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨:', error.message);
            throw error;
        }
    }

    /**
     * AI ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¡°íšŒ
     */
    async getAIContextInfo() {
        console.log('ğŸ§  AI ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¡°íšŒ ì¤‘...');

        try {
            await this.checkRateLimit();

            const baseUrl = this.deploymentConfig[this.activeEnvironment];

            // AI ì»¨í…ìŠ¤íŠ¸ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
            const contextData = {};

            // ê¸°ë³¸ AI ìƒíƒœ
            try {
                const aiStatus = await this.makeRequest(`${baseUrl}${this.endpoints.aiStatus}`);
                contextData.aiStatus = aiStatus.data;
            } catch (e) {
                contextData.aiStatus = { error: e.message };
            }

            // ì‹œìŠ¤í…œ í†µí•© ìƒíƒœ
            try {
                const systemStatus = await this.makeRequest(`${baseUrl}${this.endpoints.systemContext}`);
                contextData.systemStatus = systemStatus.data;
            } catch (e) {
                contextData.systemStatus = { error: e.message };
            }

            console.log('ğŸ§  AI ì»¨í…ìŠ¤íŠ¸ ì •ë³´:');
            console.log(JSON.stringify(contextData, null, 2));

            return contextData;

        } catch (error) {
            console.error('âŒ AI ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨:', error.message);
            throw error;
        }
    }

    /**
     * ë°°í¬í™˜ê²½ AIì™€ ëŒ€í™”
     */
    async chatWithDeployedAI(question, context = {}) {
        console.log(`ğŸ’¬ ë°°í¬í™˜ê²½ AIì™€ ëŒ€í™”: "${question}"`);

        try {
            await this.checkRateLimit();

            const baseUrl = this.deploymentConfig[this.activeEnvironment];
            const payload = {
                message: question,
                context: {
                    source: 'cursor-communicator',
                    timestamp: new Date().toISOString(),
                    ...context
                }
            };

            const response = await this.makeRequest(
                `${baseUrl}/api/ai-chat`,
                'POST',
                payload
            );

            console.log('ğŸ¤– AI ì‘ë‹µ:');
            console.log(response.data.response || response.data);

            return response.data;

        } catch (error) {
            console.error('âŒ AI ëŒ€í™” ì‹¤íŒ¨:', error.message);
            throw error;
        }
    }

    /**
     * Rate Limiting ì²´í¬ (Google AI API ë³´í˜¸)
     */
    async checkRateLimit() {
        const now = Date.now();
        const timeSinceLastRequest = now - this.rateLimiter.lastRequest;

        // ìµœì†Œ ê°„ê²© ì²´í¬
        if (timeSinceLastRequest < this.rateLimiter.minInterval) {
            const waitTime = this.rateLimiter.minInterval - timeSinceLastRequest;
            console.log(`â³ Rate limit ë³´í˜¸: ${waitTime}ms ëŒ€ê¸° ì¤‘...`);
            await new Promise(resolve => setTimeout(resolve, waitTime));
        }

        // ë¶„ë‹¹ ìš”ì²­ ìˆ˜ ì²´í¬
        this.rateLimiter.requestCount++;
        if (this.rateLimiter.requestCount > this.rateLimiter.maxRequestsPerMinute) {
            console.log('âš ï¸ ë¶„ë‹¹ ìš”ì²­ í•œë„ ì´ˆê³¼, 1ë¶„ ëŒ€ê¸°...');
            await new Promise(resolve => setTimeout(resolve, 60000));
            this.rateLimiter.requestCount = 0;
        }

        this.rateLimiter.lastRequest = Date.now();
    }

    /**
     * HTTP ìš”ì²­ í—¬í¼
     */
    async makeRequest(url, method = 'GET', data = null) {
        return new Promise((resolve, reject) => {
            const startTime = Date.now();
            const urlObj = new URL(url);
            const isHttps = urlObj.protocol === 'https:';
            const client = isHttps ? https : http;

            const options = {
                hostname: urlObj.hostname,
                port: urlObj.port || (isHttps ? 443 : 80),
                path: urlObj.pathname + urlObj.search,
                method: method,
                headers: {
                    'Content-Type': 'application/json',
                    'User-Agent': 'Cursor-Deployment-Communicator/1.0'
                }
            };

            if (data && method !== 'GET') {
                const jsonData = JSON.stringify(data);
                options.headers['Content-Length'] = Buffer.byteLength(jsonData);
            }

            const req = client.request(options, (res) => {
                let responseData = '';

                res.on('data', (chunk) => {
                    responseData += chunk;
                });

                res.on('end', () => {
                    const responseTime = Date.now() - startTime;

                    try {
                        const parsedData = JSON.parse(responseData);
                        resolve({
                            data: parsedData,
                            statusCode: res.statusCode,
                            responseTime: responseTime
                        });
                    } catch (e) {
                        resolve({
                            data: responseData,
                            statusCode: res.statusCode,
                            responseTime: responseTime
                        });
                    }
                });
            });

            req.on('error', (error) => {
                reject(new Error(`Request failed: ${error.message}`));
            });

            if (data && method !== 'GET') {
                req.write(JSON.stringify(data));
            }

            req.end();
        });
    }

    /**
     * ì¢…í•© ì‹œìŠ¤í…œ ë¶„ì„
     */
    async performComprehensiveAnalysis() {
        console.log('ğŸ” ì¢…í•© ì‹œìŠ¤í…œ ë¶„ì„ ì‹œì‘...');

        try {
            // 1. ë°°í¬í™˜ê²½ ìƒíƒœ í™•ì¸
            const healthCheck = await this.checkDeploymentHealth();

            // 2. AI ì—”ì§„ ìƒíƒœ ì¡°íšŒ
            const aiStatus = await this.getAIEngineStatus();

            // 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ
            const performance = await this.getPerformanceMetrics();

            // 4. AI ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¡°íšŒ
            const contextInfo = await this.getAIContextInfo();

            // 5. ì¢…í•© ë¶„ì„ ê²°ê³¼
            const analysis = {
                timestamp: new Date().toISOString(),
                environment: this.activeEnvironment,
                healthCheck,
                aiStatus,
                performance,
                contextInfo,
                summary: {
                    overallStatus: this.calculateOverallStatus(healthCheck, aiStatus, performance),
                    recommendations: this.generateRecommendations(aiStatus, performance, contextInfo)
                }
            };

            console.log('ğŸ“‹ ì¢…í•© ë¶„ì„ ì™„ë£Œ:');
            console.log(JSON.stringify(analysis.summary, null, 2));

            return analysis;

        } catch (error) {
            console.error('âŒ ì¢…í•© ë¶„ì„ ì‹¤íŒ¨:', error.message);
            throw error;
        }
    }

    /**
     * ì „ì²´ ìƒíƒœ ê³„ì‚°
     */
    calculateOverallStatus(healthCheck, aiStatus, performance) {
        const onlineEnvironments = Object.values(healthCheck).filter(env => env.status === 'online').length;
        const aiHealthy = aiStatus && !aiStatus.error;
        const performanceGood = performance && performance.responseTime < 5000;

        if (onlineEnvironments > 0 && aiHealthy && performanceGood) {
            return 'healthy';
        } else if (onlineEnvironments > 0) {
            return 'degraded';
        } else {
            return 'critical';
        }
    }

    /**
     * ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±
     */
    generateRecommendations(aiStatus, performance, contextInfo) {
        const recommendations = [];

        if (performance && performance.responseTime > 3000) {
            recommendations.push('API ì‘ë‹µì‹œê°„ ìµœì í™” í•„ìš” (í˜„ì¬: ' + performance.responseTime + 'ms)');
        }

        if (aiStatus && aiStatus.error) {
            recommendations.push('AI ì—”ì§„ ì—°ê²° ë¬¸ì œ í•´ê²° í•„ìš”');
        }

        if (contextInfo && contextInfo.systemStatus && contextInfo.systemStatus.error) {
            recommendations.push('ì‹œìŠ¤í…œ í†µí•© ìƒíƒœ ì ê²€ í•„ìš”');
        }

        if (recommendations.length === 0) {
            recommendations.push('ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤');
        }

        return recommendations;
    }
}

// CLI ì‹¤í–‰
async function main() {
    const args = process.argv.slice(2);
    const action = args.find(arg => arg.startsWith('--action='))?.split('=')[1] || 'comprehensive';

    const communicator = new CursorDeploymentCommunicator();

    try {
        switch (action) {
            case 'status':
                await communicator.checkDeploymentHealth();
                break;

            case 'ai-engines':
                await communicator.getAIEngineStatus();
                break;

            case 'performance':
                await communicator.getPerformanceMetrics();
                break;

            case 'context':
                await communicator.getAIContextInfo();
                break;

            case 'chat':
                const question = args.find(arg => arg.startsWith('--question='))?.split('=')[1] || 'ì‹œìŠ¤í…œ ìƒíƒœ ì–´ë•Œ?';
                await communicator.chatWithDeployedAI(question);
                break;

            case 'comprehensive':
            default:
                await communicator.performComprehensiveAnalysis();
                break;
        }

    } catch (error) {
        console.error('âŒ ì‹¤í–‰ ì‹¤íŒ¨:', error.message);
        process.exit(1);
    }
}

// ëª¨ë“ˆë¡œ ì‚¬ìš©í•  ë•Œì™€ ì§ì ‘ ì‹¤í–‰í•  ë•Œ êµ¬ë¶„
if (require.main === module) {
    main();
}

module.exports = CursorDeploymentCommunicator; 