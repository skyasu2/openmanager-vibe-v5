#!/usr/bin/env node

/**
 * ğŸ¯ 24ì‹œê°„ í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë‚˜ë¦¬ì˜¤ ë©”íŠ¸ë¦­ìŠ¤ ìƒì„±ê¸°
 * 
 * ê° ì‹œê°„ëŒ€ë³„ë¡œ 8ê°œ ì„œë²„ì˜ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 */

const fs = require('fs');
const path = require('path');

// ê¸°ë³¸ ì„œë²„ ë©”íƒ€ë°ì´í„° ë¡œë“œ
const serverMetadataPath = path.join(__dirname, '../public/server-scenarios/servers-metadata.json');
const serverMetadata = JSON.parse(fs.readFileSync(serverMetadataPath, 'utf8'));

// ì¶œë ¥ ë””ë ‰í† ë¦¬
const outputDir = path.join(__dirname, '../public/server-scenarios/hourly-metrics');

// ğŸ­ 24ì‹œê°„ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜
const hourlyScenarios = {
  // ğŸŒƒ ìƒˆë²½ (00:00-06:00)
  0: { scenario: "ì •ìƒ ìš´ì˜", incidents: [] },
  1: { scenario: "ì •ìƒ ìš´ì˜", incidents: [] },
  2: { 
    scenario: "Cache ë©”ëª¨ë¦¬ ë¶€ì¡± ê²½ê³ ", 
    incidents: [
      { serverId: "cache-server-1", type: "memory_pressure", severity: "warning", factor: 1.4 }
    ]
  },
  3: { 
    scenario: "DB ë³µì œ ì§€ì—°", 
    incidents: [
      { serverId: "cache-server-1", type: "memory_pressure", severity: "warning", factor: 1.3 },
      { serverId: "db-replica-1", type: "replication_lag", severity: "warning", factor: 1.2 }
    ]
  },
  4: { 
    scenario: "ì ì§„ì  íšŒë³µ", 
    incidents: [
      { serverId: "cache-server-1", type: "memory_pressure", severity: "warning", factor: 1.2 }
    ]
  },
  5: { scenario: "ì •ìƒí™”", incidents: [] },

  // ğŸŒ… ì•„ì¹¨ (06:00-12:00)
  6: { scenario: "íŠ¸ë˜í”½ ì¦ê°€ ì‹œì‘", incidents: [], trafficFactor: 1.2 },
  7: { scenario: "ì•„ì¹¨ íŠ¸ë˜í”½ ì¦ê°€", incidents: [], trafficFactor: 1.4 },
  8: { 
    scenario: "ì›¹ì„œë²„ CPU ìŠ¤íŒŒì´í¬", 
    incidents: [
      { serverId: "web-server-1", type: "cpu_spike", severity: "critical", factor: 1.8 }
    ],
    trafficFactor: 1.6 
  },
  9: { 
    scenario: "API ì‘ë‹µì‹œê°„ ì¦ê°€", 
    incidents: [
      { serverId: "web-server-1", type: "cpu_spike", severity: "warning", factor: 1.4 },
      { serverId: "api-server-1", type: "response_time", severity: "warning", factor: 1.3 }
    ],
    trafficFactor: 1.5 
  },
  10: { 
    scenario: "ë©”ì‹œì§€ í ë°±ë¡œê·¸", 
    incidents: [
      { serverId: "api-server-1", type: "response_time", severity: "warning", factor: 1.2 },
      { serverId: "queue-server-1", type: "queue_backlog", severity: "warning", factor: 1.5 }
    ],
    trafficFactor: 1.4 
  },
  11: { 
    scenario: "ë¶€í•˜ ë¶„ì‚°ìœ¼ë¡œ ì•ˆì •í™”", 
    incidents: [
      { serverId: "queue-server-1", type: "queue_backlog", severity: "warning", factor: 1.2 }
    ],
    trafficFactor: 1.3 
  },

  // â˜€ï¸ ì˜¤í›„ (12:00-18:00)
  12: { scenario: "ì ì‹¬ í”¼í¬ íŠ¸ë˜í”½", incidents: [], trafficFactor: 1.5 },
  13: { 
    scenario: "ìŠ¤í† ë¦¬ì§€ ë””ìŠ¤í¬ ê²½ê³ ", 
    incidents: [
      { serverId: "storage-server-1", type: "disk_full", severity: "critical", factor: 1.6 }
    ],
    trafficFactor: 1.4 
  },
  14: { 
    scenario: "DB ìŠ¬ë¡œìš° ì¿¼ë¦¬ ê¸‰ì¦", 
    incidents: [
      { serverId: "storage-server-1", type: "disk_full", severity: "warning", factor: 1.4 },
      { serverId: "db-master-1", type: "slow_queries", severity: "warning", factor: 1.3 }
    ],
    trafficFactor: 1.3 
  },
  15: { 
    scenario: "ëª¨ë‹ˆí„°ë§ ìˆ˜ì§‘ ì§€ì—°", 
    incidents: [
      { serverId: "db-master-1", type: "slow_queries", severity: "warning", factor: 1.2 },
      { serverId: "monitoring-server-1", type: "collection_delay", severity: "warning", factor: 1.3 }
    ],
    trafficFactor: 1.2 
  },
  16: { scenario: "ì ì§„ì  ì •ìƒí™”", incidents: [], trafficFactor: 1.1 },
  17: { scenario: "ì •ìƒ ìš´ì˜", incidents: [], trafficFactor: 1.0 },

  // ğŸŒ™ ì €ë… (18:00-24:00)
  18: { scenario: "í‡´ê·¼ ì‹œê°„ íŠ¸ë˜í”½ í”¼í¬", incidents: [], trafficFactor: 1.7 },
  19: { 
    scenario: "API ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€", 
    incidents: [
      { serverId: "api-server-1", type: "memory_leak", severity: "warning", factor: 1.3 }
    ],
    trafficFactor: 1.6 
  },
  20: { 
    scenario: "DB ì»¤ë„¥ì…˜ í’€ ê³ ê°ˆ", 
    incidents: [
      { serverId: "api-server-1", type: "memory_leak", severity: "warning", factor: 1.4 },
      { serverId: "db-master-1", type: "connection_pool", severity: "critical", factor: 1.5 }
    ],
    trafficFactor: 1.5 
  },
  21: { 
    scenario: "ì›¹ì„œë²„ 503 ì—ëŸ¬", 
    incidents: [
      { serverId: "web-server-1", type: "http_errors", severity: "critical", factor: 1.6 },
      { serverId: "db-master-1", type: "connection_pool", severity: "critical", factor: 1.4 }
    ],
    trafficFactor: 1.4 
  },
  22: { 
    scenario: "ê¸´ê¸‰ íŒ¨ì¹˜ ì ìš©", 
    incidents: [
      { serverId: "web-server-1", type: "maintenance", severity: "warning", factor: 0.8 },
      { serverId: "api-server-1", type: "maintenance", severity: "warning", factor: 0.7 }
    ],
    trafficFactor: 1.2 
  },
  23: { scenario: "ì‹œìŠ¤í…œ ì•ˆì •í™”", incidents: [], trafficFactor: 1.0 }
};

// ğŸ“Š ë©”íŠ¸ë¦­ìŠ¤ ê³„ì‚° í•¨ìˆ˜
function calculateMetrics(baseMetrics, incidents, trafficFactor = 1.0) {
  const metrics = { ...baseMetrics };
  
  // íŠ¸ë˜í”½ íŒ©í„° ì ìš©
  metrics.cpu = Math.round(metrics.cpu * trafficFactor);
  metrics.memory = Math.round(metrics.memory * trafficFactor);
  metrics.network = Math.round(metrics.network * trafficFactor * 1.2);
  
  // ìƒí•œì„  ì ìš©
  metrics.cpu = Math.min(metrics.cpu, 95);
  metrics.memory = Math.min(metrics.memory, 95);
  metrics.disk = Math.min(metrics.disk, 95);
  metrics.network = Math.min(metrics.network, 99);
  
  return metrics;
}

// ğŸš¨ ìƒíƒœ ê²°ì • í•¨ìˆ˜
function determineStatus(metrics, incidents) {
  if (incidents.some(inc => inc.severity === "critical")) return "critical";
  if (incidents.some(inc => inc.severity === "warning")) return "warning";
  if (metrics.cpu > 90 || metrics.memory > 90 || metrics.disk > 90) return "warning";
  return "healthy";
}

// ğŸ“ˆ ì—…íƒ€ì„ ê³„ì‚° (ì¥ì•  ì‹œê°„ ë°˜ì˜)
function calculateUptime(baseUptime, incidents) {
  const totalDowntime = incidents.reduce((acc, inc) => {
    return acc + (inc.severity === "critical" ? 300 : 60); // critical: 5ë¶„, warning: 1ë¶„
  }, 0);
  return Math.max(baseUptime - totalDowntime, 0);
}

// ğŸ¯ ì•Œë¦¼ ìƒì„± í•¨ìˆ˜
function generateAlerts(incidents) {
  return incidents.map(incident => {
    const alertMessages = {
      memory_pressure: "Memory usage exceeding 85% threshold",
      replication_lag: "Database replication lag detected",
      cpu_spike: "CPU usage spike detected",
      response_time: "API response time above threshold",
      queue_backlog: "Message queue backlog building up",
      disk_full: "Disk usage critical - above 90%",
      slow_queries: "Slow database queries detected",
      collection_delay: "Metrics collection experiencing delays",
      memory_leak: "Memory leak pattern detected",
      connection_pool: "Database connection pool exhausted",
      http_errors: "HTTP 5xx errors increasing",
      maintenance: "Scheduled maintenance in progress"
    };
    return alertMessages[incident.type] || "System alert detected";
  });
}

// ğŸ“ ì‹œê°„ë³„ ë©”íŠ¸ë¦­ìŠ¤ ìƒì„±
function generateHourlyMetrics(hour) {
  const scenario = hourlyScenarios[hour];
  const timestamp = new Date();
  timestamp.setHours(hour, 0, 0, 0);
  
  const hourlyData = {
    hour,
    timestamp: timestamp.toISOString(),
    scenario: scenario.scenario,
    trafficFactor: scenario.trafficFactor || 1.0,
    servers: {}
  };

  serverMetadata.servers.forEach(server => {
    const serverIncidents = scenario.incidents.filter(inc => inc.serverId === server.id);
    
    // ë² ì´ìŠ¤ ë©”íŠ¸ë¦­ìŠ¤ì— ì¥ì•  íŒ©í„° ì ìš©
    let metrics = { ...server.baseMetrics };
    
    serverIncidents.forEach(incident => {
      switch (incident.type) {
        case "memory_pressure":
        case "memory_leak":
          metrics.memory = Math.round(metrics.memory * incident.factor);
          break;
        case "cpu_spike":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          break;
        case "disk_full":
          metrics.disk = Math.round(metrics.disk * incident.factor);
          break;
        case "response_time":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.memory = Math.round(metrics.memory * incident.factor * 0.9);
          break;
        case "queue_backlog":
          metrics.memory = Math.round(metrics.memory * incident.factor);
          metrics.network = Math.round(metrics.network * incident.factor);
          break;
        case "slow_queries":
        case "connection_pool":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.memory = Math.round(metrics.memory * incident.factor);
          break;
        case "http_errors":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.network = Math.round(metrics.network * incident.factor);
          break;
        case "collection_delay":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.disk = Math.round(metrics.disk * incident.factor);
          break;
        case "maintenance":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.memory = Math.round(metrics.memory * incident.factor);
          break;
      }
    });

    // íŠ¸ë˜í”½ íŒ©í„° ë° ìƒí•œì„  ì ìš©
    metrics = calculateMetrics(metrics, serverIncidents, scenario.trafficFactor);
    
    const status = determineStatus(metrics, serverIncidents);
    const uptime = calculateUptime(86400 * 30, serverIncidents); // 30ì¼ ê¸°ì¤€
    const alerts = generateAlerts(serverIncidents);
    
    hourlyData.servers[server.id] = {
      id: server.id,
      name: server.name,
      hostname: server.hostname,
      status,
      cpu: metrics.cpu,
      memory: metrics.memory,
      disk: metrics.disk,
      network: metrics.network,
      uptime,
      location: server.location,
      environment: server.environment,
      provider: server.provider,
      type: server.type,
      service: server.service,
      alerts: alerts.length,
      alertMessages: alerts,
      lastUpdate: timestamp.toISOString(),
      incidents: serverIncidents.map(inc => ({
        type: inc.type,
        severity: inc.severity,
        active: true
      })),
      metrics: {
        cpu: {
          usage: metrics.cpu,
          cores: server.specs.cpu_cores,
          temperature: 35 + Math.round(metrics.cpu * 0.3)
        },
        memory: {
          used: Math.round((metrics.memory * server.specs.memory_gb) / 100),
          total: server.specs.memory_gb,
          usage: metrics.memory
        },
        disk: {
          used: Math.round((metrics.disk * server.specs.disk_gb) / 100),
          total: server.specs.disk_gb,
          usage: metrics.disk
        },
        network: {
          bytesIn: Math.round(metrics.network * 0.6),
          bytesOut: Math.round(metrics.network * 0.4),
          packetsIn: Math.round(metrics.network * 10),
          packetsOut: Math.round(metrics.network * 8)
        },
        timestamp: timestamp.toISOString(),
        uptime
      }
    };
  });

  return hourlyData;
}

// ğŸš€ ë©”ì¸ ì‹¤í–‰
function main() {
  console.log('ğŸ¯ 24ì‹œê°„ í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë‚˜ë¦¬ì˜¤ ë©”íŠ¸ë¦­ìŠ¤ ìƒì„± ì‹œì‘...\n');
  
  // ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }
  
  // 24ì‹œê°„ ë©”íŠ¸ë¦­ìŠ¤ ìƒì„±
  for (let hour = 0; hour < 24; hour++) {
    const hourlyMetrics = generateHourlyMetrics(hour);
    const filename = `${hour.toString().padStart(2, '0')}.json`;
    const filepath = path.join(outputDir, filename);
    
    fs.writeFileSync(filepath, JSON.stringify(hourlyMetrics, null, 2));
    
    const scenario = hourlyScenarios[hour];
    console.log(`âœ… ${filename}: ${scenario.scenario} (${Object.keys(hourlyMetrics.servers).length}ê°œ ì„œë²„)`);
    
    if (scenario.incidents.length > 0) {
      scenario.incidents.forEach(inc => {
        console.log(`   ğŸš¨ ${inc.serverId}: ${inc.type} (${inc.severity})`);
      });
    }
  }
  
  console.log(`\nğŸ‰ ì´ 24ê°œì˜ ì‹œê°„ë³„ ë©”íŠ¸ë¦­ìŠ¤ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!`);
  console.log(`ğŸ“‚ ìœ„ì¹˜: ${outputDir}`);
  console.log(`\nğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ ìš”ì•½:`);
  console.log(`   - ì •ìƒ ìš´ì˜: 8ì‹œê°„`);
  console.log(`   - ê²½ê³  ìƒí™©: 12ì‹œê°„`);
  console.log(`   - ì‹¬ê°í•œ ì¥ì• : 4ì‹œê°„`);
  console.log(`   - 8ê°œ ì„œë²„ë³„ ë‹¤ì–‘í•œ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨`);
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
if (require.main === module) {
  main();
}

module.exports = { generateHourlyMetrics, hourlyScenarios };