#!/usr/bin/env node

/**
 * üéØ 24ÏãúÍ∞Ñ Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÏãúÎÇòÎ¶¨Ïò§ Î©îÌä∏Î¶≠Ïä§ ÏÉùÏÑ±Í∏∞
 * 
 * Í∞Å ÏãúÍ∞ÑÎåÄÎ≥ÑÎ°ú 8Í∞ú ÏÑúÎ≤ÑÏùò Ïû•Ïï† ÏãúÎÇòÎ¶¨Ïò§ Îç∞Ïù¥ÌÑ∞Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
 */

const fs = require('fs');
const path = require('path');

// Í∏∞Î≥∏ ÏÑúÎ≤Ñ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î°úÎìú
const serverMetadataPath = path.join(__dirname, '../public/server-scenarios/servers-metadata.json');
const serverMetadata = JSON.parse(fs.readFileSync(serverMetadataPath, 'utf8'));

// Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨
const outputDir = path.join(__dirname, '../public/server-scenarios/hourly-metrics');

// üé≠ 24ÏãúÍ∞Ñ ÏãúÎÇòÎ¶¨Ïò§ Ï†ïÏùò
const hourlyScenarios = {
  // üåÉ ÏÉàÎ≤Ω (00:00-06:00)
  0: { scenario: "Ï†ïÏÉÅ Ïö¥ÏòÅ", incidents: [] },
  1: { scenario: "Ï†ïÏÉÅ Ïö¥ÏòÅ", incidents: [] },
  2: { 
    scenario: "Cache Î©îÎ™®Î¶¨ Î∂ÄÏ°± Í≤ΩÍ≥†", 
    incidents: [
      { serverId: "cache-server-1", type: "memory_pressure", severity: "warning", factor: 1.4 }
    ]
  },
  3: { 
    scenario: "DB Î≥µÏ†ú ÏßÄÏó∞", 
    incidents: [
      { serverId: "cache-server-1", type: "memory_pressure", severity: "warning", factor: 1.3 },
      { serverId: "db-replica-1", type: "replication_lag", severity: "warning", factor: 1.2 }
    ]
  },
  4: { 
    scenario: "Ï†êÏßÑÏ†Å ÌöåÎ≥µ", 
    incidents: [
      { serverId: "cache-server-1", type: "memory_pressure", severity: "warning", factor: 1.2 }
    ]
  },
  5: { scenario: "Ï†ïÏÉÅÌôî", incidents: [] },

  // üåÖ ÏïÑÏπ® (06:00-12:00)
  6: { scenario: "Ìä∏ÎûòÌîΩ Ï¶ùÍ∞Ä ÏãúÏûë", incidents: [], trafficFactor: 1.2 },
  7: { scenario: "ÏïÑÏπ® Ìä∏ÎûòÌîΩ Ï¶ùÍ∞Ä", incidents: [], trafficFactor: 1.4 },
  8: { 
    scenario: "ÏõπÏÑúÎ≤Ñ CPU Ïä§ÌååÏù¥ÌÅ¨", 
    incidents: [
      { serverId: "web-server-1", type: "cpu_spike", severity: "critical", factor: 1.8 }
    ],
    trafficFactor: 1.6 
  },
  9: { 
    scenario: "API ÏùëÎãµÏãúÍ∞Ñ Ï¶ùÍ∞Ä", 
    incidents: [
      { serverId: "web-server-1", type: "cpu_spike", severity: "warning", factor: 1.4 },
      { serverId: "api-server-1", type: "response_time", severity: "warning", factor: 1.3 }
    ],
    trafficFactor: 1.5 
  },
  10: { 
    scenario: "Î©îÏãúÏßÄ ÌÅê Î∞±Î°úÍ∑∏", 
    incidents: [
      { serverId: "api-server-1", type: "response_time", severity: "warning", factor: 1.2 },
      { serverId: "queue-server-1", type: "queue_backlog", severity: "warning", factor: 1.5 }
    ],
    trafficFactor: 1.4 
  },
  11: { 
    scenario: "Î∂ÄÌïò Î∂ÑÏÇ∞ÏúºÎ°ú ÏïàÏ†ïÌôî", 
    incidents: [
      { serverId: "queue-server-1", type: "queue_backlog", severity: "warning", factor: 1.2 }
    ],
    trafficFactor: 1.3 
  },

  // ‚òÄÔ∏è Ïò§ÌõÑ (12:00-18:00)
  12: { scenario: "Ï†êÏã¨ ÌîºÌÅ¨ Ìä∏ÎûòÌîΩ", incidents: [], trafficFactor: 1.5 },
  13: { 
    scenario: "Ïä§ÌÜ†Î¶¨ÏßÄ ÎîîÏä§ÌÅ¨ Í≤ΩÍ≥†", 
    incidents: [
      { serverId: "storage-server-1", type: "disk_full", severity: "critical", factor: 1.6 }
    ],
    trafficFactor: 1.4 
  },
  14: { 
    scenario: "DB Ïä¨Î°úÏö∞ ÏøºÎ¶¨ Í∏âÏ¶ù", 
    incidents: [
      { serverId: "storage-server-1", type: "disk_full", severity: "warning", factor: 1.4 },
      { serverId: "db-master-1", type: "slow_queries", severity: "warning", factor: 1.3 }
    ],
    trafficFactor: 1.3 
  },
  15: { 
    scenario: "Î™®ÎãàÌÑ∞ÎßÅ ÏàòÏßë ÏßÄÏó∞", 
    incidents: [
      { serverId: "db-master-1", type: "slow_queries", severity: "warning", factor: 1.2 },
      { serverId: "monitoring-server-1", type: "collection_delay", severity: "warning", factor: 1.3 }
    ],
    trafficFactor: 1.2 
  },
  16: { scenario: "Ï†êÏßÑÏ†Å Ï†ïÏÉÅÌôî", incidents: [], trafficFactor: 1.1 },
  17: { scenario: "Ï†ïÏÉÅ Ïö¥ÏòÅ", incidents: [], trafficFactor: 1.0 },

  // üåô Ï†ÄÎÖÅ (18:00-24:00)
  18: { scenario: "Ìá¥Í∑º ÏãúÍ∞Ñ Ìä∏ÎûòÌîΩ ÌîºÌÅ¨", incidents: [], trafficFactor: 1.7 },
  19: { 
    scenario: "API Î©îÎ™®Î¶¨ ÎàÑÏàò Í∞êÏßÄ", 
    incidents: [
      { serverId: "api-server-1", type: "memory_leak", severity: "warning", factor: 1.3 }
    ],
    trafficFactor: 1.6 
  },
  20: { 
    scenario: "DB Ïª§ÎÑ•ÏÖò ÌíÄ Í≥†Í∞à", 
    incidents: [
      { serverId: "api-server-1", type: "memory_leak", severity: "warning", factor: 1.4 },
      { serverId: "db-master-1", type: "connection_pool", severity: "critical", factor: 1.5 }
    ],
    trafficFactor: 1.5 
  },
  21: { 
    scenario: "ÏõπÏÑúÎ≤Ñ 503 ÏóêÎü¨", 
    incidents: [
      { serverId: "web-server-1", type: "http_errors", severity: "critical", factor: 1.6 },
      { serverId: "db-master-1", type: "connection_pool", severity: "critical", factor: 1.4 }
    ],
    trafficFactor: 1.4 
  },
  22: { 
    scenario: "Í∏¥Í∏â Ìå®Ïπò Ï†ÅÏö©", 
    incidents: [
      { serverId: "web-server-1", type: "maintenance", severity: "warning", factor: 0.8 },
      { serverId: "api-server-1", type: "maintenance", severity: "warning", factor: 0.7 }
    ],
    trafficFactor: 1.2 
  },
  23: { scenario: "ÏãúÏä§ÌÖú ÏïàÏ†ïÌôî", incidents: [], trafficFactor: 1.0 }
};

// üìä Î©îÌä∏Î¶≠Ïä§ Í≥ÑÏÇ∞ Ìï®Ïàò
function calculateMetrics(baseMetrics, incidents, trafficFactor = 1.0) {
  const metrics = { ...baseMetrics };
  
  // Ìä∏ÎûòÌîΩ Ìå©ÌÑ∞ Ï†ÅÏö©
  metrics.cpu = Math.round(metrics.cpu * trafficFactor);
  metrics.memory = Math.round(metrics.memory * trafficFactor);
  metrics.network = Math.round(metrics.network * trafficFactor * 1.2);
  
  // ÏÉÅÌïúÏÑ† Ï†ÅÏö©
  metrics.cpu = Math.min(metrics.cpu, 95);
  metrics.memory = Math.min(metrics.memory, 95);
  metrics.disk = Math.min(metrics.disk, 95);
  metrics.network = Math.min(metrics.network, 99);
  
  return metrics;
}

// üö® ÏÉÅÌÉú Í≤∞Ï†ï Ìï®Ïàò
function determineStatus(metrics, incidents) {
  if (incidents.some(inc => inc.severity === "critical")) return "critical";
  if (incidents.some(inc => inc.severity === "warning")) return "warning";
  if (metrics.cpu > 90 || metrics.memory > 90 || metrics.disk > 90) return "warning";
  return "healthy";
}

// üìà ÏóÖÌÉÄÏûÑ Í≥ÑÏÇ∞ (Ïû•Ïï† ÏãúÍ∞Ñ Î∞òÏòÅ)
function calculateUptime(baseUptime, incidents) {
  const totalDowntime = incidents.reduce((acc, inc) => {
    return acc + (inc.severity === "critical" ? 300 : 60); // critical: 5Î∂Ñ, warning: 1Î∂Ñ
  }, 0);
  return Math.max(baseUptime - totalDowntime, 0);
}

// üéØ ÏïåÎ¶º ÏÉùÏÑ± Ìï®Ïàò
function generateAlerts(incidents) {
  return incidents.map(incident => {
    const alertMessages = {
      memory_pressure: "Memory usage exceeding 85% threshold",
      replication_lag: "Database replication lag detected",
      cpu_spike: "CPU usage spike detected",
      response_time: "API response time above threshold",
      queue_backlog: "Message queue backlog building up",
      disk_full: "Disk usage critical - above 90%",
      slow_queries: "Slow database queries detected",
      collection_delay: "Metrics collection experiencing delays",
      memory_leak: "Memory leak pattern detected",
      connection_pool: "Database connection pool exhausted",
      http_errors: "HTTP 5xx errors increasing",
      maintenance: "Scheduled maintenance in progress"
    };
    return alertMessages[incident.type] || "System alert detected";
  });
}

// üìù ÏãúÍ∞ÑÎ≥Ñ Î©îÌä∏Î¶≠Ïä§ ÏÉùÏÑ±
function generateHourlyMetrics(hour) {
  const scenario = hourlyScenarios[hour];
  const timestamp = new Date();
  timestamp.setHours(hour, 0, 0, 0);
  
  const hourlyData = {
    hour,
    timestamp: timestamp.toISOString(),
    scenario: scenario.scenario,
    trafficFactor: scenario.trafficFactor || 1.0,
    servers: {}
  };

  serverMetadata.servers.forEach(server => {
    const serverIncidents = scenario.incidents.filter(inc => inc.serverId === server.id);
    
    // Î≤†Ïù¥Ïä§ Î©îÌä∏Î¶≠Ïä§Ïóê Ïû•Ïï† Ìå©ÌÑ∞ Ï†ÅÏö©
    let metrics = { ...server.baseMetrics };
    
    serverIncidents.forEach(incident => {
      switch (incident.type) {
        case "memory_pressure":
        case "memory_leak":
          metrics.memory = Math.round(metrics.memory * incident.factor);
          break;
        case "cpu_spike":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          break;
        case "disk_full":
          metrics.disk = Math.round(metrics.disk * incident.factor);
          break;
        case "response_time":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.memory = Math.round(metrics.memory * incident.factor * 0.9);
          break;
        case "queue_backlog":
          metrics.memory = Math.round(metrics.memory * incident.factor);
          metrics.network = Math.round(metrics.network * incident.factor);
          break;
        case "slow_queries":
        case "connection_pool":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.memory = Math.round(metrics.memory * incident.factor);
          break;
        case "http_errors":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.network = Math.round(metrics.network * incident.factor);
          break;
        case "collection_delay":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.disk = Math.round(metrics.disk * incident.factor);
          break;
        case "maintenance":
          metrics.cpu = Math.round(metrics.cpu * incident.factor);
          metrics.memory = Math.round(metrics.memory * incident.factor);
          break;
      }
    });

    // Ìä∏ÎûòÌîΩ Ìå©ÌÑ∞ Î∞è ÏÉÅÌïúÏÑ† Ï†ÅÏö©
    metrics = calculateMetrics(metrics, serverIncidents, scenario.trafficFactor);
    
    const status = determineStatus(metrics, serverIncidents);
    const uptime = calculateUptime(86400 * 30, serverIncidents); // 30Ïùº Í∏∞Ï§Ä
    const alerts = generateAlerts(serverIncidents);
    
    hourlyData.servers[server.id] = {
      id: server.id,
      name: server.name,
      hostname: server.hostname,
      status,
      cpu: metrics.cpu,
      memory: metrics.memory,
      disk: metrics.disk,
      network: metrics.network,
      uptime,
      location: server.location,
      environment: server.environment,
      provider: server.provider,
      type: server.type,
      service: server.service,
      alerts: alerts.length,
      alertMessages: alerts,
      lastUpdate: timestamp.toISOString(),
      incidents: serverIncidents.map(inc => ({
        type: inc.type,
        severity: inc.severity,
        active: true
      })),
      metrics: {
        cpu: {
          usage: metrics.cpu,
          cores: server.specs.cpu_cores,
          temperature: 35 + Math.round(metrics.cpu * 0.3)
        },
        memory: {
          used: Math.round((metrics.memory * server.specs.memory_gb) / 100),
          total: server.specs.memory_gb,
          usage: metrics.memory
        },
        disk: {
          used: Math.round((metrics.disk * server.specs.disk_gb) / 100),
          total: server.specs.disk_gb,
          usage: metrics.disk
        },
        network: {
          bytesIn: Math.round(metrics.network * 0.6),
          bytesOut: Math.round(metrics.network * 0.4),
          packetsIn: Math.round(metrics.network * 10),
          packetsOut: Math.round(metrics.network * 8)
        },
        timestamp: timestamp.toISOString(),
        uptime
      }
    };
  });

  return hourlyData;
}

// üöÄ Î©îÏù∏ Ïã§Ìñâ
function main() {
  console.log('üéØ 24ÏãúÍ∞Ñ Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÏãúÎÇòÎ¶¨Ïò§ Î©îÌä∏Î¶≠Ïä§ ÏÉùÏÑ± ÏãúÏûë...\n');
  
  // Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨ ÌôïÏù∏
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }
  
  // 24ÏãúÍ∞Ñ Î©îÌä∏Î¶≠Ïä§ ÏÉùÏÑ±
  for (let hour = 0; hour < 24; hour++) {
    const hourlyMetrics = generateHourlyMetrics(hour);
    const filename = `${hour.toString().padStart(2, '0')}.json`;
    const filepath = path.join(outputDir, filename);
    
    fs.writeFileSync(filepath, JSON.stringify(hourlyMetrics, null, 2));
    
    const scenario = hourlyScenarios[hour];
    console.log(`‚úÖ ${filename}: ${scenario.scenario} (${Object.keys(hourlyMetrics.servers).length}Í∞ú ÏÑúÎ≤Ñ)`);
    
    if (scenario.incidents.length > 0) {
      scenario.incidents.forEach(inc => {
        console.log(`   üö® ${inc.serverId}: ${inc.type} (${inc.severity})`);
      });
    }
  }
  
  console.log(`\nüéâ Ï¥ù 24Í∞úÏùò ÏãúÍ∞ÑÎ≥Ñ Î©îÌä∏Î¶≠Ïä§ ÌååÏùºÏù¥ ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§!`);
  console.log(`üìÇ ÏúÑÏπò: ${outputDir}`);
  console.log(`\nüìä ÏãúÎÇòÎ¶¨Ïò§ ÏöîÏïΩ:`);
  console.log(`   - Ï†ïÏÉÅ Ïö¥ÏòÅ: 8ÏãúÍ∞Ñ`);
  console.log(`   - Í≤ΩÍ≥† ÏÉÅÌô©: 12ÏãúÍ∞Ñ`);
  console.log(`   - Ïã¨Í∞ÅÌïú Ïû•Ïï†: 4ÏãúÍ∞Ñ`);
  console.log(`   - 8Í∞ú ÏÑúÎ≤ÑÎ≥Ñ Îã§ÏñëÌïú Ïû•Ïï† ÏãúÎÇòÎ¶¨Ïò§ Ìè¨Ìï®`);
}

// Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ
if (require.main === module) {
  main();
}

module.exports = { generateHourlyMetrics, hourlyScenarios };