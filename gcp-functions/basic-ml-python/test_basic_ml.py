"""
ğŸ§ª Basic ML Function í…ŒìŠ¤íŠ¸
TDD ë°©ì‹ìœ¼ë¡œ Python êµ¬í˜„ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
"""

import unittest
import json
import numpy as np
from unittest.mock import Mock, patch
from main import (
    classify_text,
    generate_embedding,
    predict_trend,
    analyze_statistics,
    process_basic_ml,
    basic_ml
)


class TestTextClassification(unittest.TestCase):
    """í…ìŠ¤íŠ¸ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸"""

    def test_classify_technical_text(self):
        """ê¸°ìˆ ì  í…ìŠ¤íŠ¸ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸"""
        queries = [
            "ì„œë²„ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤",
            "ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
            "ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤"
        ]
        for query in queries:
            result = classify_text(query)
            self.assertEqual(result['classification'], 'technical')
            self.assertGreater(result['confidence'], 0.6)

    def test_classify_operational_text(self):
        """ìš´ì˜ ê´€ë ¨ í…ìŠ¤íŠ¸ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸"""
        queries = [
            "ë°±ì—… ì„¤ì •ì„ ë³€ê²½í•´ì£¼ì„¸ìš”",
            "ì‹œìŠ¤í…œ ê¶Œí•œì„ ê´€ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤",
            "ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•´ì£¼ì„¸ìš”"
        ]
        for query in queries:
            result = classify_text(query)
            self.assertEqual(result['classification'], 'operational')

    def test_classify_analysis_text(self):
        """ë¶„ì„ ê´€ë ¨ í…ìŠ¤íŠ¸ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸"""
        queries = [
            "ì§€ë‚œ ì£¼ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
            "ë©”íŠ¸ë¦­ íŒ¨í„´ì„ ë³´ì—¬ì£¼ì„¸ìš”",
            "í†µê³„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”"
        ]
        for query in queries:
            result = classify_text(query)
            self.assertEqual(result['classification'], 'analysis')

    def test_classification_scores(self):
        """ë¶„ë¥˜ ì ìˆ˜ ë° í™•ë¥  í…ŒìŠ¤íŠ¸"""
        query = "ì„œë²„ ì„±ëŠ¥ ë¶„ì„ê³¼ ë°±ì—… ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”"
        result = classify_text(query)
        
        # ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ê°€ ë§¤ì¹­ë˜ëŠ” ê²½ìš°
        self.assertIn('classification', result)
        self.assertIn('confidence', result)
        self.assertIn('probabilities', result)
        
        # í™•ë¥ ì˜ í•©ì´ 1ì¸ì§€ í™•ì¸
        prob_sum = sum(result['probabilities'].values())
        self.assertAlmostEqual(prob_sum, 1.0, places=5)


class TestEmbedding(unittest.TestCase):
    """í…ìŠ¤íŠ¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""

    def test_generate_embedding_basic(self):
        """ê¸°ë³¸ ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸"""
        text = "ì„œë²„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë¶„ì„"
        embedding = generate_embedding(text)
        
        # ì„ë² ë”© ì°¨ì› í™•ì¸
        self.assertIsInstance(embedding, np.ndarray)
        self.assertEqual(len(embedding), 100)  # ì˜ˆìƒ ì°¨ì›
        
        # ì •ê·œí™” í™•ì¸
        norm = np.linalg.norm(embedding)
        self.assertAlmostEqual(norm, 1.0, places=5)

    def test_embedding_similarity(self):
        """ìœ ì‚¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸"""
        text1 = "ì„œë²„ CPU ëª¨ë‹ˆí„°ë§"
        text2 = "ì„œë²„ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§"
        text3 = "ë‚ ì”¨ê°€ ì¢‹ìŠµë‹ˆë‹¤"
        
        emb1 = generate_embedding(text1)
        emb2 = generate_embedding(text2)
        emb3 = generate_embedding(text3)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        sim12 = np.dot(emb1, emb2)
        sim13 = np.dot(emb1, emb3)
        
        # ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¼ë¦¬ ë” ë†’ì€ ìœ ì‚¬ë„
        self.assertGreater(sim12, sim13)

    def test_embedding_korean_text(self):
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
        text = "ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”"
        embedding = generate_embedding(text)
        
        # 0ì´ ì•„ë‹Œ ê°’ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
        self.assertTrue(np.any(embedding != 0))


class TestPrediction(unittest.TestCase):
    """ì˜ˆì¸¡ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""

    def test_predict_trend_increasing(self):
        """ì¦ê°€ ì¶”ì„¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
        data = [10, 12, 15, 18, 22, 25, 30]
        result = predict_trend(data)
        
        self.assertEqual(result['trend'], 'increasing')
        self.assertGreater(result['prediction'], data[-1])
        self.assertGreater(result['confidence'], 0.8)

    def test_predict_trend_decreasing(self):
        """ê°ì†Œ ì¶”ì„¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
        data = [30, 28, 25, 22, 18, 15, 10]
        result = predict_trend(data)
        
        self.assertEqual(result['trend'], 'decreasing')
        self.assertLess(result['prediction'], data[-1])

    def test_predict_trend_stable(self):
        """ì•ˆì •ì  ì¶”ì„¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
        data = [20, 19, 21, 20, 19, 20, 21]
        result = predict_trend(data)
        
        self.assertEqual(result['trend'], 'stable')
        self.assertAlmostEqual(result['prediction'], 20, delta=2)

    def test_predict_with_seasonality(self):
        """ê³„ì ˆì„± íŒ¨í„´ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
        # ê°„ë‹¨í•œ ê³„ì ˆì„± íŒ¨í„´
        data = [10, 20, 15, 25, 10, 20, 15, 25]
        result = predict_trend(data)
        
        self.assertIn('seasonality', result)
        self.assertIn('period', result)

    def test_anomaly_detection(self):
        """ì´ìƒì¹˜ íƒì§€ í…ŒìŠ¤íŠ¸"""
        data = [20, 22, 21, 20, 100, 19, 21, 22]  # 100ì€ ì´ìƒì¹˜
        result = predict_trend(data)
        
        self.assertIn('anomalies', result)
        self.assertGreater(len(result['anomalies']), 0)


class TestStatistics(unittest.TestCase):
    """í†µê³„ ë¶„ì„ í…ŒìŠ¤íŠ¸"""

    def test_basic_statistics(self):
        """ê¸°ë³¸ í†µê³„ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        data = [10, 20, 30, 40, 50]
        stats = analyze_statistics(data)
        
        self.assertEqual(stats['mean'], 30)
        self.assertEqual(stats['median'], 30)
        self.assertEqual(stats['min'], 10)
        self.assertEqual(stats['max'], 50)
        self.assertGreater(stats['std'], 0)

    def test_outlier_detection(self):
        """ì´ìƒì¹˜ íƒì§€ í…ŒìŠ¤íŠ¸"""
        data = [10, 11, 12, 13, 14, 15, 100]  # 100ì€ ì´ìƒì¹˜
        stats = analyze_statistics(data)
        
        self.assertIn('outliers', stats)
        self.assertEqual(len(stats['outliers']), 1)
        self.assertEqual(stats['outliers'][0], 100)

    def test_percentiles(self):
        """ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        data = list(range(1, 101))  # 1~100
        stats = analyze_statistics(data)
        
        self.assertAlmostEqual(stats['p25'], 25.5, delta=1)
        self.assertAlmostEqual(stats['p50'], 50.5, delta=1)
        self.assertAlmostEqual(stats['p75'], 75.5, delta=1)

    def test_empty_data(self):
        """ë¹ˆ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        stats = analyze_statistics([])
        
        self.assertEqual(stats['mean'], 0)
        self.assertEqual(stats['count'], 0)
        self.assertEqual(len(stats['outliers']), 0)


class TestProcessBasicML(unittest.TestCase):
    """í†µí•© ML ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""

    def test_process_basic_ml_success(self):
        """ML ì²˜ë¦¬ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        query = "ì„œë²„ ì„±ëŠ¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”"
        context = {
            'metrics': [70, 75, 80, 85, 90, 95]
        }
        
        result = process_basic_ml(query, context)
        
        self.assertTrue(result['success'])
        self.assertIn('response', result)
        self.assertIn('classification', result)
        self.assertIn('embeddings', result)
        self.assertIn('predictions', result)
        self.assertIn('statistics', result)

    def test_process_without_metrics(self):
        """ë©”íŠ¸ë¦­ ì—†ì´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        query = "ì„œë²„ ìƒíƒœê°€ ì–´ë–¤ê°€ìš”?"
        result = process_basic_ml(query)
        
        self.assertTrue(result['success'])
        self.assertIsNone(result['predictions'])
        self.assertIsNone(result['statistics'])

    def test_response_generation(self):
        """ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸"""
        query = "CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ë° ë¶„ì„í•´ì£¼ì„¸ìš”"
        context = {
            'metrics': [60, 70, 80, 90, 95, 98]
        }
        
        result = process_basic_ml(query, context)
        
        # ì‘ë‹µì— ë¶„ë¥˜ ê²°ê³¼ í¬í•¨
        self.assertIn('ê¸°ìˆ ', result['response'])
        # ì˜ˆì¸¡ ê²°ê³¼ í¬í•¨
        self.assertIn('ì¦ê°€', result['response'])


class TestHTTPFunction(unittest.TestCase):
    """HTTP í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""

    def setUp(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •"""
        self.mock_request = Mock()
        self.mock_request.method = 'POST'
        self.mock_request.get_json = Mock()
        self.mock_request.headers = {'Content-Type': 'application/json'}

    def test_basic_ml_http_success(self):
        """HTTP ìš”ì²­ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        self.mock_request.get_json.return_value = {
            'query': 'ì„œë²„ ì„±ëŠ¥ ë¶„ì„í•´ì£¼ì„¸ìš”',
            'context': {
                'metrics': [70, 75, 80, 85, 90]
            }
        }
        
        response = basic_ml(self.mock_request)
        
        self.assertEqual(response[1], 200)
        response_data = json.loads(response[0])
        self.assertTrue(response_data['success'])
        self.assertEqual(response_data['engine'], 'basic-ml-python')

    def test_basic_ml_health_check(self):
        """í—¬ìŠ¤ ì²´í¬ í…ŒìŠ¤íŠ¸"""
        from main import basic_ml_health
        
        mock_request = Mock()
        mock_request.method = 'GET'
        
        response = basic_ml_health(mock_request)
        
        self.assertEqual(response[1], 200)
        health_data = json.loads(response[0])
        self.assertEqual(health_data['status'], 'healthy')
        self.assertIn('features', health_data)


class TestPerformanceOptimization(unittest.TestCase):
    """ì„±ëŠ¥ ìµœì í™” í…ŒìŠ¤íŠ¸"""

    def test_batch_processing(self):
        """ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        queries = [
            "ì„œë²„ ìƒíƒœ í™•ì¸",
            "ì„±ëŠ¥ ë¶„ì„ ìš”ì²­",
            "íŠ¸ë Œë“œ ì˜ˆì¸¡"
        ]
        
        import time
        start = time.time()
        
        for query in queries:
            process_basic_ml(query)
        
        end = time.time()
        avg_time = (end - start) / len(queries) * 1000  # ms
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ì´ 50ms ë¯¸ë§Œ
        self.assertLess(avg_time, 50)

    def test_memory_efficiency(self):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬
        for _ in range(100):
            data = list(range(1000))
            analyze_statistics(data)
            predict_trend(data[:100])
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        # ë©”ëª¨ë¦¬ ì¦ê°€ê°€ 100MB ë¯¸ë§Œ (ë¬´ë£Œí‹°ì–´ ìµœì í™”)
        self.assertLess(memory_increase, 100)


if __name__ == '__main__':
    unittest.main()