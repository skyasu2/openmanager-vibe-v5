# 🎯 AI 엔진 설계 요약

> **왜 MCP 기반 AI 엔진을 선택했는가?**

## 💡 핵심 설계 원칙

### 1. **외부 LLM API 없이 독립 동작**

- ❌ 외부 LLM API 의존성 완전 제거 (Claude, GPT 등 불필요)
- ✅ MCP Protocol + 패턴 매칭 + 규칙 기반 추론
- ✅ 무료 티어에서도 완전 기능

### 2. **패턴 매칭 기반 지능형 응답**

- ❌ 무거운 벡터 DB 대신
- ✅ 의도 분류 + 엔티티 추출 + 템플릿 매칭
- ✅ 서버 모니터링 도메인 특화 응답

### 3. **Vercel 최적화**

- ✅ 서버리스 환경 완벽 활용
- ✅ 1GB 메모리 제한 대응
- ✅ Edge Functions 최적화

## 🚀 기술적 장점

| 기존 LLM 방식 | MCP 기반 방식 |
| ------------- | ------------- |
| 외부 API 필수 | 완전 독립     |
| 벡터 DB 필요  | 패턴 매칭     |
| API 비용 발생 | 제한 없음     |
| 300ms+ 응답   | 즉시 응답     |
| 일관성 부족   | 100% 일관성   |

## 📊 성능 비교

- **응답 속도**: < 100ms (외부 LLM 대비 3배 빠름)
- **메모리 사용**: 50MB (벡터 DB 대비 80% 절약)
- **비용**: $0 (외부 API 비용 완전 없음)
- **일관성**: 100% (같은 입력 → 같은 출력)

## 🔧 구현 세부사항

### MCP 프로토콜 활용

- **의도 분류**: 자연어 쿼리에서 사용자 의도 파악
- **엔티티 추출**: 서버명, 메트릭명 등 핵심 정보 추출
- **패턴 매칭**: 미리 정의된 규칙과 템플릿으로 응답 생성
- **컨텍스트 학습**: 세션별 대화 히스토리 관리

### 로컬 추론 엔진

- **규칙 기반**: 서버 모니터링 도메인에 특화된 규칙 적용
- **즉시 응답**: 네트워크 지연 없이 로컬에서 즉시 처리
- **일관된 결과**: 같은 입력에 대해 항상 동일한 출력 보장

상세 내용: `docs/WHY_MCP_AI_ENGINE.md` 참조
