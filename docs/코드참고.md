# ğŸ’» OpenManager Vibe v5.44.2 ì½”ë“œ ì°¸ê³ 

> **ë²„ì „**: v5.44.2  
> **ì—…ë°ì´íŠ¸**: 2025ë…„ 6ì›” 21ì¼  
> **ìƒíƒœ**: ì™„ì „ ì™„ì„±, ëª©ì—… ì‹œìŠ¤í…œ í†µí•©, í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ

---

## ğŸ¯ í•µì‹¬ ì½”ë“œ ìƒ˜í”Œ

### **1. UnifiedAIEngine (ë©”ì¸ AI í—ˆë¸Œ)**

```typescript
// src/core/ai/UnifiedAIEngine.ts
export class UnifiedAIEngine {
  private googleAI?: GoogleAIService;
  private ragEngine: LocalRAGEngine;
  private mcpClient: RealMCPClient | null = null;
  private localEngine: LocalAIEngine;

  async processQuery(
    request: UnifiedAnalysisRequest
  ): Promise<UnifiedAnalysisResponse> {
    // ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
    const [localResult, ragResult, mcpResult, googleResult] =
      await Promise.allSettled([
        this.localEngine.processQuery(request.query),
        this.ragEngine.searchAndAnswer(request.query),
        this.mcpClient?.analyze(request) || Promise.resolve(null),
        this.googleAI?.processQuery(request) || Promise.resolve(null),
      ]);

    // ê²°ê³¼ ìœµí•© ë° ì‹ ë¢°ë„ ê³„ì‚°
    return this.fuseResults({
      local: this.extractResult(localResult),
      rag: this.extractResult(ragResult),
      mcp: this.extractResult(mcpResult),
      google: this.extractResult(googleResult),
    });
  }

  private fuseResults(results: MultiAIResults): UnifiedAnalysisResponse {
    const validResults = Object.values(results).filter(
      r => r?.success && r.confidence > 0.5
    );

    if (validResults.length === 0) {
      return this.generateFallbackResponse();
    }

    // ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±
    const weightedContent = this.calculateWeightedResponse(validResults);
    const averageConfidence =
      validResults.reduce((sum, r) => sum + r.confidence, 0) /
      validResults.length;

    return {
      success: true,
      content: weightedContent,
      confidence: averageConfidence,
      sources: validResults.map(r => r.source),
      processingTime: Math.max(...validResults.map(r => r.processingTime)),
      isMockMode: validResults.some(r => r.isMockMode),
    };
  }
}
```

### **2. ëª©ì—… ì‹œìŠ¤í…œ (ìë™ ê°ì§€)**

```typescript
// src/services/ai/MockSystemManager.ts
export class MockSystemManager {
  detectMockMode(): boolean {
    return (
      this.isHealthCheckContext() ||
      this.isTestContext() ||
      this.isEnvironmentMissing() ||
      process.env.FORCE_MOCK_MODE === 'true'
    );
  }

  private isHealthCheckContext(): boolean {
    if (typeof window === 'undefined') {
      // ì„œë²„ ì‚¬ì´ë“œ ë Œë”ë§ í™˜ê²½
      return true;
    }

    const userAgent = navigator.userAgent;
    const referer = document.referrer;

    return (
      userAgent?.includes('health-check') ||
      referer?.includes('/health') ||
      window.location.pathname.includes('/health')
    );
  }

  async processWithMockFallback<T>(
    realOperation: () => Promise<T>,
    mockOperation: () => T | Promise<T>
  ): Promise<T> {
    if (this.detectMockMode()) {
      return await mockOperation();
    }

    try {
      return await realOperation();
    } catch (error) {
      console.warn('Real operation failed, switching to mock:', error);
      return await mockOperation();
    }
  }
}
```

### **3. Google AI ì„œë¹„ìŠ¤ (í• ë‹¹ëŸ‰ ë³´í˜¸)**

```typescript
// src/services/ai/GoogleAIService.ts
export class GoogleAIService {
  private circuitBreaker: GoogleAICircuitBreaker;
  private quotaManager: GoogleAIQuotaManager;
  private mockManager: GoogleAIMockManager;

  async generateContent(
    request: GenerateContentRequest
  ): Promise<GoogleAIResponse> {
    // ëª©ì—… ëª¨ë“œ í™•ì¸
    if (this.mockManager.detectMockMode()) {
      return this.mockManager.generateMockResponse(request);
    }

    // Circuit Breaker íŒ¨í„´ ì ìš©
    return await this.circuitBreaker.executeWithCircuitBreaker(async () => {
      // í• ë‹¹ëŸ‰ í™•ì¸
      await this.quotaManager.checkQuotaLimits();

      // ì‹¤ì œ Google AI í˜¸ì¶œ
      const response = await this.client.generateContent({
        contents: [{ parts: [{ text: request.prompt }] }],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 1024,
        },
      });

      // ì‚¬ìš©ëŸ‰ ì¶”ì 
      await this.quotaManager.trackUsage('generateContent');

      return this.parseResponse(response);
    });
  }

  private parseResponse(response: any): GoogleAIResponse {
    const content = response.candidates?.[0]?.content?.parts?.[0]?.text || '';

    return {
      success: true,
      content: content,
      confidence: 0.9,
      processingTime: Date.now() - this.startTime,
      isMockMode: false,
      source: 'google-ai',
    };
  }
}
```

### **4. ì„œë²„ ë°ì´í„° ìƒì„±ê¸° (ëª©ì—… í†µí•©)**

```typescript
// src/services/data-generator/RealServerDataGenerator.ts
export class RealServerDataGenerator {
  private mockMode: boolean;
  private servers: ServerInstance[] = [];

  constructor() {
    this.mockMode = this.detectMockMode();
    this.initializeServers();
    this.startDataGeneration();
  }

  private detectMockMode(): boolean {
    return (
      (typeof window !== 'undefined' &&
        window.location.pathname.includes('/health')) ||
      process.env.NODE_ENV === 'test' ||
      process.env.FORCE_MOCK_DATA === 'true'
    );
  }

  private initializeServers(): void {
    // ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì„œë²„ ìƒíƒœ ë¶„í¬
    const serverConfigs = [
      { region: 'us-east-1', count: 5 },
      { region: 'eu-west-1', count: 5 },
      { region: 'ap-southeast-1', count: 5 },
    ];

    this.servers = serverConfigs.flatMap(config =>
      Array.from({ length: config.count }, (_, i) => ({
        id: `${config.region}-${i + 1}`,
        name: `Server-${config.region}-${i + 1}`,
        region: config.region,
        status: this.determineInitialStatus(i),
        metrics: this.generateInitialMetrics(),
        lastUpdated: new Date().toISOString(),
      }))
    );
  }

  private determineInitialStatus(index: number): ServerStatus {
    // ê³ ì •ëœ ì‹œë‚˜ë¦¬ì˜¤: 2ê°œ Critical, 30% Warning, ë‚˜ë¨¸ì§€ Healthy
    if (index < 2) return 'error';
    if (index < 6) return 'warning';
    return 'healthy';
  }

  private generateRealisticMetrics(): ServerMetrics {
    const baseTime = Date.now();
    const variation = Math.random() * 0.2 - 0.1; // Â±10% ë³€ë™

    return {
      cpu: Math.max(0, Math.min(100, 45 + variation * 100)),
      memory: Math.max(0, Math.min(100, 60 + variation * 100)),
      disk: Math.max(0, Math.min(100, 35 + variation * 100)),
      network: {
        incoming: Math.random() * 1000,
        outgoing: Math.random() * 800,
      },
      responseTime: 50 + Math.random() * 100,
      uptime: baseTime - Math.random() * 86400000, // ìµœëŒ€ 1ì¼ ì „
    };
  }
}
```

### **5. AI ì‚¬ì´ë“œë°” ì»´í¬ë„ŒíŠ¸**

```typescript
// src/components/ai/AISidebarV2.tsx
export const AISidebarV2: React.FC = () => {
  const [isOpen, setIsOpen] = useState(false);
  const [currentQuery, setCurrentQuery] = useState('');
  const [aiResponse, setAiResponse] = useState<AIResponse | null>(null);
  const [isLoading, setIsLoading] = useState(false);

  const handleSubmitQuery = async (query: string) => {
    setIsLoading(true);
    setCurrentQuery(query);

    try {
      const response = await fetch('/api/ai/unified-analysis', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query,
          includeThinking: true,
          engines: ['google-ai', 'mcp', 'rag', 'local']
        })
      });

      const result = await response.json();
      setAiResponse(result);
    } catch (error) {
      console.error('AI query failed:', error);
      setAiResponse({
        success: false,
        content: 'ì£„ì†¡í•©ë‹ˆë‹¤. AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        confidence: 0,
        isMockMode: true
      });
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className={`ai-sidebar ${isOpen ? 'open' : 'closed'}`}>
      <div className="sidebar-header">
        <h3>AI ì–´ì‹œìŠ¤í„´íŠ¸</h3>
        <button onClick={() => setIsOpen(!isOpen)}>
          {isOpen ? 'ë‹«ê¸°' : 'ì—´ê¸°'}
        </button>
      </div>

      {isOpen && (
        <div className="sidebar-content">
          <AIQueryInput onSubmit={handleSubmitQuery} />

          {isLoading && <AIThinkingViewer />}

          {aiResponse && (
            <AIResponseDisplay
              response={aiResponse}
              showSources={true}
              showConfidence={true}
            />
          )}

          <AIPresetQuestions onSelect={handleSubmitQuery} />
        </div>
      )}
    </div>
  );
};
```

---

## ğŸ”§ í™˜ê²½ ì„¤ì •

### **.env.local (ê°œë°œí™˜ê²½)**

```env
# ê¸°ë³¸ ì„¤ì •
NODE_ENV=development
NEXT_PUBLIC_APP_URL=http://localhost:3001

# Google AI (ì„ íƒì‚¬í•­)
GOOGLE_AI_API_KEY=your_google_ai_api_key
GOOGLE_AI_ENABLED=true
GOOGLE_AI_QUOTA_PROTECTION=true
GOOGLE_AI_TEST_LIMIT_PER_DAY=5
GOOGLE_AI_HEALTH_CHECK_CACHE_HOURS=24

# Supabase (ì„ íƒì‚¬í•­)
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# Redis (ì„ íƒì‚¬í•­)
REDIS_URL=redis://your-redis-url:6379
REDIS_PASSWORD=your_redis_password

# MCP ì„œë²„
MCP_RENDER_URL=https://openmanager-vibe-v5.onrender.com
MCP_LOCAL_URL=http://localhost:3001/api/mcp
MCP_TIMEOUT_MS=3000

# ëª©ì—… ëª¨ë“œ ê°•ì œ í™œì„±í™” (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
FORCE_MOCK_GOOGLE_AI=false
FORCE_MOCK_REDIS=false
FORCE_MOCK_SUPABASE=false
FORCE_MOCK_MCP=false

# ë””ë²„ê·¸ ëª¨ë“œ
DEBUG_AI_ENGINES=false
DEBUG_MCP_REQUESTS=false
DEBUG_PERFORMANCE=false

# ì„±ëŠ¥ ìµœì í™”
ENABLE_AI_CACHING=true
ENABLE_RESPONSE_COMPRESSION=true
MAX_CONCURRENT_AI_REQUESTS=5
```

### **.env.production (í”„ë¡œë•ì…˜)**

```env
# ê¸°ë³¸ ì„¤ì •
NODE_ENV=production
NEXT_PUBLIC_APP_URL=https://your-domain.vercel.app

# Google AI (ì‹¤ì œ í‚¤ í•„ìš”)
GOOGLE_AI_API_KEY=your_production_google_ai_key
GOOGLE_AI_ENABLED=true
GOOGLE_AI_QUOTA_PROTECTION=true

# Supabase (ì‹¤ì œ í”„ë¡œì íŠ¸)
NEXT_PUBLIC_SUPABASE_URL=https://your-prod-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_prod_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_prod_service_role_key

# Redis (í”„ë¡œë•ì…˜ ì¸ìŠ¤í„´ìŠ¤)
REDIS_URL=redis://your-prod-redis:6379
REDIS_PASSWORD=your_prod_redis_password

# MCP ì„œë²„ (í”„ë¡œë•ì…˜)
MCP_RENDER_URL=https://openmanager-vibe-v5.onrender.com
MCP_TIMEOUT_MS=5000

# ë³´ì•ˆ ì„¤ì •
NEXT_TELEMETRY_DISABLED=1
DISABLE_SOURCEMAPS=true

# ì„±ëŠ¥ ìµœì í™”
ENABLE_AI_CACHING=true
ENABLE_RESPONSE_COMPRESSION=true
MAX_CONCURRENT_AI_REQUESTS=10
```

---

## ğŸš€ API ì—”ë“œí¬ì¸íŠ¸

### **AI ê´€ë ¨ API**

#### **í†µí•© AI ë¶„ì„**

```typescript
// POST /api/ai/unified-analysis
interface UnifiedAnalysisRequest {
  query: string;
  includeThinking?: boolean;
  engines?: ('google-ai' | 'mcp' | 'rag' | 'local')[];
  context?: {
    serverData?: ServerInstance[];
    previousQueries?: string[];
  };
}

// ì‚¬ìš© ì˜ˆì‹œ
const response = await fetch('/api/ai/unified-analysis', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    query: 'CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ ì„œë²„ëŠ”?',
    includeThinking: true,
    engines: ['google-ai', 'mcp', 'rag', 'local'],
  }),
});
```

#### **Google AI ìƒíƒœ í™•ì¸**

```typescript
// GET /api/ai/google-ai/status
interface GoogleAIStatusResponse {
  enabled: boolean;
  available: boolean;
  quotaUsage: {
    daily: { used: number; limit: number };
    hourly: { used: number; limit: number };
  };
  circuitBreakerState: 'CLOSED' | 'OPEN' | 'HALF_OPEN';
  mockModeActive: boolean;
  lastHealthCheck: string;
}
```

### **ë°ì´í„° ê´€ë ¨ API**

#### **ì„œë²„ ë°ì´í„° ì¡°íšŒ**

```typescript
// GET /api/data-generator/servers
interface ServerDataResponse {
  servers: ServerInstance[];
  summary: {
    total: number;
    healthy: number;
    warning: number;
    critical: number;
  };
  lastUpdated: string;
  isMockMode: boolean;
}
```

#### **ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­**

```typescript
// GET /api/metrics/realtime
interface RealtimeMetricsResponse {
  timestamp: string;
  servers: ServerMetrics[];
  aggregated: {
    avgCpu: number;
    avgMemory: number;
    avgDisk: number;
    totalNetworkTraffic: number;
  };
  alerts: AlertMetric[];
}
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì½”ë“œ ìƒ˜í”Œ

### **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Jest)**

```typescript
// tests/unit/UnifiedAIEngine.test.ts
describe('UnifiedAIEngine', () => {
  let engine: UnifiedAIEngine;

  beforeEach(() => {
    engine = new UnifiedAIEngine({ forceMockMode: true });
  });

  it('should handle mock mode gracefully', async () => {
    const request: UnifiedAnalysisRequest = {
      query: 'Test query',
      engines: ['local', 'rag'],
    };

    const response = await engine.processQuery(request);

    expect(response.success).toBe(true);
    expect(response.isMockMode).toBe(true);
    expect(response.confidence).toBeGreaterThan(0.5);
  });

  it('should fuse multiple AI results correctly', async () => {
    const mockResults = {
      local: { success: true, content: 'Local result', confidence: 0.8 },
      rag: { success: true, content: 'RAG result', confidence: 0.9 },
    };

    const fusedResult = engine['fuseResults'](mockResults);

    expect(fusedResult.confidence).toBeCloseTo(0.85); // í‰ê· 
    expect(fusedResult.sources).toHaveLength(2);
  });
});
```

### **í†µí•© í…ŒìŠ¤íŠ¸**

```typescript
// tests/integration/ai-api.test.ts
describe('AI API Integration', () => {
  it('should handle unified analysis request', async () => {
    const response = await request(app)
      .post('/api/ai/unified-analysis')
      .send({
        query: 'CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ ì„œë²„ëŠ”?',
        engines: ['local', 'rag'],
      })
      .expect(200);

    expect(response.body.success).toBe(true);
    expect(response.body.content).toBeDefined();
    expect(response.body.confidence).toBeGreaterThan(0);
  });
});
```

---

## ğŸ¯ ì£¼ìš” ìœ í‹¸ë¦¬í‹°

### **íƒ€ì… ì •ì˜**

```typescript
// src/types/ai-agent.ts
export interface AIResponse {
  success: boolean;
  content: string;
  confidence: number;
  processingTime: number;
  engine: 'google-ai' | 'mcp' | 'rag' | 'local';
  isMockMode: boolean;
  sources?: string[];
  thinkingSteps?: AIThinkingStep[];
}

export interface ServerInstance {
  id: string;
  name: string;
  region: string;
  status: 'healthy' | 'warning' | 'error';
  metrics: ServerMetrics;
  lastUpdated: string;
}

export interface ServerMetrics {
  cpu: number;
  memory: number;
  disk: number;
  network: {
    incoming: number;
    outgoing: number;
  };
  responseTime: number;
  uptime: number;
}
```

### **ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜**

```typescript
// src/utils/ai-helpers.ts
export function calculateConfidence(responses: AIResponse[]): number {
  const validResponses = responses.filter(r => r.success);
  if (validResponses.length === 0) return 0;

  return (
    validResponses.reduce((sum, r) => sum + r.confidence, 0) /
    validResponses.length
  );
}

export function formatAIResponse(response: AIResponse): string {
  const prefix = response.isMockMode ? '[ëª©ì—…] ' : '';
  const confidence = Math.round(response.confidence * 100);

  return `${prefix}${response.content} (ì‹ ë¢°ë„: ${confidence}%)`;
}

export function determineServerStatus(metrics: ServerMetrics): ServerStatus {
  const { cpu, memory, disk } = metrics;

  if (cpu > 90 || memory > 95 || disk > 95) return 'error';
  if (cpu > 75 || memory > 80 || disk > 85) return 'warning';
  return 'healthy';
}
```

---

## ğŸ“ ê°œë°œ ê°€ì´ë“œ

### **ìƒˆë¡œìš´ AI ì—”ì§„ ì¶”ê°€**

1. **ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„**

```typescript
interface AIEngine {
  processQuery(query: string): Promise<AIResponse>;
  isAvailable(): Promise<boolean>;
  getEngineInfo(): EngineInfo;
}
```

2. **UnifiedAIEngineì— ë“±ë¡**

```typescript
// src/core/ai/UnifiedAIEngine.ts
this.customEngine = new CustomAIEngine();
```

3. **ëª©ì—… ì‘ë‹µ êµ¬í˜„**

```typescript
generateMockResponse(request: AIRequest): AIResponse {
  return {
    success: true,
    content: 'Custom AI mock response',
    confidence: 0.8,
    isMockMode: true
  };
}
```

### **ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€**

1. **API ë¼ìš°íŠ¸ ìƒì„±**

```typescript
// src/app/api/custom/route.ts
export async function POST(request: Request) {
  try {
    const body = await request.json();
    // ì²˜ë¦¬ ë¡œì§
    return NextResponse.json({ success: true, data: result });
  } catch (error) {
    return NextResponse.json(
      { success: false, error: error.message },
      { status: 500 }
    );
  }
}
```

2. **íƒ€ì… ì •ì˜ ì¶”ê°€**

```typescript
// src/types/custom.ts
export interface CustomRequest {
  // ìš”ì²­ íƒ€ì… ì •ì˜
}
```

ì´ ì½”ë“œ ì°¸ê³  ë¬¸ì„œë¥¼ í†µí•´ OpenManager Vibe v5.44.2ì˜ í•µì‹¬ êµ¬ì¡°ì™€ êµ¬í˜„ ë°©ë²•ì„ ì™„ì „íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€
