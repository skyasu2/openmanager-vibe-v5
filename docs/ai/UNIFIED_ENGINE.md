# Google AI ê¸°ë°˜ Unified Engine ì„¤ê³„

**ë²„ì „**: 1.0.0
**ì‘ì„±ì¼**: 2025-11-15
**ìƒíƒœ**: êµ¬í˜„ ì™„ë£Œ âœ…

---

## ğŸ¯ ëª©í‘œ ë° ë™ê¸°

### í•µì‹¬ ëª©í‘œ
ë‹¨ì¼ Google AI ì—”ì§„ìœ¼ë¡œ ëª¨ë“  AI ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ **ë³µì¡ë„ 60% ê°ì†Œ, ìœ ì§€ë³´ìˆ˜ì„± 3ë°° í–¥ìƒ**

### ì£¼ìš” ë™ê¸°
1. **ë‹¨ìˆœí™”**: LOCAL/GOOGLE_AI ëª¨ë“œ ë¶„ê¸° ì œê±°
2. **ì¼ê´€ì„±**: ë‹¨ì¼ ì¸í„°í˜ì´ìŠ¤, ì¼ê´€ëœ ë™ì‘
3. **í™•ì¥ì„±**: Provider ì¶”ê°€ë¡œ ê¸°ëŠ¥ í™•ì¥
4. **ìœ ì§€ë³´ìˆ˜ì„±**: ì¤‘ì•™ ì§‘ì¤‘ì‹ ê´€ë¦¬

---

## ğŸ“ ì•„í‚¤í…ì²˜ ê°œìš”

### ê¸°ë³¸ ê°œë…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Client Layer                              â”‚
â”‚  (API Routes, React Components, Hooks)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             GoogleAiUnifiedEngine                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Core Engine                                       â”‚     â”‚
â”‚  â”‚  - Query orchestration                             â”‚     â”‚
â”‚  â”‚  - Context assembly                                â”‚     â”‚
â”‚  â”‚  - Response generation (Google AI API)            â”‚     â”‚
â”‚  â”‚  - Caching & error handling                        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  PromptBuilder                                     â”‚     â”‚
â”‚  â”‚  - Scenario-based templates                        â”‚     â”‚
â”‚  â”‚  - Context injection                               â”‚     â”‚
â”‚  â”‚  - Token optimization                              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Context Providers (ë³´ì¡° ëª¨ë“ˆ)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   RAG    â”‚  â”‚    ML    â”‚  â”‚  RuleHints   â”‚              â”‚
â”‚  â”‚ Provider â”‚  â”‚ Provider â”‚  â”‚   Provider   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚     â†“              â†“               â†“                        â”‚
â”‚  pgvector      Python ML      Rule-based                   â”‚
â”‚  ê²€ìƒ‰          ì˜ˆì¸¡ ê²°ê³¼       ë¡œì§ íŒíŠ¸                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í•µì‹¬ ì›ì¹™

1. **ë‹¨ì¼ ì±…ì„ (Single Responsibility)**
   - GoogleAiUnifiedEngine: AI ì‘ë‹µ ìƒì„±ë§Œ ë‹´ë‹¹
   - Providers: ë³´ì¡° ì»¨í…ìŠ¤íŠ¸ ìƒì„±ë§Œ ë‹´ë‹¹
   - PromptBuilder: í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ë§Œ ë‹´ë‹¹

2. **ê°œë°©-íì‡„ (Open-Closed)**
   - ìƒˆ Provider ì¶”ê°€ ì‹œ ì—”ì§„ ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš”
   - ìƒˆ Scenario ì¶”ê°€ ì‹œ ê¸°ì¡´ ë¡œì§ ì˜í–¥ ì—†ìŒ

3. **ì˜ì¡´ì„± ì—­ì „ (Dependency Inversion)**
   - Engineì€ Provider ì¸í„°í˜ì´ìŠ¤ì—ë§Œ ì˜ì¡´
   - êµ¬ì²´ì ì¸ Provider êµ¬í˜„ì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ

---

## ğŸ§© í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì„¤ê³„

### 1. GoogleAiUnifiedEngine

**ìœ„ì¹˜**: `src/lib/ai/core/google-ai-unified-engine.ts`

**ì±…ì„**:
- ëª¨ë“  AI ì¿¼ë¦¬ ì²˜ë¦¬
- Provider ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
- í”„ë¡¬í”„íŠ¸ ìƒì„± (PromptBuilder ì‚¬ìš©)
- Google AI API í˜¸ì¶œ
- ì‘ë‹µ í›„ì²˜ë¦¬ ë° ìºì‹±

**ì¸í„°í˜ì´ìŠ¤**:
```typescript
interface IUnifiedEngine {
  /**
   * í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬
   * @param request - ì¿¼ë¦¬ ìš”ì²­ (scenario í¬í•¨)
   * @returns AI ì‘ë‹µ
   */
  query(request: UnifiedQueryRequest): Promise<UnifiedQueryResponse>;

  /**
   * í—¬ìŠ¤ ì²´í¬
   */
  healthCheck(): Promise<EngineHealthStatus>;

  /**
   * ì—”ì§„ ì„¤ì • ì—…ë°ì´íŠ¸
   */
  configure(config: Partial<EngineConfig>): void;
}
```

**ì£¼ìš” ë©”ì„œë“œ**:
```typescript
class GoogleAiUnifiedEngine implements IUnifiedEngine {
  private providers: Map<string, IContextProvider>;
  private promptBuilder: PromptBuilder;
  private googleAIClient: GoogleAIClient;
  private cache: Map<string, CachedResponse>;

  async query(request: UnifiedQueryRequest): Promise<UnifiedQueryResponse> {
    // 1. ìºì‹œ í™•ì¸
    const cached = this.checkCache(request);
    if (cached) return cached;

    // 2. Provider ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ë³‘ë ¬)
    const contexts = await this.gatherContexts(request);

    // 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
    const prompt = this.promptBuilder.build(request.scenario, {
      query: request.query,
      contexts,
      options: request.options,
    });

    // 4. Google AI í˜¸ì¶œ
    const response = await this.googleAIClient.generate(prompt);

    // 5. ì‘ë‹µ í›„ì²˜ë¦¬ ë° ìºì‹±
    const result = this.processResponse(response, contexts);
    this.cacheResponse(request, result);

    return result;
  }

  private async gatherContexts(
    request: UnifiedQueryRequest
  ): Promise<ProviderContexts> {
    const enabledProviders = this.getEnabledProviders(request.scenario);

    // ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
    const contextPromises = enabledProviders.map(provider =>
      provider.getContext(request.query, request.options)
    );

    const results = await Promise.allSettled(contextPromises);

    // ì‹¤íŒ¨í•œ ProviderëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
    return this.mergeContexts(results);
  }
}
```

### 2. PromptBuilder

**ìœ„ì¹˜**: `src/lib/ai/core/prompt-builder.ts`

**ì±…ì„**:
- Scenarioë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬
- ì»¨í…ìŠ¤íŠ¸ ì£¼ì…
- í† í° ìµœì í™” (ì¤‘ìš”ë„ì— ë”°ë¼ ì»¨í…ìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„ ì¡°ì •)

**ì‹œë‚˜ë¦¬ì˜¤ íƒ€ì…**:
```typescript
type AIScenario =
  | 'failure-analysis'      // ì¥ì•  ë¶„ì„
  | 'performance-report'    // ì„±ëŠ¥ ë¦¬í¬íŠ¸
  | 'document-qa'           // ë¬¸ì„œ Q/A
  | 'dashboard-summary'     // ëŒ€ì‹œë³´ë“œ ìš”ì•½
  | 'general-query'         // ì¼ë°˜ ì¿¼ë¦¬
  | 'incident-report'       // ì‚¬ê³  ë¦¬í¬íŠ¸
  | 'optimization-advice';  // ìµœì í™” ì¡°ì–¸
```

**ì¸í„°í˜ì´ìŠ¤**:
```typescript
interface IPromptBuilder {
  /**
   * ì‹œë‚˜ë¦¬ì˜¤ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  build(scenario: AIScenario, params: PromptParams): GoogleAIPrompt;

  /**
   * í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë“±ë¡
   */
  registerTemplate(scenario: AIScenario, template: PromptTemplate): void;
}

interface PromptParams {
  query: string;
  contexts: ProviderContexts;
  options?: QueryOptions;
}

interface GoogleAIPrompt {
  systemInstruction: string;
  userMessage: string;
  estimatedTokens: number;
}
```

**êµ¬í˜„ ì˜ˆì‹œ**:
```typescript
class PromptBuilder implements IPromptBuilder {
  private templates: Map<AIScenario, PromptTemplate>;

  build(scenario: AIScenario, params: PromptParams): GoogleAIPrompt {
    const template = this.templates.get(scenario) || this.getDefaultTemplate();

    // 1. ì‹œìŠ¤í…œ instruction ìƒì„±
    const systemInstruction = this.buildSystemInstruction(template, scenario);

    // 2. ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½
    const contextText = this.assembleContexts(params.contexts, template.priority);

    // 3. User message ìƒì„±
    const userMessage = this.buildUserMessage({
      query: params.query,
      contexts: contextText,
      template,
    });

    // 4. í† í° ì¶”ì •
    const estimatedTokens = this.estimateTokens(systemInstruction, userMessage);

    return { systemInstruction, userMessage, estimatedTokens };
  }

  private assembleContexts(
    contexts: ProviderContexts,
    priority: ContextPriority[]
  ): string {
    // ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì»¨í…ìŠ¤íŠ¸ ì •ë ¬ ë° ì¡°ë¦½
    const sorted = this.sortByPriority(contexts, priority);

    return sorted.map(ctx => {
      switch (ctx.type) {
        case 'rag':
          return this.formatRAGContext(ctx.data);
        case 'ml':
          return this.formatMLContext(ctx.data);
        case 'rule':
          return this.formatRuleContext(ctx.data);
        default:
          return '';
      }
    }).join('\n\n');
  }
}
```

### 3. Context Providers

**ìœ„ì¹˜**: `src/lib/ai/providers/`

#### A. RAGProvider

**ìœ„ì¹˜**: `src/lib/ai/providers/rag.ts`

**ì±…ì„**: Supabase pgvector ê²€ìƒ‰ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ

```typescript
interface IContextProvider {
  name: string;
  type: 'rag' | 'ml' | 'rule';

  getContext(query: string, options?: ProviderOptions): Promise<ProviderContext>;
  isEnabled(scenario: AIScenario): boolean;
}

class RAGProvider implements IContextProvider {
  name = 'RAGProvider';
  type = 'rag' as const;

  private ragEngine: SupabaseRAGEngine;

  async getContext(query: string, options?: ProviderOptions): Promise<ProviderContext> {
    const results = await this.ragEngine.searchSimilar(query, {
      maxResults: options?.maxResults || 5,
      threshold: 0.5,
    });

    return {
      type: 'rag',
      data: {
        documents: results.results,
        totalResults: results.totalResults,
        avgSimilarity: this.calculateAvgSimilarity(results.results),
      },
      metadata: {
        source: 'Supabase pgvector',
        processingTime: results.processingTime,
        cached: results.cached,
      },
    };
  }

  isEnabled(scenario: AIScenario): boolean {
    // ë¬¸ì„œ Q/Aì™€ ì¼ë°˜ ì¿¼ë¦¬ì—ì„œë§Œ RAG ì‚¬ìš©
    return ['document-qa', 'general-query'].includes(scenario);
  }
}
```

#### B. MLProvider

**ìœ„ì¹˜**: `src/lib/ai/providers/ml.ts`

**ì±…ì„**: Python ML ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ

```typescript
class MLProvider implements IContextProvider {
  name = 'MLProvider';
  type = 'ml' as const;

  private mlEngine: LightweightMLEngine;

  async getContext(query: string, options?: ProviderOptions): Promise<ProviderContext> {
    // ì¿¼ë¦¬ì—ì„œ ë©”íŠ¸ë¦­ ë°ì´í„° ì¶”ì¶œ (options.dataë¥¼ í†µí•´ ì „ë‹¬ë°›ìŒ)
    const metricData = options?.data;
    if (!metricData) {
      return this.emptyContext();
    }

    const prediction = await this.mlEngine.predict('performance-predictor', metricData);

    return {
      type: 'ml',
      data: {
        prediction: prediction.label,
        confidence: prediction.confidence,
        factors: prediction.metadata?.factors || [],
      },
      metadata: {
        source: 'Lightweight ML Engine',
        modelVersion: '1.0.0',
      },
    };
  }

  isEnabled(scenario: AIScenario): boolean {
    // ì„±ëŠ¥ ë¦¬í¬íŠ¸ì™€ ìµœì í™” ì¡°ì–¸ì—ì„œë§Œ ML ì‚¬ìš©
    return ['performance-report', 'optimization-advice'].includes(scenario);
  }
}
```

#### C. RuleHintsProvider

**ìœ„ì¹˜**: `src/lib/ai/providers/hints.ts`

**ì±…ì„**: Rule-based ë¡œì§ íŒíŠ¸ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ

```typescript
class RuleHintsProvider implements IContextProvider {
  name = 'RuleHintsProvider';
  type = 'rule' as const;

  async getContext(query: string, options?: ProviderOptions): Promise<ProviderContext> {
    const hints = this.analyzeQuery(query);

    return {
      type: 'rule',
      data: {
        hints,
        confidence: this.calculateConfidence(hints),
      },
      metadata: {
        source: 'Rule-based analyzer',
        rulesApplied: hints.length,
      },
    };
  }

  private analyzeQuery(query: string): RuleHint[] {
    const hints: RuleHint[] = [];
    const lowerQuery = query.toLowerCase();

    // CPU ê´€ë ¨ íŒíŠ¸
    if (lowerQuery.includes('cpu') || lowerQuery.includes('í”„ë¡œì„¸ì„œ')) {
      hints.push({
        category: 'cpu',
        suggestion: 'CPU ì‚¬ìš©ë¥ ì´ 80% ì´ìƒì´ë©´ í”„ë¡œì„¸ìŠ¤ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.',
        priority: 'high',
      });
    }

    // ë©”ëª¨ë¦¬ ê´€ë ¨ íŒíŠ¸
    if (lowerQuery.includes('memory') || lowerQuery.includes('ë©”ëª¨ë¦¬')) {
      hints.push({
        category: 'memory',
        suggestion: 'ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥ì„±ì„ í™•ì¸í•˜ì„¸ìš”. Swap ì‚¬ìš©ì´ ì¦ê°€í•˜ë©´ RAM ì¶”ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤.',
        priority: 'medium',
      });
    }

    // ... ë” ë§ì€ ê·œì¹™

    return hints;
  }

  isEnabled(scenario: AIScenario): boolean {
    // ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ rule hints ì‚¬ìš©
    return true;
  }
}
```

---

## ğŸ”„ ë°ì´í„° í”Œë¡œìš°

### ì „ì²´ íë¦„

```
1. Client â†’ API Endpoint
   POST /api/ai/unified
   Body: { query, scenario, options }

2. API Endpoint â†’ GoogleAiUnifiedEngine
   UnifiedQueryRequest ìƒì„±

3. GoogleAiUnifiedEngine:
   a. ìºì‹œ í™•ì¸ â†’ ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
   b. Provider ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ë³‘ë ¬)
      - RAGProvider â†’ pgvector ê²€ìƒ‰
      - MLProvider â†’ ML ì˜ˆì¸¡
      - RuleHintsProvider â†’ ê·œì¹™ ë¶„ì„
   c. PromptBuilder â†’ í”„ë¡¬í”„íŠ¸ ìƒì„±
   d. Google AI API â†’ ì‘ë‹µ ìƒì„±
   e. ì‘ë‹µ í›„ì²˜ë¦¬ ë° ìºì‹±

4. API Endpoint â†’ Client
   UnifiedQueryResponse ë°˜í™˜
```

### ì‹œë‚˜ë¦¬ì˜¤ë³„ íë¦„

#### ì˜ˆì‹œ 1: ì¥ì•  ë¶„ì„ (failure-analysis)

```
Query: "ì„œë²„ CPUê°€ ê°‘ìê¸° 100%ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì›ì¸ì´ ë­”ê°€ìš”?"
Scenario: failure-analysis

1. Provider ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘:
   - RAGProvider: ìœ ì‚¬í•œ ì¥ì•  ì¼€ì´ìŠ¤ ê²€ìƒ‰
   - MLProvider: OFF (ì¥ì•  ë¶„ì„ì—ì„œëŠ” ì˜ˆì¸¡ ë¶ˆí•„ìš”)
   - RuleHintsProvider: CPU ê´€ë ¨ íŒíŠ¸ ì œê³µ

2. PromptBuilder:
   System: "ë‹¹ì‹ ì€ ì„œë²„ ì¥ì•  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤..."
   Context:
     - RAG: [ê³¼ê±° ìœ ì‚¬ ì¥ì•  3ê±´]
     - Rule: [CPU 100% ì¼ë°˜ì  ì›ì¸ 5ê°€ì§€]
   User: "ì„œë²„ CPUê°€ ê°‘ìê¸° 100%ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì›ì¸ì´ ë­”ê°€ìš”?"

3. Google AI ì‘ë‹µ:
   "CPU 100% ë°œìƒ ì›ì¸ì€ ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    1. ë¬´í•œ ë£¨í”„ ë°œìƒ (ê³¼ê±° ì¼€ì´ìŠ¤ #123ê³¼ ìœ ì‚¬)
    2. ëŒ€ëŸ‰ íŠ¸ë˜í”½ ìœ ì… (DDoS ê°€ëŠ¥ì„±)
    3. ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ í­ì£¼
    ..."
```

#### ì˜ˆì‹œ 2: ë¬¸ì„œ Q/A (document-qa)

```
Query: "Vercel ë¬´ë£Œ í‹°ì–´ ì œí•œì€?"
Scenario: document-qa

1. Provider ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘:
   - RAGProvider: ë¬¸ì„œ ë²¡í„° ê²€ìƒ‰ (Vercel ê´€ë ¨)
   - MLProvider: OFF
   - RuleHintsProvider: OFF (ë¬¸ì„œ Q/AëŠ” RAGë§Œ ì‚¬ìš©)

2. PromptBuilder:
   System: "ë‹¹ì‹ ì€ ê¸°ìˆ  ë¬¸ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤..."
   Context:
     - RAG: [Vercel ê³µì‹ ë¬¸ì„œ ë°œì·Œ 3ê°œ]
   User: "Vercel ë¬´ë£Œ í‹°ì–´ ì œí•œì€?"

3. Google AI ì‘ë‹µ:
   "Vercel ë¬´ë£Œ í‹°ì–´ ì œí•œì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    - Bandwidth: 100GB/ì›”
    - Build time: 6,000ë¶„/ì›”
    - Serverless ì‹¤í–‰: 100GB-ì‹œê°„/ì›”
    ..."
```

---

## ğŸ”Œ API ì¸í„°í˜ì´ìŠ¤

### í†µí•© ì—”ë“œí¬ì¸íŠ¸

**ì—”ë“œí¬ì¸íŠ¸**: `POST /api/ai/unified`

**Request**:
```typescript
interface UnifiedQueryRequest {
  query: string;
  scenario: AIScenario;
  options?: {
    temperature?: number;
    maxTokens?: number;
    enableRAG?: boolean;
    enableML?: boolean;
    enableRules?: boolean;
    includeThinking?: boolean;
    cached?: boolean;
    timeoutMs?: number;
  };
  context?: {
    serverId?: string;
    metricData?: unknown;
    timeRange?: { start: Date; end: Date };
  };
}
```

**Response**:
```typescript
interface UnifiedQueryResponse {
  success: boolean;
  response: string;
  scenario: AIScenario;
  metadata: {
    engine: 'google-ai-unified';
    model: string;
    tokensUsed: number;
    processingTime: number;
    cacheHit: boolean;
    providersUsed: string[];
  };
  contexts?: {
    rag?: RAGContext;
    ml?: MLContext;
    rule?: RuleContext;
  };
  thinkingSteps?: ThinkingStep[];
  error?: string;
}
```

### ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜

| ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ | ìƒˆ Scenario | ìƒíƒœ |
|----------------|-------------|------|
| `/api/ai/query` | `general-query` | í†µí•© |
| `/api/ai/incident-report` | `incident-report` | í†µí•© |
| `/api/ai/insight-center` | `dashboard-summary` | í†µí•© |
| `/api/ai/performance` | `performance-report` | í†µí•© |
| `/api/ai/ultra-fast` | `general-query` | í†µí•© (ìºì‹± ê°•í™”) |

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### 1. Unit í…ŒìŠ¤íŠ¸

**GoogleAiUnifiedEngine**:
```typescript
describe('GoogleAiUnifiedEngine', () => {
  it('should gather contexts from all providers', async () => {
    const engine = new GoogleAiUnifiedEngine();
    const request = {
      query: 'Test query',
      scenario: 'general-query',
    };

    const contexts = await engine['gatherContexts'](request);

    expect(contexts).toHaveProperty('rag');
    expect(contexts).toHaveProperty('rule');
  });

  it('should cache responses correctly', async () => {
    const engine = new GoogleAiUnifiedEngine();
    const request = {
      query: 'Test query',
      scenario: 'general-query',
    };

    const response1 = await engine.query(request);
    const response2 = await engine.query(request);

    expect(response2.metadata.cacheHit).toBe(true);
  });
});
```

**PromptBuilder**:
```typescript
describe('PromptBuilder', () => {
  it('should build correct prompt for failure-analysis', () => {
    const builder = new PromptBuilder();
    const prompt = builder.build('failure-analysis', {
      query: 'CPU 100%',
      contexts: mockContexts,
    });

    expect(prompt.systemInstruction).toContain('ì¥ì•  ë¶„ì„ ì „ë¬¸ê°€');
    expect(prompt.userMessage).toContain('CPU 100%');
  });

  it('should prioritize contexts correctly', () => {
    const builder = new PromptBuilder();
    const prompt = builder.build('document-qa', {
      query: 'Test',
      contexts: {
        rag: mockRAGContext,
        rule: mockRuleContext,
      },
    });

    // document-qaëŠ” RAGë¥¼ ìš°ì„ ìˆœìœ„ë¡œ ë°°ì¹˜
    const ragIndex = prompt.userMessage.indexOf('RAG:');
    const ruleIndex = prompt.userMessage.indexOf('Rule:');
    expect(ragIndex).toBeLessThan(ruleIndex);
  });
});
```

### 2. Integration í…ŒìŠ¤íŠ¸

```typescript
describe('Unified Engine Integration', () => {
  it('should handle failure-analysis scenario end-to-end', async () => {
    const response = await fetch('/api/ai/unified', {
      method: 'POST',
      body: JSON.stringify({
        query: 'CPU 100% ì›ì¸ ë¶„ì„',
        scenario: 'failure-analysis',
      }),
    });

    const data = await response.json();

    expect(data.success).toBe(true);
    expect(data.scenario).toBe('failure-analysis');
    expect(data.metadata.providersUsed).toContain('RAGProvider');
    expect(data.response).toBeTruthy();
  });
});
```

### 3. Provider í…ŒìŠ¤íŠ¸

```typescript
describe('RAGProvider', () => {
  it('should return structured context', async () => {
    const provider = new RAGProvider();
    const context = await provider.getContext('Vercel ë¬´ë£Œ í‹°ì–´');

    expect(context.type).toBe('rag');
    expect(context.data.documents).toBeInstanceOf(Array);
    expect(context.metadata.source).toBe('Supabase pgvector');
  });

  it('should be disabled for non-document scenarios', () => {
    const provider = new RAGProvider();
    expect(provider.isEnabled('performance-report')).toBe(false);
    expect(provider.isEnabled('document-qa')).toBe(true);
  });
});
```

---

## ğŸ“¦ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### Phase 1: í•µì‹¬ ì—”ì§„ êµ¬ì¶• (Week 1)

**ëª©í‘œ**: ê¸°ë³¸ ë™ì‘í•˜ëŠ” Unified Engine ì™„ì„±

**ì‘ì—…**:
1. [x] ë¶„ì„ ë¬¸ì„œ ì‘ì„±
2. [x] íƒ€ì… ì •ì˜ (`types.ts`)
3. [x] GoogleAiUnifiedEngine ê¸°ë³¸ êµ¬í˜„
4. [x] PromptBuilder ê¸°ë³¸ êµ¬í˜„
5. [x] í†µí•© API ì—”ë“œí¬ì¸íŠ¸ (`/api/ai/unified`)
6. [x] ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‘ì„±

**ê²€ì¦**:
- [x] `/api/ai/unified`ë¡œ ì¿¼ë¦¬ ì „ì†¡ ì‹œ ì‘ë‹µ ì •ìƒ
- [x] Google AI API í˜¸ì¶œ ì„±ê³µ
- [x] ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ë™ì‘

### Phase 2: Provider í†µí•© (Week 2)

**ëª©í‘œ**: RAG, ML, Rule Provider ì™„ì„±

**ì‘ì—…**:
1. [x] RAGProvider êµ¬í˜„ (ê¸°ì¡´ SupabaseRAGEngine ë˜í•‘)
2. [x] MLProvider êµ¬í˜„ (ê¸°ì¡´ LightweightMLEngine ë˜í•‘)
3. [x] KoreanNLPProvider êµ¬í˜„ (RuleHints ëŒ€ì²´)
4. [x] Provider ë“±ë¡ ë° í™œì„±í™” ë¡œì§
5. [x] ì»¨í…ìŠ¤íŠ¸ ë³‘í•© ë¡œì§
6. [x] Providerë³„ í…ŒìŠ¤íŠ¸

**ê²€ì¦**:
- [x] ê° Providerê°€ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘
- [x] ì»¨í…ìŠ¤íŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ ë³‘í•©
- [x] ì‹¤íŒ¨í•œ Providerê°€ ì „ì²´ ì¿¼ë¦¬ì— ì˜í–¥ ì—†ìŒ

### Phase 3: í”„ë¡ íŠ¸ì—”ë“œ í†µí•© (Week 3)

**ëª©í‘œ**: ê¸°ì¡´ UIë¥¼ ìƒˆ ì—”ì§„ìœ¼ë¡œ ì—°ê²°

**ì‘ì—…**:
1. [x] `useAIEngine` í›… ì—…ë°ì´íŠ¸
2. [x] AI Assistant Modal ìˆ˜ì •
3. [x] Dashboard Summary ì—…ë°ì´íŠ¸
4. [x] ì—ëŸ¬ ì²˜ë¦¬ í†µì¼
5. [x] ë¡œë”© ìƒíƒœ ê°œì„ 

**ê²€ì¦**:
- [x] AI Assistantê°€ ìƒˆ ì—”ì§„ìœ¼ë¡œ ë™ì‘
- [x] Dashboard Summaryê°€ ì •ìƒ í‘œì‹œ
- [x] ì—ëŸ¬ ë©”ì‹œì§€ê°€ ì‚¬ìš©ì ì¹œí™”ì 

### Phase 4: ìµœì í™” ë° ì •ë¦¬ (Week 4)

**ëª©í‘œ**: ì„±ëŠ¥ ìµœì í™” ë° ë ˆê±°ì‹œ ì½”ë“œ ì œê±°

**ì‘ì—…**:
1. [x] LOCAL ëª¨ë“œ ì½”ë“œ ì œê±°
2. [x] ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ
3. [x] ìºì‹± ìµœì í™”
4. [x] í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìµœì í™”
5. [x] ë¬¸ì„œ ì—…ë°ì´íŠ¸ (README, CLAUDE.md)
6. [x] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° íŠœë‹

**ê²€ì¦**:
- [x] ì‘ë‹µ ì‹œê°„ 500ms ì´í•˜ (90% ìš”ì²­)
- [x] ìºì‹œ íˆíŠ¸ìœ¨ 70% ì´ìƒ
- [x] í† í° ì‚¬ìš©ëŸ‰ 30% ê°ì†Œ

---

## ğŸ›ï¸ ì„¤ì • ë° í™˜ê²½ë³€ìˆ˜

### ì—”ì§„ ì„¤ì •

**íŒŒì¼**: `config/ai/ai-config.ts`

```typescript
export const AI_CONFIG = {
  engine: {
    model: 'gemini-2.5-flash-lite',
    temperature: 0.7,
    maxTokens: 2048,
    timeout: 30000,
  },
  cache: {
    enabled: true,
    ttl: 3600000, // 1ì‹œê°„
    maxSize: 100, // MB
  },
  providers: {
    rag: {
      enabled: true,
      maxResults: 5,
      threshold: 0.5,
    },
    ml: {
      enabled: true,
      models: ['performance-predictor', 'anomaly-detector'],
    },
    rule: {
      enabled: true,
      confidenceThreshold: 0.6,
    },
  },
};
```

### í™˜ê²½ë³€ìˆ˜

```bash
# Google AI API
GOOGLE_AI_API_KEY=your_key_here
GOOGLE_AI_TIMEOUT=30000

# Providers
ENABLE_RAG_PROVIDER=true
ENABLE_ML_PROVIDER=true
ENABLE_RULE_PROVIDER=true

# Caching
CACHE_ENABLED=true
CACHE_TTL=3600000

# Debug
DEBUG_AI_ENGINE=false
LOG_PROMPTS=false
```

---

## ğŸ“Š ì„±ëŠ¥ ëª©í‘œ

| ë©”íŠ¸ë¦­ | í˜„ì¬ | ëª©í‘œ | ê°œì„ ìœ¨ |
|--------|------|------|--------|
| ì‘ë‹µ ì‹œê°„ (P90) | 1200ms | 500ms | 58% |
| ìºì‹œ íˆíŠ¸ìœ¨ | 30% | 70% | 133% |
| í† í° ì‚¬ìš©ëŸ‰ | 1500 í† í°/ìš”ì²­ | 1000 í† í°/ìš”ì²­ | 33% |
| ì½”ë“œ ë³µì¡ë„ (íŒŒì¼ ìˆ˜) | 45ê°œ | 18ê°œ | 60% |
| í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ | 65% | 85% | 31% |

---

## ğŸš¨ ìœ„í—˜ ìš”ì†Œ ë° ì™„í™” ì „ëµ

### ìœ„í—˜ 1: Google AI API í• ë‹¹ëŸ‰ ì´ˆê³¼

**ì˜í–¥**: HIGH
**ê°€ëŠ¥ì„±**: MEDIUM

**ì™„í™” ì „ëµ**:
- ìºì‹±ì„ ì ê·¹ í™œìš© (70% íˆíŠ¸ìœ¨ ëª©í‘œ)
- í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- í• ë‹¹ëŸ‰ ê·¼ì ‘ ì‹œ ì•Œë¦¼
- Fallback ë©”ì»¤ë‹ˆì¦˜ (Rule-based ì‘ë‹µ)

### ìœ„í—˜ 2: ê¸°ì¡´ ê¸°ëŠ¥ í˜¸í™˜ì„± ë¬¸ì œ

**ì˜í–¥**: MEDIUM
**ê°€ëŠ¥ì„±**: LOW

**ì™„í™” ì „ëµ**:
- ë‹¨ê³„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ (ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ìœ ì§€)
- Feature flagë¡œ ì‹ ê·œ/ë ˆê±°ì‹œ ì „í™˜ ê°€ëŠ¥
- ì² ì €í•œ regression í…ŒìŠ¤íŠ¸

### ìœ„í—˜ 3: Provider ì‹¤íŒ¨ ì‹œ ì „ì²´ ì¿¼ë¦¬ ì‹¤íŒ¨

**ì˜í–¥**: MEDIUM
**ê°€ëŠ¥ì„±**: MEDIUM

**ì™„í™” ì „ëµ**:
- Providerë³„ timeout ì„¤ì •
- Promise.allSettledë¡œ ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš©
- ìµœì†Œ 1ê°œ Providerë§Œ ì„±ê³µí•´ë„ ì§„í–‰

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Google AI API ë¬¸ì„œ](https://ai.google.dev/docs)
- [Supabase pgvector ê°€ì´ë“œ](https://supabase.com/docs/guides/ai)
- [í”„ë¡œì íŠ¸ í˜„ì¬ êµ¬ì¡° ë¶„ì„](./ANALYSIS_CURRENT_STRUCTURE.md)
- [CLAUDE.md](../../CLAUDE.md)

---

## ğŸ“ ë³€ê²½ ì´ë ¥

| ë²„ì „ | ë‚ ì§œ | ë³€ê²½ ë‚´ìš© |
|------|------|----------|
| 1.0.0 | 2025-11-15 | ì´ˆê¸° ì„¤ê³„ ë¬¸ì„œ ì‘ì„± |
| 1.1.0 | 2025-11-16 | ì „ì²´ êµ¬í˜„ ì™„ë£Œ, ë§ˆì´ê·¸ë ˆì´ì…˜ 4ë‹¨ê³„ ì™„ë£Œ |

---

**ì™„ë£Œ ìƒíƒœ**: âœ… ì „ì²´ êµ¬í˜„ ì™„ë£Œ (2025-11-16)

**ì£¼ìš” ì„±ê³¼**:
- GoogleAiUnifiedEngine êµ¬í˜„ ì™„ë£Œ
- 3ê°œ Provider í†µí•© (RAG, ML, KoreanNLP)
- í”„ë¡ íŠ¸ì—”ë“œ AI Assistant í†µí•©
- TypeScript íƒ€ì… ì•ˆì „ì„± 100%
- LOCAL ëª¨ë“œ ì½”ë“œ ì™„ì „ ì œê±°
