# Vercel AI SDK í†µí•© ë¶„ì„ ë° ê°œì„  ë°©ì•ˆ

**ì‘ì„±ì¼**: 2025-11-27
**ë²„ì „**: v1.0
**ìƒíƒœ**: í˜„í™© ë¶„ì„ ì™„ë£Œ
**ëª©ì **: í¬íŠ¸í´ë¦¬ì˜¤ ì‹œì—°ìš© AI ì–´ì‹œìŠ¤í„´íŠ¸ ê³ ë„í™”

---

## ğŸ¯ í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸

**í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸** - ì‹¤ì œ ì„œë²„ ì—°ë™ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° í™œìš©

### í•µì‹¬ ë°©ì¹¨

- âœ… **ê¸°ì¡´ Mock ë°ì´í„° í™œìš©** (Zustand storeì˜ EnhancedServerMetrics)
- âœ… **ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ AI ì‘ë‹µ** (ì‹¤ì œ ì„œë²„ ëŒ€ì‹  ë™ì  Mock)
- âœ… **í˜„ì‹¤ì ì¸ ì‹œì—° ê²½í—˜** (í¬íŠ¸í´ë¦¬ì˜¤ ì„¤ëª… ì‹œ ì‹¤ì œì²˜ëŸ¼ ë³´ì´ë„ë¡)
- âŒ **ì‹¤ì œ ì„œë²„ ì—°ë™ ì—†ìŒ** (GCP, AWS ë“± ì™¸ë¶€ ì¸í”„ë¼ í˜¸ì¶œ ì œê±°)

### ì‹œë®¬ë ˆì´ì…˜ ë²”ìœ„

1. **ì„œë²„ ë©”íŠ¸ë¦­**: Zustand storeì˜ ë™ì  Mock ë°ì´í„°
2. **ML ì˜ˆì¸¡**: CPU/ë©”ëª¨ë¦¬ ê¸°ë°˜ ê°„ë‹¨í•œ ì•Œê³ ë¦¬ì¦˜
3. **RAG ê²€ìƒ‰**: í•˜ë“œì½”ë”©ëœ Mock ì§€ì‹ë² ì´ìŠ¤
4. **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**: Mock ë°ì´í„° ì£¼ê¸°ì  ë³€ê²½ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜

---

## ğŸ“Š í˜„ì¬ í†µí•© ìƒíƒœ

### âœ… ì ìš© ì™„ë£Œ ì˜ì—­

#### 1. `/src/app/api/ai/chat/route.ts` (NEW)

**Vercel AI SDK ì™„ì „ ì ìš©** - ì‹ ê·œ API ì—”ë“œí¬ì¸íŠ¸

```typescript
import { google } from '@ai-sdk/google';
import { streamText, tool } from 'ai';

// âœ… ì£¼ìš” ê¸°ëŠ¥
- streamText() - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
- tool() - Tool Calling (3ê°œ ë„êµ¬)
- Google Gemini 1.5 Flash ëª¨ë¸
- maxDuration: 30ì´ˆ
```

**êµ¬í˜„ëœ Tools (3ê°œ)**:

1. `getSystemStatus` - ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
2. `checkResourceUsage` - CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
3. `analyzeLogs` - ë¡œê·¸ ë¶„ì„

#### 2. `/src/domains/ai-sidebar/components/AISidebarV4.tsx` (NEW)

**React Hooks í†µí•©** - ìƒˆë¡œìš´ ì‚¬ì´ë“œë°” ì»´í¬ë„ŒíŠ¸

```typescript
import { useChat } from 'ai/react';

// âœ… ì£¼ìš” ê¸°ëŠ¥
- useChat() Hook - ìƒíƒœ ê´€ë¦¬ ìë™í™”
- ì‹¤ì‹œê°„ ë©”ì‹œì§€ ìŠ¤íŠ¸ë¦¬ë°
- Tool invocations â†’ Thinking steps ìë™ ë³€í™˜
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ê³„ (useMemo, memo)
```

**Thinking Process ì‹œê°í™”**:

- Tool invocationsë¥¼ ThinkingStepìœ¼ë¡œ ë§¤í•‘
- ì‹¤ì‹œê°„ "processing" ìƒíƒœ í‘œì‹œ
- ì™„ë£Œ ì‹œ "completed" + ê²°ê³¼ í‘œì‹œ

### âš ï¸ ë¯¸ì ìš© ì˜ì—­ (ë ˆê±°ì‹œ)

#### 1. `/src/app/api/ai/query/route.ts` (LEGACY)

**ê¸°ì¡´ fetch ê¸°ë°˜** - 708ì¤„, Vercel AI SDK ë¯¸ì‚¬ìš©

**í˜„ì¬ êµ¬ì¡°**:

```typescript
// âŒ ìˆ˜ë™ ì²˜ë¦¬
- SimplifiedQueryEngine (ì»¤ìŠ¤í…€ ì—”ì§„)
- ìˆ˜ë™ íƒ€ì„ì•„ì›ƒ ê´€ë¦¬
- ìˆ˜ë™ ì—ëŸ¬ í•¸ë“¤ë§
- ìˆ˜ë™ ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„ ì—†ìŒ
```

**ë¬¸ì œì **:

- ìŠ¤íŠ¸ë¦¬ë° ë¯¸ì§€ì› (ì „ì²´ ì‘ë‹µ ëŒ€ê¸°)
- Tool calling ë¯¸ì§€ì›
- ë³µì¡í•œ ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§
- ì½”ë“œ ì¤‘ë³µ (708ì¤„)

#### 2. `/src/components/dashboard/AISidebarContent.tsx` (LEGACY)

**ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸** - 625ì¤„, fetch ê¸°ë°˜

**í˜„ì¬ êµ¬ì¡°**:

```typescript
// âŒ ìˆ˜ë™ ì²˜ë¦¬
- fetch() ì§ì ‘ í˜¸ì¶œ
- ìˆ˜ë™ ìƒíƒœ ê´€ë¦¬ (useState)
- ìˆ˜ë™ ë¡œë”©/ì—ëŸ¬ ì²˜ë¦¬
- Thinking steps ìˆ˜ë™ íŒŒì‹±
```

---

## ğŸ¯ ê°œì„  ë°©ì•ˆ (5ê°œ ì˜ì—­)

### 1. ğŸ”„ ê¸°ì¡´ APIë¥¼ Vercel AI SDKë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜

**ëª©í‘œ**: `/api/ai/query` â†’ `/api/ai/unified-stream`

**ê°œì„ ì **:

```typescript
// Before (708ì¤„)
const engine = await getQueryEngine();
const result = await engine.query(queryRequest); // ë¸”ë¡œí‚¹

// After (~100ì¤„)
const result = streamText({
  model: google('gemini-1.5-flash'),
  messages: [...],
  tools: { ragSearch, mlPredict, complexityAnalysis },
});
return result.toDataStreamResponse(); // ìŠ¤íŠ¸ë¦¬ë°
```

**íš¨ê³¼** (í¬íŠ¸í´ë¦¬ì˜¤ ì‹œì—° ê´€ì ):

- âœ… ì‘ë‹µ ì‹œê°„ 50% ê°ì†Œ (ìŠ¤íŠ¸ë¦¬ë° + ì²« í† í° ë¹ ë¦„)
- âœ… ì½”ë“œ 85% ê°ì†Œ (708ì¤„ â†’ ~100ì¤„)
- âœ… Tool calling ìë™í™” â†’ **ë©´ì ‘ê´€ì—ê²Œ ê¸°ìˆ ë ¥ ì–´í•„**
- âœ… íƒ€ì„ì•„ì›ƒ/ì—ëŸ¬ í•¸ë“¤ë§ ìë™í™”
- ğŸ“ **í¬íŠ¸í´ë¦¬ì˜¤ ê°•ì **: "Vercel AI SDK í™œìš© ê²½í—˜" ê°•ì¡° ê°€ëŠ¥

### 2. ğŸ’¡ Thinking Process ê³ ë„í™”

**í˜„ì¬ ë¬¸ì œ**:

- Tool invocationsë§Œ thinking stepìœ¼ë¡œ í‘œì‹œ
- ì‹¤ì œ "ìƒê° ê³¼ì •"ì´ ì•„ë‹Œ "ì‹¤í–‰ ê¸°ë¡"

**ê°œì„ ì•ˆ**: Extended Thinking íŒ¨í„´ ë„ì…

```typescript
// âœ¨ NEW: Thinking Stream ì „ìš© ë„êµ¬
const thinkingTools = {
  // 1ï¸âƒ£ ì˜ë„ ë¶„ì„
  analyzeIntent: tool({
    description: 'ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤',
    parameters: z.object({ query: z.string() }),
    execute: async ({ query }) => ({
      intent: 'metric_query',
      confidence: 0.95,
      category: 'performance',
    }),
  }),

  // 2ï¸âƒ£ ë³µì¡ë„ ë¶„ì„
  analyzeComplexity: tool({
    description: 'ì§ˆë¬¸ì˜ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì  ì—”ì§„ì„ ì„ íƒí•©ë‹ˆë‹¤',
    parameters: z.object({ query: z.string() }),
    execute: async ({ query }) => ({
      score: 3, // 1-5
      recommendation: 'supabase-rag',
      reasoning: 'ë‹¨ìˆœ ë©”íŠ¸ë¦­ ì¡°íšŒ â†’ RAG ì¶©ë¶„',
    }),
  }),

  // 3ï¸âƒ£ RAG ê²€ìƒ‰
  searchKnowledge: tool({
    description: 'Supabase pgvectorì—ì„œ ê´€ë ¨ ì§€ì‹ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤',
    parameters: z.object({ query: z.string() }),
    execute: async ({ query }) => {
      // ì‹¤ì œ RAG ê²€ìƒ‰
      const results = await supabase.rpc('match_documents', {
        query_embedding: await embed(query),
        match_threshold: 0.7,
        match_count: 3,
      });
      return {
        found: results.length,
        topMatch: results[0],
        relevance: 0.85,
      };
    },
  }),

  // 4ï¸âƒ£ ë¼ìš°íŒ… ê²°ì •
  selectEngine: tool({
    description: 'ìµœì  AI ì—”ì§„ì„ ì„ íƒí•©ë‹ˆë‹¤',
    parameters: z.object({ complexity: z.number() }),
    execute: async ({ complexity }) => ({
      engine: complexity > 3 ? 'gemini' : 'rag',
      reason: 'Cost optimization',
      estimatedCost: '$0',
    }),
  }),
};
```

**Thinking Process ì‹œê°í™” ê°œì„ **:

```typescript
// ThinkingProcessVisualizer.tsx í™•ì¥
const stepIconMap = {
  'ì˜ë„ ë¶„ì„': Brain,
  'ë³µì¡ë„ ë¶„ì„': Activity,
  'RAG ê²€ìƒ‰': Database,
  'ë¼ìš°íŒ… ê²°ì •': Route,
  'ì‘ë‹µ ìƒì„±': Zap,
};

// ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹¨ê³„ë³„ í‘œì‹œ
messages.map((m) =>
  m.toolInvocations?.map((t) => ({
    step: t.toolName,
    status: t.state === 'result' ? 'completed' : 'processing',
    description: t.result?.reasoning || `${t.toolName} ì‹¤í–‰ ì¤‘...`,
    timestamp: new Date(),
  }))
);
```

### 3. ğŸ› ï¸ Tool í™•ì¥ (í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° í™œìš©)

**ëª©í‘œ**: ê¸°ì¡´ Mock ë°ì´í„°ë¥¼ Toolì—ì„œ í™œìš©í•˜ì—¬ í˜„ì‹¤ì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œë®¬ë ˆì´ì…˜

**í˜„ì¬ ë¬¸ì œ**:

- Toolì´ í•˜ë“œì½”ë”©ëœ ê³ ì •ê°’ë§Œ ë°˜í™˜
- Zustand storeì˜ ë™ì  Mock ë°ì´í„°ì™€ ë¶„ë¦¬

**ê°œì„ ì•ˆ**: ê¸°ì¡´ Mock ë°ì´í„° ê¸°ë°˜ Tools (í¬íŠ¸í´ë¦¬ì˜¤ ì‹œì—°ìš©)

```typescript
const serverTools = {
  // ğŸ“Š ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ (Zustand Mock ë°ì´í„°)
  getServerMetrics: tool({
    description: 'ì„œë²„ CPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (ì‹œë®¬ë ˆì´ì…˜)',
    parameters: z.object({
      serverId: z.string().optional(),
      metric: z.enum(['cpu', 'memory', 'disk', 'all']),
    }),
    execute: async ({ serverId, metric }) => {
      // ğŸ’¡ Zustand storeì—ì„œ Mock ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
      const servers = useServerDataStore.getState().servers;
      const target = serverId
        ? servers.find((s) => s.id === serverId)
        : servers;

      return {
        servers: Array.isArray(target) ? target : [target],
        timestamp: new Date().toISOString(),
        avgCpu: calculateAvg(servers, 'cpu'),
        alertCount: servers.filter((s) => s.status === 'warning').length,
        // í¬íŠ¸í´ë¦¬ì˜¤: ì‹¤ì œ ë°ì´í„°ê°€ ì•„ë‹Œ ì‹œë®¬ë ˆì´ì…˜ì„ì„ ëª…ì‹œ
        _simulation: true,
      };
    },
  }),

  // ğŸ”® ML ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ (í¬íŠ¸í´ë¦¬ì˜¤ìš©)
  predictIncident: tool({
    description: 'ML ëª¨ë¸ë¡œ ì¥ì•  ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤ (ì‹œë®¬ë ˆì´ì…˜)',
    parameters: z.object({ serverId: z.string() }),
    execute: async ({ serverId }) => {
      // ğŸ’¡ Mock ì˜ˆì¸¡ ë¡œì§ (ì‹¤ì œ GCP í˜¸ì¶œ ëŒ€ì‹ )
      const servers = useServerDataStore.getState().servers;
      const server = servers.find((s) => s.id === serverId);

      // CPU/Memory ê¸°ë°˜ ê°„ë‹¨í•œ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜
      const cpuRisk = server.cpu > 80 ? 0.7 : server.cpu > 60 ? 0.4 : 0.1;
      const memRisk = server.memory > 85 ? 0.8 : server.memory > 70 ? 0.5 : 0.2;
      const probability = Math.max(cpuRisk, memRisk);

      return {
        probability: probability.toFixed(2),
        timeframe: '1h',
        confidence: 0.85,
        factors: [
          cpuRisk > 0.5 ? 'High CPU usage' : null,
          memRisk > 0.5 ? 'High memory usage' : null,
        ].filter(Boolean),
        _simulation: true,
      };
    },
  }),

  // ğŸ“š RAG ì§€ì‹ë² ì´ìŠ¤ ì‹œë®¬ë ˆì´ì…˜
  searchKnowledgeBase: tool({
    description: 'ê³¼ê±° ì¥ì•  ì´ë ¥ ë° í•´ê²° ë°©ë²•ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤ (ì‹œë®¬ë ˆì´ì…˜)',
    parameters: z.object({ query: z.string() }),
    execute: async ({ query }) => {
      // ğŸ’¡ Mock RAG ê²€ìƒ‰ ê²°ê³¼ (ì‹¤ì œ Supabase í˜¸ì¶œ ëŒ€ì‹ )
      const mockKnowledge = [
        {
          incident: 'CPU ê³¼ë¶€í•˜',
          solution: 'PM2 í´ëŸ¬ìŠ¤í„° ëª¨ë“œ í™•ì¥ ë° ë¡œë“œë°¸ëŸ°ì‹± ì ìš©',
          similarity: 0.92,
        },
        {
          incident: 'ë©”ëª¨ë¦¬ ëˆ„ìˆ˜',
          solution: 'Node.js ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ í›„ ìºì‹œ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€',
          similarity: 0.85,
        },
        {
          incident: 'ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±',
          solution: 'ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì • ë° ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ',
          similarity: 0.78,
        },
      ];

      // ì¿¼ë¦¬ í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨í•œ ë§¤ì¹­
      const keywords = query.toLowerCase();
      const matches = mockKnowledge.filter((k) =>
        keywords.includes(k.incident.toLowerCase().split(' ')[0])
      );

      return {
        matches: matches.length,
        topSolution: matches[0]?.solution || mockKnowledge[0].solution,
        relevance: matches[0]?.similarity || 0.65,
        allResults: matches.slice(0, 3),
        _simulation: true,
      };
    },
  }),

  // ğŸ“ˆ ì„œë²„ ìƒíƒœ ë¶„ì„ (í†µê³„ ê¸°ë°˜)
  analyzeServerHealth: tool({
    description: 'ì „ì²´ ì„œë²„ì˜ ê±´ê°•ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (ì‹œë®¬ë ˆì´ì…˜)',
    parameters: z.object({}),
    execute: async () => {
      const servers = useServerDataStore.getState().servers;

      const healthScore =
        servers.reduce((sum, s) => {
          const cpuScore = (100 - s.cpu) / 100;
          const memScore = (100 - s.memory) / 100;
          const diskScore = (100 - s.disk) / 100;
          return sum + (cpuScore + memScore + diskScore) / 3;
        }, 0) / servers.length;

      return {
        overallHealth: (healthScore * 100).toFixed(1),
        criticalServers: servers.filter((s) => s.status === 'critical').length,
        warningServers: servers.filter((s) => s.status === 'warning').length,
        healthyServers: servers.filter((s) => s.status === 'online').length,
        recommendations: [
          healthScore < 0.6 ? 'ì¼ë¶€ ì„œë²„ ë¦¬ì†ŒìŠ¤ í™•ì¥ í•„ìš”' : null,
          servers.some((s) => s.cpu > 80) ? 'CPU ë¶€í•˜ ë¶„ì‚° ê¶Œì¥' : null,
          servers.some((s) => s.memory > 85) ? 'ë©”ëª¨ë¦¬ ìµœì í™” í•„ìš”' : null,
        ].filter(Boolean),
        _simulation: true,
      };
    },
  }),
};
```

### 4. ğŸ“¡ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ê°œì„ 

**í˜„ì¬**: ê¸°ë³¸ text streamingë§Œ ì§€ì›

**ê°œì„ ì•ˆ**: Structured Streaming + Partial JSON

```typescript
import { streamObject, experimental_useObject } from 'ai/react';

// Server-side: Structured streaming
export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamObject({
    model: google('gemini-1.5-flash'),
    schema: z.object({
      analysis: z.object({
        intent: z.string(),
        complexity: z.number(),
        recommendation: z.string(),
      }),
      servers: z.array(z.object({
        id: z.string(),
        status: z.enum(['healthy', 'warning', 'critical']),
        metrics: z.object({
          cpu: z.number(),
          memory: z.number(),
        }),
      })),
      insights: z.array(z.string()),
    }),
    messages,
  });

  return result.toTextStreamResponse();
}

// Client-side: Partial object consumption
function AIChat() {
  const { object, isLoading } = experimental_useObject({
    api: '/api/ai/stream-object',
  });

  // ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶€ë¶„ ê°ì²´ í‘œì‹œ
  return (
    <div>
      {object?.analysis && (
        <div>ë³µì¡ë„: {object.analysis.complexity}/5</div>
      )}
      {object?.servers?.map(s => (
        <ServerCard key={s.id} data={s} />
      ))}
    </div>
  );
}
```

**íš¨ê³¼**:

- âœ… íƒ€ì… ì•ˆì „í•œ ìŠ¤íŠ¸ë¦¬ë° (Zod schema)
- âœ… ë¶€ë¶„ ê°ì²´ ì‹¤ì‹œê°„ ë Œë”ë§
- âœ… ë³µì¡í•œ ë°ì´í„° êµ¬ì¡° ì§€ì›

### 5. ğŸ¨ UI/UX ê°œì„ 

**ê°œì„ ì•ˆ 1**: Multi-step Reasoning ì‹œê°í™”

```typescript
// ê° ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© í‘œì‹œ
<ThinkingProcessVisualizer
  steps={[
    { step: 'ì§ˆë¬¸ ë¶„ì„', status: 'completed', duration: 120 },
    { step: 'RAG ê²€ìƒ‰', status: 'completed', duration: 340 },
    { step: 'ì„œë²„ ë°ì´í„° ì¡°íšŒ', status: 'processing', duration: null },
    { step: 'ì‘ë‹µ ìƒì„±', status: 'pending', duration: null },
  ]}
  isActive={isLoading}
/>
```

**ê°œì„ ì•ˆ 2**: Tool Call Results ì¸í„°ë™í‹°ë¸Œ í‘œì‹œ

```tsx
// Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ í™•ì¥ ê°€ëŠ¥í•œ ì¹´ë“œë¡œ í‘œì‹œ
{
  message.toolInvocations?.map((t) => (
    <ToolResultCard
      key={t.toolCallId}
      name={t.toolName}
      state={t.state}
      result={t.result}
      expandable
    />
  ));
}
```

**ê°œì„ ì•ˆ 3**: ì‹¤ì‹œê°„ ë¹„ìš© í‘œì‹œ

```tsx
<FreeTierMonitor>
  <div className="flex items-center space-x-2">
    <DollarSign className="h-4 w-4" />
    <span>ì´ë²ˆ ì‘ë‹µ ë¹„ìš©: $0.0012</span>
    <span className="text-green-600">(-85% vs Gemini API)</span>
  </div>
</FreeTierMonitor>
```

---

## ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼

### ì„±ëŠ¥ ê°œì„ 

- **ì‘ë‹µ ì‹œê°„**: 600ms â†’ 300ms (50% ê°ì†Œ, ì²« í† í° ë¹ ë¦„)
- **ì½”ë“œ í¬ê¸°**: 708ì¤„ â†’ ~150ì¤„ (79% ê°ì†Œ)
- **ìœ ì§€ë³´ìˆ˜ì„±**: â­â­â­ â†’ â­â­â­â­â­

### ì‚¬ìš©ì ê²½í—˜

- **ì‹¤ì‹œê°„ í”¼ë“œë°±**: ì‘ë‹µ ëŒ€ê¸° â†’ ì‹¤ì‹œê°„ thinking í‘œì‹œ
- **íˆ¬ëª…ì„±**: ë¸”ë™ë°•ìŠ¤ â†’ ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì • ê³µê°œ
- **ì‹ ë¢°ì„±**: Tool calling ìë™ ê²€ì¦

### ë¹„ìš© íš¨ìœ¨

- **RAG ìš°ì„ **: ë‹¨ìˆœ ì§ˆë¬¸ì€ $0 (Supabase only)
- **ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…**: ë³µì¡ë„ ê¸°ë°˜ ì—”ì§„ ì„ íƒ
- **ë¬´ë£Œ í‹°ì–´ ìµœì í™”**: ì›” $0 ìš´ì˜ ìœ ì§€

---

## ğŸš€ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: í•µì‹¬ ë§ˆì´ê·¸ë ˆì´ì…˜ (1-2ì¼)

1. `/api/ai/query` â†’ `/api/ai/unified-stream` ë³€í™˜
2. `AISidebarContent` â†’ `AISidebarV4` í†µí•©
3. ê¸°ë³¸ tool calling êµ¬í˜„

### Phase 2: Thinking Process ê³ ë„í™” (1ì¼)

1. Extended thinking tools êµ¬í˜„
2. ThinkingProcessVisualizer ê°œì„ 
3. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë‹¨ê³„ í‘œì‹œ

### Phase 3: Tool í™•ì¥ (1-2ì¼)

1. **í¬íŠ¸í´ë¦¬ì˜¤ìš© ì‹œë®¬ë ˆì´ì…˜ tools** êµ¬í˜„
2. Zustand Mock ë°ì´í„° ê¸°ë°˜ ë©”íŠ¸ë¦­ ì¡°íšŒ
3. ê°„ë‹¨í•œ ML ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ (CPU/ë©”ëª¨ë¦¬ ê¸°ë°˜)
4. Mock RAG ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰

### Phase 4: ê³ ê¸‰ ê¸°ëŠ¥ (ì„ íƒ, 1-2ì¼)

1. Structured streaming (`streamObject`)
2. Partial JSON rendering
3. Multi-modal ì…ë ¥ ì§€ì› (ì´ë¯¸ì§€, ì°¨íŠ¸)

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [Vercel AI SDK ê³µì‹ ë¬¸ì„œ](https://sdk.vercel.ai/docs)
- [Tool Calling Guide](https://sdk.vercel.ai/docs/ai-sdk-core/tools-and-tool-calling)
- [Structured Outputs](https://sdk.vercel.ai/docs/ai-sdk-core/structured-outputs)
- [React Hooks](https://sdk.vercel.ai/docs/ai-sdk-ui/overview)

---

**ë‹¤ìŒ ë‹¨ê³„**: ìš°ì„ ìˆœìœ„ í™•ì¸ í›„ Phase 1ë¶€í„° êµ¬í˜„ ì‹œì‘
