# ğŸ“¡ OpenManager v5 - API ë ˆí¼ëŸ°ìŠ¤

**ë²„ì „**: v5.13.5  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-05-31  
**Base URL**: `http://localhost:3001` (ê°œë°œ) / `https://your-app.vercel.app` (í”„ë¡œë•ì…˜)  

---

## ğŸ¯ API ê°œìš”

OpenManager v5ëŠ” **RESTful API**ì™€ **WebSocket** ê¸°ë°˜ì˜ ì‹¤ì‹œê°„ í†µì‹ ì„ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“  APIëŠ” JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ìœ¼ë©°, Prometheus í‘œì¤€ ë©”íŠ¸ë¦­ì„ ì§€ì›í•©ë‹ˆë‹¤.

### ì¸ì¦
```bash
# ê´€ë¦¬ì APIëŠ” PIN ê¸°ë°˜ ì¸ì¦ í•„ìš”
Authorization: Bearer <admin_token>

# ì¼ë°˜ APIëŠ” ì¸ì¦ ë¶ˆí•„ìš” (ê°œë°œ í™˜ê²½)
```

### ì‘ë‹µ í˜•ì‹
```json
{
  "success": true,
  "data": { /* ì‘ë‹µ ë°ì´í„° */ },
  "message": "ì„±ê³µ ë©”ì‹œì§€",
  "timestamp": "2025-05-31T10:00:00Z",
  "version": "v5.13.5"
}
```

---

## ğŸ”§ ì‹œìŠ¤í…œ ì œì–´ API

### ì‹œìŠ¤í…œ ìƒíƒœ ê´€ë¦¬

#### GET /api/system/status
ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ ì¡°íšŒ

```bash
curl http://localhost:3001/api/system/status
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "data": {
    "system_running": true,
    "timers_active": 4,
    "memory_usage": "80MB",
    "cpu_usage": "12%",
    "uptime": "2h 30m",
    "active_connections": 15,
    "last_update": "2025-05-31T10:00:00Z"
  }
}
```

#### POST /api/system/start
ì‹œìŠ¤í…œ ì‹œì‘

```bash
curl -X POST http://localhost:3001/api/system/start
```

#### POST /api/system/stop
ì‹œìŠ¤í…œ ì¢…ë£Œ

```bash
curl -X POST http://localhost:3001/api/system/stop
```

#### POST /api/system/pause
ì‹œìŠ¤í…œ ì¼ì‹œì •ì§€

```bash
curl -X POST http://localhost:3001/api/system/pause
```

### íƒ€ì´ë¨¸ ê´€ë¦¬

#### GET /api/system/timers
í™œì„± íƒ€ì´ë¨¸ ëª©ë¡ ì¡°íšŒ

```bash
curl http://localhost:3001/api/system/timers
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "data": {
    "active_timers": [
      {
        "id": "unified-metrics-generation",
        "interval": 15000,
        "next_execution": "2025-05-31T10:00:15Z",
        "status": "running"
      },
      {
        "id": "unified-ai-analysis", 
        "interval": 30000,
        "next_execution": "2025-05-31T10:00:30Z",
        "status": "running"
      }
    ],
    "total_count": 4
  }
}
```

---

## ğŸ“Š ë©”íŠ¸ë¦­ API

### í†µí•© ë©”íŠ¸ë¦­ ê´€ë¦¬

#### GET /api/unified-metrics
í†µí•© ë©”íŠ¸ë¦­ ë°ì´í„° ì¡°íšŒ

**ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°:**
- `action`: `servers` | `summary` | `detailed`
- `limit`: ë°˜í™˜í•  ì„œë²„ ìˆ˜ (ê¸°ë³¸ê°’: 20)
- `format`: `json` | `prometheus`

```bash
# ì„œë²„ ëª©ë¡ ì¡°íšŒ
curl "http://localhost:3001/api/unified-metrics?action=servers&limit=10"

# ìš”ì•½ ì •ë³´ ì¡°íšŒ
curl "http://localhost:3001/api/unified-metrics?action=summary"

# Prometheus í˜•ì‹
curl "http://localhost:3001/api/unified-metrics?format=prometheus"
```

**ì‘ë‹µ (servers):**
```json
{
  "success": true,
  "data": {
    "servers": [
      {
        "id": "web-server-01",
        "name": "Web Server 01",
        "type": "web",
        "status": "healthy",
        "metrics": {
          "cpu": 75.3,
          "memory": 68.7,
          "disk": 45.2,
          "network": {
            "in": 1234567,
            "out": 987654
          }
        },
        "alerts": [],
        "last_update": "2025-05-31T10:00:00Z"
      }
    ],
    "total_count": 20,
    "healthy_count": 18,
    "warning_count": 2,
    "critical_count": 0
  }
}
```

#### POST /api/unified-metrics
ë©”íŠ¸ë¦­ ë°ì´í„° ì—…ë°ì´íŠ¸

```bash
curl -X POST http://localhost:3001/api/unified-metrics \
  -H "Content-Type: application/json" \
  -d '{
    "action": "update_server",
    "server_id": "web-server-01",
    "metrics": {
      "cpu": 80.5,
      "memory": 72.1
    }
  }'
```

### Prometheus í˜¸í™˜ API

#### GET /api/prometheus/metrics
Prometheus í‘œì¤€ ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸

```bash
curl http://localhost:3001/api/prometheus/metrics
```

**ì‘ë‹µ (Prometheus í˜•ì‹):**
```prometheus
# HELP openmanager_cpu_usage_percent CPU usage percentage
# TYPE openmanager_cpu_usage_percent gauge
openmanager_cpu_usage_percent{server="web-01"} 75.3

# HELP openmanager_memory_usage_percent Memory usage percentage  
# TYPE openmanager_memory_usage_percent gauge
openmanager_memory_usage_percent{server="web-01"} 68.7

# HELP openmanager_disk_usage_percent Disk usage percentage
# TYPE openmanager_disk_usage_percent gauge
openmanager_disk_usage_percent{server="web-01"} 45.2
```

#### GET /api/prometheus/query
Prometheus ì¿¼ë¦¬ ì‹¤í–‰

**ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°:**
- `query`: PromQL ì¿¼ë¦¬
- `time`: ì¡°íšŒ ì‹œì  (Unix timestamp)

```bash
curl "http://localhost:3001/api/prometheus/query?query=openmanager_cpu_usage_percent&time=1640995200"
```

---

## ğŸ¤– AI ì—ì´ì „íŠ¸ API

### MCP ê¸°ë°˜ AI ë¶„ì„

#### POST /api/ai/mcp
MCP ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¥¼ í†µí•œ AI ë¶„ì„

```bash
curl -X POST http://localhost:3001/api/ai/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "query": "CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ ì„œë²„ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
    "parameters": {
      "metrics": {
        "cpu": [75, 80, 85, 90, 95],
        "memory": [60, 65, 70, 75, 80]
      }
    },
    "context": {
      "session_id": "analysis_session_123",
      "urgency": "medium"
    }
  }'
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "data": {
    "analysis_id": "mcp_analysis_456",
    "tools_used": ["statistical_analysis", "anomaly_detection"],
    "execution_time": 1.2,
    "results": {
      "summary": "CPU ì‚¬ìš©ë¥ ì´ í‰ìƒì‹œ ëŒ€ë¹„ 40% ì¦ê°€í–ˆìŠµë‹ˆë‹¤.",
      "findings": [
        {
          "tool": "statistical_analysis",
          "result": "í‰ê·  CPU: 85%, í‘œì¤€í¸ì°¨: 7.9",
          "confidence": 0.95
        }
      ],
      "recommendations": [
        "ì›Œí¬ë¡œë“œ ë¶„ì‚° ê²€í†  í•„ìš”",
        "ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥ì„± í™•ì¸"
      ]
    }
  }
}
```

### AI ì—ì´ì „íŠ¸ ê³„ì¸µë³„ API

#### POST /api/ai-agent/optimized
ìµœì í™”ëœ AI ì—”ì§„ (1ì°¨)

```bash
curl -X POST http://localhost:3001/api/ai-agent/optimized \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ì„œë²„ ì„±ëŠ¥ ë¶„ì„",
    "data": { /* ë©”íŠ¸ë¦­ ë°ì´í„° */ }
  }'
```

#### POST /api/ai-agent/pattern-query
íŒ¨í„´ ë§¤ì¹­ ì‹œìŠ¤í…œ (2ì°¨)

```bash
curl -X POST http://localhost:3001/api/ai-agent/pattern-query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ì´ìƒ íŒ¨í„´ íƒì§€",
    "pattern_type": "anomaly"
  }'
```

#### POST /api/ai-agent/integrated
í†µí•© ì‹œìŠ¤í…œ (3ì°¨ í´ë°±)

```bash
curl -X POST http://localhost:3001/api/ai-agent/integrated \
  -H "Content-Type: application/json" \
  -d '{
    "query": "ì „ì²´ ì‹œìŠ¤í…œ ë¶„ì„",
    "fallback_mode": true
  }'
```

### ì‹¤ì‹œê°„ ì‚¬ê³  ê³¼ì • ìŠ¤íŠ¸ë¦¬ë°

#### GET /api/ai-agent/thinking-process
Server-Sent Events (SSE) ìŠ¤íŠ¸ë¦¼

```bash
curl -N http://localhost:3001/api/ai-agent/thinking-process \
  -H "Accept: text/event-stream"
```

**ì‘ë‹µ (SSE ìŠ¤íŠ¸ë¦¼):**
```
data: {"step": "tool_selection", "message": "ë¶„ì„ ë„êµ¬ ì„ íƒ ì¤‘..."}

data: {"step": "data_processing", "message": "ë©”íŠ¸ë¦­ ë°ì´í„° ì²˜ë¦¬ ì¤‘..."}

data: {"step": "pattern_analysis", "message": "íŒ¨í„´ ë¶„ì„ ì‹¤í–‰ ì¤‘..."}

data: {"step": "complete", "result": {...}}
```

---

## ğŸ“Š ë°ì´í„° ìƒì„± API

### ì„œë²„ ë°ì´í„° ì‹œë®¬ë ˆì´í„°

#### GET /api/data-generator/status
ë°ì´í„° ìƒì„±ê¸° ìƒíƒœ ì¡°íšŒ

```bash
curl http://localhost:3001/api/data-generator/status
```

#### POST /api/data-generator/start
ë°ì´í„° ìƒì„± ì‹œì‘

```bash
curl -X POST http://localhost:3001/api/data-generator/start \
  -H "Content-Type: application/json" \
  -d '{
    "scenario": "normal",
    "duration": 3600,
    "servers": 20
  }'
```

#### POST /api/data-generator/scenario
íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰

```bash
curl -X POST http://localhost:3001/api/data-generator/scenario \
  -H "Content-Type: application/json" \
  -d '{
    "type": "cpu_spike",
    "target_servers": ["web-01", "web-02"],
    "duration": 300,
    "intensity": "high"
  }'
```

### ìˆœì°¨ ì„œë²„ ìƒì„±

#### POST /api/servers/next
ë‹¤ìŒ ì„œë²„ ìƒì„±

```bash
curl -X POST http://localhost:3001/api/servers/next \
  -H "Content-Type: application/json" \
  -d '{
    "currentCount": 5,
    "reset": false
  }'
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "data": {
    "server": {
      "id": "database-server-01",
      "name": "Database Server 01",
      "type": "database",
      "status": "healthy"
    },
    "currentCount": 6,
    "isComplete": false,
    "progress": 30,
    "nextServerType": "API Server"
  }
}
```

---

## ğŸ”” ì•Œë¦¼ ë° ì›¹ì†Œì¼“ API

### WebSocket ì—°ê²°

#### WS /api/websocket/servers
ì‹¤ì‹œê°„ ì„œë²„ ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¼

```javascript
const ws = new WebSocket('ws://localhost:3001/api/websocket/servers');

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­:', data);
};
```

### ì•Œë¦¼ API

#### GET /api/alerts
í™œì„± ì•Œë¦¼ ëª©ë¡

```bash
curl http://localhost:3001/api/alerts
```

#### POST /api/notifications/slack
Slack ì•Œë¦¼ ì „ì†¡

```bash
curl -X POST http://localhost:3001/api/notifications/slack \
  -H "Content-Type: application/json" \
  -d '{
    "message": "CPU ì‚¬ìš©ë¥  ê²½ê³ ",
    "severity": "warning",
    "server": "web-01"
  }'
```

---

## ğŸ› ï¸ ê´€ë¦¬ì API

### ì‹œìŠ¤í…œ ê´€ë¦¬

#### GET /api/admin/logs
ì‹œìŠ¤í…œ ë¡œê·¸ ì¡°íšŒ

**ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°:**
- `level`: `debug` | `info` | `warn` | `error`
- `component`: ì»´í¬ë„ŒíŠ¸ ì´ë¦„
- `limit`: ë¡œê·¸ ìˆ˜ (ê¸°ë³¸ê°’: 100)

```bash
curl "http://localhost:3001/api/admin/logs?level=error&limit=50" \
  -H "Authorization: Bearer <admin_token>"
```

#### GET /api/admin/metrics
ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­

```bash
curl http://localhost:3001/api/admin/metrics \
  -H "Authorization: Bearer <admin_token>"
```

#### POST /api/admin/backup
ë°ì´í„° ë°±ì—… ìƒì„±

```bash
curl -X POST http://localhost:3001/api/admin/backup \
  -H "Authorization: Bearer <admin_token>"
```

### AI ì—ì´ì „íŠ¸ ê´€ë¦¬

#### GET /api/ai-agent/admin/status
AI ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ

```bash
curl http://localhost:3001/api/ai-agent/admin/status \
  -H "Authorization: Bearer <admin_token>"
```

#### POST /api/ai-agent/admin/retrain
AI ëª¨ë¸ ì¬í›ˆë ¨

```bash
curl -X POST http://localhost:3001/api/ai-agent/admin/retrain \
  -H "Authorization: Bearer <admin_token>" \
  -H "Content-Type: application/json" \
  -d '{
    "force_update": true,
    "clear_cache": true
  }'
```

---

## ğŸ“ˆ ì„±ëŠ¥ ë° í—¬ìŠ¤ì²´í¬ API

### í—¬ìŠ¤ì²´í¬

#### GET /api/health
ê¸°ë³¸ í—¬ìŠ¤ì²´í¬

```bash
curl http://localhost:3001/api/health
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "data": {
    "status": "healthy",
    "uptime": "2h 30m",
    "memory": "80MB",
    "cpu": "12%",
    "timestamp": "2025-05-31T10:00:00Z"
  }
}
```

#### GET /api/health/detailed
ìƒì„¸ í—¬ìŠ¤ì²´í¬

```bash
curl http://localhost:3001/api/health/detailed
```

### ì„±ëŠ¥ ë©”íŠ¸ë¦­

#### GET /api/system/performance
ì‹œìŠ¤í…œ ì„±ëŠ¥ ì§€í‘œ

```bash
curl http://localhost:3001/api/system/performance
```

#### GET /api/system/memory
ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìƒì„¸

```bash
curl http://localhost:3001/api/system/memory
```

---

## ğŸ”§ ìœ í‹¸ë¦¬í‹° API

### ìºì‹œ ê´€ë¦¬

#### DELETE /api/cache/clear
ì „ì²´ ìºì‹œ ì •ë¦¬

```bash
curl -X DELETE http://localhost:3001/api/cache/clear
```

#### GET /api/cache/stats
ìºì‹œ í†µê³„

```bash
curl http://localhost:3001/api/cache/stats
```

### ì„¤ì • ê´€ë¦¬

#### GET /api/config
í˜„ì¬ ì„¤ì • ì¡°íšŒ

```bash
curl http://localhost:3001/api/config
```

#### POST /api/config/adaptive
ì ì‘í˜• ì„¤ì • ì—…ë°ì´íŠ¸

```bash
curl -X POST http://localhost:3001/api/config/adaptive \
  -H "Content-Type: application/json" \
  -d '{
    "auto_scaling": true,
    "performance_mode": "optimized"
  }'
```

---

## ğŸ“š SDK ë° í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬

### JavaScript/TypeScript SDK

```typescript
import { OpenManagerClient } from '@openmanager/sdk';

const client = new OpenManagerClient({
  baseUrl: 'http://localhost:3001',
  apiKey: 'your-api-key' // ì„ íƒì‚¬í•­
});

// ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
const status = await client.system.getStatus();

// AI ë¶„ì„ ì‹¤í–‰
const analysis = await client.ai.analyze({
  query: 'CPU ì‚¬ìš©ë¥  ë¶„ì„',
  data: metricsData
});

// ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ êµ¬ë…
client.metrics.subscribe((data) => {
  console.log('ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­:', data);
});
```

### Python SDK

```python
from openmanager_sdk import OpenManagerClient

client = OpenManagerClient(
    base_url='http://localhost:3001',
    api_key='your-api-key'  # ì„ íƒì‚¬í•­
)

# ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
status = client.system.get_status()

# AI ë¶„ì„ ì‹¤í–‰
analysis = client.ai.analyze(
    query='CPU ì‚¬ìš©ë¥  ë¶„ì„',
    data=metrics_data
)
```

---

## ğŸš¨ ì—ëŸ¬ ì½”ë“œ

### HTTP ìƒíƒœ ì½”ë“œ
- `200`: ì„±ê³µ
- `400`: ì˜ëª»ëœ ìš”ì²­
- `401`: ì¸ì¦ í•„ìš”
- `403`: ê¶Œí•œ ì—†ìŒ
- `404`: ë¦¬ì†ŒìŠ¤ ì—†ìŒ
- `429`: ìš”ì²­ ì œí•œ ì´ˆê³¼
- `500`: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜

### ì»¤ìŠ¤í…€ ì—ëŸ¬ ì½”ë“œ
```json
{
  "success": false,
  "error": {
    "code": "AI_ENGINE_TIMEOUT",
    "message": "AI ì—”ì§„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼",
    "details": "Python ì—”ì§„ ì—°ê²° ì‹¤íŒ¨, TypeScript í´ë°±ìœ¼ë¡œ ì „í™˜ë¨"
  }
}
```

---

**ì´ì „ ë¬¸ì„œ**: [7_TROUBLESHOOTING.md](./7_TROUBLESHOOTING.md) - ë¬¸ì œí•´ê²° ê°€ì´ë“œ  
**ë‹¤ìŒ ë¬¸ì„œ**: [9_MCP_ENGINE_REFERENCE.md](./9_MCP_ENGINE_REFERENCE.md) - MCP ì—”ì§„ ë ˆí¼ëŸ°ìŠ¤ 