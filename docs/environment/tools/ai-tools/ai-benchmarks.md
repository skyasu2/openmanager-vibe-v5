# AI 도구 벤치마크 비교

**2025년 성능 지표** - Codex, Gemini, Qwen 벤치마크

최종 업데이트: 2025-11-27

---

## 📊 벤치마크 요약

| AI 도구    | 버전              | HumanEval               | SWE-bench | 특화 영역           |
| ---------- | ----------------- | ----------------------- | --------- | ------------------- |
| **Codex**  | GPT-5 v0.58.0     | 94%                     | 74.5%     | 함수 단위 문제 해결 |
| **Gemini** | 2.5 Flash v0.8.1  | -                       | 54%       | 범용 개발           |
| **Qwen**   | 2.5 Coder v0.0.14 | 88.4% (7B), 92.7% (32B) | -         | 성능 최적화         |

---

## 🎯 Codex CLI (GPT-5 v0.58.0)

### 핵심 성능

- **HumanEval**: 94% pass@1 (함수 단위 문제 해결 최강)
- **SWE-bench Verified**: 74.5% (다중 파일 버그 수정)
- **Code Refactoring**: 51.3% vs GPT-5 33.9%
- **토큰 효율**: 93.7% 절약
- **LiveCodeBench**: 70%+ (대화형 코드 편집)

### 특징

- **철학**: "사용자 지침 준수 & 재현 가능성"
- **응답 속도**: 6~12초 (자동 코드 리뷰 로그 기준)
- **한도**: 30-150 메시지/5시간 (실사용 기준)

---

## 🌐 Gemini CLI (2.5 Flash v0.8.1)

### 핵심 성능

- **SWE-bench Verified**: 54% (48.9% → 54% 5% 개선)
- **테스트 커버리지**: 98.2% (54/55 통과) - 프로젝트 실적
- **문제 발견율**: 95%+
- **다목적 활용**: 아키텍처, 구현, 디버깅, 리뷰 전반

### 특징

- **역할**: Universal AI Developer Partner (범용 AI 개발 파트너)
- **Proactive Problem Solving**: 요청 너머의 근본 원인 파악 및 해결
- **Objective Verification**: "정말 최선인가?" 끊임없이 질문하고 검증
- **무료 티어**: OAuth 인증, 1,000 RPD, 60 RPM

---

## ⚡ Qwen Code CLI (2.5 Coder v0.0.14)

### 핵심 성능

- **HumanEval**: 88.4% (7B), 92.7% (32B) - 오픈소스 최고 성능
- **MBPP**: 84.5% - Python 코드 생성 특화
- **Math**: 57.2% (32B) - 수학적 최적화
- **컨텍스트**: 256K 기본, 1M 확장 가능

### 특징

- **Apache 2.0**: 100% 무료, 자체 호스팅 가능
- **무료 티어**: 2,000/day, 60/minute
- **WSL 최적화**: 병렬 작업 지원 (동시 세션 10개)

---

## 📈 실전 성능 비교 (OpenManager VIBE 프로젝트)

### 자동 코드 리뷰 시스템 (v5.0.0)

| 항목               | Codex     | Gemini    | Qwen        | Claude Code |
| ------------------ | --------- | --------- | ----------- | ----------- |
| **평균 응답 시간** | 6-12초    | 8-15초    | 10-20초     | 5-10초      |
| **가용성**         | 99.9%     | 99.9%     | 99.5%       | 99.99%      |
| **비율**           | 25%       | 25%       | 25%         | 25% (폴백)  |
| **강점**           | 정밀 분석 | 범용 검증 | 성능 최적화 | 통합 리뷰   |

### 토큰 효율성

- **Codex**: 93.7% 절약 (벤치마크)
- **MCP 활용**: 85% 절약 (MCP 82% + @-mention 3%)
- **Claude Code Skills**: 평균 73% 절약

---

## 🎯 도구 선택 가이드

### 상황별 최적 AI

| 상황                   | 1순위  | 2순위  | 이유             |
| ---------------------- | ------ | ------ | ---------------- |
| **함수 단위 버그**     | Codex  | Claude | HumanEval 94%    |
| **다중 파일 리팩토링** | Codex  | Gemini | SWE-bench 74.5%  |
| **아키텍처 설계**      | Gemini | Claude | 범용 개발 파트너 |
| **성능 최적화**        | Qwen   | Codex  | Math 57.2%       |
| **통합 리뷰**          | Claude | Gemini | 99.99% 가용성    |

---

## 📚 관련 문서

- **상세 사용법**: AGENTS.md (Codex), GEMINI.md, QWEN.md
- **코딩 규칙**: <!-- Imported from: docs/ai/ai-coding-standards.md -->
- **자동 리뷰**: <!-- Imported from: scripts/code-review/auto-ai-review.sh -->

---

**결론**: 각 AI 도구는 특화 영역에서 최고 성능을 발휘하며, 1:1:1:1 균등 분배로 99.99% 가용성을 달성합니다.
