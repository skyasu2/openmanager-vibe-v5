# GCP Functions í†µí•© ë¶„ì„ ë° Provider ì„¤ê³„

> **ğŸ“ ë¹ ë¥¸ ì°¸ì¡°**: í•µì‹¬ ìš”ì•½ì€ [@GCP-FUNCTIONS-SUMMARY.md](./GCP-FUNCTIONS-SUMMARY.md) ì°¸ì¡°

**ì‘ì„±ì¼**: 2025-11-15
**ëª©ì **: ì‹¤ì œ ìš´ì˜ ì¤‘ì¸ Google Cloud Functions Python ì½”ë“œ ë¶„ì„ ë° Unified Engine Provider í†µí•© ì„¤ê³„

---

## ğŸ“Š ê°œìš”

### ë°œê²¬ëœ GCP Functions (3ê°œ)

| Function                 | ìœ„ì¹˜                                         | ëª©ì                           | ë¼ì¸ ìˆ˜ | ì„±ëŠ¥        |
| ------------------------ | -------------------------------------------- | ----------------------------- | ------- | ----------- |
| **enhanced-korean-nlp**  | `gcp-functions/enhanced-korean-nlp/main.py`  | í•œêµ­ì–´ NLP 6ë‹¨ê³„ ë¶„ì„         | 928ì¤„   | 10-50ë°°     |
| **ml-analytics-engine**  | `gcp-functions/ml-analytics-engine/main.py`  | ML ê¸°ë°˜ ì´ìƒ íƒì§€/íŠ¸ë Œë“œ ë¶„ì„ | 418ì¤„   | 10-50ë°°     |
| **unified-ai-processor** | `gcp-functions/unified-ai-processor/main.py` | AI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (ë³‘ë ¬ ì²˜ë¦¬) | 405ì¤„   | ìºì‹± + ë³‘ë ¬ |

**ì¤‘ìš” ë°œê²¬**:

- âœ… **ì‹¤ì œ ML êµ¬í˜„ ì¡´ì¬** (scikit-learn ê¸°ë°˜, DBSCAN, StandardScaler, Linear Regression)
- âœ… **í”„ë¡œë•ì…˜ í™˜ê²½ ìš´ì˜ ì¤‘** (ë³´ì•ˆ, ìºì‹±, ì—ëŸ¬ ì²˜ë¦¬ ì™„ë¹„)
- âŒ **ë”ë¯¸ êµ¬í˜„ ì •ë¦¬ í•„ìš”** (`LightweightMLEngine.ts` â†’ ëœë¤ ê°’ë§Œ ë°˜í™˜)

---

## ğŸ” ê° Function ìƒì„¸ ë¶„ì„

### 1. Enhanced Korean NLP (`enhanced-korean-nlp`)

#### ê¸°ëŠ¥ ê°œìš”

**6ë‹¨ê³„ ë¶„ì„ íŒŒì´í”„ë¼ì¸**ìœ¼ë¡œ ì„œë²„ ëª¨ë‹ˆí„°ë§ íŠ¹í™” í•œêµ­ì–´ ì²˜ë¦¬

```python
# Phase 1: Basic NLU analysis (ê¸°ë³¸ ìì—°ì–´ ì´í•´)
# Phase 2: Semantic analysis (ì˜ë¯¸ ë¶„ì„)
# Phase 3: Domain-specific analysis (ë„ë©”ì¸ íŠ¹í™”)
# Phase 4: Context analysis (ì»¨í…ìŠ¤íŠ¸ ë¶„ì„)
# Phase 5: Response guide generation (ì‘ë‹µ ê°€ì´ë“œ)
# Phase 6: Quality metrics calculation (í’ˆì§ˆ ë©”íŠ¸ë¦­)
```

#### API ì¸í„°í˜ì´ìŠ¤

**ìš”ì²­ í˜•ì‹**:

```json
{
  "query": "ì›¹ì„œë²„ CPU ì‚¬ìš©ë¥ ì´ ë†’ì•„ìš”",
  "context": {
    "user_id": "user123",
    "session_id": "session456",
    "previous_query": "ì„œë²„ ìƒíƒœ í™•ì¸",
    "servers": [{ "id": "web-001", "type": "web_server" }]
  },
  "features": {
    "entity_extraction": true,
    "semantic_analysis": true,
    "response_guidance": true
  }
}
```

**ì‘ë‹µ í˜•ì‹**:

```json
{
  "success": true,
  "data": {
    "intent": "performance_check",
    "entities": [
      { "type": "server", "value": "web-001", "confidence": 0.95 },
      { "type": "metric", "value": "cpu_usage", "confidence": 0.98 }
    ],
    "semantic_analysis": {
      "primary_topic": "ì„œë²„ ì„±ëŠ¥",
      "urgency_level": "high",
      "action_needed": "immediate_check"
    },
    "server_context": {
      "target_servers": ["web-001"],
      "target_metrics": ["cpu_usage"],
      "urgency": "high"
    },
    "response_guidance": {
      "suggested_tone": "professional_urgent",
      "key_points": ["CPU ì‚¬ìš©ë¥  í™•ì¸", "ì›ì¸ ë¶„ì„", "ìµœì í™” ì œì•ˆ"]
    },
    "quality_metrics": {
      "confidence": 0.92,
      "completeness": 0.88
    }
  },
  "function_name": "enhanced-korean-nlp",
  "source": "gcp-functions",
  "timestamp": "2025-11-15T10:30:00Z",
  "performance": {
    "total_processing_time_ms": 245,
    "phase_times": {
      "basic_nlu": 45,
      "semantic": 60,
      "domain": 50,
      "context": 40,
      "guidance": 30,
      "quality": 20
    }
  }
}
```

#### ë„ë©”ì¸ ì–´íœ˜ (Domain Vocabulary)

**ì„œë²„ ê´€ë ¨** (45ê°œ):

- í•œêµ­ì–´: ì›¹ì„œë²„, APIì„œë²„, ë°ì´í„°ë² ì´ìŠ¤, ë¡œë“œë°¸ëŸ°ì„œ, ìºì‹œì„œë²„
- ì˜ì–´: web_server, api_server, database, load_balancer, cache_server

**ë©”íŠ¸ë¦­** (80ê°œ):

- í•œêµ­ì–´: CPUì‚¬ìš©ë¥ , ë©”ëª¨ë¦¬, ë””ìŠ¤í¬, ë„¤íŠ¸ì›Œí¬, ì‘ë‹µì‹œê°„
- ì˜ì–´: cpu_usage, memory, disk, network, response_time

**ë¦¬ëˆ…ìŠ¤ ëª…ë ¹ì–´** (30ê°œ):

- top, htop, ps, netstat, ss, lsof, du, df, free

**ë³´ì•ˆ ê²€ì¦**:

```python
malicious_patterns = [
    'system(', 'exec(', 'eval(', '__import__',
    'rm -rf', 'DROP TABLE', '<script',
    'ê´€ë¦¬ì ê¶Œí•œ', 'ì‹œìŠ¤í…œ í•´í‚¹'
]
```

#### ì„±ëŠ¥ íŠ¹ì„±

- **í‰ê·  ì‘ë‹µ ì‹œê°„**: 245ms (6ë‹¨ê³„ íŒŒì´í”„ë¼ì¸)
- **ìºì‹± ì „ëµ**: ì—†ìŒ (stateless, ë§¤ë²ˆ ë¶„ì„)
- **ë™ì‹œ ì²˜ë¦¬**: GCP Functions ìë™ ìŠ¤ì¼€ì¼ë§
- **ë¬´ë£Œ í‹°ì–´ í•œë„**: 2M í˜¸ì¶œ/ì›”, 400K GB-ì´ˆ/ì›”

---

### 2. ML Analytics Engine (`ml-analytics-engine`)

#### ê¸°ëŠ¥ ê°œìš”

**ì‹¤ì œ ML ì•Œê³ ë¦¬ì¦˜**ì„ ì‚¬ìš©í•œ ì´ìƒ íƒì§€, íŠ¸ë Œë“œ ë¶„ì„, íŒ¨í„´ ì¸ì‹

```python
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN
import pandas as pd
import numpy as np

class MLAnalyticsEngine:
    def __init__(self):
        self.scaler = StandardScaler()
        self.anomaly_detector = DBSCAN(eps=0.5, min_samples=5)
```

#### ì£¼ìš” ê¸°ëŠ¥

**1. ì´ìƒ íƒì§€ (Anomaly Detection)**

- **ì•Œê³ ë¦¬ì¦˜**: 3-sigma í†µê³„ ë°©ë²•
- **ì…ë ¥**: ì‹œê³„ì—´ ë©”íŠ¸ë¦­ ë°ì´í„° (ìµœì†Œ 10ê°œ ë°ì´í„° í¬ì¸íŠ¸)
- **ì¶œë ¥**: ì´ìƒ ì§•í›„ ë¦¬ìŠ¤íŠ¸ (severity: low/medium/high)

```python
async def _detect_anomalies(self, data: List[MetricData]) -> List[AnomalyResult]:
    mean = np.mean(values)
    std = np.std(values)
    lower_bound = mean - 3 * std
    upper_bound = mean + 3 * std

    # 3-sigma ë²”ìœ„ ë°–ì˜ ê°’ì„ ì´ìƒ ì§•í›„ë¡œ íŒë‹¨
    if value < lower_bound or value > upper_bound:
        severity = self._calculate_severity(value, mean, std)
        anomalies.append(AnomalyResult(...))
```

**2. íŠ¸ë Œë“œ ë¶„ì„ (Trend Analysis)**

- **ì•Œê³ ë¦¬ì¦˜**: ì„ í˜• íšŒê·€ (Linear Regression)
- **ì…ë ¥**: ì‹œê³„ì—´ ë©”íŠ¸ë¦­ ë°ì´í„° (ìµœì†Œ 5ê°œ ë°ì´í„° í¬ì¸íŠ¸)
- **ì¶œë ¥**: ë°©í–¥ì„± (increasing/decreasing/stable), ë³€í™”ìœ¨, 24ì‹œê°„ ì˜ˆì¸¡

```python
async def _analyze_trend(self, data: List[MetricData]) -> TrendAnalysis:
    # Simple linear regression
    slope = np.polyfit(x, y, 1)[0]

    # Determine direction
    if abs(slope) < 0.01:
        direction = 'stable'
    elif slope > 0:
        direction = 'increasing'
    else:
        direction = 'decreasing'

    # 24h prediction
    prediction_24h = last_value + (slope * 24)
```

**3. íŒ¨í„´ ì¸ì‹ (Pattern Recognition)**

- **Peak hour íƒì§€**: ì‹œê°„ëŒ€ë³„ í‰ê·  ì‚¬ìš©ëŸ‰ ë¶„ì„
- **Weekly cycle**: ì£¼ê°„ ë°˜ë³µ íŒ¨í„´ íƒì§€ (168ê°œ ì´ìƒ ë°ì´í„° í•„ìš”)

#### API ì¸í„°í˜ì´ìŠ¤

**ìš”ì²­ í˜•ì‹**:

```json
{
  "metrics": [
    {
      "timestamp": "2025-11-15T10:00:00Z",
      "value": 75.5,
      "server_id": "web-001",
      "metric_type": "cpu"
    },
    {
      "timestamp": "2025-11-15T11:00:00Z",
      "value": 78.2,
      "server_id": "web-001",
      "metric_type": "cpu"
    }
  ],
  "context": {
    "analysis_type": "anomaly_detection",
    "threshold": 0.8
  }
}
```

**ì‘ë‹µ í˜•ì‹**:

```json
{
  "success": true,
  "data": {
    "anomalies": [
      {
        "is_anomaly": true,
        "severity": "high",
        "confidence": 0.85,
        "timestamp": "2025-11-15T12:00:00Z",
        "value": 95.3,
        "expected_range": [40.2, 82.7]
      }
    ],
    "trend": {
      "direction": "increasing",
      "rate_of_change": 0.45,
      "prediction_24h": 82.5,
      "confidence": 0.75
    },
    "patterns": [
      {
        "type": "peak_hour",
        "description": "Peak usage typically occurs at 14:00",
        "confidence": 0.8
      }
    ],
    "recommendations": [
      "ğŸš¨ 1ê°œì˜ ì‹¬ê°í•œ ì´ìƒ ì§•í›„ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.",
      "ğŸ“ˆ ì§€ì†ì ì¸ ì¦ê°€ ì¶”ì„¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìš©ëŸ‰ í™•ì¥ì„ ê³ ë ¤í•˜ì„¸ìš”."
    ]
  },
  "function_name": "ml-analytics-engine",
  "source": "gcp-functions",
  "timestamp": "2025-11-15T10:30:00Z",
  "performance": {
    "processing_time_ms": 187,
    "metrics_analyzed": 24,
    "anomalies_found": 1
  }
}
```

#### ì„±ëŠ¥ íŠ¹ì„±

- **í‰ê·  ì‘ë‹µ ì‹œê°„**: 187ms (24ê°œ ë©”íŠ¸ë¦­ ê¸°ì¤€)
- **ìµœì†Œ ë°ì´í„°**: 10ê°œ (ì´ìƒ íƒì§€), 5ê°œ (íŠ¸ë Œë“œ ë¶„ì„)
- **ìµœì  ë°ì´í„°**: 168ê°œ ì´ìƒ (ì£¼ê°„ íŒ¨í„´ íƒì§€)
- **ë¬´ë£Œ í‹°ì–´ í•œë„**: 2M í˜¸ì¶œ/ì›”

---

### 3. Unified AI Processor (`unified-ai-processor`)

#### ê¸°ëŠ¥ ê°œìš”

**ë©€í‹° í”„ë¡œì„¸ì„œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**ì„ í†µí•œ í†µí•© AI ë¶„ì„

```python
from cachetools import TTLCache
import httpx
import asyncio

# Global cache (5 minutes TTL)
response_cache = TTLCache(maxsize=1000, ttl=300)

class UnifiedAIProcessor:
    async def _process_parallel(self, request):
        async with httpx.AsyncClient(timeout=10) as client:
            tasks = [self._call_processor(client, p, request)
                    for p in request.processors]
            results = await asyncio.gather(*tasks, return_exceptions=True)
```

#### í”„ë¡œì„¸ì„œ ì—”ë“œí¬ì¸íŠ¸ (5ê°œ)

| Processor       | Weight | Endpoint              |
| --------------- | ------ | --------------------- |
| korean_nlp      | 0.25   | `enhanced-korean-nlp` |
| ml_analytics    | 0.20   | `ml-analytics-engine` |
| server_analyzer | 0.25   | `server-analyzer`     |
| pattern_matcher | 0.15   | `pattern-matcher`     |
| trend_predictor | 0.15   | `trend-predictor`     |

#### ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì§‘ê³„ (Weighted Aggregation)

```python
def _aggregate_results(self, results: List[ProcessingResult]) -> Dict:
    aggregated = {
        'confidence_score': 0.0,
        'main_insights': [],
        'entities': {},
        'metrics': {},
        'patterns': [],
        'anomalies': []
    }

    for result in results:
        if result.success:
            weight = self.processor_weights[result.processor]
            aggregated['confidence_score'] += result.data['confidence'] * weight
```

#### API ì¸í„°í˜ì´ìŠ¤

**ìš”ì²­ í˜•ì‹**:

```json
{
  "query": "ì›¹ì„œë²„ CPU ì‚¬ìš©ë¥  ë¶„ì„í•´ì£¼ì„¸ìš”",
  "context": {
    "server_id": "web-001"
  },
  "processors": ["korean_nlp", "ml_analytics"],
  "options": {
    "nlp_features": {},
    "ml_model": "auto"
  }
}
```

**ì‘ë‹µ í˜•ì‹**:

```json
{
  "success": true,
  "data": {
    "results": [
      {
        "processor": "korean_nlp",
        "success": true,
        "data": { "intent": "performance_check" },
        "processing_time": 245
      },
      {
        "processor": "ml_analytics",
        "success": true,
        "data": { "anomalies": [...] },
        "processing_time": 187
      }
    ],
    "aggregated_data": {
      "confidence_score": 0.92,
      "main_insights": ["CPU ì‚¬ìš©ë¥  ë†’ìŒ", "ì´ìƒ ì§•í›„ ê°ì§€"],
      "entities": {},
      "metrics": {},
      "patterns": [],
      "anomalies": [...]
    },
    "recommendations": [
      "ğŸš¨ ì´ìƒ ì§•í›„ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
    ],
    "cache_hit": false
  },
  "performance": {
    "total_processing_time_ms": 432,
    "confidence_score": 0.92,
    "processors_used": 2,
    "cache_hit": false
  }
}
```

#### ìºì‹± ì „ëµ

- **êµ¬í˜„**: TTLCache (Python cachetools)
- **TTL**: 5ë¶„ (300ì´ˆ)
- **ìºì‹œ í‚¤**: `query + processors` ì¡°í•©
- **ìµœëŒ€ í¬ê¸°**: 1,000ê°œ í•­ëª©
- **ë¬´ë£Œ í‹°ì–´ ìµœì í™”**: ìºì‹œ íˆíŠ¸ ì‹œ 0 API í˜¸ì¶œ

---

## ğŸ”„ Provider ì„¤ê³„

### MLProvider

**ëª©ì **: LightweightMLEngine ëŒ€ì²´, ì‹¤ì œ ML ë¶„ì„ ì œê³µ

```typescript
// src/lib/ai/providers/ml-provider.ts
import type {
  IContextProvider,
  ProviderContext,
  MLData,
  ProviderOptions,
  AIScenario,
} from '@/lib/ai/core/types';

interface MLAnalyticsRequest {
  metrics: Array<{
    timestamp: string;
    value: number;
    server_id: string;
    metric_type: string;
  }>;
  context?: {
    analysis_type?:
      | 'anomaly_detection'
      | 'trend_analysis'
      | 'pattern_recognition';
    threshold?: number;
  };
}

interface MLAnalyticsResponse {
  success: boolean;
  data: {
    anomalies: Array<{
      is_anomaly: boolean;
      severity: 'low' | 'medium' | 'high';
      confidence: number;
      timestamp: string;
      value: number;
      expected_range: [number, number];
    }>;
    trend: {
      direction: 'increasing' | 'decreasing' | 'stable';
      rate_of_change: number;
      prediction_24h: number;
      confidence: number;
    };
    patterns: Array<{
      type: string;
      description: string;
      confidence: number;
    }>;
    recommendations: string[];
  };
  performance: {
    processing_time_ms: number;
    metrics_analyzed: number;
    anomalies_found: number;
  };
}

export class MLProvider implements IContextProvider {
  readonly name = 'ML Analytics';
  readonly type = 'ml' as const;

  private readonly gcpEndpoint =
    'https://us-central1-openmanager-free-tier.cloudfunctions.net/ml-analytics-engine';

  private cache = new Map<string, { data: MLData; timestamp: number }>();
  private readonly cacheTTL = 5 * 60 * 1000; // 5ë¶„

  async getContext(
    query: string,
    options?: ProviderOptions
  ): Promise<ProviderContext> {
    const cacheKey = this.getCacheKey(query, options);
    const cached = this.getFromCache(cacheKey);

    if (cached) {
      return {
        type: 'ml',
        data: cached,
        metadata: {
          source: 'gcp-ml-analytics',
          confidence: 0.9,
          cached: true,
        },
      };
    }

    // ë©”íŠ¸ë¦­ ë°ì´í„° ì¤€ë¹„ (optionsì—ì„œ ì¶”ì¶œ)
    const metrics = this.prepareMetrics(options);

    if (metrics.length < 10) {
      // ìµœì†Œ ë°ì´í„° ë¶€ì¡± ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
      return this.getEmptyContext();
    }

    const request: MLAnalyticsRequest = {
      metrics,
      context: {
        analysis_type: options?.analysisType || 'anomaly_detection',
        threshold: options?.threshold || 0.8,
      },
    };

    try {
      const response = await fetch(this.gcpEndpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(request),
      });

      if (!response.ok) {
        throw new Error(`ML Analytics API error: ${response.status}`);
      }

      const result: MLAnalyticsResponse = await response.json();

      const mlData: MLData = {
        anomalies: result.data.anomalies.map((a) => ({
          severity: a.severity,
          description: `ê°’ ${a.value}ì´(ê°€) ì˜ˆìƒ ë²”ìœ„ [${a.expected_range[0]}, ${a.expected_range[1]}]ë¥¼ ë²—ì–´ë‚¨`,
          metric:
            metrics.find((m) => m.timestamp === a.timestamp)?.metric_type ||
            'unknown',
          value: a.value,
          timestamp: a.timestamp,
        })),
        trends: [
          {
            direction: result.data.trend.direction,
            confidence: result.data.trend.confidence,
            prediction: result.data.trend.prediction_24h,
            timeframe: '24h',
          },
        ],
        patterns: result.data.patterns.map((p) => ({
          type: p.type,
          description: p.description,
          confidence: p.confidence,
        })),
        recommendations: result.data.recommendations,
      };

      this.setCache(cacheKey, mlData);

      return {
        type: 'ml',
        data: mlData,
        metadata: {
          source: 'gcp-ml-analytics',
          confidence: result.data.trend.confidence,
          cached: false,
          processingTime: result.performance.processing_time_ms,
        },
      };
    } catch (error) {
      console.error('ML Analytics API error:', error);
      return this.getEmptyContext();
    }
  }

  isEnabled(scenario: AIScenario): boolean {
    // ML ë¶„ì„ì´ ìœ ìš©í•œ ì‹œë‚˜ë¦¬ì˜¤
    return [
      'performance-report',
      'failure-analysis',
      'optimization-advice',
    ].includes(scenario);
  }

  private getCacheKey(query: string, options?: ProviderOptions): string {
    return `ml:${query}:${JSON.stringify(options?.metricsData || {})}`;
  }

  private getFromCache(key: string): MLData | null {
    const cached = this.cache.get(key);
    if (!cached) return null;

    const now = Date.now();
    if (now - cached.timestamp > this.cacheTTL) {
      this.cache.delete(key);
      return null;
    }

    return cached.data;
  }

  private setCache(key: string, data: MLData): void {
    this.cache.set(key, { data, timestamp: Date.now() });
  }

  private prepareMetrics(
    options?: ProviderOptions
  ): MLAnalyticsRequest['metrics'] {
    // options.metricsDataì—ì„œ ì‹œê³„ì—´ ë©”íŠ¸ë¦­ ì¶”ì¶œ
    const metricsData = options?.metricsData || {};
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” DBì—ì„œ ìµœê·¼ ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì˜¬ ìˆ˜ë„ ìˆìŒ
    return [];
  }

  private getEmptyContext(): ProviderContext {
    return {
      type: 'ml',
      data: {
        anomalies: [],
        trends: [],
        patterns: [],
        recommendations: [],
      },
      metadata: {
        source: 'gcp-ml-analytics',
        confidence: 0,
        cached: false,
      },
    };
  }
}
```

**ì£¼ìš” íŠ¹ì§•**:

- âœ… **ìºì‹±**: 5ë¶„ TTLë¡œ ë¬´ë£Œ í‹°ì–´ ìµœì í™”
- âœ… **ìµœì†Œ ë°ì´í„° ê²€ì¦**: 10ê°œ ë¯¸ë§Œ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
- âœ… **ì—ëŸ¬ í•¸ë“¤ë§**: API ì‹¤íŒ¨ ì‹œ ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜
- âœ… **ì‹œë‚˜ë¦¬ì˜¤ í•„í„°ë§**: ì„±ëŠ¥/ì¥ì• /ìµœì í™” ì‹œë‚˜ë¦¬ì˜¤ë§Œ í™œì„±í™”

---

### KoreanNLPProvider

**ëª©ì **: í•œêµ­ì–´ ì¿¼ë¦¬ ë¶„ì„ ì œê³µ (ê¸°ì¡´ CloudContextLoader í†µí•©)

```typescript
// src/lib/ai/providers/korean-nlp-provider.ts
import type {
  IContextProvider,
  ProviderContext,
  ProviderOptions,
  AIScenario,
} from '@/lib/ai/core/types';

interface KoreanNLPRequest {
  query: string;
  context?: {
    user_id?: string;
    session_id?: string;
    previous_query?: string;
    servers?: Array<{ id: string; type: string }>;
  };
  features?: {
    entity_extraction?: boolean;
    semantic_analysis?: boolean;
    response_guidance?: boolean;
  };
}

interface KoreanNLPResponse {
  success: boolean;
  data: {
    intent: string;
    entities: Array<{
      type: string;
      value: string;
      confidence: number;
    }>;
    semantic_analysis: {
      primary_topic: string;
      urgency_level: string;
      action_needed: string;
    };
    server_context: {
      target_servers: string[];
      target_metrics: string[];
      urgency: string;
    };
    response_guidance: {
      suggested_tone: string;
      key_points: string[];
    };
    quality_metrics: {
      confidence: number;
      completeness: number;
    };
  };
  performance: {
    total_processing_time_ms: number;
    phase_times: Record<string, number>;
  };
}

export class KoreanNLPProvider implements IContextProvider {
  readonly name = 'Korean NLP';
  readonly type = 'rule' as const; // Rule Providerë¡œ ë¶„ë¥˜ (ì–¸ì–´ ì²˜ë¦¬ ê·œì¹™)

  private readonly gcpEndpoint =
    'https://us-central1-openmanager-free-tier.cloudfunctions.net/enhanced-korean-nlp';

  private cache = new Map<string, { data: any; timestamp: number }>();
  private readonly cacheTTL = 5 * 60 * 1000; // 5ë¶„

  async getContext(
    query: string,
    options?: ProviderOptions
  ): Promise<ProviderContext> {
    const cacheKey = `nlp:${query}`;
    const cached = this.getFromCache(cacheKey);

    if (cached) {
      return {
        type: 'rule',
        data: cached,
        metadata: {
          source: 'gcp-korean-nlp',
          confidence: 0.95,
          cached: true,
        },
      };
    }

    const request: KoreanNLPRequest = {
      query,
      context: {
        user_id: options?.userId,
        session_id: options?.sessionId,
      },
      features: {
        entity_extraction: true,
        semantic_analysis: true,
        response_guidance: true,
      },
    };

    try {
      const response = await fetch(this.gcpEndpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(request),
      });

      if (!response.ok) {
        throw new Error(`Korean NLP API error: ${response.status}`);
      }

      const result: KoreanNLPResponse = await response.json();

      const ruleData = {
        entities: result.data.entities.map((e) => ({
          type: e.type,
          value: e.value,
          confidence: e.confidence,
        })),
        intent: result.data.intent,
        urgency: result.data.semantic_analysis.urgency_level,
        targetServers: result.data.server_context.target_servers,
        targetMetrics: result.data.server_context.target_metrics,
        responseGuidance: result.data.response_guidance,
      };

      this.setCache(cacheKey, ruleData);

      return {
        type: 'rule',
        data: ruleData,
        metadata: {
          source: 'gcp-korean-nlp',
          confidence: result.data.quality_metrics.confidence,
          cached: false,
          processingTime: result.performance.total_processing_time_ms,
        },
      };
    } catch (error) {
      console.error('Korean NLP API error:', error);
      return this.getEmptyContext();
    }
  }

  isEnabled(scenario: AIScenario): boolean {
    // ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ í•œêµ­ì–´ ë¶„ì„ í™œì„±í™”
    return true;
  }

  private getFromCache(key: string): any | null {
    const cached = this.cache.get(key);
    if (!cached) return null;

    const now = Date.now();
    if (now - cached.timestamp > this.cacheTTL) {
      this.cache.delete(key);
      return null;
    }

    return cached.data;
  }

  private setCache(key: string, data: any): void {
    this.cache.set(key, { data, timestamp: Date.now() });
  }

  private getEmptyContext(): ProviderContext {
    return {
      type: 'rule',
      data: {
        entities: [],
        intent: 'unknown',
        urgency: 'low',
        targetServers: [],
        targetMetrics: [],
        responseGuidance: {
          suggested_tone: 'professional',
          key_points: [],
        },
      },
      metadata: {
        source: 'gcp-korean-nlp',
        confidence: 0,
        cached: false,
      },
    };
  }
}
```

---

### RAGProvider

**ëª©ì **: Supabase pgvector ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ (ê¸°ì¡´ SupabaseRAGEngine ë˜í•‘)

```typescript
// src/lib/ai/providers/rag-provider.ts
import type {
  IContextProvider,
  ProviderContext,
  RAGData,
  ProviderOptions,
  AIScenario,
} from '@/lib/ai/core/types';
import { SupabaseRAGEngine } from '@/services/ai/supabase-rag-engine';

export class RAGProvider implements IContextProvider {
  readonly name = 'RAG';
  readonly type = 'rag' as const;

  private ragEngine: SupabaseRAGEngine;

  constructor() {
    this.ragEngine = new SupabaseRAGEngine();
  }

  async getContext(
    query: string,
    options?: ProviderOptions
  ): Promise<ProviderContext> {
    try {
      const result = await this.ragEngine.searchSimilar(query, {
        topK: options?.topK || 5,
        threshold: options?.threshold || 0.7,
      });

      const ragData: RAGData = {
        documents: result.results.map((r) => ({
          content: r.content,
          metadata: r.metadata,
          score: r.score,
        })),
        sources: result.results.map((r) => r.metadata?.source || 'unknown'),
      };

      return {
        type: 'rag',
        data: ragData,
        metadata: {
          source: 'supabase-pgvector',
          confidence: result.results[0]?.score || 0,
          cached: false,
        },
      };
    } catch (error) {
      console.error('RAG Provider error:', error);
      return {
        type: 'rag',
        data: { documents: [], sources: [] },
        metadata: {
          source: 'supabase-pgvector',
          confidence: 0,
          cached: false,
        },
      };
    }
  }

  isEnabled(scenario: AIScenario): boolean {
    // ë¬¸ì„œ QA ì‹œë‚˜ë¦¬ì˜¤ì—ì„œë§Œ í™œì„±í™”
    return scenario === 'document-qa';
  }
}
```

---

## ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

### Phase 1: Provider êµ¬í˜„ (í˜„ì¬ ë‹¨ê³„)

**ì‘ì—… ë‚´ì—­**:

- âœ… MLProvider ì„¤ê³„ ì™„ë£Œ
- âœ… KoreanNLPProvider ì„¤ê³„ ì™„ë£Œ
- âœ… RAGProvider ì„¤ê³„ ì™„ë£Œ
- â³ ì‹¤ì œ êµ¬í˜„ íŒŒì¼ ìƒì„±
- â³ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

**ì˜ˆìƒ ì†Œìš”**: 1ì¼

---

### Phase 2: ë”ë¯¸ êµ¬í˜„ ì œê±°

**ì œê±° ëŒ€ìƒ**:

1. `/src/lib/ml/LightweightMLEngine.ts` (ì „ì²´ íŒŒì¼ ì‚­ì œ)
   - ëœë¤ ê°’ë§Œ ë°˜í™˜í•˜ëŠ” ë”ë¯¸ êµ¬í˜„
   - MLProviderë¡œ ì™„ì „ ëŒ€ì²´

**ê²€ì¦ ë°©ë²•**:

```bash
# 1. LightweightMLEngine ì°¸ì¡° í™•ì¸
grep -r "LightweightMLEngine" src/

# 2. ì˜í–¥ë°›ëŠ” íŒŒì¼ ìˆ˜ì •
# â†’ ëª¨ë‘ MLProviderë¡œ êµì²´

# 3. TypeScript ì»´íŒŒì¼ í™•ì¸
npm run type-check

# 4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
npm run test:fast
```

**ì˜ˆìƒ ì†Œìš”**: 0.5ì¼

---

### Phase 3: GoogleAiUnifiedEngine í†µí•©

**í†µí•© ë°©ë²•**:

```typescript
// src/lib/ai/core/google-ai-unified-engine.ts

export class GoogleAiUnifiedEngine {
  private providers: Map<string, IContextProvider>;

  constructor() {
    this.providers = new Map([
      ['rag', new RAGProvider()],
      ['ml', new MLProvider()],
      ['korean-nlp', new KoreanNLPProvider()],
    ]);
  }

  async query(request: UnifiedQueryRequest): Promise<UnifiedQueryResponse> {
    // 1. ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¼ í™œì„±í™”í•  Provider ê²°ì •
    const enabledProviders = Array.from(this.providers.values()).filter((p) =>
      p.isEnabled(request.scenario)
    );

    // 2. ë³‘ë ¬ë¡œ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    const contexts = await Promise.all(
      enabledProviders.map((p) => p.getContext(request.query, request.options))
    );

    // 3. í”„ë¡¬í”„íŠ¸ ìƒì„± (PromptBuilder ì‚¬ìš©)
    const prompt = this.buildPrompt(request, contexts);

    // 4. Google AI API í˜¸ì¶œ
    const aiResponse = await this.callGoogleAI(prompt);

    // 5. ì‘ë‹µ í›„ì²˜ë¦¬
    return this.postProcess(aiResponse, contexts);
  }
}
```

**ì˜ˆìƒ ì†Œìš”**: 1ì¼

---

## ğŸ’° ë¬´ë£Œ í‹°ì–´ ìµœì í™” ì „ëµ

### GCP Functions ë¬´ë£Œ í•œë„

- **í˜¸ì¶œ íšŸìˆ˜**: 2M í˜¸ì¶œ/ì›”
- **ì»´í“¨íŒ…**: 400K GB-ì´ˆ/ì›”, 200K GHz-ì´ˆ/ì›”
- **ë„¤íŠ¸ì›Œí¬**: 5GB ì†¡ì‹ /ì›”

### ìµœì í™” ë°©ë²•

**1. ìºì‹± ì „ëµ** (ìµœìš°ì„ )

```typescript
// 5ë¶„ TTL ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
private cache = new Map<string, { data: any; timestamp: number }>();
private readonly cacheTTL = 5 * 60 * 1000; // 5ë¶„

// ìºì‹œ íˆíŠ¸ìœ¨ ëª©í‘œ: 70% ì´ìƒ
// â†’ ì‹¤ì œ GCP í˜¸ì¶œ: 30% ì´í•˜
```

**ì˜ˆìƒ íš¨ê³¼**:

- ì›” 10,000 ì¿¼ë¦¬ ê¸°ì¤€
- ìºì‹œ íˆíŠ¸ 70% ì ìš© ì‹œ: 3,000 GCP í˜¸ì¶œ (ë¬´ë£Œ í•œë„ì˜ 0.15%)

**2. ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì„ íƒì  í˜¸ì¶œ**

```typescript
// ML AnalyticsëŠ” ì„±ëŠ¥ ê´€ë ¨ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œë§Œ
isEnabled(scenario: AIScenario): boolean {
  return ['performance-report', 'failure-analysis', 'optimization-advice']
    .includes(scenario);
}
```

**ì˜ˆìƒ íš¨ê³¼**:

- 7ê°œ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ 3ê°œë§Œ ML í˜¸ì¶œ (43% ê°ì†Œ)

**3. ë°°ì¹˜ ì²˜ë¦¬**

```typescript
// ì—¬ëŸ¬ ë©”íŠ¸ë¦­ì„ í•˜ë‚˜ì˜ ìš”ì²­ìœ¼ë¡œ ì²˜ë¦¬
const metrics = this.aggregateMetrics(last24Hours);
await fetch(gcpEndpoint, {
  method: 'POST',
  body: JSON.stringify({ metrics }), // í•œ ë²ˆì— ì „ì†¡
});
```

**ì˜ˆìƒ íš¨ê³¼**:

- 10ê°œ ë©”íŠ¸ë¦­ ê°œë³„ í˜¸ì¶œ â†’ 1ê°œ ë°°ì¹˜ í˜¸ì¶œ (90% ê°ì†Œ)

**4. ì‹¤íŒ¨ ì¬ì‹œë„ ì œí•œ**

```typescript
const maxRetries = 1; // ìµœëŒ€ 1íšŒë§Œ ì¬ì‹œë„
const timeout = 10000; // 10ì´ˆ íƒ€ì„ì•„ì›ƒ
```

---

## ğŸ¯ ì„±ëŠ¥ ëª©í‘œ

| ì§€í‘œ          | í˜„ì¬ (ì˜ˆìƒ) | ëª©í‘œ     | GCP Functions ê¸°ì—¬       |
| ------------- | ----------- | -------- | ------------------------ |
| P90 ì‘ë‹µ ì‹œê°„ | 2,000ms     | 500ms    | -1,200ms (ML ë³‘ë ¬ ì²˜ë¦¬)  |
| ìºì‹œ íˆíŠ¸ìœ¨   | 50%         | 70%      | Provider ìºì‹±            |
| í† í° ì‚¬ìš©ëŸ‰   | 1,000 í† í°  | 670 í† í° | -33% (êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸) |
| ì •í™•ë„        | 80%         | 90%      | +10% (ì‹¤ì œ ML ì•Œê³ ë¦¬ì¦˜)  |

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### Provider êµ¬í˜„

- [ ] MLProvider íŒŒì¼ ìƒì„±
- [ ] KoreanNLPProvider íŒŒì¼ ìƒì„±
- [ ] RAGProvider íŒŒì¼ ìƒì„±
- [ ] ê° Provider ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

### ë”ë¯¸ ì œê±°

- [ ] LightweightMLEngine.ts ì‚­ì œ
- [ ] ì°¸ì¡° íŒŒì¼ ìˆ˜ì •
- [ ] TypeScript ì»´íŒŒì¼ í™•ì¸
- [ ] í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸

### í†µí•©

- [ ] GoogleAiUnifiedEngineì— Provider ë“±ë¡
- [ ] ì‹œë‚˜ë¦¬ì˜¤ë³„ Provider í™œì„±í™” ì„¤ì •
- [ ] ìºì‹± ë¡œì§ êµ¬í˜„
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”

### ê²€ì¦

- [ ] ë¬´ë£Œ í‹°ì–´ í•œë„ ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
- [ ] E2E í…ŒìŠ¤íŠ¸ (Vercel í™˜ê²½)
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸

---

**ë‹¤ìŒ ë‹¨ê³„**: Provider êµ¬í˜„ íŒŒì¼ ìƒì„± â†’ ë”ë¯¸ ì œê±° â†’ GoogleAiUnifiedEngine í†µí•©

---

## ğŸ§  Cloud Functions vs Google AI API ì—­í•  ë¶„ë¦¬ ì›ì¹™

**í•µì‹¬ ì² í•™**:

> **"êµ¬ê¸€ AI APIëŠ” 'ìƒê°Â·ì„¤ëª…Â·ë³´ê³ ì„œ'ì—ë§Œ ì“°ê³ ,
> ìˆ«ì ê³„ì‚°Â·ë£°Â·ìºì‹±Â·ì „ì²˜ë¦¬ëŠ” ìµœëŒ€í•œ Cloud Functionsì—ì„œ ì²˜ë¦¬í•œë‹¤."**

ì´ë ‡ê²Œ ê°€ì ¸ê°€ë©´ **ì‚¬ìš©ëŸ‰(ìš”ê¸ˆ) ì¤„ì´ê³ , ì •í™•ë„Â·ì„±ëŠ¥ ë‘˜ ë‹¤ ì˜¬ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

### ì—­í•  ì •ì˜

#### Google AI API = ë¸Œë ˆì¸ (ì„¤ëª…Â·ìš”ì•½Â·ì˜ì‚¬ê²°ì •)

- âœ… ìì—°ì–´ ì„¤ëª… ìƒì„±
- âœ… ì¸ì‚¬ì´íŠ¸ ìš”ì•½
- âœ… ì‚¬ìš©ì ì¹œí™”ì  ë¦¬í¬íŠ¸ ì‘ì„±
- âœ… ë³µì¡í•œ ì˜ì‚¬ê²°ì • ì¶”ë¡ 

#### Cloud Functions = ë³´ì¡° CPU (ì „ì²˜ë¦¬Â·MLÂ·ìºì‹±Â·ë£° ê¸°ë°˜ ì²˜ë¦¬)

- âœ… ìˆ«ì ê³„ì‚° ë° í†µê³„ ì²˜ë¦¬
- âœ… ML ì•Œê³ ë¦¬ì¦˜ (ì´ìƒ íƒì§€, íŠ¸ë Œë“œ ë¶„ì„)
- âœ… ìºì‹± ë° ì‚¬ì „ ê³„ì‚°
- âœ… ë£° ê¸°ë°˜ íŒë‹¨ (ì„ê³„ê°’, ìš°ì„ ìˆœìœ„)
- âœ… ë°ì´í„° ì „ì²˜ë¦¬ ë° í”¼ì²˜ ì¶”ì¶œ

---

### Cloud Functionsì˜ 3ê°€ì§€ í•µì‹¬ ì—­í• 

#### 1. LLM í˜¸ì¶œ ìì²´ë¥¼ ì¤„ì´ê¸° (ì•ˆ ì¨ë„ ë˜ëŠ” ìƒí™© ì°¨ë‹¨)

**íŒ¨í„´ A: ë£° ê¸°ë°˜ Fast Path**

```typescript
// LLM ì—†ì´ ë°”ë¡œ ë‹µí•  ìˆ˜ ìˆëŠ” ì¼€ì´ìŠ¤ëŠ” CFì—ì„œ ë°”ë¡œ ì²˜ë¦¬
// ì˜ˆ: ë‹¨ìˆœ í†µê³„, ê°„ë‹¨ í•„í„°ë§, ê³ ì • í¬ë§· ì‘ë‹µ

// 1. í”„ë¡ íŠ¸ â†’ /api/ai/unified ìš”ì²­
// 2. ë°±ì—”ë“œ:
//    - Cloud Function í˜¸ì¶œ â†’ "ì´ê±´ ë£°/SQLë¡œ ë‹µì´ ë‚˜ì˜¤ëƒ?" ì²´í¬
//    - ë‹µì´ ë‚˜ì˜¤ë©´ â†’ ê·¸ëŒ€ë¡œ ë°˜í™˜ (LLM í˜¸ì¶œ ì•ˆ í•¨)
//    - ì•ˆ ë˜ë©´ â†’ ê·¸ë•Œ Google AI í˜¸ì¶œ

// ì˜ˆì‹œ ì¿¼ë¦¬:
// - "ì–´ì œ ì•ŒëŒ ëª‡ ê±´ì´ì—ˆì–´?" â†’ Supabase SQLë¡œ ë°”ë¡œ ë‹µë³€
// - "CPU 80% ë„˜ëŠ” ì„œë²„ ìˆ˜?" â†’ SQL ì§‘ê³„ë¡œ ë°”ë¡œ ë‹µë³€
// - "ì •ê¸° ì ê²€ ì‹œê°„ ì•Œë ¤ì¤˜" â†’ í™˜ê²½ ì„¤ì •ê°’ ì½ì–´ì„œ ë°”ë¡œ ë¦¬í„´
```

**íŒ¨í„´ B: ìºì‹œ ì„œë²„ ì—­í• **

```python
# Cloud Functionì´ ì •ê¸° ìŠ¤ì¼€ì¤„ë¡œ ê³„ì‚° â†’ ê²°ê³¼ë¥¼ Supabaseì— ì €ì¥
# ë˜ëŠ” ì²« ìš”ì²­ ì‹œ ê³„ì‚° â†’ ìºì‹œ ì €ì¥, ì´í›„ ëª‡ ë¶„ ë™ì•ˆ ì¬ì‚¬ìš©

# ìì£¼ ë°˜ë³µë˜ëŠ” ì§ˆì˜:
# - "ìµœê·¼ 24ì‹œê°„ ìš”ì•½ ë¦¬í¬íŠ¸"
# - "ì„œë²„ ê·¸ë£¹ë³„ í‰ê·  ì§€í‘œ"

# LLMì—ëŠ” ìºì‹œëœ ìš”ì•½ JSONë§Œ ë„˜ê²¨ì„œ:
# "ì´ ë°ì´í„°ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜"ë§Œ ì‹œí‚´
# â†’ LLMì€ 'ìƒˆ ê³„ì‚°'ì´ ì•„ë‹ˆë¼ 'ì´ë¯¸ ê³„ì‚°ëœ ë°ì´í„° ì„¤ëª…'ë§Œ ë‹´ë‹¹
```

**íŒ¨í„´ C: ì§ˆë¬¸ ë¼ìš°íŒ…**

```python
# Cloud Functionì´ ê°„ë‹¨í•œ NLP/í‚¤ì›Œë“œ ë§¤ì¹­ + ê·œì¹™ìœ¼ë¡œ:
# - "ì´ê±´ ë¬¸ì„œ QA(RAG) ì „ìš©" â†’ RAGProviderë§Œ í™œì„±í™”
# - "ì´ê±´ ë©”íŠ¸ë¦­ ë¶„ì„ + ì˜ˆì¸¡" â†’ MLProviderë§Œ í™œì„±í™”
# - "ì´ê±´ ë‹¨ìˆœ ì¡°íšŒ(LLM ë¶ˆí•„ìš”)" â†’ Fast Pathë¡œ ì²˜ë¦¬
# - "ì´ê±´ ë³µí•© ë¶„ì„ â†’ LLM í•„ìš”" â†’ Unified ì—”ì§„ìœ¼ë¡œ ì „ë‹¬
```

**ì˜ˆìƒ íš¨ê³¼**:

- LLM í˜¸ì¶œ ìˆ˜ 40-60% ê°ì†Œ
- ì‘ë‹µ ì†ë„ 3-5ë°° í–¥ìƒ (ìºì‹œ íˆíŠ¸ ì‹œ)

---

#### 2. LLMì´ ë¨¹ì„ ì…ë ¥ì„ ì‘ê²ŒÂ·ê¹¨ë—í•˜ê²Œ ë§Œë“¤ì–´ì£¼ê¸° (í† í°/ì†ë„ ìµœì í™”)

**íŒ¨í„´ D: ì „ì²˜ë¦¬ + í”¼ì²˜ ì¶”ì¶œ**

```python
# LLMì—ê²Œ ì›ì‹œ ë°ì´í„°(ê¸´ ë¡œê·¸, ì‹œê³„ì—´ ì „ì²´)ë¥¼ ê·¸ëŒ€ë¡œ ë˜ì§€ì§€ ë§ê³ :
# Cloud Functions(Python)ì—ì„œ:
# - ì´ìƒì¹˜ íƒì§€
# - ìœ„í—˜ ì ìˆ˜ ê³„ì‚°
# - Top N ì„œë²„/ì„œë¹„ìŠ¤ ì„ ì •
# - ëŒ€í‘œ ì´ë²¤íŠ¸/ë¡œê·¸ 3~5ê°œë§Œ ì¶”ì¶œ

# â†’ ê·¸ë¦¬ê³  ì´ "ì •ì œëœ JSON ìš”ì•½"ë§Œ Google AIì— ë„£ê¸°

# ì˜ˆì‹œ:
# âŒ Before: 1,000ê°œ ë¡œê·¸ ì „ì²´ â†’ LLM (10,000 í† í°)
# âœ… After: ìƒìœ„ 5ê°œ ì´ë²¤íŠ¸ ìš”ì•½ â†’ LLM (500 í† í°)
```

**í˜„ì¬ êµ¬í˜„ ì˜ˆì‹œ (MLProvider)**:

```typescript
// 1. GCP ml-analytics-engineì—ì„œ ì „ì²˜ë¦¬
const result: MLAnalyticsResponse = await fetch(gcpEndpoint, {
  method: 'POST',
  body: JSON.stringify({ metrics }), // ì›ì‹œ ì‹œê³„ì—´ ë°ì´í„°
});

// 2. ì •ì œëœ ê²°ê³¼ë§Œ ì¶”ì¶œ
const mlData: MLData = {
  anomalies: result.data.anomalies, // Top 5 ì´ìƒ ì§•í›„ë§Œ
  trends: [result.data.trend], // ìš”ì•½ëœ íŠ¸ë Œë“œ 1ê°œ
  patterns: result.data.patterns.slice(0, 3), // ìƒìœ„ 3ê°œ íŒ¨í„´
  recommendations: result.data.recommendations, // í•µì‹¬ ê¶Œì¥ì‚¬í•­
};

// 3. LLMì—ê²ŒëŠ” ì´ ì •ì œëœ JSONë§Œ ì „ë‹¬
// â†’ í† í° ìˆ˜ â†“, ì†ë„ â†‘, ì •í™•ë„ â†‘
```

**íš¨ê³¼**:

- í† í° ìˆ˜ 70-90% ê°ì†Œ
- ì‘ë‹µ ì†ë„ 2-3ë°° í–¥ìƒ
- LLMì´ "ì¡ìŒ ë§ì€ ì›ì‹œ ë°ì´í„°"ì— í—›ì†Œë¦¬í•  í™•ë¥ â†“
- "ì •í™•í•œ ì§‘ê³„/ê³„ì‚°"ì€ Pythonì´ í•˜ë¯€ë¡œ **ìˆ˜ì¹˜ ì •í™•ë„â†‘**

---

#### 3. LLM ê²°ê³¼ë¥¼ ë” ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ ë³´ì •í•˜ê¸° (ì •í™•ë„Â·ì¼ê´€ì„± í–¥ìƒ)

**íŒ¨í„´ E: LLM ê²°ê³¼ ê²€ì¦/ë³´ì • (í•˜ë“œ ê²€ì¦)**

```python
# ì¤‘ìš”í•œ ê¸°ëŠ¥(ì˜ˆ: ì‹¤ì œ ì¥ì•  ë³´ê³ ì„œ, ê´€ë¦¬ììš© ë¦¬í¬íŠ¸)ì—ëŠ”:

# 1. Google AIê°€ JSON+í…ìŠ¤íŠ¸ë¥¼ ìƒì„±
# 2. Cloud Functionì—ì„œ:
#    - JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦
#    - ê°’ ë²”ìœ„ ì²´í¬ (ì˜ˆ: CPU 0~100%, ì‹œê°„ í¬ë§· ë“±)
#    - ì˜ëª»ëœ ê°’ì´ ìˆìœ¼ë©´:
#      - ë³´ì •í•˜ê±°ë‚˜
#      - LLMì— "ì´ í•„ë“œ ë‹¤ì‹œ ìƒì„±" ìš”ì²­ (í•„ìš” ì‹œ)

# â†’ í˜¸ì¶œ ìˆ˜ë¥¼ ì•½ê°„ ëŠ˜ë¦´ ìˆ˜ ìˆì§€ë§Œ,
# "ê²°ê³¼ í’ˆì§ˆì´ ì¤‘ìš”í•œ ì¼ë¶€ ê¸°ëŠ¥ì—ë§Œ ì œí•œ ì ìš©"í•˜ë©´,
# ì‹ ë¢°ë„ë¥¼ ì˜¬ë¦¬ëŠ” ë° ë§¤ìš° ì¢‹ìŒ
```

**íŒ¨í„´ F: íŒë‹¨ì€ CF, ì„¤ëª…ì€ LLM**

```python
# ì˜ˆ: ì–´ë–¤ ì„œë²„ê°€ "ìœ„í—˜/ê²½ê³ /ì •ìƒ"ì¸ì§€ íŒë‹¨í•  ë•Œ
# LLMì—ê²Œ ì• ë§¤í•œ ê¸°ì¤€ì„ ë§¡ê¸°ê¸°ë³´ë‹¤:

# Cloud Functionsì—ì„œ:
# - ì„ê³„ê°’/ë£°/ML ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ risk_level ê²°ì •
# - LLMì—ê²ŒëŠ”:
#   "ìœ„í—˜ë„ëŠ” ì´ë¯¸ ê³„ì‚°ë¨ â†’ ë„ˆëŠ” ì´ê±¸ ì„¤ëª…ë§Œ í•´ë¼"ë¼ê³  ë„˜ê²¨ì¤Œ

# í˜„ì¬ êµ¬í˜„ ì˜ˆì‹œ (MLProvider):
async getContext(query: string, options?: ProviderOptions) {
  const result = await fetch(gcpEndpoint, { /* ML ë¶„ì„ */ });

  // Cloud Functionsê°€ ì´ë¯¸ íŒë‹¨ ì™„ë£Œ:
  // - severity: 'low' | 'medium' | 'high'
  // - direction: 'increasing' | 'decreasing' | 'stable'
  // - confidence: 0.85

  // LLMì€ ì´ íŒë‹¨ì„ ì„¤ëª…ë§Œ í•¨:
  // "ML ë¶„ì„ ê²°ê³¼ ìœ„í—˜ë„ 'high', ì‹ ë¢°ë„ 85%ì…ë‹ˆë‹¤.
  //  CPU ì‚¬ìš©ë¥ ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€ ì¤‘ì…ë‹ˆë‹¤..."
}

# â†’ LLMì€ íŒë‹¨ì´ ì•„ë‹ˆë¼ ì„¤ëª…Â·ë¦¬í¬íŠ¸ ì—­í• ë¡œ ì œí•œ
# â†’ ë‹µë³€ì´ ë” ì¼ê´€ë˜ê³ , ìš´ì˜ ì •ì±…ê³¼ë„ ì •í™•íˆ ë§ê²Œ ë¨
```

---

### Cloud Functions ì—­í•  ì¬ì •ì˜

#### âœ… ìœ ì§€Â·ê°•í™”í•  ì—­í• 

1. **Metrics/ML ì „ì²˜ë¦¬ ì—”ì§„**
   - ì‹œê³„ì—´ ìš”ì•½, ì´ìƒíƒì§€, ìœ„í—˜ë„ ê³„ì‚°
   - ê²°ê³¼ë¥¼ JSON/í…Œì´ë¸”ë¡œ Supabaseì— ì €ì¥
   - **í˜„ì¬ êµ¬í˜„**: `ml-analytics-engine` (scikit-learn ê¸°ë°˜)

2. **Fast-path ë£° ì—”ì§„**
   - LLM ì—†ì´ ë°”ë¡œ ë‹µí•  ìˆ˜ ìˆëŠ” ì¿¼ë¦¬ ì²˜ë¦¬
   - "ì´ ì¼€ì´ìŠ¤ëŠ” Google AI ì•ˆ ì¨ë„ ëœë‹¤"ë¥¼ íŒë‹¨í•˜ëŠ” í•„í„°
   - **êµ¬í˜„ ì˜ˆì •**: `rule-based-router` ì¶”ê°€

3. **ë°°ì¹˜/ìºì‹œ ì—”ì§„**
   - ì •ê¸° ì§‘ê³„/ìš”ì•½/ë³´ê³ ìš© ë°ì´í„° ì‚¬ì „ ê³„ì‚°
   - LLMì€ ì´ ë°ì´í„°ë¥¼ ë°›ì•„ ì„¤ëª…ë§Œ í•˜ëŠ” êµ¬ì¡°ë¡œ ë³€ê²½
   - **í˜„ì¬ êµ¬í˜„**: `unified-ai-processor` (TTLCache 5ë¶„)

4. **(ì„ íƒ) ê²°ê³¼ ê²€ì¦ìš© ê°€ë“œë ˆì¼**
   - íŠ¹ì • API(ë³´ê³ ì„œ ìƒì„± ë“±)ì— í•œí•´
   - LLM ê²°ê³¼ì˜ JSON êµ¬ì¡°Â·ë²”ìœ„ ê²€ì¦
   - **êµ¬í˜„ ì˜ˆì •**: `response-validator` ì¶”ê°€

#### âŒ ì¤„ì´ê±°ë‚˜ ì—†ì•¨ ì—­í• 

1. **ì‚¬ìš©ì ìš”ì²­ë§ˆë‹¤ ì¦‰ì„ìœ¼ë¡œ ë¬´ê±°ìš´ ML ëŒë¦¬ê³ , ê·¸ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ëŠ” êµ¬ì¡°**
   - â†’ ëŒ€ë¶€ë¶„ì€ "ì‚¬ì „ ê³„ì‚° + LLM ì„¤ëª…"ìœ¼ë¡œ ëŒ€ì²´
   - **ë³€ê²½**: ë°°ì¹˜ ì²˜ë¦¬ + ìºì‹± ê°•í™”

2. **Cloud Functionsê°€ ì§ì ‘ ìì—°ì–´ ë¦¬í¬íŠ¸ê¹Œì§€ ë§Œë“œëŠ” êµ¬ì¡°**
   - â†’ ìì—°ì–´ëŠ” ë¬´ì¡°ê±´ Google AIì˜ ì—­í• ë¡œ í†µí•©
   - **ì œê±°**: enhanced-korean-nlpì˜ response_guidance ì œê±° ê²€í† 

3. **í”„ë¡ íŠ¸ì—ì„œ CFë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ë¶€ë¶„**
   - â†’ ë¬´ì¡°ê±´ `/api/ai/unified` â†’ ë°±ì—”ë“œ â†’ CF/LLM ìˆœì„œë¡œ í†µì¼
   - **ë³€ê²½**: API ì—”ë“œí¬ì¸íŠ¸ í†µí•© (Task 11)

---

### ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸

#### Provider êµ¬í˜„ì— ë°˜ì˜ëœ ì›ì¹™ âœ…

- [x] **MLProvider**:
  - âœ… GCP Functionì—ì„œ ML ì „ì²˜ë¦¬ (3-sigma, Linear Regression)
  - âœ… ì •ì œëœ ê²°ê³¼ë§Œ ì¶”ì¶œ (anomalies, trends, patterns)
  - âœ… 5ë¶„ TTL ìºì‹±
  - âœ… ì‹œë‚˜ë¦¬ì˜¤ í•„í„°ë§ (ì„±ëŠ¥/ì¥ì• /ìµœì í™”ë§Œ)

- [x] **KoreanNLPProvider**:
  - âœ… GCP Functionì—ì„œ 6-Phase ì „ì²˜ë¦¬
  - âœ… ì—”í‹°í‹°/ì˜ë„/ë„ë©”ì¸ ìš©ì–´ ì¶”ì¶œ
  - âœ… 10ë¶„ TTL ìºì‹± (NLPëŠ” ë” ê¸´ ìºì‹±)
  - âœ… ì§§ì€ ì¿¼ë¦¬ ìŠ¤í‚µ (5ì ë¯¸ë§Œ)

- [x] **RAGProvider**:
  - âœ… Supabase pgvectorì—ì„œ ì „ì²˜ë¦¬ (ìœ ì‚¬ë„ ê²€ìƒ‰)
  - âœ… ìƒìœ„ 5ê°œ ë¬¸ì„œë§Œ ì¶”ì¶œ
  - âœ… 3ë¶„ TTL ìºì‹± (RAGëŠ” ì§§ì€ ìºì‹±)
  - âœ… ì‹œë‚˜ë¦¬ì˜¤ í•„í„°ë§ (document-qa ì¤‘ì‹¬)

#### í–¥í›„ ê°œì„  ê³¼ì œ â³

- [ ] **Rule-based Router ì¶”ê°€**
  - Fast Path êµ¬í˜„ (ë‹¨ìˆœ ì¡°íšŒëŠ” LLM ìŠ¤í‚µ)
  - SQL ê¸°ë°˜ ì¦‰ì‹œ ì‘ë‹µ (ì•ŒëŒ ê±´ìˆ˜, ì„œë²„ í†µê³„ ë“±)

- [ ] **Response Validator ì¶”ê°€**
  - LLM ê²°ê³¼ JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦
  - ê°’ ë²”ìœ„ ì²´í¬ (CPU 0-100%, ë‚ ì§œ í¬ë§· ë“±)

- [ ] **Batch Scheduler ì¶”ê°€**
  - ì •ê¸° ì§‘ê³„ ìŠ¤ì¼€ì¤„ëŸ¬ (ë§¤ì‹œê°„/ë§¤ì¼)
  - ì‚¬ì „ ê³„ì‚° ê²°ê³¼ë¥¼ Supabaseì— ì €ì¥

---

### ì˜ˆìƒ íš¨ê³¼ (ìµœì¢… ëª©í‘œ)

| ì§€í‘œ               | í˜„ì¬            | ê°œì„  í›„       | ê°œì„ ìœ¨ |
| ------------------ | --------------- | ------------- | ------ |
| **LLM í˜¸ì¶œ ìˆ˜**    | 10,000íšŒ/ì›”     | 3,000íšŒ/ì›”    | -70%   |
| **í† í° ì‚¬ìš©ëŸ‰**    | 1,000 í† í°/ì¿¼ë¦¬ | 300 í† í°/ì¿¼ë¦¬ | -70%   |
| **í‰ê·  ì‘ë‹µ ì†ë„** | 2,000ms         | 500ms         | -75%   |
| **ìˆ˜ì¹˜ ì •í™•ë„**    | 80%             | 95%           | +15%   |
| **ìºì‹œ íˆíŠ¸ìœ¨**    | 50%             | 70%           | +40%   |
| **ì›”ê°„ ë¹„ìš©**      | $50             | $15           | -70%   |

**í•µì‹¬**: Cloud FunctionsëŠ” "LLM ì•/ë’¤ë¥¼ ì •ë¦¬í•´ ì£¼ëŠ” ë˜‘ë˜‘í•œ í•„í„° + ê³„ì‚°ê¸°", Google AI APIëŠ” "ì‚¬ëŒì—ê²Œ ë³´ì—¬ì¤„ ë§/ë¦¬í¬íŠ¸ ìƒì„±ê¸°"ë¡œ ì—­í•  ë¶„ë¦¬

---

**ì°¸ì¡° ë¬¸ì„œ**:

- [Provider êµ¬í˜„ ì™„ë£Œ](#-provider-ì„¤ê³„)
- [ë¬´ë£Œ í‹°ì–´ ìµœì í™”](#-ë¬´ë£Œ-í‹°ì–´-ìµœì í™”-ì „ëµ)
- [ì„±ëŠ¥ ëª©í‘œ](#-ì„±ëŠ¥-ëª©í‘œ)
