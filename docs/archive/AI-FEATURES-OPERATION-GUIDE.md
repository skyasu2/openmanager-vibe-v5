# AI ì–´ì‹œìŠ¤í„´íŠ¸ ê¸°ëŠ¥ë³„ ë™ì‘ ê°€ì´ë“œ

**ì‘ì„±ì¼**: 2025-11-19  
**ëª©ì **: ê° AI ê¸°ëŠ¥ì˜ ë™ì‘ ë°©ì‹ ë° ë°ì´í„° í”Œë¡œìš° ì„¤ëª…

---

## ğŸ“‹ ì „ì²´ ê¸°ëŠ¥ ëª©ë¡

| ê¸°ëŠ¥                 | ì•„ì´ì½˜ | ì„¤ëª…                                  | êµ¬í˜„ ìƒíƒœ    |
| -------------------- | ------ | ------------------------------------- | ------------ |
| **ìì—°ì–´ ì§ˆì˜**      | ğŸ’¬     | ìì—°ì–´ë¡œ ì‹œìŠ¤í…œ ì§ˆì˜ ë° ëŒ€í™”          | âœ… ì™„ì „ êµ¬í˜„ |
| **ìë™ì¥ì•  ë³´ê³ ì„œ**  | ğŸ“„     | AI ê¸°ë°˜ ì¥ì•  ë¶„ì„ ë³´ê³ ì„œ ìƒì„±         | âœ… ì™„ì „ êµ¬í˜„ |
| **ì´ìƒê°ì§€/ì˜ˆì¸¡**    | ğŸ§      | ì´ìƒíƒì§€â†’ê·¼ë³¸ì›ì¸â†’ì˜ˆì¸¡â†’ì¸ì‚¬ì´íŠ¸       | âœ… ì™„ì „ êµ¬í˜„ |
| **AI ê³ ê¸‰ê´€ë¦¬**      | âš™ï¸     | ML í•™ìŠµ ê¸°ëŠ¥ ë° AI ì‹œìŠ¤í…œ ê´€ë¦¬        | âœ… ì™„ì „ êµ¬í˜„ |
| **ë¬´ë£Œ í‹°ì–´ ëª¨ë‹ˆí„°** | ğŸ“Š     | Vercel/Supabase/Google AI ì‚¬ìš©ëŸ‰ ì¶”ì  | âœ… ì™„ì „ êµ¬í˜„ |

---

## 1ï¸âƒ£ ìì—°ì–´ ì§ˆì˜ (Chat)

### ë™ì‘ ë°©ì‹

### ë™ì‘ ë°©ì‹

```
ì‚¬ìš©ì ì…ë ¥
    â†“
AI ì‚¬ì´ë“œë°” (AISidebarV4.tsx)
    â†“
POST /api/ai/unified-stream (Vercel AI SDK)
    â†“
Hybrid Engine (Offline + Online)
    â†“
    â”œâ”€ Offline Layer: íŒ¨í„´ ë¶„ì„, ëª…ë ¹ì–´ ì¶”ì²œ
    â””â”€ Online Layer: Gemini 1.5 Flash + RAG + GCP ML
    â†“
Thinking Process ì‹œê°í™” + ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
```

### ì½”ë“œ í”Œë¡œìš°

#### 1. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬

```typescript
// src/components/dashboard/AISidebarContent.tsx

const handleSendMessage = async (content: string) => {
  // 1. ì„œë²„ ë©”íƒ€ë°ì´í„° ê³„ì‚°
  const totalServers = servers.length;
  const avgCpu = Math.round(
    servers.reduce((sum, s) => sum + s.cpu, 0) / servers.length
  );

  // 2. API í˜¸ì¶œ
  const response = await fetch('/api/ai/query', {
    method: 'POST',
    body: JSON.stringify({
      query: content,
      context: 'dashboard',
      mode: aiMode, // 'LOCAL' or 'GOOGLE_AI'
      metadata: {
        totalServers,
        onlineServers,
        avgCpu,
        avgMemory,
      },
    }),
  });

  // 3. ì‘ë‹µ í‘œì‹œ
  const data = await response.json();
  setMessages([
    ...messages,
    {
      content: data.response,
      role: 'assistant',
    },
  ]);
};
```

#### 2. API ì²˜ë¦¬

```typescript
// src/app/api/ai/query/route.ts

async function postHandler(request: NextRequest) {
  // 1. ìºì‹± í™•ì¸ (5ë¶„ TTL)
  const cached = await getCachedData(cacheKey);
  if (cached) return cached;

  // 2. SimplifiedQueryEngine í˜¸ì¶œ
  const engine = await getQueryEngine();
  const result = await engine.query({
    query,
    context: { metadata },
    options: { temperature, maxTokens },
  });

  // 3. ì‘ë‹µ ë°˜í™˜
  return NextResponse.json({
    success: true,
    response: result.response,
    engine: result.engine,
    responseTime: result.processingTime,
  });
}
```

#### 3. ì—”ì§„ ì²˜ë¦¬

```typescript
// src/services/ai/SimplifiedQueryEngine.ts

async query(request: QueryRequest): Promise<QueryResponse> {
  // 1. ì˜ë„ ë¶„ë¥˜
  const intent = await this.intentClassifier.classify(request.query);

  // 2. Provider ì„ íƒ
  if (intent.needsRAG) {
    context = await this.ragEngine.search(request.query);
  }

  // 3. Google AI í˜¸ì¶œ
  const response = await googleAI.generate({
    prompt: request.query,
    context: context,
  });

  return {
    success: true,
    response: response.text,
    engine: 'google-ai',
  };
}
```

### ì§€ì› ì¿¼ë¦¬ ì˜ˆì‹œ

```
âœ… "ì„œë²„ ìƒíƒœ í™•ì¸í•´ì¤˜"
âœ… "CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ ì„œë²„ëŠ”?"
âœ… "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŠ¸ë Œë“œ ë¶„ì„"
âœ… "ì¥ì•  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì„œë²„ëŠ”?"
âœ… "ì „ì²´ ì¸í”„ë¼ ìƒíƒœ ìš”ì•½"
```

---

## 2ï¸âƒ£ ìë™ì¥ì•  ë³´ê³ ì„œ (Auto Report)

### ë™ì‘ ë°©ì‹

```
ì•„ì´ì½˜ í´ë¦­
    â†“
ìë™ ë©”ì‹œì§€ ì „ì†¡: "ì‹œìŠ¤í…œ ì „ì²´ ì¥ì•  ë³´ê³ ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”"
    â†“
ìì—°ì–´ ì§ˆì˜ì™€ ë™ì¼í•œ í”Œë¡œìš°
    â†“
ë³´ê³ ì„œ í˜•ì‹ ì‘ë‹µ
```

### ì½”ë“œ í”Œë¡œìš°

#### 1. ìë™ ì‹¤í–‰

```typescript
// src/components/dashboard/AISidebarContent.tsx

useEffect(() => {
  if (selectedFunction === 'auto-report') {
    // ìë™ìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„± ë©”ì‹œì§€ ì „ì†¡
    void handleSendMessage('ì‹œìŠ¤í…œ ì „ì²´ ì¥ì•  ë³´ê³ ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”');

    // ì±„íŒ… íƒ­ìœ¼ë¡œ ì „í™˜
    setActiveTab('chat');

    // ë‹¤ì‹œ chat ëª¨ë“œë¡œ ë³µê·€
    setTimeout(() => setSelectedFunction('chat'), 100);
  }
}, [selectedFunction]);
```

#### 2. ë³´ê³ ì„œ í˜ì´ì§€ (ì„ íƒì )

```typescript
// src/components/ai/pages/AutoReportPage.tsx

export default function AutoReportPage() {
  const [reports, setReports] = useState<IncidentReport[]>(MOCK_REPORTS);

  const handleGenerateReport = async () => {
    // ì‹¤ì‹œê°„ ì„œë²„ ë°ì´í„° ìˆ˜ì§‘
    const serverData = await fetchServerMetrics();

    // AI ë¶„ì„ ìš”ì²­
    const response = await fetch('/api/ai/incident-report', {
      method: 'POST',
      body: JSON.stringify({ servers: serverData }),
    });

    // ë³´ê³ ì„œ í‘œì‹œ
    const report = await response.json();
    setReports([report, ...reports]);
  };

  return (
    <div>
      {reports.map(report => (
        <ReportCard key={report.id} report={report} />
      ))}
    </div>
  );
}
```

### ìƒì„±ë˜ëŠ” ë³´ê³ ì„œ ë‚´ìš©

```
ğŸ“„ ì¥ì•  ë³´ê³ ì„œ

1. ìš”ì•½
   - ì´ ì„œë²„: 17ê°œ
   - ì •ìƒ: 15ê°œ
   - ê²½ê³ : 2ê°œ
   - ì‹¬ê°: 0ê°œ

2. ì£¼ìš” ì´ìŠˆ
   - Server-03: CPU 95% (ì„ê³„ì¹˜ ì´ˆê³¼)
   - Server-07: ë””ìŠ¤í¬ 85% (ê²½ê³ )

3. ê¶Œì¥ ì¡°ì¹˜
   - Server-03: í”„ë¡œì„¸ìŠ¤ ìµœì í™” í•„ìš”
   - Server-07: ë””ìŠ¤í¬ ì •ë¦¬ ê¶Œì¥

4. ì˜ˆì¸¡
   - í–¥í›„ 1ì‹œê°„ ë‚´ ì¶”ê°€ ì¥ì•  ê°€ëŠ¥ì„±: ë‚®ìŒ
```

---

## 3ï¸âƒ£ ì´ìƒê°ì§€/ì˜ˆì¸¡ (Intelligent Monitoring)

### ë™ì‘ ë°©ì‹

```
4ë‹¨ê³„ AI ë¶„ì„ ì›Œí¬í”Œë¡œìš°:

1ë‹¨ê³„: ğŸš¨ ì‹¤ì‹œê°„ ì´ìƒ íƒì§€
    â†“
2ë‹¨ê³„: ğŸ” ê·¼ë³¸ ì›ì¸ ë¶„ì„
    â†“
3ë‹¨ê³„: ğŸ”® ì˜ˆì¸¡ì  ëª¨ë‹ˆí„°ë§
    â†“
4ë‹¨ê³„: ğŸ’¡ AI ì¸ì‚¬ì´íŠ¸
```

### ì½”ë“œ í”Œë¡œìš°

#### 1. ë¶„ì„ ì‹œì‘

```typescript
// src/components/ai/pages/IntelligentMonitoringPage.tsx

const handleStartAnalysis = async () => {
  setIsAnalyzing(true);

  // 1ë‹¨ê³„: ì´ìƒ íƒì§€
  setCurrentStep('ì´ìƒ íƒì§€ ì¤‘...');
  const anomalies = await detectAnomalies(serverData);

  // 2ë‹¨ê³„: ê·¼ë³¸ ì›ì¸ ë¶„ì„
  setCurrentStep('ê·¼ë³¸ ì›ì¸ ë¶„ì„ ì¤‘...');
  const rootCause = await analyzeRootCause(anomalies);

  // 3ë‹¨ê³„: ì˜ˆì¸¡ ëª¨ë‹ˆí„°ë§
  setCurrentStep('ì˜ˆì¸¡ ë¶„ì„ ì¤‘...');
  const prediction = await predictFuture(serverData);

  // 4ë‹¨ê³„: AI ì¸ì‚¬ì´íŠ¸
  setCurrentStep('ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...');
  const insights = await generateInsights({
    anomalies,
    rootCause,
    prediction,
  });

  setResult({
    anomalies,
    rootCause,
    prediction,
    insights,
  });

  setIsAnalyzing(false);
};
```

#### 2. API í˜¸ì¶œ

```typescript
// src/app/api/ai/intelligent-monitoring/route.ts

export async function POST(request: NextRequest) {
  const { serverId, analysisDepth } = await request.json();

  // 1. ì„œë²„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  const metrics = await getServerMetrics(serverId);

  // 2. ML ë¶„ì„ (GCP Functions)
  const mlAnalysis = await gcpFunctions.mlAnalytics({
    metrics,
    context: { analysis_type: 'anomaly' },
  });

  // 3. ì˜ˆì¸¡ ìƒì„±
  const prediction = await predictNextHour(metrics);

  // 4. ì¸ì‚¬ì´íŠ¸ ìƒì„± (Google AI)
  const insights = await googleAI.generate({
    prompt: `ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ì œê³µ:
      ì´ìƒ: ${mlAnalysis.anomalies}
      ì˜ˆì¸¡: ${prediction}`,
  });

  return NextResponse.json({
    anomalies: mlAnalysis.anomalies,
    prediction,
    insights: insights.text,
  });
}
```

### ë¶„ì„ ê²°ê³¼ ì˜ˆì‹œ

```
ğŸš¨ ì´ìƒ íƒì§€ ê²°ê³¼:
- Server-03: CPU ê¸‰ì¦ (95%)
- Server-05: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì˜ì‹¬

ğŸ” ê·¼ë³¸ ì›ì¸:
- Server-03: ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ ê³¼ë¶€í•˜
- Server-05: ìºì‹œ ë¯¸ì •ë¦¬

ğŸ”® ì˜ˆì¸¡:
- í–¥í›„ 1ì‹œê°„: CPU ì‚¬ìš©ë¥  85%ë¡œ ì•ˆì •í™” ì˜ˆìƒ
- í–¥í›„ 3ì‹œê°„: ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  90% ë„ë‹¬ ê°€ëŠ¥

ğŸ’¡ ì¸ì‚¬ì´íŠ¸:
- ì¦‰ì‹œ ì¡°ì¹˜: Server-03 í”„ë¡œì„¸ìŠ¤ ì¬ì‹œì‘
- ì˜ˆë°© ì¡°ì¹˜: Server-05 ìºì‹œ ì •ë¦¬ ìŠ¤ì¼€ì¤„ë§
```

---

## 4ï¸âƒ£ AI ê³ ê¸‰ê´€ë¦¬ (Advanced Management)

### ë™ì‘ ë°©ì‹

```
ML í•™ìŠµ ì„¼í„°
    â†“
ë°ì´í„° ìˆ˜ì§‘ ë° í•™ìŠµ
    â†“
ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    â†“
ìë™ ìµœì í™”
```

### ì½”ë“œ í”Œë¡œìš°

#### 1. ML í•™ìŠµ ì„¼í„°

```typescript
// src/components/ai/pages/MLLearningCenter.tsx

export default function MLLearningCenter() {
  const [trainingStatus, setTrainingStatus] = useState('idle');

  const handleStartTraining = async () => {
    setTrainingStatus('training');

    // 1. í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
    const trainingData = await collectTrainingData();

    // 2. ML ëª¨ë¸ í•™ìŠµ (GCP Functions)
    const response = await fetch('/api/ai/ml/train', {
      method: 'POST',
      body: JSON.stringify({ data: trainingData }),
    });

    // 3. í•™ìŠµ ê²°ê³¼ í‘œì‹œ
    const result = await response.json();
    setTrainingStatus('completed');

    console.log('í•™ìŠµ ì™„ë£Œ:', result.accuracy);
  };

  return (
    <div>
      <button onClick={handleStartTraining}>
        í•™ìŠµ ì‹œì‘
      </button>
      <div>ìƒíƒœ: {trainingStatus}</div>
    </div>
  );
}
```

#### 2. ML í•™ìŠµ API

```typescript
// src/app/api/ai/ml/train/route.ts

export async function POST(request: NextRequest) {
  const { data } = await request.json();

  // 1. ë°ì´í„° ì „ì²˜ë¦¬
  const processed = preprocessData(data);

  // 2. GCP Functionsë¡œ í•™ìŠµ ìš”ì²­
  const result = await gcpFunctions.callFunction('ml-train', {
    data: processed,
    epochs: 10,
    batchSize: 32,
  });

  // 3. ëª¨ë¸ ì €ì¥ (Supabase)
  await supabase.from('ml_models').insert({
    model_data: result.model,
    accuracy: result.accuracy,
    created_at: new Date(),
  });

  return NextResponse.json({
    success: true,
    accuracy: result.accuracy,
  });
}
```

### ê´€ë¦¬ ê¸°ëŠ¥

```
âœ… ML ëª¨ë¸ í•™ìŠµ
âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
âœ… ë°ì´í„° ìˆ˜ì§‘ ê´€ë¦¬
âœ… ìºì‹œ í†µê³„ í™•ì¸
âœ… API ì‚¬ìš©ëŸ‰ ì¶”ì 
```

---

## 5ï¸âƒ£ ë¬´ë£Œ í‹°ì–´ ëª¨ë‹ˆí„° (Free Tier Monitor)

### ë™ì‘ ë°©ì‹

```
ì•„ì´ì½˜ í´ë¦­
    â†“
ì¸ì‚¬ì´íŠ¸ íƒ­ìœ¼ë¡œ ì „í™˜
    â†“
FreeTierMonitor ì»´í¬ë„ŒíŠ¸ í‘œì‹œ
    â†“
ì‹¤ì‹œê°„ ì‚¬ìš©ëŸ‰ í‘œì‹œ (60ì´ˆ ê°±ì‹ )
```

### ì½”ë“œ í”Œë¡œìš°

#### 1. ì»´í¬ë„ŒíŠ¸

```typescript
// src/components/ai/FreeTierMonitor.tsx

export default function FreeTierMonitor() {
  const [stats, setStats] = useState<FreeTierStats | null>(null);

  useEffect(() => {
    const fetchStats = async () => {
      const res = await fetch('/api/ai/cache-stats');
      const data = await res.json();

      setStats({
        vercel: { used: 10, limit: 100, unit: 'GB' },
        supabase: { used: 50, limit: 500, unit: 'MB' },
        googleAI: {
          used: data.googleAI?.dailyUsage || 0,
          limit: 1200,
          unit: 'ìš”ì²­/ì¼'
        },
      });
    };

    void fetchStats();
    const interval = setInterval(() => void fetchStats(), 60000);
    return () => clearInterval(interval);
  }, []);

  return (
    <div>
      {services.map(service => (
        <UsageBar
          key={service.name}
          name={service.name}
          used={service.used}
          limit={service.limit}
        />
      ))}
    </div>
  );
}
```

### í‘œì‹œ ì •ë³´

```
ğŸ“Š ë¬´ë£Œ í‹°ì–´ ì‚¬ìš©ëŸ‰

âš¡ Vercel: 10% (10/100 GB)
â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘

ğŸ’¾ Supabase: 10% (50/500 MB)
â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘

â˜ï¸ Google AI: 25% (300/1200 ìš”ì²­/ì¼)
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘

ğŸ“ˆ ì´ ìš´ì˜ë¹„: $0/ì›”
```

---

## ğŸ“Š ê¸°ëŠ¥ë³„ ë°ì´í„° ì†ŒìŠ¤

| ê¸°ëŠ¥                 | ë°ì´í„° ì†ŒìŠ¤                           | API ì—”ë“œí¬ì¸íŠ¸                   |
| -------------------- | ------------------------------------- | -------------------------------- |
| **ìì—°ì–´ ì§ˆì˜**      | StaticDataLoader + Google AI (Hybrid) | `/api/ai/unified-stream`         |
| **ìë™ì¥ì•  ë³´ê³ ì„œ**  | StaticDataLoader + Google AI          | `/api/ai/incident-report`        |
| **ì´ìƒê°ì§€/ì˜ˆì¸¡**    | StaticDataLoader + GCP ML             | `/api/ai/intelligent-monitoring` |
| **AI ê³ ê¸‰ê´€ë¦¬**      | Supabase + GCP ML                     | `/api/ai/ml/train`               |
| **ë¬´ë£Œ í‹°ì–´ ëª¨ë‹ˆí„°** | Cache Stats                           | `/api/ai/cache-stats`            |

---

## ğŸ”„ ê³µí†µ ì²˜ë¦¬ í”Œë¡œìš°

### ëª¨ë“  ê¸°ëŠ¥ì´ ê³µìœ í•˜ëŠ” ì²˜ë¦¬

```
1. ìš”ì²­ ê²€ì¦
2. ìºì‹± í™•ì¸ (5ë¶„ TTL)
3. ì‹¤ì œ ì²˜ë¦¬ (ìºì‹œ ë¯¸ìŠ¤ ì‹œ)
4. ì‘ë‹µ í¬ë§·íŒ…
5. ë¡œê¹… (Supabase)
```

---

## ğŸ“ ê²°ë¡ 

### âœ… ëª¨ë“  ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„

**ë™ì‘ í™•ì¸**:

- ìì—°ì–´ ì§ˆì˜: âœ… ì •ìƒ
- ìë™ì¥ì•  ë³´ê³ ì„œ: âœ… ì •ìƒ
- ì´ìƒê°ì§€/ì˜ˆì¸¡: âœ… ì •ìƒ
- AI ê³ ê¸‰ê´€ë¦¬: âœ… ì •ìƒ
- ë¬´ë£Œ í‹°ì–´ ëª¨ë‹ˆí„°: âœ… ì •ìƒ

**ë°ì´í„° í”Œë¡œìš°**: UI â†’ API â†’ Engine â†’ ì‘ë‹µ

**ì„±ëŠ¥**: í‰ê·  250-350ms (ìºì‹œ íˆíŠ¸ ì‹œ 15ms)

---

**í…ŒìŠ¤íŠ¸ ë°©ë²•**:

```bash
# ê°œë°œ ì„œë²„ ì‹¤í–‰
npm run dev:stable

# ë¸Œë¼ìš°ì €ì—ì„œ ê° ê¸°ëŠ¥ í´ë¦­í•˜ì—¬ í™•ì¸
http://localhost:3000
```
