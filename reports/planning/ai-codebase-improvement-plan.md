# AI ì½”ë“œë² ì´ìŠ¤ ê°œì„  ì‘ì—… ê³„íšì„œ

**ì‘ì„±ì¼**: 2026-01-24
**ë²„ì „**: v7.0.0 ê¸°ì¤€
**ëª©í‘œ**: AI Assistant + Cloud Run AI Engine ì½”ë“œ í’ˆì§ˆ ê°œì„ 

---

## 1. ê°œìš”

### 1.1 ë¶„ì„ ë²”ìœ„
| ì˜ì—­ | íŒŒì¼ | ë¼ì¸ ìˆ˜ |
|------|------|--------:|
| Frontend AI Hooks | 6ê°œ | ~2,200 |
| Cloud Run AI Engine | 6ê°œ | ~3,750 |
| **ì´ê³„** | **12ê°œ** | **~5,950** |

### 1.2 ë°œê²¬ëœ ì´ìŠˆ ìš”ì•½
| ìš°ì„ ìˆœìœ„ | ê°œìˆ˜ | ìœ í˜• |
|:--------:|:----:|------|
| ğŸ”´ P0 (Critical) | 3ê°œ | Resource Leak, Memory Leak, Race Condition |
| ğŸŸ  P1 (High) | 3ê°œ | Error Handling, Type Safety |
| ğŸŸ¡ P2 (Medium) | 3ê°œ | UX, Code Quality |

---

## 2. Phase 1: P0 Critical Issues (ì˜ˆìƒ: 45ë¶„)

### 2.1 Generator Resource Leak ìˆ˜ì •
**íŒŒì¼**: `cloud-run/ai-engine/src/services/ai-sdk/supervisor.ts`
**ë¼ì¸**: 763-780

**í˜„ì¬ ì½”ë“œ**:
```typescript
for await (const textPart of result.textStream) {
  const elapsed = Date.now() - startTime;
  if (elapsed >= SINGLE_AGENT_HARD_TIMEOUT) {
    console.error(`ğŸ›‘ [SingleAgent] Hard timeout reached...`);
    yield { type: 'error', data: { ... } };
    return; // âš ï¸ streamTextê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì† ì‹¤í–‰
  }
  fullText += textPart;
  yield { type: 'text_delta', data: textPart };
}
```

**ìˆ˜ì • ê³„íš**:
```typescript
for await (const textPart of result.textStream) {
  const elapsed = Date.now() - startTime;
  if (elapsed >= SINGLE_AGENT_HARD_TIMEOUT) {
    console.error(`ğŸ›‘ [SingleAgent] Hard timeout reached...`);

    // ğŸ¯ P0 Fix: Graceful stream abort
    try {
      result.textStream.return?.();
    } catch {
      // Silent - best effort cleanup
    }

    yield {
      type: 'error',
      data: {
        code: 'STREAM_TIMEOUT',
        message: 'Processing exceeded time limit',
        partialText: fullText.length > 0 ? fullText.slice(0, 100) + '...' : undefined
      }
    };
    return;
  }
  fullText += textPart;
  yield { type: 'text_delta', data: textPart };
}
```

**ê²€ì¦ ë°©ë²•**:
- Cloud Run ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- íƒ€ì„ì•„ì›ƒ í›„ CPU ì‚¬ìš©ëŸ‰ í™•ì¸

---

### 2.2 Stale Closure in Microtask ìˆ˜ì •
**íŒŒì¼**: `src/hooks/ai/useHybridAIQuery.ts`
**ë¼ì¸**: 452-481

**í˜„ì¬ ì½”ë“œ**:
```typescript
queueMicrotask(() => {
  if (controller.signal.aborted) return;

  // âŒ asyncQueryê°€ ë Œë” ì‹œì  ê°’ ìº¡ì²˜ë¨
  asyncQuery
    .sendQuery(query)
    .then(() => {
      if (!controller.signal.aborted) {
        setState((prev) => ({ ...prev, jobId: asyncQuery.jobId }));
      }
    })
    .catch((error) => { ... });
});
```

**ìˆ˜ì • ê³„íš**:
```typescript
// ğŸ¯ P0 Fix: Capture current reference before microtask
const currentAsyncQuery = asyncQuery;
const currentQuery = query;

queueMicrotask(() => {
  if (controller.signal.aborted) return;

  currentAsyncQuery
    .sendQuery(currentQuery)
    .then(() => {
      if (!controller.signal.aborted) {
        // Use functional update to get latest state
        setState((prev) => ({
          ...prev,
          jobId: currentAsyncQuery.jobId
        }));
      }
    })
    .catch((error) => { ... });
});
```

**ê²€ì¦ ë°©ë²•**:
- ë¹ ë¥¸ ì—°ì† ìš”ì²­ ì‹œ jobId ì¼ì¹˜ í™•ì¸
- React DevToolsë¡œ ìƒíƒœ ì¶”ì 

---

### 2.3 EventSource Memory Leak ìˆ˜ì •
**íŒŒì¼**: `src/hooks/ai/useAsyncAIQuery.ts`
**ë¼ì¸**: 200-350

**í˜„ì¬ ì½”ë“œ**:
```typescript
const connectSSE = (jobId: string, reconnectAttempt = 0) => {
  if (eventSourceRef.current) {
    listenersRef.current.forEach((listener, eventType) => {
      eventSourceRef.current?.removeEventListener(eventType, listener);
    });
    listenersRef.current.clear();
    eventSourceRef.current.close();
  }

  const eventSource = new EventSource(`/api/ai/jobs/${jobId}/stream`);
  eventSourceRef.current = eventSource;

  // âŒ ë§¤ reconnectë§ˆë‹¤ ìƒˆ í•¨ìˆ˜ ìƒì„±
  const addTrackedListener = (eventType: string, handler: EventListener) => {
    eventSource.addEventListener(eventType, handler);
    listenersRef.current.set(eventType, handler);
  };

  addTrackedListener('connected', () => { ... });
  addTrackedListener('progress', ((event: MessageEvent) => { ... }) as EventListener);
  // ...
};
```

**ìˆ˜ì • ê³„íš**:
```typescript
// ğŸ¯ P0 Fix: Define handlers outside connectSSE to maintain stable references
const handlersRef = useRef<{
  connected: EventListener | null;
  progress: EventListener | null;
  result: EventListener | null;
  error: EventListener | null;
  heartbeat: EventListener | null;
}>({
  connected: null,
  progress: null,
  result: null,
  error: null,
  heartbeat: null,
});

const connectSSE = useCallback((jobId: string, reconnectAttempt = 0) => {
  // Cleanup previous connection
  if (eventSourceRef.current) {
    const es = eventSourceRef.current;
    Object.entries(handlersRef.current).forEach(([type, handler]) => {
      if (handler) es.removeEventListener(type, handler);
    });
    es.close();
  }

  const eventSource = new EventSource(`/api/ai/jobs/${jobId}/stream`);
  eventSourceRef.current = eventSource;

  // Create handlers with current closure context
  handlersRef.current.connected = () => { ... };
  handlersRef.current.progress = ((event: MessageEvent) => { ... }) as EventListener;
  // ... other handlers

  // Register all handlers
  Object.entries(handlersRef.current).forEach(([type, handler]) => {
    if (handler) eventSource.addEventListener(type, handler);
  });
}, [/* stable dependencies */]);
```

**ê²€ì¦ ë°©ë²•**:
- Chrome DevTools Memory íƒ­ì—ì„œ í™ ìŠ¤ëƒ…ìƒ· ë¹„êµ
- 10íšŒ reconnect í›„ ë©”ëª¨ë¦¬ ì¦ê°€ í™•ì¸

---

## 3. Phase 2: P1 High Issues (ì˜ˆìƒ: 35ë¶„)

### 3.1 Promise.all â†’ Promise.allSettled ë³€ê²½
**íŒŒì¼**: `cloud-run/ai-engine/src/services/ai-sdk/agents/orchestrator.ts`
**ë¼ì¸**: 1007

**í˜„ì¬ ì½”ë“œ**:
```typescript
const results = await Promise.all(subtaskPromises);
```

**ìˆ˜ì • ê³„íš**:
```typescript
// ğŸ¯ P1 Fix: Use allSettled for graceful partial failure handling
const settledResults = await Promise.allSettled(subtaskPromises);

const results = settledResults.map((result, index) => {
  if (result.status === 'fulfilled') {
    return result.value;
  } else {
    console.error(`âŒ [Parallel] Subtask ${index + 1} rejected:`, result.reason);
    return { subtask: subtasks[index], result: null, index };
  }
});

// Log partial success rate
const successCount = settledResults.filter(r => r.status === 'fulfilled').length;
console.info(`ğŸ“Š [Parallel] ${successCount}/${settledResults.length} subtasks completed`);
```

---

### 3.2 Type Casting ì•ˆì „ì„± ê°•í™”
**íŒŒì¼**: `cloud-run/ai-engine/src/services/ai-sdk/model-provider.ts`
**ë¼ì¸**: 175-178

**í˜„ì¬ ì½”ë“œ**:
```typescript
function asLanguageModel(model: any): LanguageModel {
  return model as LanguageModel;
}
```

**ìˆ˜ì • ê³„íš**:
```typescript
import { LanguageModel } from 'ai';

/**
 * ğŸ¯ P1 Fix: Runtime validation for LanguageModel interface
 */
function asLanguageModel(model: unknown): LanguageModel {
  if (!model || typeof model !== 'object') {
    throw new TypeError('[ModelProvider] Model must be an object');
  }

  // Check for essential LanguageModel methods
  const m = model as Record<string, unknown>;
  if (typeof m.doGenerate !== 'function' && typeof m.doStream !== 'function') {
    throw new TypeError(
      '[ModelProvider] Model does not implement LanguageModel interface (missing doGenerate/doStream)'
    );
  }

  return model as LanguageModel;
}
```

---

### 3.3 stopChat Await ì¶”ê°€
**íŒŒì¼**: `src/hooks/ai/useHybridAIQuery.ts`
**ë¼ì¸**: 425-430

**í˜„ì¬ ì½”ë“œ**:
```typescript
stopChat();  // âŒ await ì—†ìŒ
queueMicrotask(() => {
  asyncQuery.sendQuery(query);
});
```

**ìˆ˜ì • ê³„íš**:
```typescript
// ğŸ¯ P1 Fix: Ensure stopChat completes before redirect
const handleRedirect = async () => {
  try {
    await Promise.resolve(stopChat());
  } catch (e) {
    // stopChat may not return a promise, ignore errors
  }

  // Now safe to redirect to job queue
  const currentAsyncQuery = asyncQuery;
  currentAsyncQuery
    .sendQuery(query)
    .then(() => { ... })
    .catch((error) => { ... });
};

handleRedirect();
```

---

## 4. Phase 3: P2 Medium Issues (ì˜ˆìƒ: 30ë¶„)

### 4.1 Progress ìƒíƒœ ì—ëŸ¬ ì‹œ ì´ˆê¸°í™”
**íŒŒì¼**: `src/hooks/ai/useAsyncAIQuery.ts`
**ë¼ì¸**: 174-185

**ìˆ˜ì • ê³„íš**:
```typescript
const handleError = (error: string) => {
  cleanup();
  setState((prev) => ({
    ...prev,
    isLoading: false,
    isConnected: false,
    error,
    progress: null,  // ğŸ¯ P2 Fix: Clear progress on error
  }));
  onError?.(error);
  resolve({ success: false, error });
};
```

---

### 4.2 onError Callback ì‹¤íš¨ì„± ê°œì„ 
**íŒŒì¼**: `cloud-run/ai-engine/src/services/ai-sdk/supervisor.ts`
**ë¼ì¸**: 746-756

**ìˆ˜ì • ê³„íš**:
```typescript
let streamError: Error | null = null;

const result = streamText({
  // ...
  onError: ({ error }) => {
    console.error('âŒ [SingleAgent] streamText error:', {
      error: error instanceof Error ? error.message : String(error),
    });
    // ğŸ¯ P2 Fix: Track error for later handling
    streamError = error instanceof Error ? error : new Error(String(error));
  },
});

// After stream loop, check for errors
if (streamError) {
  yield {
    type: 'warning',
    data: {
      code: 'STREAM_ERROR_OCCURRED',
      message: streamError.message
    }
  };
}
```

---

### 4.3 Handoff Array ìµœì í™”
**íŒŒì¼**: `cloud-run/ai-engine/src/services/ai-sdk/agents/orchestrator.ts`
**ë¼ì¸**: 518-541

**ìˆ˜ì • ê³„íš**:
```typescript
// ğŸ¯ P2 Fix: Use Map with timestamp key for O(1) operations
const handoffEventsMap = new Map<number, { from: string; to: string; reason?: string }>();

function recordHandoff(from: string, to: string, reason?: string) {
  const now = Date.now();
  const cutoff = now - HANDOFF_EVENTS_CONFIG.cleanupAge;

  // O(n) cleanup only when needed (every 10 events)
  if (handoffEventsMap.size >= HANDOFF_EVENTS_CONFIG.maxSize) {
    for (const [timestamp] of handoffEventsMap) {
      if (timestamp < cutoff) {
        handoffEventsMap.delete(timestamp);
      }
    }
  }

  // O(1) insert
  handoffEventsMap.set(now, { from, to, reason });
}

// Convert to array when needed
function getHandoffEvents() {
  return Array.from(handoffEventsMap.entries())
    .map(([timestamp, event]) => ({ ...event, timestamp: new Date(timestamp) }));
}
```

---

## 5. ê²€ì¦ ê³„íš

### 5.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```bash
npm run test:quick
```
- 228ê°œ í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸

### 5.2 íƒ€ì… ì²´í¬
```bash
npm run type-check
```
- TypeScript strict mode í†µê³¼

### 5.3 ë¹Œë“œ ê²€ì¦
```bash
npm run build
```
- Next.js 16 + Cloud Run ë¹Œë“œ ì„±ê³µ

### 5.4 í†µí•© ê²€ì¦ (ì„ íƒ)
- AI ì±„íŒ… ì •ìƒ ë™ì‘
- Job Queue ì „í™˜ í…ŒìŠ¤íŠ¸
- íƒ€ì„ì•„ì›ƒ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

---

## 6. ì»¤ë°‹ ì „ëµ

### Phase 1 ì»¤ë°‹
```
fix(ai-engine): P0 generator resource leak and stream cleanup

- Add graceful abort for streamText on timeout
- Include partial text in error response
- Prevent Cloud Run background resource consumption
```

### Phase 2 ì»¤ë°‹
```
fix(ai): P0-P1 closure and error handling improvements

- Fix stale closure in redirect microtask
- Fix EventSource listener memory leak
- Change Promise.all to Promise.allSettled for graceful failures
- Add runtime validation for LanguageModel casting
- Await stopChat before job queue redirect
```

### Phase 3 ì»¤ë°‹
```
refactor(ai): P2 UX and code quality improvements

- Clear progress state on error
- Track stream errors for warning emission
- Optimize handoff events with Map for O(1) operations
```

---

## 7. ë¡¤ë°± ê³„íš

ë¬¸ì œ ë°œìƒ ì‹œ:
```bash
git revert HEAD~3..HEAD  # 3ê°œ ì»¤ë°‹ ë¡¤ë°±
```

ë˜ëŠ” íŠ¹ì • ì»¤ë°‹ë§Œ:
```bash
git revert <commit-hash>
```

---

## 8. ì¼ì •

| Phase | ì‘ì—… | ì˜ˆìƒ ì‹œê°„ |
|:-----:|------|:---------:|
| 1 | P0 Critical (3ê°œ) | 45ë¶„ |
| 2 | P1 High (3ê°œ) | 35ë¶„ |
| 3 | P2 Medium (3ê°œ) | 30ë¶„ |
| 4 | ê²€ì¦ + ì»¤ë°‹ | 20ë¶„ |
| **ì´ê³„** | | **~130ë¶„** |

---

**ìŠ¹ì¸ í›„ Phase 1ë¶€í„° ìˆœì°¨ ì§„í–‰**
