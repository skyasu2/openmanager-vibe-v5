# ============================================================================
# Cloud Build - Rust ML Inference Service
# Deploys to Cloud Run with IAM Authentication
# ============================================================================

steps:
  # Step 1: Build Docker image
  - id: 'build-image'
    name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - 'gcr.io/$PROJECT_ID/rust-inference:$SHORT_SHA'
      - '-t'
      - 'gcr.io/$PROJECT_ID/rust-inference:latest'
      - '.'
    dir: 'cloud-run/rust-inference'

  # Step 2: Push to Container Registry
  - id: 'push-image'
    name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - 'gcr.io/$PROJECT_ID/rust-inference:$SHORT_SHA'
    waitFor: ['build-image']

  - id: 'push-latest'
    name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - 'gcr.io/$PROJECT_ID/rust-inference:latest'
    waitFor: ['build-image']

  # Step 3: Deploy to Cloud Run
  - id: 'deploy'
    name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - 'run'
      - 'deploy'
      - 'rust-inference'
      - '--image=gcr.io/$PROJECT_ID/rust-inference:$SHORT_SHA'
      - '--region=asia-northeast3'
      - '--platform=managed'
      - '--allow-unauthenticated'         # ğŸŒ Public (ë‚´ë¶€ ML ì „ìš©, ë¯¼ê° ë°ì´í„° ì—†ìŒ)
      - '--memory=256Mi'                 # RustëŠ” ë©”ëª¨ë¦¬ ì ê²Œ ì‚¬ìš©
      - '--cpu=1'
      - '--min-instances=0'              # ğŸ’° Scale to Zero
      - '--max-instances=3'
      - '--timeout=30s'                  # ML ì¶”ë¡ ì€ ë¹ ë¦„
      - '--concurrency=80'               # RustëŠ” ë†’ì€ ë™ì‹œì„± ì²˜ë¦¬ ê°€ëŠ¥
    waitFor: ['push-image']

# Build timeout (Rust ë¹Œë“œëŠ” ì‹œê°„ ì†Œìš”)
timeout: '900s'

# Required images
images:
  - 'gcr.io/$PROJECT_ID/rust-inference:$SHORT_SHA'
  - 'gcr.io/$PROJECT_ID/rust-inference:latest'

# Note: Region is hardcoded to asia-northeast3 in deploy step
