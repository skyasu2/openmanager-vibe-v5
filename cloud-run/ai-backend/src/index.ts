/**
 * OpenManager AI Backend - Hono Server
 * Cloud Run ë°°í¬ìš© LangGraph Multi-Agent ì„œë²„
 */

import { serve } from '@hono/node-server';
import { Hono } from 'hono';
import { cors } from 'hono/cors';
import { logger } from 'hono/logger';
import { secureHeaders } from 'hono/secure-headers';
import { healthRoute } from './routes/health.js';
import { unifiedStreamRoute } from './routes/unified-stream.js';

const app = new Hono();

// ============================================================================
// Middleware
// ============================================================================

// CORS ì„¤ì • (Vercel ë„ë©”ì¸ í—ˆìš©)
app.use(
  '*',
  cors({
    origin: [
      'https://openmanager-vibe-v5.vercel.app',
      'https://*.vercel.app',
      'http://localhost:3000',
    ],
    allowMethods: ['GET', 'POST', 'OPTIONS'],
    allowHeaders: ['Content-Type', 'Authorization', 'X-Session-Id'],
    exposeHeaders: ['X-Session-Id', 'X-Target-Agent'],
    credentials: true,
  })
);

// ë³´ì•ˆ í—¤ë”
app.use('*', secureHeaders());

// ë¡œê¹…
app.use('*', logger());

// ============================================================================
// Routes
// ============================================================================

// í—¬ìŠ¤ì²´í¬
app.route('/health', healthRoute);

// AI ë¼ìš°íŠ¸ (LangGraph Multi-Agent)
app.route('/api/ai/unified-stream', unifiedStreamRoute);

// ê¸°ë³¸ ë¼ìš°íŠ¸
app.get('/', (c) => {
  return c.json({
    service: 'OpenManager AI Backend',
    version: '1.0.0',
    status: 'running',
    agents: ['supervisor', 'nlq-agent', 'analyst-agent', 'reporter-agent'],
  });
});

// ============================================================================
// Server Start
// ============================================================================

const port = Number(process.env.PORT) || 8080;

console.log(`ðŸš€ AI Backend starting on port ${port}...`);
console.log(`ðŸ“¡ Environment: ${process.env.NODE_ENV || 'development'}`);

serve({
  fetch: app.fetch,
  port,
});

console.log(`âœ… AI Backend running at http://localhost:${port}`);
