/**
 * Server Metrics Tools (AI SDK Format)
 *
 * Converted from LangChain tools to Vercel AI SDK format.
 * Used by the new AI SDK Supervisor.
 *
 * @version 1.0.0
 * @updated 2025-12-28
 */

import { tool } from 'ai';
import { z } from 'zod';

// ============================================================================
// Cache Key Utilities
// ============================================================================

/**
 * Create stable cache key from filter array
 * Ensures consistent key order in objects and sorted array items
 */
function stableStringify(filters: Array<Record<string, unknown>> | undefined): string {
  if (!filters || filters.length === 0) return '[]';

  // Sort each object's keys and stringify, then sort array by resulting strings
  const normalized = filters.map(filter => {
    const sortedKeys = Object.keys(filter).sort();
    const sortedObj: Record<string, unknown> = {};
    for (const key of sortedKeys) {
      sortedObj[key] = filter[key];
    }
    return JSON.stringify(sortedObj);
  }).sort();

  return `[${normalized.join(',')}]`;
}

// ============================================================================
// Response Schemas (Best Practice: Structured Output Documentation)
// ============================================================================

/**
 * Server info in response
 */
export const serverInfoSchema = z.object({
  id: z.string().describe('ì„œë²„ ê³ ìœ  ID'),
  name: z.string().describe('ì„œë²„ ì´ë¦„'),
  status: z.enum(['online', 'offline', 'warning', 'critical']).describe('ì„œë²„ ìƒíƒœ'),
  cpu: z.number().describe('CPU ì‚¬ìš©ë¥  (%)'),
  memory: z.number().describe('ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)'),
  disk: z.number().describe('ë””ìŠ¤í¬ ì‚¬ìš©ë¥  (%)'),
});

/**
 * getServerMetrics response schema
 */
export const getServerMetricsResponseSchema = z.object({
  success: z.boolean(),
  servers: z.array(serverInfoSchema),
  summary: z.object({
    total: z.number().describe('ì „ì²´ ì„œë²„ ìˆ˜'),
    alertCount: z.number().describe('ê²½ê³ /ìœ„í—˜ ìƒíƒœ ì„œë²„ ìˆ˜'),
  }),
  timestamp: z.string().describe('ì¡°íšŒ ì‹œê°„ (ISO 8601)'),
});

/**
 * getServerMetricsAdvanced response schema
 */
export const getServerMetricsAdvancedResponseSchema = z.object({
  success: z.boolean(),
  answer: z.string().describe('âš ï¸ ì‚¬ìš©ìì—ê²Œ ì´ ê°’ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì„¸ìš”'),
  globalSummary: z.record(z.number()).describe('ì „ì²´ ì„œë²„ ì§‘ê³„: cpu_avg, cpu_max, cpu_min ë“±'),
  serverCount: z.number().describe('ì¡°íšŒëœ ì„œë²„ ìˆ˜'),
  query: z.object({
    timeRange: z.string().optional(),
    metric: z.string().optional(),
    aggregation: z.string().optional(),
    sortBy: z.string().optional(),
    limit: z.number().optional(),
  }),
  servers: z.array(z.object({
    id: z.string(),
    name: z.string(),
    type: z.string(),
    location: z.string(),
    metrics: z.record(z.number()),
    dataPoints: z.number().optional(),
  })).describe('ìƒìœ„ 5ê°œ ì„œë²„ ìƒ˜í”Œ'),
  hasMore: z.boolean().describe('5ê°œ ì´ìƒì¼ ë•Œ true'),
  timestamp: z.string(),
});

/**
 * filterServers response schema
 */
export const filterServersResponseSchema = z.object({
  success: z.boolean(),
  condition: z.string().describe('ì ìš©ëœ í•„í„° ì¡°ê±´'),
  servers: z.array(z.object({
    id: z.string(),
    name: z.string(),
    status: z.string(),
  }).passthrough()), // Allow additional fields
  summary: z.object({
    matched: z.number().describe('ì¡°ê±´ì— ë§ëŠ” ì„œë²„ ìˆ˜'),
    returned: z.number().describe('ë°˜í™˜ëœ ì„œë²„ ìˆ˜'),
    total: z.number().describe('ì „ì²´ ì„œë²„ ìˆ˜'),
  }),
  timestamp: z.string(),
});

/**
 * getServerByGroup response schema
 */
export const getServerByGroupAdvancedResponseSchema = z.object({
  success: z.boolean(),
  group: z.string(),
  servers: z.array(serverInfoSchema),
  summary: z.object({
    total: z.number(),
    online: z.number(),
    warning: z.number(),
    critical: z.number(),
    filtered: z.number().describe('Number of servers after applying filters'),
  }),
  appliedFilters: z.object({
    cpuMin: z.number().optional(),
    cpuMax: z.number().optional(),
    memoryMin: z.number().optional(),
    memoryMax: z.number().optional(),
    status: z.string().optional(),
  }).optional(),
  appliedSort: z.object({
    by: z.string(),
    order: z.string(),
  }).optional(),
  timestamp: z.string(),
});

export const getServerByGroupResponseSchema = z.object({
  success: z.boolean(),
  group: z.string().describe('ì¡°íšŒëœ ì„œë²„ ê·¸ë£¹/íƒ€ì…'),
  servers: z.array(z.object({
    id: z.string(),
    name: z.string(),
    type: z.string(),
    status: z.enum(['online', 'warning', 'critical']),
    cpu: z.number(),
    memory: z.number(),
    disk: z.number(),
  })),
  summary: z.object({
    total: z.number().describe('í•´ë‹¹ ê·¸ë£¹ ì„œë²„ ì´ ìˆ˜'),
    online: z.number().describe('ì˜¨ë¼ì¸ ìƒíƒœ ìˆ˜'),
    warning: z.number().describe('ê²½ê³  ìƒíƒœ ìˆ˜'),
    critical: z.number().describe('ìœ„í—˜ ìƒíƒœ ìˆ˜'),
  }),
  timestamp: z.string(),
});

// Export types for external use
export type ServerInfo = z.infer<typeof serverInfoSchema>;
export type GetServerMetricsResponse = z.infer<typeof getServerMetricsResponseSchema>;
export type GetServerMetricsAdvancedResponse = z.infer<typeof getServerMetricsAdvancedResponseSchema>;
export type FilterServersResponse = z.infer<typeof filterServersResponseSchema>;
export type GetServerByGroupResponse = z.infer<typeof getServerByGroupResponseSchema>;

// Data sources
import {
  getCurrentState,
  type ServerSnapshot,
} from '../data/precomputed-state';
import {
  FIXED_24H_DATASETS,
  getDataAtMinute,
  getRecentData,
  type Server24hDataset,
  type Fixed10MinMetric,
} from '../data/fixed-24h-metrics';

// Caching
import { getDataCache } from '../lib/cache-layer';

// ============================================================================
// 1. Helper Functions
// ============================================================================

/**
 * Get current minute of day (KST)
 */
function getCurrentMinuteOfDay(): number {
  const koreaTime = new Date().toLocaleString('en-US', {
    timeZone: 'Asia/Seoul',
  });
  const koreaDate = new Date(koreaTime);
  return koreaDate.getHours() * 60 + koreaDate.getMinutes();
}

/**
 * Calculate aggregation over time series data
 */
function calculateAggregation(
  dataPoints: Array<{ cpu: number; memory: number; disk: number }>,
  metric: 'cpu' | 'memory' | 'disk' | 'network' | 'all',
  func: 'avg' | 'max' | 'min' | 'count'
): Record<string, number> {
  if (func === 'count') {
    return { count: dataPoints.length };
  }

  const metrics = metric === 'all' ? ['cpu', 'memory', 'disk'] : [metric];
  const result: Record<string, number> = {};

  for (const m of metrics) {
    const values = dataPoints
      .map((d) => d[m as keyof typeof d] as number)
      .filter((v) => v !== undefined);

    if (values.length === 0) {
      result[m] = 0;
      continue;
    }

    switch (func) {
      case 'avg':
        result[m] =
          Math.round((values.reduce((a, b) => a + b, 0) / values.length) * 10) /
          10;
        break;
      case 'max':
        result[m] = Math.max(...values);
        break;
      case 'min':
        result[m] = Math.min(...values);
        break;
    }
  }

  return result;
}

/**
 * Get time range data points for a server
 */
function getTimeRangeData(
  dataset: Server24hDataset,
  timeRange: string
): Fixed10MinMetric[] {
  const currentMinute = getCurrentMinuteOfDay();

  let hoursBack = 0;
  switch (timeRange) {
    case 'last1h':
      hoursBack = 1;
      break;
    case 'last6h':
      hoursBack = 6;
      break;
    case 'last24h':
      hoursBack = 24;
      break;
    case 'current':
    default:
      return [getDataAtMinute(dataset, currentMinute)].filter(
        Boolean
      ) as Fixed10MinMetric[];
  }

  const pointsNeeded = hoursBack * 6;
  return getRecentData(dataset, currentMinute, pointsNeeded);
}

// ============================================================================
// 2. AI SDK Tools
// ============================================================================

/**
 * Basic Server Metrics Tool
 * O(1) lookup using precomputed state
 *
 * Best Practices Applied:
 * - Detailed description with input/output examples
 * - .describe() on all schema fields
 * - Clear response structure documentation
 */
export const getServerMetrics = tool({
  description: `[í˜„ì¬ ìƒíƒœ ì „ìš©] ì„œë²„ CPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬ì˜ ì‹¤ì‹œê°„ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

âš ï¸ ì‹œê°„ ë²”ìœ„(ì§€ë‚œ 1ì‹œê°„, 6ì‹œê°„ ë“±), í‰ê· /ìµœëŒ€ê°’ ì§‘ê³„ê°€ í•„ìš”í•˜ë©´ getServerMetricsAdvancedë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

## ì…ë ¥ ì˜ˆì‹œ
1. ì „ì²´ ì„œë²„ í˜„ì¬ ìƒíƒœ: { }
2. íŠ¹ì • ì„œë²„: { "serverId": "web-nginx-icn-01" }

## ì¶œë ¥ í˜•ì‹
{ "success": true, "servers": [{ "id": "...", "name": "...", "cpu": 45, "memory": 67, "disk": 55 }], "summary": { "total": 15 } }

## ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
- "ì„œë²„ ìƒíƒœ" / "í˜„ì¬ CPU" â†’ ì´ ë„êµ¬
- "ì§€ë‚œ 6ì‹œê°„ í‰ê· " / "ìµœê·¼ 1ì‹œê°„ ìµœëŒ€ê°’" â†’ getServerMetricsAdvanced ì‚¬ìš©`,
  inputSchema: z.object({
    serverId: z
      .string()
      .optional()
      .describe('ì¡°íšŒí•  ì„œë²„ ID. ì˜ˆ: "api-server-01", "db-server-02". ìƒëµí•˜ë©´ ëª¨ë“  ì„œë²„ ì¡°íšŒ. ì ˆëŒ€ "all" ë¬¸ìì—´ì„ ë„£ì§€ ë§ˆì„¸ìš”.'),
    metric: z
      .enum(['cpu', 'memory', 'disk', 'all'])
      .default('all')
      .describe('ì¡°íšŒí•  ë©”íŠ¸ë¦­ ì¢…ë¥˜. cpu=CPU ì‚¬ìš©ë¥ , memory=ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ , disk=ë””ìŠ¤í¬ ì‚¬ìš©ë¥ , all=ì „ì²´'),
  }),
  execute: async ({
    serverId,
    metric,
  }: {
    serverId?: string;
    metric: 'cpu' | 'memory' | 'disk' | 'all';
  }) => {
    const cache = getDataCache();
    const cacheKey = serverId || 'all';

    // Best Practice: Use cache.getMetrics with lazy computation
    return cache.getMetrics(cacheKey, async () => {
      const state = getCurrentState();

      const servers: ServerSnapshot[] = serverId
        ? state.servers.filter((s) => s.id === serverId)
        : state.servers;

      console.log(`ğŸ“Š [getServerMetrics] Computing for ${cacheKey} (cache miss)`);

      return {
        success: true,
        servers: servers.map((s) => ({
          id: s.id,
          name: s.name,
          status: s.status,
          cpu: s.cpu,
          memory: s.memory,
          disk: s.disk,
        })),
        summary: {
          total: servers.length,
          alertCount: servers.filter(
            (s) => s.status === 'warning' || s.status === 'critical'
          ).length,
        },
        timestamp: new Date().toISOString(),
        _cached: false,
      };
    });
  },
});

/**
 * Advanced Server Metrics Tool
 * Supports time range, filtering, aggregation
 *
 * Best Practices Applied:
 * - Comprehensive description with input/output examples
 * - .describe() on all schema fields
 * - Clear response structure documentation
 */
export const getServerMetricsAdvanced = tool({
  description: `ì‹œê°„ ë²”ìœ„ ì§‘ê³„ ë„êµ¬. "ì§€ë‚œ Nì‹œê°„", "í‰ê· ", "ìµœëŒ€ê°’" ì§ˆë¬¸ì— ì‚¬ìš©.

âš ï¸ ì¤‘ìš”: ì‘ë‹µì˜ "answer" í•„ë“œë¥¼ ì‚¬ìš©ìì—ê²Œ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì„¸ìš”.

ì˜ˆì‹œ:
- "6ì‹œê°„ CPU í‰ê· " â†’ { "timeRange": "last6h", "metric": "cpu", "aggregation": "avg" }

ì¶œë ¥: { answer: "ì§€ë‚œ 6ì‹œê°„ ì „ì²´ 15ëŒ€ ì„œë²„ ì§‘ê³„: cpu_avg=34%...", globalSummary: {...} }`,
  inputSchema: z.object({
    serverId: z
      .string()
      .optional()
      .describe('ì¡°íšŒí•  ì„œë²„ ID. ì˜ˆ: "db-server-01". ìƒëµí•˜ë©´ ëª¨ë“  ì„œë²„ ëŒ€ìƒ. ì ˆëŒ€ "all" ë¬¸ìì—´ì„ ë„£ì§€ ë§ˆì„¸ìš”.'),
    metric: z
      .enum(['cpu', 'memory', 'disk', 'network', 'all'])
      .default('all')
      .describe('ì¡°íšŒí•  ë©”íŠ¸ë¦­. cpu/memory/disk/network ì¤‘ ì„ íƒ ë˜ëŠ” all(ì „ì²´)'),
    timeRange: z
      .enum(['current', 'last1h', 'last6h', 'last24h'])
      .default('current')
      .describe('ì‹œê°„ ë²”ìœ„. current=í˜„ì¬, last1h=ìµœê·¼ 1ì‹œê°„, last6h=ìµœê·¼ 6ì‹œê°„, last24h=ìµœê·¼ 24ì‹œê°„'),
    filters: z
      .array(
        z.object({
          field: z.enum(['cpu', 'memory', 'disk', 'network', 'status']).describe('í•„í„° ëŒ€ìƒ í•„ë“œ'),
          operator: z.enum(['>', '<', '>=', '<=', '==', '!=']).describe('ë¹„êµ ì—°ì‚°ì'),
          value: z.union([z.number(), z.string()]).describe('ë¹„êµí•  ê°’ (ìˆ«ì ë˜ëŠ” ë¬¸ìì—´)'),
        })
      )
      .optional()
      .describe('í•„í„° ì¡°ê±´ ë°°ì—´. ì˜ˆ: [{field:"cpu", operator:">", value:80}]'),
    aggregation: z
      .enum(['avg', 'max', 'min', 'count', 'none'])
      .default('none')
      .describe('ì§‘ê³„ í•¨ìˆ˜. avg=í‰ê· , max=ìµœëŒ€ê°’, min=ìµœì†Œê°’, count=ê°œìˆ˜, none=ì§‘ê³„ì•ˆí•¨'),
    sortBy: z
      .enum(['cpu', 'memory', 'disk', 'network', 'name'])
      .optional()
      .describe('ì •ë ¬ ê¸°ì¤€ í•„ë“œ'),
    sortOrder: z.enum(['asc', 'desc']).default('desc').describe('ì •ë ¬ ìˆœì„œ. asc=ì˜¤ë¦„ì°¨ìˆœ, desc=ë‚´ë¦¼ì°¨ìˆœ'),
    limit: z.number().optional().describe('ë°˜í™˜í•  ìµœëŒ€ ì„œë²„ ìˆ˜. ì˜ˆ: 5ë©´ TOP 5'),
  }),
  execute: async ({
    serverId,
    metric,
    timeRange,
    filters,
    aggregation,
    sortBy,
    sortOrder,
    limit,
  }: {
    serverId?: string;
    metric: 'cpu' | 'memory' | 'disk' | 'network' | 'all';
    timeRange: 'current' | 'last1h' | 'last6h' | 'last24h';
    filters?: Array<{
      field: 'cpu' | 'memory' | 'disk' | 'network' | 'status';
      operator: '>' | '<' | '>=' | '<=' | '==' | '!=';
      value: number | string;
    }>;
    aggregation: 'avg' | 'max' | 'min' | 'count' | 'none';
    sortBy?: 'cpu' | 'memory' | 'disk' | 'network' | 'name';
    sortOrder: 'asc' | 'desc';
    limit?: number;
  }) => {
    const cache = getDataCache();
    // Cache key: combine all parameters that affect the result
    // Use stableStringify for filters to ensure consistent key order
    const cacheKey = `adv:${serverId || 'all'}:${timeRange}:${metric}:${aggregation}:${sortBy || 'none'}:${sortOrder}:${limit || 0}:${stableStringify(filters)}`;

    return cache.getOrCompute('metrics', cacheKey, async () => {
    console.log(`ğŸ“Š [getServerMetricsAdvanced] Computing for ${cacheKey} (cache miss)`);
    try {
      // 1. Get target datasets
      const targetDatasets = serverId
        ? FIXED_24H_DATASETS.filter((d) => d.serverId === serverId)
        : FIXED_24H_DATASETS;

      if (targetDatasets.length === 0) {
        return { success: false, error: `Server not found: ${serverId}` };
      }

      // 2. Collect time range data
      const serverResults: Array<{
        id: string;
        name: string;
        type: string;
        location: string;
        metrics: Record<string, number>;
        dataPoints?: number;
      }> = [];

      for (const dataset of targetDatasets) {
        const dataPoints = getTimeRangeData(dataset, timeRange);
        if (dataPoints.length === 0) continue;

        let metrics: Record<string, number>;
        if (aggregation && aggregation !== 'none') {
          metrics = calculateAggregation(dataPoints, metric, aggregation);
        } else {
          const latest = dataPoints[dataPoints.length - 1] || dataPoints[0];
          metrics =
            metric === 'all'
              ? {
                  cpu: latest.cpu,
                  memory: latest.memory,
                  disk: latest.disk,
                  network: latest.network,
                }
              : { [metric]: latest[metric] };
        }

        serverResults.push({
          id: dataset.serverId,
          name: dataset.serverId,
          type: dataset.serverType,
          location: dataset.location,
          metrics,
          dataPoints: dataPoints.length,
        });
      }

      // 3. Apply filters
      let filteredResults = serverResults;
      if (filters && filters.length > 0) {
        filteredResults = serverResults.filter((server) => {
          return filters.every((filter) => {
            const value = server.metrics[filter.field];
            if (value === undefined) return true;

            switch (filter.operator) {
              case '>':
                return value > Number(filter.value);
              case '<':
                return value < Number(filter.value);
              case '>=':
                return value >= Number(filter.value);
              case '<=':
                return value <= Number(filter.value);
              case '==':
                return value === Number(filter.value);
              case '!=':
                return value !== Number(filter.value);
              default:
                return true;
            }
          });
        });
      }

      // 4. Apply sorting
      if (sortBy) {
        filteredResults.sort((a, b) => {
          const aVal = sortBy === 'name' ? a.name : (a.metrics[sortBy] ?? 0);
          const bVal = sortBy === 'name' ? b.name : (b.metrics[sortBy] ?? 0);
          if (typeof aVal === 'string' && typeof bVal === 'string') {
            return sortOrder === 'asc'
              ? aVal.localeCompare(bVal)
              : bVal.localeCompare(aVal);
          }
          return sortOrder === 'asc'
            ? Number(aVal) - Number(bVal)
            : Number(bVal) - Number(aVal);
        });
      }

      // 5. Apply limit
      if (limit && limit > 0) {
        filteredResults = filteredResults.slice(0, limit);
      }

      // 6. Calculate global summary (across all servers)
      const globalSummary: Record<string, number> = {};
      if (filteredResults.length > 0) {
        const metricsToSummarize = metric === 'all' ? ['cpu', 'memory', 'disk'] : [metric];
        for (const m of metricsToSummarize) {
          const values = filteredResults
            .map((s) => s.metrics[m])
            .filter((v) => v !== undefined);
          if (values.length > 0) {
            globalSummary[`${m}_avg`] = Math.round((values.reduce((a, b) => a + b, 0) / values.length) * 10) / 10;
            globalSummary[`${m}_max`] = Math.max(...values);
            globalSummary[`${m}_min`] = Math.min(...values);
          }
        }
      }

      // 7. Generate interpretation for LLM
      const timeRangeKr = {
        current: 'í˜„ì¬',
        last1h: 'ì§€ë‚œ 1ì‹œê°„',
        last6h: 'ì§€ë‚œ 6ì‹œê°„',
        last24h: 'ì§€ë‚œ 24ì‹œê°„',
      }[timeRange];

      const interpretation = Object.keys(globalSummary).length > 0
        ? `[ì‘ë‹µ ê°€ì´ë“œ] ${timeRangeKr} ì „ì²´ ${filteredResults.length}ëŒ€ ì„œë²„ ì§‘ê³„: ` +
          Object.entries(globalSummary)
            .map(([k, v]) => `${k}=${v}%`)
            .join(', ') +
          '. ì´ ê°’ì„ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•˜ì„¸ìš”.'
        : null;

      return {
        success: true,
        // âš ï¸ LLM: ì•„ë˜ answerë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”
        answer: interpretation || `${timeRangeKr} ë°ì´í„° ì¡°íšŒ ì™„ë£Œ`,
        globalSummary,
        serverCount: filteredResults.length,
        query: { timeRange, metric, aggregation, sortBy, limit },
        servers: filteredResults.slice(0, 5), // ìƒìœ„ 5ê°œë§Œ ë°˜í™˜ (í† í° ì ˆì•½)
        hasMore: filteredResults.length > 5,
        timestamp: new Date().toISOString(),
      };
    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : String(error),
      };
    }
    }); // End of cache.getOrCompute wrapper
  },
});

/**
 * Filter Servers Tool
 * Quick filtering by condition
 *
 * Best Practices Applied:
 * - Clear description with input/output examples
 * - .describe() on all schema fields
 * - Clear response structure documentation
 */
export const filterServers = tool({
  description: `ì¡°ê±´ì— ë§ëŠ” ì„œë²„ë¥¼ ë¹ ë¥´ê²Œ í•„í„°ë§í•©ë‹ˆë‹¤.

## ì…ë ¥ ì˜ˆì‹œ (Input Examples)
1. CPU 80% ì´ˆê³¼:
   { "field": "cpu", "operator": ">", "value": 80 }

2. ë©”ëª¨ë¦¬ 90% ì´ìƒ TOP 3:
   { "field": "memory", "operator": ">=", "value": 90, "limit": 3 }

3. ë””ìŠ¤í¬ 50% ë¯¸ë§Œ:
   { "field": "disk", "operator": "<", "value": 50 }

## ì¶œë ¥ í˜•ì‹ (Output Schema)
{
  "success": true,
  "condition": "cpu > 80%",
  "servers": [
    { "id": "db-server-01", "name": "DB Server 01", "status": "warning", "cpu": 92.5 }
  ],
  "summary": { "matched": 3, "returned": 3, "total": 10 },
  "timestamp": "2025-01-04T12:00:00Z"
}

## ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
- "CPU 80% ì´ìƒ ì„œë²„" â†’ field="cpu", operator=">", value=80
- "ë©”ëª¨ë¦¬ 90% ë„˜ëŠ” ì„œë²„ 3ê°œ" â†’ field="memory", operator=">", value=90, limit=3`,
  inputSchema: z.object({
    field: z
      .enum(['cpu', 'memory', 'disk'])
      .describe('í•„í„°ë§í•  ë©”íŠ¸ë¦­. cpu=CPU ì‚¬ìš©ë¥ , memory=ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ , disk=ë””ìŠ¤í¬ ì‚¬ìš©ë¥ '),
    operator: z
      .enum(['>', '<', '>=', '<='])
      .describe('ë¹„êµ ì—°ì‚°ì. >: ì´ˆê³¼, <: ë¯¸ë§Œ, >=: ì´ìƒ, <=: ì´í•˜'),
    value: z.number().describe('ë¹„êµí•  ì„ê³„ê°’ (í¼ì„¼íŠ¸). ì˜ˆ: 80ì´ë©´ 80% ì˜ë¯¸'),
    limit: z.number().default(10).describe('ë°˜í™˜í•  ìµœëŒ€ ì„œë²„ ìˆ˜ (ê¸°ë³¸ê°’: 10). TOP N ê²°ê³¼'),
  }),
  execute: async ({
    field,
    operator,
    value,
    limit,
  }: {
    field: 'cpu' | 'memory' | 'disk';
    operator: '>' | '<' | '>=' | '<=';
    value: number;
    limit: number;
  }) => {
    const cache = getDataCache();
    const cacheKey = `filter:${field}:${operator}:${value}:${limit}`;

    return cache.getOrCompute('metrics', cacheKey, async () => {
    console.log(`ğŸ“Š [filterServers] Computing for ${cacheKey} (cache miss)`);
    const state = getCurrentState();

    const filtered = state.servers.filter((server) => {
      const serverValue = server[field] as number;
      switch (operator) {
        case '>':
          return serverValue > value;
        case '<':
          return serverValue < value;
        case '>=':
          return serverValue >= value;
        case '<=':
          return serverValue <= value;
        default:
          return false;
      }
    });

    // Sort by the filtered field (descending for >, ascending for <)
    const sortedResults = filtered.sort((a, b) =>
      operator.includes('>') ? b[field] - a[field] : a[field] - b[field]
    );

    const limitedResults = sortedResults.slice(0, limit);

    return {
      success: true,
      condition: `${field} ${operator} ${value}%`,
      servers: limitedResults.map((s) => ({
        id: s.id,
        name: s.name,
        status: s.status,
        [field]: s[field],
      })),
      summary: {
        matched: filtered.length,
        returned: limitedResults.length,
        total: state.servers.length,
      },
      timestamp: new Date().toISOString(),
    };
    }); // End of cache.getOrCompute wrapper
  },
});

/**
 * Server By Group Tool
 * Query servers by type/group (db, lb, web, cache, etc.)
 *
 * Best Practices Applied:
 * - Supports common abbreviations (dbâ†’database, lbâ†’loadbalancer)
 * - Clear description with input/output examples
 * - Cached for performance
 */
export const getServerByGroup = tool({
  description: `ì„œë²„ ê·¸ë£¹/íƒ€ì…ìœ¼ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤. DB ì„œë²„, ë¡œë“œë°¸ëŸ°ì„œ, ì›¹ ì„œë²„ ë“± íŠ¹ì • ìœ í˜•ì˜ ì„œë²„ë¥¼ ì¡°íšŒí•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.

## ì§€ì›í•˜ëŠ” ê·¸ë£¹/íƒ€ì…
- database (ë˜ëŠ” db, mysql, postgres, mongodb, oracle): ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„
- loadbalancer (ë˜ëŠ” lb, haproxy, f5): ë¡œë“œë°¸ëŸ°ì„œ ì„œë²„
- web (ë˜ëŠ” nginx, apache, httpd, frontend): ì›¹ ì„œë²„
- cache (ë˜ëŠ” redis, memcached, varnish): ìºì‹œ ì„œë²„
- storage (ë˜ëŠ” nas, s3, minio, nfs): ìŠ¤í† ë¦¬ì§€ ì„œë²„
- application (ë˜ëŠ” api, app, backend): ì• í”Œë¦¬ì¼€ì´ì…˜/API ì„œë²„

## ì…ë ¥ ì˜ˆì‹œ
1. DB ì„œë²„ ì¡°íšŒ: { "group": "db" } ë˜ëŠ” { "group": "database" }
2. ë¡œë“œë°¸ëŸ°ì„œ ì¡°íšŒ: { "group": "lb" } ë˜ëŠ” { "group": "loadbalancer" }
3. ì›¹ ì„œë²„ ì¡°íšŒ: { "group": "web" }
4. ìºì‹œ ì„œë²„ ì¡°íšŒ: { "group": "cache" }

## ì¶œë ¥ í˜•ì‹
{
  "success": true,
  "group": "database",
  "servers": [
    { "id": "db-mysql-icn-01", "name": "MySQL Primary", "type": "database", "status": "online", "cpu": 45, "memory": 78, "disk": 62 }
  ],
  "summary": { "total": 2, "online": 2, "warning": 0, "critical": 0 }
}

## ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
- "DB ì„œë²„ ìƒíƒœ ì•Œë ¤ì¤˜" â†’ group="db"
- "ë¡œë“œë°¸ëŸ°ì„œ í˜„í™©" â†’ group="lb"
- "ì›¹ ì„œë²„ ëª©ë¡" â†’ group="web"
- "ìºì‹œ ì„œë²„ í™•ì¸" â†’ group="cache"`,
  inputSchema: z.object({
    group: z
      .string()
      .describe('ì„œë²„ ê·¸ë£¹/íƒ€ì…. ê¸°ë³¸: db, database, lb, loadbalancer, web, cache, storage, application, api, app. í™•ì¥: mysql, postgres, mongodb, oracle, haproxy, f5, nginx, apache, redis, memcached, nas, s3, backend'),
  }),
  execute: async ({ group }: { group: string }) => {
    const cache = getDataCache();
    const normalizedGroup = group.toLowerCase().trim();
    const cacheKey = `group:${normalizedGroup}`;

    return cache.getOrCompute('metrics', cacheKey, async () => {
      console.log(`ğŸ“Š [getServerByGroup] Computing for ${cacheKey} (cache miss)`);

      // Abbreviation mapping (technology stack â†’ canonical type)
      const typeMap: Record<string, string> = {
        // Database variants
        'db': 'database',
        'mysql': 'database',
        'postgres': 'database',
        'postgresql': 'database',
        'mongodb': 'database',
        'oracle': 'database',
        'mariadb': 'database',
        // Load Balancer variants
        'lb': 'loadbalancer',
        'haproxy': 'loadbalancer',
        'f5': 'loadbalancer',
        'elb': 'loadbalancer',
        'alb': 'loadbalancer',
        // Web server variants
        'nginx': 'web',
        'apache': 'web',
        'httpd': 'web',
        'frontend': 'web',
        // Cache variants
        'redis': 'cache',
        'memcached': 'cache',
        'varnish': 'cache',
        'elasticache': 'cache',
        // Storage variants
        'nas': 'storage',
        's3': 'storage',
        'minio': 'storage',
        'nfs': 'storage',
        'efs': 'storage',
        // Application variants
        'api': 'application',
        'app': 'application',
        'backend': 'application',
        'server': 'application',
      };

      const targetType = typeMap[normalizedGroup] || normalizedGroup;
      const state = getCurrentState();

      // Normalize server type (handles both directions)
      const normalizeType = (type: string): string => {
        const t = type.toLowerCase().trim();
        return typeMap[t] || t;
      };

      // Filter by server type (exact match only after normalization)
      const filteredServers = state.servers.filter((s) => {
        const serverType = normalizeType(s.type || '');
        return serverType === targetType;
      });

      // Calculate summary
      const summary = {
        total: filteredServers.length,
        online: filteredServers.filter((s) => s.status === 'online').length,
        warning: filteredServers.filter((s) => s.status === 'warning').length,
        critical: filteredServers.filter((s) => s.status === 'critical').length,
      };

      return {
        success: true,
        group: targetType,
        servers: filteredServers.map((s) => ({
          id: s.id,
          name: s.name,
          type: s.type || targetType,
          status: s.status,
          cpu: s.cpu,
          memory: s.memory,
          disk: s.disk,
        })),
        summary,
        timestamp: new Date().toISOString(),
      };
    });
  },
});

/**
 * Server By Group Advanced Tool
 * Query servers by type/group with filtering and sorting support
 *
 * Best Practices Applied:
 * - Extends getServerByGroup with filtering/sorting
 * - Supports compound queries like "DB ì„œë²„ ì¤‘ CPU 80% ì´ìƒ"
 * - Maintains backward compatibility
 */
export const getServerByGroupAdvanced = tool({
  description: `ì„œë²„ ê·¸ë£¹/íƒ€ì… ì¡°íšŒ + í•„í„°ë§/ì •ë ¬ ê¸°ëŠ¥. ë³µí•© ì¡°ê±´ ì¿¼ë¦¬ì— ì‚¬ìš©í•˜ì„¸ìš”.

## ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤
- "DB ì„œë²„ ì¤‘ CPU 80% ì´ìƒ" â†’ group="db", filters={ cpuMin: 80 }
- "ì›¹ ì„œë²„ ë©”ëª¨ë¦¬ ìˆœìœ¼ë¡œ ì •ë ¬" â†’ group="web", sort={ by: "memory", order: "desc" }
- "ìºì‹œ ì„œë²„ ì¤‘ warning ìƒíƒœ" â†’ group="cache", filters={ status: "warning" }
- "ìƒìœ„ 3ê°œ DB ì„œë²„ (CPU ê¸°ì¤€)" â†’ group="db", sort={ by: "cpu", order: "desc" }, limit=3

## ì§€ì› ê·¸ë£¹ (getServerByGroupê³¼ ë™ì¼)
database, loadbalancer, web, cache, storage, application + ê¸°ìˆ  ìŠ¤íƒ ì•½ì–´

## í•„í„° ì˜µì…˜
- cpuMin/cpuMax: CPU ì‚¬ìš©ë¥  ë²”ìœ„ (0-100)
- memoryMin/memoryMax: ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë²”ìœ„ (0-100)
- status: online | warning | critical

## ì •ë ¬ ì˜µì…˜
- by: cpu | memory | disk | network | name
- order: asc | desc`,
  inputSchema: z.object({
    group: z
      .string()
      .describe('ì„œë²„ ê·¸ë£¹/íƒ€ì… (db, mysql, nginx, redis ë“±)'),
    filters: z.object({
      cpuMin: z.number().min(0).max(100).optional().describe('ìµœì†Œ CPU ì‚¬ìš©ë¥ '),
      cpuMax: z.number().min(0).max(100).optional().describe('ìµœëŒ€ CPU ì‚¬ìš©ë¥ '),
      memoryMin: z.number().min(0).max(100).optional().describe('ìµœì†Œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ '),
      memoryMax: z.number().min(0).max(100).optional().describe('ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ '),
      status: z.enum(['online', 'warning', 'critical']).optional().describe('ì„œë²„ ìƒíƒœ'),
    }).optional().describe('í•„í„° ì¡°ê±´'),
    sort: z.object({
      by: z.enum(['cpu', 'memory', 'disk', 'network', 'name']).describe('ì •ë ¬ ê¸°ì¤€'),
      order: z.enum(['asc', 'desc']).describe('ì •ë ¬ ìˆœì„œ'),
    }).optional().describe('ì •ë ¬ ì˜µì…˜'),
    limit: z.number().min(1).max(100).optional().describe('ìµœëŒ€ ê²°ê³¼ ìˆ˜'),
  }),
  execute: async ({
    group,
    filters,
    sort,
    limit,
  }: {
    group: string;
    filters?: {
      cpuMin?: number;
      cpuMax?: number;
      memoryMin?: number;
      memoryMax?: number;
      status?: 'online' | 'warning' | 'critical';
    };
    sort?: {
      by: 'cpu' | 'memory' | 'disk' | 'network' | 'name';
      order: 'asc' | 'desc';
    };
    limit?: number;
  }) => {
    const cache = getDataCache();
    const normalizedGroup = group.toLowerCase().trim();
    const filterKey = filters ? JSON.stringify(filters) : 'none';
    const sortKey = sort ? `${sort.by}-${sort.order}` : 'none';
    const cacheKey = `group-adv:${normalizedGroup}:${filterKey}:${sortKey}:${limit || 'all'}`;

    return cache.getOrCompute('metrics', cacheKey, async () => {
      console.log(`ğŸ“Š [getServerByGroupAdvanced] Computing for ${cacheKey} (cache miss)`);

      // Reuse typeMap from getServerByGroup
      const typeMap: Record<string, string> = {
        // Database variants
        'db': 'database',
        'mysql': 'database',
        'postgres': 'database',
        'postgresql': 'database',
        'mongodb': 'database',
        'oracle': 'database',
        'mariadb': 'database',
        // Load Balancer variants
        'lb': 'loadbalancer',
        'haproxy': 'loadbalancer',
        'f5': 'loadbalancer',
        'elb': 'loadbalancer',
        'alb': 'loadbalancer',
        // Web server variants
        'nginx': 'web',
        'apache': 'web',
        'httpd': 'web',
        'frontend': 'web',
        // Cache variants
        'redis': 'cache',
        'memcached': 'cache',
        'varnish': 'cache',
        'elasticache': 'cache',
        // Storage variants
        'nas': 'storage',
        's3': 'storage',
        'minio': 'storage',
        'nfs': 'storage',
        'efs': 'storage',
        // Application variants
        'api': 'application',
        'app': 'application',
        'backend': 'application',
        'server': 'application',
      };

      const targetType = typeMap[normalizedGroup] || normalizedGroup;
      const state = getCurrentState();

      // Normalize server type
      const normalizeType = (type: string): string => {
        const t = type.toLowerCase().trim();
        return typeMap[t] || t;
      };

      // Step 1: Filter by server type
      let filteredServers = state.servers.filter((s) => {
        const serverType = normalizeType(s.type || '');
        return serverType === targetType;
      });

      const totalBeforeFilters = filteredServers.length;

      // Step 2: Apply metric filters
      if (filters) {
        if (filters.cpuMin !== undefined) {
          filteredServers = filteredServers.filter((s) => s.cpu >= filters.cpuMin!);
        }
        if (filters.cpuMax !== undefined) {
          filteredServers = filteredServers.filter((s) => s.cpu <= filters.cpuMax!);
        }
        if (filters.memoryMin !== undefined) {
          filteredServers = filteredServers.filter((s) => s.memory >= filters.memoryMin!);
        }
        if (filters.memoryMax !== undefined) {
          filteredServers = filteredServers.filter((s) => s.memory <= filters.memoryMax!);
        }
        if (filters.status) {
          filteredServers = filteredServers.filter((s) => s.status === filters.status);
        }
      }

      // Step 3: Apply sorting
      if (sort) {
        filteredServers.sort((a, b) => {
          let valueA: number | string;
          let valueB: number | string;

          switch (sort.by) {
            case 'cpu':
              valueA = a.cpu;
              valueB = b.cpu;
              break;
            case 'memory':
              valueA = a.memory;
              valueB = b.memory;
              break;
            case 'disk':
              valueA = a.disk;
              valueB = b.disk;
              break;
            case 'network':
              valueA = a.network || 0;
              valueB = b.network || 0;
              break;
            case 'name':
              valueA = a.name;
              valueB = b.name;
              break;
            default:
              valueA = a.cpu;
              valueB = b.cpu;
          }

          if (typeof valueA === 'string' && typeof valueB === 'string') {
            return sort.order === 'asc'
              ? valueA.localeCompare(valueB)
              : valueB.localeCompare(valueA);
          }

          return sort.order === 'asc'
            ? (valueA as number) - (valueB as number)
            : (valueB as number) - (valueA as number);
        });
      }

      // Step 4: Apply limit
      if (limit && limit > 0) {
        filteredServers = filteredServers.slice(0, limit);
      }

      // Calculate summary (from filtered results)
      const summary = {
        total: totalBeforeFilters,
        online: filteredServers.filter((s) => s.status === 'online').length,
        warning: filteredServers.filter((s) => s.status === 'warning').length,
        critical: filteredServers.filter((s) => s.status === 'critical').length,
        filtered: filteredServers.length,
      };

      return {
        success: true,
        group: targetType,
        servers: filteredServers.map((s) => ({
          id: s.id,
          name: s.name,
          type: s.type || targetType,
          status: s.status,
          cpu: s.cpu,
          memory: s.memory,
          disk: s.disk,
          network: s.network,
        })),
        summary,
        appliedFilters: filters || undefined,
        appliedSort: sort || undefined,
        timestamp: new Date().toISOString(),
      };
    });
  },
});
