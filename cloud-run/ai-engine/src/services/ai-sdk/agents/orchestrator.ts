/**
 * Multi-Agent Orchestrator
 *
 * Routes user queries to specialized agents using pattern matching and LLM.
 * Uses Cerebras for ultra-fast routing decisions (~200ms).
 *
 * Architecture:
 * Orchestrator (Cerebras) ‚Üí NLQ/Analyst/Reporter/Advisor (Cerebras/Groq/Mistral)
 *
 * @version 2.1.0 - Removed Summarizer Agent (merged into NLQ)
 * @updated 2026-01-12 - OpenRouter and Summarizer Agent removed
 */

import { Agent } from '@ai-sdk-tools/agents';
import { generateText, stepCountIs } from 'ai';
import { getCerebrasModel, getGroqModel, getMistralModel, checkProviderStatus, type ProviderName } from '../model-provider';
import { generateTextWithRetry } from '../../resilience/retry-with-fallback';
import { sanitizeChineseCharacters } from '../../../lib/text-sanitizer';
import type { StreamEvent } from '../supervisor';
import { logTimeoutEvent, createTimeoutSpan } from '../../observability/langfuse';
import { nlqAgent } from './nlq-agent';
import { analystAgent } from './analyst-agent';
import { reporterAgent } from './reporter-agent';
import { advisorAgent } from './advisor-agent';

// Import SSOT config
import { AGENT_CONFIGS } from './config';

// ============================================================================
// Configuration
// ============================================================================

/**
 * Orchestrator timeout configuration
 * - Multi-agent queries can take 20-60s with multiple handoffs
 * - Set generous timeout but prevent infinite hangs
 */
const ORCHESTRATOR_CONFIG = {
  /** Maximum execution time (ms) - 50s for Vercel 60s limit compliance */
  timeout: 50_000,
  /** Warning threshold (ms) - log warning if execution exceeds this */
  warnThreshold: 25_000,
};

// ============================================================================
// Types
// ============================================================================

export interface MultiAgentRequest {
  messages: Array<{ role: 'user' | 'assistant'; content: string }>;
  sessionId: string;
  enableTracing?: boolean;
}

export interface MultiAgentResponse {
  success: boolean;
  response: string;
  handoffs: Array<{
    from: string;
    to: string;
    reason?: string;
  }>;
  finalAgent: string;
  toolsCalled: string[];
  usage: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  metadata: {
    provider: string;
    modelId: string;
    totalRounds: number;
    durationMs: number;
  };
}

export interface MultiAgentError {
  success: false;
  error: string;
  code: string;
}

// ============================================================================
// Orchestrator Instructions
// ============================================================================

const ORCHESTRATOR_INSTRUCTIONS = `ÎãπÏã†ÏùÄ **ÏÑúÎ≤Ñ Î™®ÎãàÌÑ∞ÎßÅ ÌîåÎû´Ìèº (OpenManager)** Ïùò AI Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞ÏûÖÎãàÎã§.

## ‚ö†Ô∏è Ï§ëÏöî Ïª®ÌÖçÏä§Ìä∏
- Ïù¥ ÏãúÏä§ÌÖúÏùÄ **IT Ïù∏ÌîÑÎùº/ÏÑúÎ≤Ñ Î™®ÎãàÌÑ∞ÎßÅ** Ï†ÑÏö©ÏûÖÎãàÎã§
- "Ïû•Ïï†"Îäî **ÏÑúÎ≤Ñ Ïû•Ïï†/ÏãúÏä§ÌÖú Ïû•Ïï†**Î•º ÏùòÎØ∏Ìï©ÎãàÎã§ (Ïó≠ÏÇ¨Ï†Å Ïû¨Ïïô/ÏßàÎ≥ë ÏïÑÎãò)
- "ÏÇ¨Î°Ä"Îäî **Í≥ºÍ±∞ ÏÑúÎ≤Ñ Ïù∏ÏãúÎçòÌä∏ Í∏∞Î°ù**ÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§
  - Ïòà: "2024-01 DB ÏÑúÎ≤Ñ OOM Ïû•Ïï†", "CPU Ïä§ÌååÏù¥ÌÅ¨Î°ú Ïù∏Ìïú ÏÑúÎπÑÏä§ Îã§Ïö¥ÌÉÄÏûÑ"
  - Knowledge BaseÏóê Ï†ÄÏû•Îêú Ìä∏Îü¨Î∏îÏäàÌåÖ Ïù¥Î†• Ï∞∏Ï°∞
- Î™®Îì† ÏßàÎ¨∏ÏùÄ ÏÑúÎ≤Ñ/Ïù∏ÌîÑÎùº Í¥ÄÏ†êÏóêÏÑú Ìï¥ÏÑùÌïòÏÑ∏Ïöî

## ÌïµÏã¨ Ïó≠Ìï† (ÎìÄÏñº Î™®Îìú)
1. **ÏùºÎ∞ò ÏßàÎ¨∏**: ÏßÅÏ†ë Îπ†Î•¥Í≤å ÎãµÎ≥Ä
2. **ÏÑúÎ≤Ñ/Î™®ÎãàÌÑ∞ÎßÅ Í¥ÄÎ†®**: Ï†ÑÎ¨∏ ÏóêÏù¥Ï†ÑÌä∏ÏóêÍ≤å Ìï∏ÎìúÏò§ÌîÑ

## 1Îã®Í≥Ñ: ÏßàÎ¨∏ Î∂ÑÎ•ò

### ÏßÅÏ†ë ÎãµÎ≥Ä (Ìï∏ÎìúÏò§ÌîÑ ÏóÜÏù¥ Î∞îÎ°ú ÏùëÎãµ)
Îã§Ïùå Ïú†ÌòïÏùò ÏßàÎ¨∏ÏùÄ **ÏßÅÏ†ë ÎãµÎ≥Ä**ÌïòÏÑ∏Ïöî:
- Ïù∏ÏÇ¨Îßê: "ÏïàÎÖï", "ÌïòÏù¥", "Ìó¨Î°ú", "Î∞òÍ∞ÄÏõå"
- ÎÇ†Ïî®: "Ïò§Îäò ÎÇ†Ïî®", "ÎÇ†Ïî® Ïñ¥Îïå"
- ÎÇ†Ïßú/ÏãúÍ∞Ñ: "Ïò§Îäò Î™áÏùº", "ÏßÄÍ∏à Î™áÏãú", "Ïò§Îäò ÏöîÏùº"
- ÏùºÎ∞ò ÎåÄÌôî: "Í≥†ÎßàÏõå", "ÏûòÍ∞Ä", "ÏàòÍ≥†Ìï¥"
- ÏãúÏä§ÌÖú ÏÜåÍ∞ú: "ÎÑå Î≠êÏïº", "Î≠ò Ìï† Ïàò ÏûàÏñ¥", "ÎèÑÏõÄÎßê"

**ÏßÅÏ†ë ÎãµÎ≥Ä ÏòàÏãú**:
- "ÏïàÎÖï" ‚Üí "ÏïàÎÖïÌïòÏÑ∏Ïöî! ÏÑúÎ≤Ñ Î™®ÎãàÌÑ∞ÎßÅ AIÏûÖÎãàÎã§. ÏÑúÎ≤Ñ ÏÉÅÌÉú, Ïù¥ÏÉÅ ÌÉêÏßÄ, Ïû•Ïï† Î∂ÑÏÑù Îì±ÏùÑ ÎèÑÏôÄÎìúÎ¶ΩÎãàÎã§."
- "Ïò§Îäò Î™áÏùºÏù¥Ïïº" ‚Üí "Ïò§ÎäòÏùÄ [ÎÇ†Ïßú]ÏûÖÎãàÎã§."
- "ÎÑå Î≠êÏïº" ‚Üí "Ï†ÄÎäî OpenManager ÏÑúÎ≤Ñ Î™®ÎãàÌÑ∞ÎßÅ AIÏûÖÎãàÎã§. ÏÑúÎ≤Ñ ÏÉÅÌÉú Ï°∞Ìöå, Ïù¥ÏÉÅ ÌÉêÏßÄ, Ïû•Ïï† Î≥¥Í≥†ÏÑú ÏÉùÏÑ± Îì±ÏùÑ ÏßÄÏõêÌï©ÎãàÎã§."

### Ìï∏ÎìúÏò§ÌîÑ ÎåÄÏÉÅ (Ï†ÑÎ¨∏ ÏóêÏù¥Ï†ÑÌä∏ ÏúÑÏûÑ)
Îã§Ïùå ÌÇ§ÏõåÎìúÍ∞Ä Ìè¨Ìï®Îêú **ÏÑúÎ≤Ñ/Î™®ÎãàÌÑ∞ÎßÅ Í¥ÄÎ†®** ÏßàÎ¨∏Îßå Ìï∏ÎìúÏò§ÌîÑ:

#### NLQ Agent - ÏÑúÎ≤Ñ Îç∞Ïù¥ÌÑ∞ ÏßàÏùò
**ÌÇ§ÏõåÎìú**: ÏÑúÎ≤Ñ, ÏÉÅÌÉú, CPU, Î©îÎ™®Î¶¨, ÎîîÏä§ÌÅ¨, Î™©Î°ù, Ï°∞Ìöå, Î™á ÎåÄ, Ïñ¥Îñ§ ÏÑúÎ≤Ñ, ÌèâÍ∑†, ÏµúÎåÄ, ÏµúÏÜå, ÏßÄÎÇú, ÏãúÍ∞Ñ
- "ÏÑúÎ≤Ñ ÏÉÅÌÉú ÏïåÎ†§Ï§ò" ‚Üí NLQ Agent
- "CPU ÎÜíÏùÄ ÏÑúÎ≤Ñ" ‚Üí NLQ Agent
- "ÏßÄÎÇú 6ÏãúÍ∞Ñ CPU ÌèâÍ∑†" ‚Üí NLQ Agent (ÏãúÍ∞Ñ Î≤îÏúÑ ÏßëÍ≥Ñ)
- "Ï†ÑÏ≤¥ ÏÑúÎ≤Ñ Î©îÎ™®Î¶¨ ÏµúÎåÄÍ∞í" ‚Üí NLQ Agent

#### Analyst Agent - Ïù¥ÏÉÅ ÌÉêÏßÄ/Î∂ÑÏÑù
**ÌÇ§ÏõåÎìú**: Ïù¥ÏÉÅ, Î∂ÑÏÑù, ÏòàÏ∏°, Ìä∏Î†åÎìú, Ìå®ÌÑ¥, ÏõêÏù∏, Ïôú (ÏÑúÎ≤Ñ/ÏãúÏä§ÌÖú Í¥ÄÎ†®)
- "Ïù¥ÏÉÅ ÏûàÏñ¥?" ‚Üí Analyst Agent
- "Ïôú ÎäêÎ†§Ï°åÏñ¥?" ‚Üí Analyst Agent

#### Reporter Agent - Î≥¥Í≥†ÏÑú ÏÉùÏÑ±
**ÌÇ§ÏõåÎìú**: Î≥¥Í≥†ÏÑú, Î¶¨Ìè¨Ìä∏, ÌÉÄÏûÑÎùºÏù∏, Ïû•Ïï† ÏöîÏïΩ, Ïù∏ÏãúÎçòÌä∏
- "Ïû•Ïï† Î≥¥Í≥†ÏÑú ÎßåÎì§Ïñ¥Ï§ò" ‚Üí Reporter Agent

#### Advisor Agent - Ìï¥Í≤∞ Î∞©Î≤ï ÏïàÎÇ¥
**ÌÇ§ÏõåÎìú**: Ìï¥Í≤∞, Î∞©Î≤ï, Î™ÖÎ†πÏñ¥, Í∞ÄÏù¥Îìú, Í≥ºÍ±∞ ÏÇ¨Î°Ä (ÏÑúÎ≤Ñ Í¥ÄÎ†®)
- "Î©îÎ™®Î¶¨ Î∂ÄÏ°± Ìï¥Í≤∞ Î∞©Î≤ï" ‚Üí Advisor Agent

## 2Îã®Í≥Ñ: ÌåêÎã® Í∏∞Ï§Ä

**Ìï∏ÎìúÏò§ÌîÑ Ïó¨Î∂Ä Í≤∞Ï†ï ÌîåÎ°úÏö∞**:
1. ÏÑúÎ≤Ñ/CPU/Î©îÎ™®Î¶¨/ÎîîÏä§ÌÅ¨/Ïû•Ïï†/Î™®ÎãàÌÑ∞ÎßÅ ÌÇ§ÏõåÎìúÍ∞Ä ÏûàÎäîÍ∞Ä?
   - ÏóÜÏùå ‚Üí ÏßÅÏ†ë ÎãµÎ≥Ä
   - ÏûàÏùå ‚Üí 2Î≤àÏúºÎ°ú
2. Ïñ¥Îñ§ Ï†ÑÎ¨∏ ÏóêÏù¥Ï†ÑÌä∏Í∞Ä Ï†ÅÌï©ÌïúÍ∞Ä?
   - Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå/ÏöîÏïΩ ‚Üí NLQ Agent (ÏöîÏïΩ Ìè¨Ìï®)
   - Ïù¥ÏÉÅ/Î∂ÑÏÑù ‚Üí Analyst Agent
   - Î≥¥Í≥†ÏÑú ‚Üí Reporter Agent
   - Ìï¥Í≤∞Î≤ï ‚Üí Advisor Agent

## Ï§ëÏöî Í∑úÏπô
1. **ÏùºÎ∞ò ÎåÄÌôîÎäî Îπ†Î•¥Í≤å ÏßÅÏ†ë ÎãµÎ≥Ä** (Ìï∏ÎìúÏò§ÌîÑ Í∏àÏßÄ)
2. **ÏÑúÎ≤Ñ Í¥ÄÎ†® ÏßàÎ¨∏Îßå Ìï∏ÎìúÏò§ÌîÑ**
3. Î∂àÎ™ÖÌôïÌïòÏßÄÎßå ÏÑúÎ≤Ñ Í¥ÄÎ†®Ïù∏ Í≤É Í∞ôÏúºÎ©¥ ‚Üí NLQ Agent
4. Ìï∏ÎìúÏò§ÌîÑ Ïãú reason Î™ÖÏãú
5. **ÌïúÍµ≠Ïñ¥Î°ú ÏùëÎãµ / Respond in Korean** (ÌïúÏûê Ï†àÎåÄ Í∏àÏßÄ / No Chinese characters, Îü¨ÏãúÏïÑÏñ¥/ÎèÖÏùºÏñ¥/ÏùºÎ≥∏Ïñ¥/Î≤†Ìä∏ÎÇ®Ïñ¥ Îì± Îã§Î•∏ Ïñ∏Ïñ¥ Í∏àÏßÄ, Í∏∞Ïà†Ïö©Ïñ¥Îäî ÏòÅÏñ¥ ÌóàÏö©)
`;

// ============================================================================
// Rule-based Pre-filter (Fast Path)
// ============================================================================

/**
 * Intent classification for fast routing
 * Returns direct response if applicable, otherwise null for LLM routing
 */
interface PreFilterResult {
  shouldHandoff: boolean;
  directResponse?: string;
  suggestedAgent?: string;
  confidence: number;
}

const GREETING_PATTERNS = [
  /^(ÏïàÎÖïÌïòÏÑ∏Ïöî|ÏïàÎÖï|ÌïòÏù¥|Ìó¨Î°ú|hi|hello|hey|Î∞òÍ∞ÄÏõå|Ï¢ãÏùÄ\s*(ÏïÑÏπ®|Ïò§ÌõÑ|Ï†ÄÎÖÅ))[\s!?.]*$/i,
  /^(Í≥†ÎßàÏõå|Í∞êÏÇ¨Ìï©ÎãàÎã§|Í∞êÏÇ¨|„Ñ±„ÖÖ|ÏàòÍ≥†|ÏûòÍ∞Ä|Î∞îÏù¥|bye|thanks)[\s!?.]*$/i,
];

const GENERAL_PATTERNS = [
  /^(Ïò§Îäò|ÏßÄÍ∏à)\s*(ÎÇ†Ïî®|Î™á\s*Ïùº|Î™á\s*Ïãú|ÏöîÏùº|Î©∞Ïπ†)[\s?]*$/i,
  /^(ÎÑå|ÎÑàÎäî?|Î≠êÏïº|ÎàÑÍµ¨|Î≠ò\s*Ìï†\s*Ïàò|ÎèÑÏõÄÎßê|help|ÎèÑÏôÄÏ§ò)[\s?]*$/i,
  /^(ÌÖåÏä§Ìä∏|ping|echo)[\s?]*$/i,
];

const SERVER_KEYWORDS = [
  'ÏÑúÎ≤Ñ', 'cpu', 'Î©îÎ™®Î¶¨', 'ÎîîÏä§ÌÅ¨', 'memory', 'disk', 'ÏÉÅÌÉú',
  'Ïù¥ÏÉÅ', 'Î∂ÑÏÑù', 'ÏòàÏ∏°', 'Ìä∏Î†åÎìú', 'Ïû•Ïï†', 'Î≥¥Í≥†ÏÑú', 'Î¶¨Ìè¨Ìä∏',
  'Ìï¥Í≤∞', 'Î™ÖÎ†πÏñ¥', 'ÏöîÏïΩ', 'Î™®ÎãàÌÑ∞ÎßÅ', 'server', 'ÏïåÎûå', 'Í≤ΩÍ≥†',
  'ÌèâÍ∑†', 'ÏµúÎåÄ', 'ÏµúÏÜå', 'ÏßÄÎÇú', 'ÏãúÍ∞Ñ', 'Ï†ÑÏ≤¥',
  // Ï∂îÍ∞Ä: Ïû•Ïï† ÏÇ¨Î°Ä, Ïù¥Î†• Í¥ÄÎ†® ÌÇ§ÏõåÎìú
  'ÏÇ¨Î°Ä', 'Ïù¥Î†•', 'Í≥ºÍ±∞', 'Ïú†ÏÇ¨', 'Ïù∏ÏãúÎçòÌä∏', 'incident',
];

/**
 * Fast pre-filter before LLM routing
 * Handles simple queries without LLM call
 */
export function preFilterQuery(query: string): PreFilterResult {
  const normalized = query.trim().toLowerCase();

  // 1. Check greeting patterns - direct response
  for (const pattern of GREETING_PATTERNS) {
    if (pattern.test(query)) {
      return {
        shouldHandoff: false,
        directResponse: 'ÏïàÎÖïÌïòÏÑ∏Ïöî! ÏÑúÎ≤Ñ Î™®ÎãàÌÑ∞ÎßÅ AIÏûÖÎãàÎã§. ÏÑúÎ≤Ñ ÏÉÅÌÉú, Ïù¥ÏÉÅ ÌÉêÏßÄ, Ïû•Ïï† Î∂ÑÏÑù Îì±ÏùÑ ÎèÑÏôÄÎìúÎ¶ΩÎãàÎã§. Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?',
        confidence: 0.95,
      };
    }
  }

  // 2. Check general patterns - direct response
  for (const pattern of GENERAL_PATTERNS) {
    if (pattern.test(query)) {
      // Date query
      if (/ÎÇ†Ïßú|Î™á\s*Ïùº|Î©∞Ïπ†/.test(query)) {
        const today = new Date().toLocaleDateString('ko-KR', {
          year: 'numeric',
          month: 'long',
          day: 'numeric',
          weekday: 'long',
        });
        return {
          shouldHandoff: false,
          directResponse: `Ïò§ÎäòÏùÄ ${today}ÏûÖÎãàÎã§.`,
          confidence: 0.95,
        };
      }
      // Time query
      if (/Î™á\s*Ïãú/.test(query)) {
        const now = new Date().toLocaleTimeString('ko-KR', {
          hour: '2-digit',
          minute: '2-digit',
        });
        return {
          shouldHandoff: false,
          directResponse: `ÌòÑÏû¨ ÏãúÍ∞ÑÏùÄ ${now}ÏûÖÎãàÎã§.`,
          confidence: 0.95,
        };
      }
      // Identity query
      if (/ÎÑå|ÎÑàÎäî?|Î≠êÏïº|ÎàÑÍµ¨/.test(query)) {
        return {
          shouldHandoff: false,
          directResponse: 'Ï†ÄÎäî OpenManager ÏÑúÎ≤Ñ Î™®ÎãàÌÑ∞ÎßÅ AIÏûÖÎãàÎã§. ÏÑúÎ≤Ñ ÏÉÅÌÉú Ï°∞Ìöå, Ïù¥ÏÉÅ ÌÉêÏßÄ, Ìä∏Î†åÎìú ÏòàÏ∏°, Ïû•Ïï† Î≥¥Í≥†ÏÑú ÏÉùÏÑ± Îì±ÏùÑ ÏßÄÏõêÌï©ÎãàÎã§.',
          confidence: 0.95,
        };
      }
      // Help query
      if (/ÎèÑÏõÄÎßê|help|Î≠ò\s*Ìï†\s*Ïàò/.test(query)) {
        return {
          shouldHandoff: false,
          directResponse: `Îã§ÏùåÍ≥º Í∞ôÏùÄ Í∏∞Îä•ÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§:
‚Ä¢ **ÏÑúÎ≤Ñ ÏÉÅÌÉú Ï°∞Ìöå**: "ÏÑúÎ≤Ñ ÏÉÅÌÉú ÏïåÎ†§Ï§ò", "CPU ÎÜíÏùÄ ÏÑúÎ≤Ñ"
‚Ä¢ **Ïù¥ÏÉÅ ÌÉêÏßÄ**: "Ïù¥ÏÉÅ ÏûàÏñ¥?", "Î¨∏Ï†ú ÏÑúÎ≤Ñ Ï∞æÏïÑÏ§ò"
‚Ä¢ **Ìä∏Î†åÎìú Î∂ÑÏÑù**: "Ìä∏Î†åÎìú ÏòàÏ∏°Ìï¥Ï§ò"
‚Ä¢ **Ïû•Ïï† Î≥¥Í≥†ÏÑú**: "Ïû•Ïï† Î≥¥Í≥†ÏÑú ÎßåÎì§Ïñ¥Ï§ò"
‚Ä¢ **Ìï¥Í≤∞ Î∞©Î≤ï**: "Î©îÎ™®Î¶¨ Î∂ÄÏ°± Ìï¥Í≤∞ Î∞©Î≤ï"`,
          confidence: 0.95,
        };
      }
      // Test/ping
      if (/ÌÖåÏä§Ìä∏|ping|echo/.test(query)) {
        return {
          shouldHandoff: false,
          directResponse: 'Pong! ÏÑúÎ≤Ñ Î™®ÎãàÌÑ∞ÎßÅ AIÍ∞Ä Ï†ïÏÉÅ ÎèôÏûë Ï§ëÏûÖÎãàÎã§.',
          confidence: 0.95,
        };
      }
    }
  }

  // 3. Check for server-related keywords - needs handoff
  const hasServerKeyword = SERVER_KEYWORDS.some(kw => normalized.includes(kw));

  if (hasServerKeyword) {
    // Suggest agent based on keywords
    let suggestedAgent = 'NLQ Agent';
    if (/Ïù¥ÏÉÅ|Î∂ÑÏÑù|ÏòàÏ∏°|Ìä∏Î†åÎìú|Ìå®ÌÑ¥|ÏõêÏù∏|Ïôú/.test(query)) {
      suggestedAgent = 'Analyst Agent';
    } else if (/Î≥¥Í≥†ÏÑú|Î¶¨Ìè¨Ìä∏|ÌÉÄÏûÑÎùºÏù∏|Ïù∏ÏãúÎçòÌä∏/.test(query)) {
      suggestedAgent = 'Reporter Agent';
    } else if (/Ìï¥Í≤∞|Î∞©Î≤ï|Î™ÖÎ†πÏñ¥|Í∞ÄÏù¥Îìú|Ïñ¥ÎñªÍ≤å|Í≥ºÍ±∞.*ÏÇ¨Î°Ä|ÏÇ¨Î°Ä.*Ï∞æ|Ïù¥Î†•|Ïú†ÏÇ¨/.test(query)) {
      suggestedAgent = 'Advisor Agent';
    }
    // Note: Summary requests (ÏöîÏïΩ, Í∞ÑÎã®Ìûà, ÌïµÏã¨, TL;DR) now handled by NLQ Agent (default)

    return {
      shouldHandoff: true,
      suggestedAgent,
      confidence: 0.8,
    };
  }

  // 4. Unknown - let LLM decide
  return {
    shouldHandoff: true, // Let orchestrator LLM decide
    confidence: 0.5,
  };
}

// ============================================================================
// Orchestrator Instance
// ============================================================================

/**
 * Get orchestrator model with 3-way fallback
 * Cerebras ‚Üí Groq ‚Üí Mistral
 * Ensures operation even if 2 of 3 providers are down
 */
function getOrchestratorModel(): { model: ReturnType<typeof getCerebrasModel>; provider: string; modelId: string } | null {
  const status = checkProviderStatus();

  // Primary: Cerebras (fastest routing ~200ms)
  if (status.cerebras) {
    try {
      return {
        model: getCerebrasModel('llama-3.3-70b'),
        provider: 'cerebras',
        modelId: 'llama-3.3-70b',
      };
    } catch {
      console.warn('‚ö†Ô∏è [Orchestrator] Cerebras unavailable, trying Groq');
    }
  }

  // Fallback 1: Groq (stable)
  if (status.groq) {
    try {
      return {
        model: getGroqModel('llama-3.3-70b-versatile'),
        provider: 'groq',
        modelId: 'llama-3.3-70b-versatile',
      };
    } catch {
      console.warn('‚ö†Ô∏è [Orchestrator] Groq unavailable, trying Mistral');
    }
  }

  // Fallback 2: Mistral (last resort)
  if (status.mistral) {
    try {
      return {
        model: getMistralModel('mistral-small-2506'),
        provider: 'mistral',
        modelId: 'mistral-small-2506',
      };
    } catch {
      console.warn('‚ö†Ô∏è [Orchestrator] Mistral unavailable');
    }
  }

  console.warn('‚ö†Ô∏è [Orchestrator] No model available (all 3 providers down)');
  return null;
}

// Get model config at startup
const orchestratorModelConfig = getOrchestratorModel();

// Filter out null agents for handoffs
const availableAgents = [nlqAgent, analystAgent, reporterAgent, advisorAgent].filter(
  (agent): agent is NonNullable<typeof agent> => agent !== null
);

// ‚ö†Ô∏è Critical validation: Ensure at least one agent is available
if (availableAgents.length === 0) {
  console.error('‚ùå [CRITICAL] No agents available! Check API keys: CEREBRAS_API_KEY, GROQ_API_KEY, MISTRAL_API_KEY');
}

// Track handoff events for debugging
const handoffEvents: Array<{ from: string; to: string; reason?: string; timestamp: Date }> = [];

/**
 * Main Orchestrator Agent (null if no model available)
 */
export const orchestrator = orchestratorModelConfig
  ? (() => {
      console.log(`üéØ [Orchestrator] Initialized with ${orchestratorModelConfig.provider}/${orchestratorModelConfig.modelId}`);
      console.log(`üìã [Orchestrator] Available agents: ${availableAgents.length} - [${availableAgents.map(a => a.name).join(', ')}]`);
      return new Agent({
        name: 'OpenManager Orchestrator',
        model: orchestratorModelConfig.model,
        instructions: ORCHESTRATOR_INSTRUCTIONS,
        handoffs: availableAgents,
        maxTurns: 10,
        // Track agent lifecycle events
        onEvent: async (event) => {
          switch (event.type) {
            case 'agent-handoff':
              console.log(`üîÄ [Handoff] ${event.from} ‚Üí ${event.to} (${event.reason || 'no reason'})`);
              handoffEvents.push({
                from: event.from,
                to: event.to,
                reason: event.reason,
                timestamp: new Date(),
              });
              break;
            case 'agent-start':
              console.log(`‚ñ∂Ô∏è [Agent Start] ${event.agent} (round ${event.round})`);
              break;
            case 'agent-finish':
              console.log(`‚úÖ [Agent Finish] ${event.agent} (round ${event.round})`);
              break;
          }
        },
      });
    })()
  : null;

/**
 * Get recent handoff events (for debugging)
 */
export function getRecentHandoffs() {
  return handoffEvents.slice(-10);
}

// ============================================================================
// Forced Routing (Bypass LLM for high-confidence pre-filter)
// ============================================================================

// NOTE: AGENT_CONFIGS is now imported from './config' (SSOT)
// This eliminates DRY violation where configs were duplicated here and in agent files

/**
 * Get agent instance by name (dynamic lookup for lazy initialization)
 * This ensures agents are available even if initialized after module load
 */
function getAgentByName(name: string): typeof nlqAgent | null {
  const agents: Record<string, typeof nlqAgent | null> = {
    'NLQ Agent': nlqAgent,
    'Analyst Agent': analystAgent,
    'Reporter Agent': reporterAgent,
    'Advisor Agent': advisorAgent,
  };
  return agents[name] ?? null;
}

/**
 * Get preferred provider order for an agent
 * Different agents have different optimal provider orders
 */
function getAgentProviderOrder(agentName: string): ProviderName[] {
  switch (agentName) {
    case 'NLQ Agent':
      return ['cerebras', 'groq', 'mistral'];
    case 'Analyst Agent':
    case 'Reporter Agent':
      return ['groq', 'cerebras', 'mistral'];
    case 'Advisor Agent':
      return ['mistral', 'groq', 'cerebras'];
    default:
      return ['cerebras', 'groq', 'mistral'];
  }
}

/**
 * Execute forced routing to a specific agent with retry and fallback
 *
 * Uses generateTextWithRetry for automatic 429 handling and provider fallback.
 * If primary provider hits rate limit, automatically switches to fallback.
 *
 * @returns MultiAgentResponse if successful, null if all providers exhausted
 */
async function executeForcedRouting(
  query: string,
  suggestedAgentName: string,
  startTime: number
): Promise<MultiAgentResponse | null> {
  console.log(`üîç [Forced Routing] Looking up agent config: "${suggestedAgentName}"`);

  // Get agent configuration
  const agentConfig = AGENT_CONFIGS[suggestedAgentName];

  if (!agentConfig) {
    console.warn(`‚ö†Ô∏è [Forced Routing] No config for "${suggestedAgentName}"`);
    return null;
  }

  // Get preferred provider order for this agent
  const providerOrder = getAgentProviderOrder(suggestedAgentName);
  console.log(`üéØ [Forced Routing] Using retry with fallback: [${providerOrder.join(' ‚Üí ')}]`);

  try {
    // Use generateTextWithRetry for automatic 429 handling
    const retryResult = await generateTextWithRetry(
      {
        messages: [
          { role: 'system', content: agentConfig.instructions },
          { role: 'user', content: query },
        ],
        tools: agentConfig.tools as Parameters<typeof generateText>[0]['tools'],
        stopWhen: stepCountIs(5),
        temperature: 0.2,
        maxOutputTokens: 2048,
      },
      providerOrder,
      { timeoutMs: 60000 }
    );

    if (!retryResult.success || !retryResult.result) {
      console.warn(`‚ö†Ô∏è [Forced Routing] All providers failed for ${suggestedAgentName}`);
      // Log attempt details
      for (const attempt of retryResult.attempts) {
        console.log(`   - ${attempt.provider}: ${attempt.error || 'unknown error'}`);
      }
      return null;
    }

    const { result, provider, modelId, usedFallback, attempts } = retryResult;
    const durationMs = Date.now() - startTime;

    // Extract tool calls from steps
    const toolsCalled: string[] = [];
    for (const step of result.steps) {
      for (const toolCall of step.toolCalls) {
        toolsCalled.push(toolCall.toolName);
      }
    }

    // Sanitize response
    const sanitizedResponse = sanitizeChineseCharacters(result.text);

    // Log fallback info if used
    if (usedFallback) {
      console.log(`üîÄ [Forced Routing] Used fallback: ${attempts.map(a => a.provider).join(' ‚Üí ')}`);
    }

    console.log(
      `‚úÖ [Forced Routing] ${suggestedAgentName} completed in ${durationMs}ms via ${provider}, tools: [${toolsCalled.join(', ')}]`
    );

    return {
      success: true,
      response: sanitizedResponse,
      handoffs: [{
        from: 'Orchestrator',
        to: suggestedAgentName,
        reason: usedFallback
          ? `Forced routing with fallback (${attempts.length} attempts)`
          : 'Forced routing (high confidence pre-filter)',
      }],
      finalAgent: suggestedAgentName,
      toolsCalled,
      usage: {
        promptTokens: result.usage?.inputTokens ?? 0,
        completionTokens: result.usage?.outputTokens ?? 0,
        totalTokens: result.usage?.totalTokens ?? 0,
      },
      metadata: {
        provider,
        modelId,
        totalRounds: attempts.length,
        durationMs,
      },
    };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error(`‚ùå [Forced Routing] ${suggestedAgentName} failed:`, errorMessage);
    return null;
  }
}

// ============================================================================
// Execution Function
// ============================================================================

/**
 * Execute multi-agent system
 */
export async function executeMultiAgent(
  request: MultiAgentRequest
): Promise<MultiAgentResponse | MultiAgentError> {
  const startTime = Date.now();

  // Build prompt from messages
  const lastUserMessage = request.messages
    .filter((m) => m.role === 'user')
    .pop();

  if (!lastUserMessage) {
    return {
      success: false,
      error: 'No user message found',
      code: 'INVALID_REQUEST',
    };
  }

  const query = lastUserMessage.content;

  // =========================================================================
  // Fast Path: Rule-based pre-filter for simple queries
  // =========================================================================
  const preFilterResult = preFilterQuery(query);

  // Debug logging for routing decisions
  console.log(`üìã [PreFilter] Query: "${query.substring(0, 50)}..." ‚Üí Suggested: ${preFilterResult.suggestedAgent || 'none'} (confidence: ${preFilterResult.confidence})`);

  if (!preFilterResult.shouldHandoff && preFilterResult.directResponse) {
    const durationMs = Date.now() - startTime;
    console.log(`‚ö° [Fast Path] Direct response in ${durationMs}ms (confidence: ${preFilterResult.confidence})`);

    return {
      success: true,
      response: preFilterResult.directResponse,
      handoffs: [],
      finalAgent: 'Orchestrator (Fast Path)',
      toolsCalled: [],
      usage: {
        promptTokens: 0,
        completionTokens: 0,
        totalTokens: 0,
      },
      metadata: {
        provider: 'rule-based',
        modelId: 'prefilter',
        totalRounds: 1,
        durationMs,
      },
    };
  }

  // =========================================================================
  // Forced Routing: Bypass LLM when pre-filter confidence is high
  // =========================================================================
  console.log(`üîç [Orchestrator] Forced routing check: suggestedAgent=${preFilterResult.suggestedAgent}, confidence=${preFilterResult.confidence}`);

  if (preFilterResult.suggestedAgent && preFilterResult.confidence >= 0.8) {
    console.log(`üöÄ [Orchestrator] Triggering forced routing to ${preFilterResult.suggestedAgent}`);
    const forcedResult = await executeForcedRouting(
      query,
      preFilterResult.suggestedAgent,
      startTime
    );
    if (forcedResult) {
      console.log(`‚úÖ [Orchestrator] Forced routing succeeded`);
      return forcedResult;
    }
    // If forced routing fails, fall through to LLM routing
    console.log('üîÑ [Orchestrator] Forced routing failed, falling back to LLM routing');
  } else {
    console.log(`‚è≠Ô∏è [Orchestrator] Skipping forced routing (conditions not met)`);
  }

  // =========================================================================
  // Slow Path: LLM-based routing for complex queries
  // =========================================================================

  // Check if orchestrator is available
  if (!orchestrator || !orchestratorModelConfig) {
    return {
      success: false,
      error: 'Orchestrator not available (no AI provider configured)',
      code: 'MODEL_UNAVAILABLE',
    };
  }

  try {
    const { provider, modelId } = orchestratorModelConfig;

    console.log(`üéØ [Orchestrator] LLM routing with ${provider}/${modelId} (suggested: ${preFilterResult.suggestedAgent || 'none'})`);

    // Enhance prompt with suggested agent hint when confidence is high
    let enhancedPrompt = query;
    if (preFilterResult.suggestedAgent && preFilterResult.confidence >= 0.7) {
      enhancedPrompt = `[ÏãúÏä§ÌÖú ÌûåÌä∏: Ïù¥ ÏßàÎ¨∏ÏùÄ "${preFilterResult.suggestedAgent}"ÏóêÍ≤å Ìï∏ÎìúÏò§ÌîÑÌïòÎäî Í≤ÉÏù¥ Ï†ÅÌï©Ìï©ÎãàÎã§. ÏÑúÎ≤Ñ/Ïù∏ÌîÑÎùº Í¥ÄÏ†êÏóêÏÑú Ìï¥ÏÑùÌïòÏÑ∏Ïöî.]\n\nÏÇ¨Ïö©Ïûê ÏßàÎ¨∏: ${query}`;
      console.log(`üí° [Orchestrator] Enhanced prompt with handoff hint ‚Üí ${preFilterResult.suggestedAgent}`);
    }

    // Execute orchestrator with timeout protection
    let timeoutId: NodeJS.Timeout;
    const timeoutPromise = new Promise<never>((_, reject) => {
      timeoutId = setTimeout(() => {
        reject(new Error(`Orchestrator timeout after ${ORCHESTRATOR_CONFIG.timeout}ms`));
      }, ORCHESTRATOR_CONFIG.timeout);
    });

    // Warn if execution is taking too long
    const warnTimer = setTimeout(() => {
      console.warn(`‚ö†Ô∏è [Orchestrator] Execution exceeding ${ORCHESTRATOR_CONFIG.warnThreshold}ms threshold`);
    }, ORCHESTRATOR_CONFIG.warnThreshold);

    let result;
    try {
      result = await Promise.race([
        orchestrator.generate({ prompt: enhancedPrompt }),
        timeoutPromise,
      ]);
    } finally {
      // Always cleanup timers (success, error, or timeout)
      clearTimeout(timeoutId!);
      clearTimeout(warnTimer);
    }

    const durationMs = Date.now() - startTime;

    // Extract handoff information
    const handoffs = result.handoffs?.map((h) => ({
      from: 'Orchestrator',
      to: h.targetAgent || 'Unknown',
      reason: h.reason,
    })) || [];

    // Extract tool calls from all steps
    const toolsCalled: string[] = [];
    if (result.steps) {
      for (const step of result.steps) {
        if (step.toolCalls) {
          for (const tc of step.toolCalls) {
            toolsCalled.push(tc.toolName);
          }
        }
      }
    }

    // Sanitize Chinese/other foreign characters from LLM output
    const sanitizedResponse = sanitizeChineseCharacters(result.text);

    console.log(
      `‚úÖ [Orchestrator] Completed in ${durationMs}ms, final agent: ${result.finalAgent}, tools: [${toolsCalled.join(', ')}]`
    );

    // =========================================================================
    // Handoff Fallback: If LLM didn't handoff and no tools called,
    // try the pre-filter suggested agent as fallback
    // =========================================================================
    const noHandoffOccurred = handoffs.length === 0 || result.finalAgent === 'Orchestrator';
    const noToolsCalled = toolsCalled.length === 0;
    const suggestedAgent = preFilterResult.suggestedAgent;
    const hasSuggestedAgent = suggestedAgent !== undefined && preFilterResult.confidence >= 0.6;

    if (noHandoffOccurred && noToolsCalled && hasSuggestedAgent) {
      console.log(
        `üîÑ [Handoff Fallback] No handoff/tools detected, trying ${suggestedAgent} as fallback`
      );

      const fallbackResult = await executeForcedRouting(
        query,
        suggestedAgent,
        startTime
      );

      if (fallbackResult && fallbackResult.toolsCalled.length > 0) {
        console.log(
          `‚úÖ [Handoff Fallback] ${suggestedAgent} succeeded with tools: [${fallbackResult.toolsCalled.join(', ')}]`
        );
        return {
          ...fallbackResult,
          handoffs: [{
            from: 'Orchestrator',
            to: suggestedAgent,
            reason: 'Handoff fallback (LLM failed to delegate)',
          }],
        };
      }

      // If fallback also didn't call tools, return original LLM response
      console.log('‚ö†Ô∏è [Handoff Fallback] Fallback also failed, returning original response');
    }

    return {
      success: true,
      response: sanitizedResponse,
      handoffs,
      finalAgent: result.finalAgent || 'Orchestrator',
      toolsCalled,
      usage: {
        promptTokens: result.usage?.inputTokens ?? 0,
        completionTokens: result.usage?.outputTokens ?? 0,
        totalTokens: result.usage?.totalTokens ?? 0,
      },
      metadata: {
        provider,
        modelId,
        totalRounds: (result.handoffs?.length ?? 0) + 1,
        durationMs,
      },
    };
  } catch (error) {
    const durationMs = Date.now() - startTime;
    const errorMessage = error instanceof Error ? error.message : String(error);

    console.error(`‚ùå [Orchestrator] Error after ${durationMs}ms:`, errorMessage);

    // Classify error
    let code = 'UNKNOWN_ERROR';
    if (errorMessage.includes('API key')) {
      code = 'AUTH_ERROR';
    } else if (errorMessage.includes('rate limit')) {
      code = 'RATE_LIMIT';
    } else if (errorMessage.includes('timeout')) {
      code = 'TIMEOUT';
    } else if (errorMessage.includes('model')) {
      code = 'MODEL_ERROR';
    }

    return {
      success: false,
      error: errorMessage,
      code,
    };
  }
}

// ============================================================================
// Multi-Agent Streaming Execution
// ============================================================================

/**
 * Execute multi-agent mode with real-time streaming
 * 
 * Unlike executeMultiAgent which returns a complete response,
 * this function yields StreamEvent chunks in real-time.
 * 
 * @param request - Multi-agent request with messages and session info
 * @yields StreamEvent - Real-time streaming events (text_delta, tool_call, handoff, done, error)
 */
export async function* executeMultiAgentStream(
  request: MultiAgentRequest
): AsyncGenerator<StreamEvent> {
  const startTime = Date.now();

  // Build prompt from messages
  const lastUserMessage = request.messages
    .filter((m) => m.role === 'user')
    .pop();

  if (!lastUserMessage) {
    yield { type: 'error', data: { code: 'INVALID_REQUEST', error: 'No user message found' } };
    return;
  }

  const query = lastUserMessage.content;

  // =========================================================================
  // Fast Path: Rule-based pre-filter for simple queries
  // =========================================================================
  const preFilterResult = preFilterQuery(query);

  console.log(`üìã [Stream PreFilter] Query: "${query.substring(0, 50)}..." ‚Üí Suggested: ${preFilterResult.suggestedAgent || 'none'} (confidence: ${preFilterResult.confidence})`);

  if (!preFilterResult.shouldHandoff && preFilterResult.directResponse) {
    const durationMs = Date.now() - startTime;
    console.log(`‚ö° [Stream Fast Path] Direct response in ${durationMs}ms`);

    yield { type: 'text_delta', data: preFilterResult.directResponse };
    yield {
      type: 'done',
      data: {
        success: true,
        finalAgent: 'Orchestrator (Fast Path)',
        toolsCalled: [],
        usage: { promptTokens: 0, completionTokens: 0 },
        metadata: { durationMs, provider: 'rule-based' }
      }
    };
    return;
  }

  // =========================================================================
  // Check orchestrator availability
  // =========================================================================
  if (!orchestrator || !orchestratorModelConfig) {
    yield { type: 'error', data: { code: 'MODEL_UNAVAILABLE', error: 'Orchestrator not available' } };
    return;
  }

  try {
    const { provider, modelId } = orchestratorModelConfig;

    console.log(`üéØ [Stream Orchestrator] Starting with ${provider}/${modelId}`);

    // Langfuse timeout span for tracking
    const timeoutSpan = createTimeoutSpan(
      request.sessionId,
      'orchestrator_stream',
      ORCHESTRATOR_CONFIG.timeout
    );

    // Enhance prompt with suggested agent hint when confidence is high
    let enhancedPrompt = query;
    if (preFilterResult.suggestedAgent && preFilterResult.confidence >= 0.7) {
      enhancedPrompt = `[ÏãúÏä§ÌÖú ÌûåÌä∏: Ïù¥ ÏßàÎ¨∏ÏùÄ "${preFilterResult.suggestedAgent}"ÏóêÍ≤å Ìï∏ÎìúÏò§ÌîÑÌïòÎäî Í≤ÉÏù¥ Ï†ÅÌï©Ìï©ÎãàÎã§. ÏÑúÎ≤Ñ/Ïù∏ÌîÑÎùº Í¥ÄÏ†êÏóêÏÑú Ìï¥ÏÑùÌïòÏÑ∏Ïöî.]\n\nÏÇ¨Ïö©Ïûê ÏßàÎ¨∏: ${query}`;
    }

    // =========================================================================
    // Stream from orchestrator with warning tracking
    // =========================================================================
    const streamResult = orchestrator.stream({
      prompt: enhancedPrompt,
    });

    // Warning state (only emit once)
    let warningEmitted = false;

    // Yield text chunks as they arrive with elapsed time check
    for await (const textChunk of streamResult.textStream) {
      const elapsed = Date.now() - startTime;

      // Emit warning once when threshold exceeded (25s)
      if (!warningEmitted && elapsed >= ORCHESTRATOR_CONFIG.warnThreshold) {
        warningEmitted = true;

        console.warn(
          `‚ö†Ô∏è [Stream Orchestrator] Execution exceeding ${ORCHESTRATOR_CONFIG.warnThreshold}ms threshold`
        );

        // Yield warning event to frontend
        yield {
          type: 'warning',
          data: {
            code: 'SLOW_PROCESSING',
            message: 'Ï≤òÎ¶¨ ÏãúÍ∞ÑÏù¥ 25Ï¥àÎ•º Ï¥àÍ≥ºÌñàÏäµÎãàÎã§. Î≥µÏû°Ìïú Î∂ÑÏÑùÏù¥ ÏßÑÌñâ Ï§ëÏûÖÎãàÎã§.',
            elapsed,
            threshold: ORCHESTRATOR_CONFIG.warnThreshold,
          },
        };

        // Log to Langfuse
        logTimeoutEvent('warning', {
          operation: 'orchestrator_stream',
          elapsed,
          threshold: ORCHESTRATOR_CONFIG.warnThreshold,
          sessionId: request.sessionId,
        });
      }

      const sanitized = sanitizeChineseCharacters(textChunk);
      if (sanitized) {
        yield { type: 'text_delta', data: sanitized };
      }
    }

    // Complete timeout span
    const finalElapsed = Date.now() - startTime;
    timeoutSpan.complete(true, finalElapsed);

    // =========================================================================
    // After streaming completes, gather metadata
    // =========================================================================
    const [steps, usage] = await Promise.all([
      streamResult.steps,
      streamResult.usage,
    ]);

    // Extract tool calls and handoff information from steps
    const toolsCalled: string[] = [];
    const handoffList: Array<{ from: string; to: string; reason?: string }> = [];
    let detectedFinalAgent = 'Orchestrator';

    if (steps) {
      for (const step of steps) {
        // Extract tool calls
        if (step.toolCalls) {
          for (const tc of step.toolCalls) {
            toolsCalled.push(tc.toolName);
            yield { type: 'tool_call', data: { name: tc.toolName } };
          }
        }

        // Check for agent info in step (if available)
        const stepAny = step as Record<string, unknown>;
        if (stepAny.agent && typeof stepAny.agent === 'string') {
          detectedFinalAgent = stepAny.agent;
        }
      }
    }

    // Yield handoff events from tracked handoffs
    const recentHandoffs = getRecentHandoffs();
    for (const h of recentHandoffs) {
      yield {
        type: 'handoff',
        data: {
          from: h.from,
          to: h.to,
          reason: h.reason,
        }
      };
      handoffList.push({ from: h.from, to: h.to, reason: h.reason });
    }

    const durationMs = Date.now() - startTime;

    console.log(`‚úÖ [Stream Orchestrator] Completed in ${durationMs}ms, final agent: ${detectedFinalAgent}, tools: [${toolsCalled.join(', ')}]`);

    yield {
      type: 'done',
      data: {
        success: true,
        finalAgent: detectedFinalAgent,
        toolsCalled,
        handoffs: handoffList,
        usage: {
          promptTokens: usage?.inputTokens ?? 0,
          completionTokens: usage?.outputTokens ?? 0,
        },
        metadata: {
          provider,
          modelId,
          durationMs,
        }
      }
    };

  } catch (error) {
    const durationMs = Date.now() - startTime;
    const errorMessage = error instanceof Error ? error.message : String(error);

    console.error(`‚ùå [Stream Orchestrator] Error after ${durationMs}ms:`, errorMessage);

    // Classify error
    let code = 'UNKNOWN_ERROR';
    if (errorMessage.includes('API key')) {
      code = 'AUTH_ERROR';
    } else if (errorMessage.includes('rate limit')) {
      code = 'RATE_LIMIT';
    } else if (errorMessage.includes('timeout')) {
      code = 'TIMEOUT';

      // Log timeout error to Langfuse
      logTimeoutEvent('error', {
        operation: 'orchestrator_stream',
        elapsed: durationMs,
        threshold: ORCHESTRATOR_CONFIG.timeout,
        sessionId: request.sessionId,
      });
    } else if (errorMessage.includes('model')) {
      code = 'MODEL_ERROR';
    }

    yield { type: 'error', data: { code, error: errorMessage } };
  }
}

export default orchestrator;
