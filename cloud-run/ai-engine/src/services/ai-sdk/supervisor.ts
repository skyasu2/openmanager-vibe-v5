/**
 * AI SDK Supervisor
 *
 * Router Agent pattern implementation using Vercel AI SDK.
 * Replaces LangGraph multi-agent supervisor with simpler multi-step tool calling.
 *
 * Key differences from LangGraph:
 * - LangGraph: Multi-turn tool calling for agent handoffs (broken with Cerebras)
 * - AI SDK: Single generateText call with maxSteps for multi-step tool execution
 *
 * @version 1.0.0
 * @updated 2025-12-28
 */

import { generateText, stepCountIs, type ModelMessage } from 'ai';
import { getSupervisorModel, logProviderStatus } from './model-provider';
import { allTools, toolDescriptions, type ToolName } from '../../tools-ai-sdk';

// ============================================================================
// 1. Types
// ============================================================================

export interface SupervisorRequest {
  messages: Array<{ role: 'user' | 'assistant'; content: string }>;
  sessionId: string;
  enableTracing?: boolean;
}

export interface SupervisorResponse {
  success: boolean;
  response: string;
  toolsCalled: string[];
  toolResults: Record<string, unknown>[];
  usage: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  metadata: {
    provider: string;
    modelId: string;
    stepsExecuted: number;
    durationMs: number;
  };
}

export interface SupervisorError {
  success: false;
  error: string;
  code: string;
}

// ============================================================================
// 2. System Prompt
// ============================================================================

const SYSTEM_PROMPT = `ë‹¹ì‹ ì€ ì„œë²„ ëª¨ë‹ˆí„°ë§ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

## ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬

### ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ
- getServerMetrics: ì„œë²„ ìƒíƒœ ì¡°íšŒ (CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬)
- getServerMetricsAdvanced: ê³ ê¸‰ ë©”íŠ¸ë¦­ ì¡°íšŒ (ì‹œê°„ë²”ìœ„, í•„í„°, ì§‘ê³„)
- filterServers: ì¡°ê±´ì— ë§ëŠ” ì„œë²„ í•„í„°ë§ (ì˜ˆ: CPU 80% ì´ìƒ)

### ì¥ì•  ë¶„ì„ (RCA)
- buildIncidentTimeline: ì¥ì•  íƒ€ì„ë¼ì¸ êµ¬ì„±
- correlateMetrics: ë©”íŠ¸ë¦­ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
- findRootCause: ê·¼ë³¸ ì›ì¸ ë¶„ì„

### ì´ìƒ íƒì§€ & ì˜ˆì¸¡
- detectAnomalies: ì´ìƒì¹˜ íƒì§€ (6ì‹œê°„ ì´ë™í‰ê·  + 2Ïƒ)
- predictTrends: íŠ¸ë Œë“œ ì˜ˆì¸¡ (ì„ í˜• íšŒê·€ ê¸°ë°˜)
- analyzePattern: íŒ¨í„´ ë¶„ì„

## ì‘ë‹µ ì§€ì¹¨

1. ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
2. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”
3. ìˆ«ìëŠ” ì†Œìˆ˜ì  1ìë¦¬ê¹Œì§€ë§Œ í‘œì‹œí•˜ì„¸ìš”
4. ì„œë²„ ì´ë¦„ê³¼ IDë¥¼ í•¨ê»˜ ì–¸ê¸‰í•˜ì„¸ìš”
5. ì´ìƒ ìƒíƒœê°€ ê°ì§€ë˜ë©´ ê¶Œì¥ ì¡°ì¹˜ë¥¼ ì œì•ˆí•˜ì„¸ìš”

## ì˜ˆì‹œ ì§ˆë¬¸ê³¼ ë„êµ¬ ë§¤í•‘

- "CPU 80% ì´ìƒì¸ ì„œë²„ ì•Œë ¤ì¤˜" â†’ filterServers(field: "cpu", operator: ">", value: 80)
- "ì„œë²„ ìƒíƒœ ìš”ì•½í•´ì¤˜" â†’ getServerMetrics()
- "ë©”ëª¨ë¦¬ ì¶”ì„¸ ë¶„ì„í•´ì¤˜" â†’ predictTrends(metricType: "memory")
- "ì¥ì•  ì›ì¸ ë¶„ì„í•´ì¤˜" â†’ findRootCause() + buildIncidentTimeline()
`;

// ============================================================================
// 3. Supervisor Implementation
// ============================================================================

/**
 * Execute supervisor with AI SDK
 */
export async function executeSupervisor(
  request: SupervisorRequest
): Promise<SupervisorResponse | SupervisorError> {
  const startTime = Date.now();

  try {
    // Log provider status on first call
    logProviderStatus();

    // Get model with fallback chain
    const { model, provider, modelId } = getSupervisorModel();

    console.log(`ğŸ¤– [Supervisor] Using ${provider}/${modelId}`);

    // Convert messages to ModelMessage format (AI SDK 6)
    const modelMessages: ModelMessage[] = [
      { role: 'system', content: SYSTEM_PROMPT },
      ...request.messages.map((m) => ({
        role: m.role as 'user' | 'assistant',
        content: m.content,
      })),
    ];

    // Execute with multi-step tool calling
    const result = await generateText({
      model,
      messages: modelMessages,
      tools: allTools,
      stopWhen: stepCountIs(5), // Allow up to 5 tool calls
      temperature: 0.2,
      maxOutputTokens: 2048,
    });

    // Extract tool call information
    const toolsCalled: string[] = [];
    const toolResults: Record<string, unknown>[] = [];

    for (const step of result.steps) {
      for (const toolCall of step.toolCalls) {
        toolsCalled.push(toolCall.toolName);
      }
      // toolResultsëŠ” step.toolResultsì—ì„œ ì¶”ì¶œ
      if (step.toolResults) {
        for (const tr of step.toolResults) {
          // AI SDK v4ì—ì„œ toolResultëŠ” { toolCallId, toolName, result } êµ¬ì¡°
          if ('result' in tr) {
            toolResults.push(tr.result as Record<string, unknown>);
          }
        }
      }
    }

    const durationMs = Date.now() - startTime;

    console.log(
      `âœ… [Supervisor] Completed in ${durationMs}ms, tools: [${toolsCalled.join(', ')}]`
    );

    return {
      success: true,
      response: result.text,
      toolsCalled,
      toolResults,
      usage: {
        promptTokens: result.usage?.inputTokens ?? 0,
        completionTokens: result.usage?.outputTokens ?? 0,
        totalTokens: result.usage?.totalTokens ?? 0,
      },
      metadata: {
        provider,
        modelId,
        stepsExecuted: result.steps.length,
        durationMs,
      },
    };
  } catch (error) {
    const durationMs = Date.now() - startTime;
    const errorMessage = error instanceof Error ? error.message : String(error);

    console.error(`âŒ [Supervisor] Error after ${durationMs}ms:`, errorMessage);

    // Classify error
    let code = 'UNKNOWN_ERROR';
    if (errorMessage.includes('API key')) {
      code = 'AUTH_ERROR';
    } else if (errorMessage.includes('rate limit')) {
      code = 'RATE_LIMIT';
    } else if (errorMessage.includes('timeout')) {
      code = 'TIMEOUT';
    } else if (errorMessage.includes('model')) {
      code = 'MODEL_ERROR';
    }

    return {
      success: false,
      error: errorMessage,
      code,
    };
  }
}

// ============================================================================
// 4. Streaming Supervisor (for future use)
// ============================================================================

/**
 * Execute supervisor with streaming response
 * TODO: Implement when needed for real-time UI updates
 */
export async function* executeSupervisorStream(
  request: SupervisorRequest
): AsyncGenerator<{
  type: 'tool_call' | 'tool_result' | 'text' | 'done';
  data: unknown;
}> {
  // Placeholder for streaming implementation
  const result = await executeSupervisor(request);

  if (!result.success) {
    yield { type: 'done', data: { error: (result as SupervisorError).error } };
    return;
  }

  const successResult = result as SupervisorResponse;

  // Emit tool calls
  for (const toolName of successResult.toolsCalled) {
    yield { type: 'tool_call', data: { name: toolName } };
  }

  // Emit tool results
  for (const toolResult of successResult.toolResults) {
    yield { type: 'tool_result', data: toolResult };
  }

  // Emit final text
  yield { type: 'text', data: successResult.response };
  yield { type: 'done', data: successResult.metadata };
}

// ============================================================================
// 5. Intent Classification (Optional Enhancement)
// ============================================================================

type IntentCategory = 'metrics' | 'rca' | 'analyst' | 'general';

interface ClassifiedIntent {
  category: IntentCategory;
  suggestedTools: ToolName[];
  confidence: number;
}

/**
 * Classify user intent (rule-based, for optimization)
 * This can reduce token usage by pre-filtering tools
 */
export function classifyIntent(query: string): ClassifiedIntent {
  const q = query.toLowerCase();

  // Metrics queries
  if (/cpu|ë©”ëª¨ë¦¬|memory|ë””ìŠ¤í¬|disk|ì„œë²„.*ìƒíƒœ|ìƒíƒœ.*ìš”ì•½/i.test(q)) {
    if (/\d+%.*ì´ìƒ|>\s*\d+|ì´ˆê³¼|ë†’ì€/i.test(q)) {
      return {
        category: 'metrics',
        suggestedTools: ['filterServers'],
        confidence: 0.9,
      };
    }
    return {
      category: 'metrics',
      suggestedTools: ['getServerMetrics', 'getServerMetricsAdvanced'],
      confidence: 0.85,
    };
  }

  // RCA queries
  if (/ì¥ì• |ì›ì¸|root.*cause|rca|íƒ€ì„ë¼ì¸|ìƒê´€ê´€ê³„/i.test(q)) {
    return {
      category: 'rca',
      suggestedTools: ['findRootCause', 'buildIncidentTimeline', 'correlateMetrics'],
      confidence: 0.9,
    };
  }

  // Analyst queries
  if (/ì´ìƒ|anomaly|íŠ¸ë Œë“œ|trend|ì˜ˆì¸¡|predict|íŒ¨í„´/i.test(q)) {
    return {
      category: 'analyst',
      suggestedTools: ['detectAnomalies', 'predictTrends', 'analyzePattern'],
      confidence: 0.85,
    };
  }

  // General - let LLM decide
  return {
    category: 'general',
    suggestedTools: ['getServerMetrics'],
    confidence: 0.5,
  };
}

// ============================================================================
// 6. Health Check
// ============================================================================

export interface SupervisorHealth {
  status: 'ok' | 'degraded' | 'error';
  provider: string;
  modelId: string;
  toolsAvailable: number;
}

/**
 * Check supervisor health
 */
export async function checkSupervisorHealth(): Promise<SupervisorHealth> {
  try {
    const { provider, modelId } = getSupervisorModel();
    const toolCount = Object.keys(allTools).length;

    return {
      status: 'ok',
      provider,
      modelId,
      toolsAvailable: toolCount,
    };
  } catch (error) {
    return {
      status: 'error',
      provider: 'none',
      modelId: 'none',
      toolsAvailable: 0,
    };
  }
}
