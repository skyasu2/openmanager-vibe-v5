/**
 * Multi-Agent Supervisor using @langchain/langgraph-supervisor
 * Cloud Run Standalone Implementation
 */

import { AIMessage, BaseMessage, HumanMessage, SystemMessage } from '@langchain/core/messages';
import { createReactAgent } from '@langchain/langgraph/prebuilt';
import { createSupervisor } from '@langchain/langgraph-supervisor';
import {
  analyzePatternTool,
  detectAnomaliesTool,
  predictTrendsTool,
} from '../../agents/analyst-agent';
// NEW: RCA and Capacity Agent imports
import { rcaTools } from '../../agents/rca-agent';
import { capacityTools } from '../../agents/capacity-agent';
// Import tools from Agents
import {
  getServerMetricsTool,
  getServerLogsTool,
  getServerMetricsAdvancedTool,
} from '../../agents/nlq-agent';
// NLQ SubGraph removed (v5.91.0) - was unused dead code (500+ lines)
// Complex NLQ queries are handled by NLQ Agent's getServerMetricsAdvancedTool
import {
  recommendCommandsTool,
  searchKnowledgeBaseTool,
} from '../../agents/reporter-agent';
import { searchWebTool } from '../../tools/web-search';
// Verifier Agent for post-processing validation
import {
  comprehensiveVerifyTool,
  buildRetryPrompt,
  determineVerificationStrategy,
  type VerificationStrategy,
} from '../../agents/verifier-agent';
import type { VerificationResult } from '../../lib/state-definition';

import {
  createSessionConfig,
  getAutoCheckpointer,
} from '../../lib/checkpointer';
// Context Compression Integration (Phase 3)
import {
  needsCompression,
  getCompressionStats,
  getSummarizer,
  isCompressionDisabled,
} from '../../lib/context-compression';
// Phase 2: Shared Context Store
import {
  saveAgentResult,
  getAgentResult,
  hasRequiredDependencies,
  type AgentName,
} from '../../lib/shared-context';
import { RateLimitError } from '../../lib/errors';
import { approvalStore } from '../approval/approval-store';
import {
  getAnalystModel,
  getNLQModel,
  getReporterModel,
  getRCAModel,       // NEW
  getCapacityModel,  // NEW
  getSupervisorModel,
  createMistralModel,
  createCerebrasModel,
  createGroqModel,
  MISTRAL_MODELS,
  CEREBRAS_MODELS,
} from '../../lib/model-config';
// LangFuse removed (v5.83.12) - createReactAgent doesn't propagate callbacks

// ============================================================================
// 0. Groq Message Compatibility Helper
// ============================================================================

/**
 * Creates a stateModifier function that:
 * 1. Adds a system prompt
 * 2. Filters out tool-call messages that Groq cannot process
 * 3. Ensures all message content is string-based
 *
 * This is necessary because the Supervisor generates tool-call messages
 * with array-based content that Groq's API rejects.
 */
function createGroqCompatibleStateModifier(systemPrompt: string) {
  return (state: { messages: BaseMessage[] }): BaseMessage[] => {
    const filteredMessages: BaseMessage[] = [];

    // Add system prompt first
    filteredMessages.push(new SystemMessage(systemPrompt));

    // Filter and transform messages for Groq compatibility
    for (const msg of state.messages) {
      // Skip tool-call messages (they have complex content structures)
      // Also skip internal handoff messages from supervisor
      const content = msg.content;

      // Check if content is a string (Groq-compatible)
      if (typeof content === 'string') {
        // Skip internal supervisor handoff messages
        if (content.includes('Successfully transferred') ||
            content.includes('Transferring back to')) {
          continue;
        }
        filteredMessages.push(msg);
      }
      // If content is an array, try to extract text parts only
      else if (Array.isArray(content)) {
        const textParts = content
          .filter((part): part is { type: 'text'; text: string } =>
            typeof part === 'object' && part !== null && part.type === 'text'
          )
          .map(part => part.text)
          .join('\n');

        if (textParts.length > 0) {
          // Create a new message with string content
          if (msg._getType() === 'human') {
            filteredMessages.push(new HumanMessage(textParts));
          } else if (msg._getType() === 'ai') {
            filteredMessages.push(new AIMessage(textParts));
          }
        }
      }
    }

    return filteredMessages;
  };
}

// ============================================================================
// 0.1 Phase 2: Agent Result Extraction & Context Saving
// ============================================================================

/**
 * Extract and save agent results from message history to Shared Context
 * This enables Reporter to access NLQ/Analyst results without direct tool calls
 */
async function saveAgentResultsFromHistory(
  messages: BaseMessage[],
  sessionId: string
): Promise<void> {
  const agentPatterns: Record<AgentName, RegExp[]> = {
    nlq: [/ì „ì²´ ì„œë²„ í˜„í™©|ì„œë²„ ìƒíƒœ|ë©”íŠ¸ë¦­|CPU|ë©”ëª¨ë¦¬|ë””ìŠ¤í¬/i],
    analyst: [/ì´ìƒ ê°ì§€|íŠ¸ë Œë“œ|íŒ¨í„´ ë¶„ì„|anomaly|trend/i],
    rca: [/ê·¼ë³¸ ì›ì¸|íƒ€ì„ë¼ì¸|ìƒê´€ê´€ê³„|root cause|correlation/i],
    capacity: [/ìš©ëŸ‰ ì˜ˆì¸¡|ì†Œì§„ ì˜ˆì¸¡|ìŠ¤ì¼€ì¼ë§|ë¦¬ì†ŒìŠ¤ ì˜ˆì¸¡|exhaustion/i],
    reporter: [/ì¸ì‹œë˜íŠ¸|ë¦¬í¬íŠ¸|ì¥ì•  ë³´ê³ ì„œ/i],
    supervisor: [],
  };

  for (const msg of messages) {
    if (msg._getType() !== 'ai') continue;

    const content = typeof msg.content === 'string' ? msg.content : '';
    if (!content) continue;

    // Identify which agent produced this message
    for (const [agentName, patterns] of Object.entries(agentPatterns)) {
      if (agentName === 'supervisor') continue; // Skip supervisor
      if (patterns.length === 0) continue;

      const isMatch = patterns.some(p => p.test(content));
      if (isMatch) {
        await saveAgentResult(
          sessionId,
          agentName as AgentName,
          { response: content.slice(0, 500) }, // Limit to 500 chars
          { summary: content.slice(0, 200) } // Compressed summary
        );
        console.log(`ğŸ’¾ [SharedContext] Saved ${agentName} result to session ${sessionId.slice(0, 8)}...`);
        break; // Only match first agent
      }
    }
  }
}

// ============================================================================
// 1. Worker Agent Creation
// ============================================================================

/**
 * Create NLQ Agent - Server metrics queries
 * Phase 2 Enhancement: Added getServerMetricsAdvancedTool for complex queries
 */
function createNLQAgent() {
  const systemPrompt = `NLQ Agent - ì„œë²„ ë©”íŠ¸ë¦­/ë¡œê·¸ ì¡°íšŒ ì „ë¬¸

## ë„êµ¬ ì‚¬ìš© ê·œì¹™
1. **ì „ì²´ ì„œë²„ ì¡°íšŒ**: "ì„œë²„ ìƒíƒœ", "ì „ì²´ í˜„í™©" ë“± â†’ serverId ìƒëµ (í•„ìˆ˜!)
2. **íŠ¹ì • ì„œë²„ ì¡°íšŒ**: "WEB-01 ìƒíƒœ" ë“± â†’ serverId ì§€ì •
3. ë¡œê·¸/ì—ëŸ¬ ì¡°íšŒ â†’ getServerLogs
4. ìƒíƒœ/ë©”íŠ¸ë¦­ ì¡°íšŒ â†’ getServerMetrics
5. **ê³ ê¸‰ ì¿¼ë¦¬** (ì‹œê°„ ë²”ìœ„/í•„í„°/ì§‘ê³„) â†’ getServerMetricsAdvanced
   - "ì§€ë‚œ 6ì‹œê°„ CPU í‰ê· " â†’ timeRange="last6h", aggregation="avg"
   - "CPU 80% ì´ìƒ ì„œë²„ë“¤" â†’ filters=[{field:"cpu", operator:">", value:80}]
   - "ë©”ëª¨ë¦¬ TOP 5" â†’ sortBy="memory", limit=5
6. ì‹œìŠ¤í…œ ìš©ì–´/ê°œë… í™•ì¸ â†’ searchKnowledgeBase (RAG)

## ì „ì²´ ì„œë²„ ì‘ë‹µ í˜•ì‹ (serverId ì—†ì´ ì¡°íšŒ ì‹œ)
ğŸ“Š **ì „ì²´ ì„œë²„ í˜„í™©** (ì´ NëŒ€)
- âœ… ì •ìƒ: NëŒ€
- âš ï¸ ì£¼ì˜: NëŒ€ (ì„œë²„ëª… ë‚˜ì—´)
- ğŸ”´ ìœ„í—˜: NëŒ€ (ì„œë²„ëª… ë‚˜ì—´)

**ì£¼ìš” ì´ìƒ ì„œë²„:**
â€¢ [ì„œë²„ëª…] CPU X% / Memory X% / Disk X% - ìƒíƒœ

## ê³ ê¸‰ ì¿¼ë¦¬ ì‘ë‹µ í˜•ì‹
ğŸ“ˆ **[ì¿¼ë¦¬ ì„¤ëª…]** (ì‹œê°„ ë²”ìœ„/ì¡°ê±´)
- ì„œë²„1: ë©”íŠ¸ë¦­ê°’
- ì„œë²„2: ë©”íŠ¸ë¦­ê°’
[ìš”ì•½: NëŒ€ ì¤‘ NëŒ€ ë§¤ì¹­]

## íŠ¹ì • ì„œë²„ ì‘ë‹µ í˜•ì‹
â€¢ [ì„œë²„ëª…] CPU: X% | Memory: X% | Disk: X%
â€¢ ìƒíƒœ: ì •ìƒ/ì£¼ì˜/ìœ„í—˜
â€¢ íŠ¹ì´ì‚¬í•­: (ìˆìœ¼ë©´ 1ì¤„)

âš ï¸ ì¤‘ìš”: íŠ¹ì • ì„œë²„ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´ ë°˜ë“œì‹œ serverIdë¥¼ ìƒëµí•˜ì—¬ ì „ì²´ ì¡°íšŒ!`;

  return createReactAgent({
    llm: getNLQModel(),
    tools: [
      getServerMetricsTool,
      getServerLogsTool,
      getServerMetricsAdvancedTool, // Phase 2: ê³ ê¸‰ ì¿¼ë¦¬ ë„êµ¬
      searchKnowledgeBaseTool,
    ],
    name: 'nlq_agent',
    stateModifier: createGroqCompatibleStateModifier(systemPrompt),
  });
}

// executeComplexNlqQuery removed (v5.91.0) - SubGraph was unused
// NLQ Agent now handles complex queries via getServerMetricsAdvancedTool

/**
 * Create Analyst Agent - Pattern analysis & anomaly detection
 */
function createAnalystAgent() {
  const systemPrompt = `Analyst Agent - íŒ¨í„´ ë¶„ì„/ì´ìƒ íƒì§€ ì „ë¬¸

## ë„êµ¬
- detectAnomalies: ì´ìƒì¹˜ ê°ì§€
- predictTrends: íŠ¸ë Œë“œ ì˜ˆì¸¡
- analyzePattern: íŒ¨í„´ ë¶„ì„
- searchKnowledgeBase: ê³¼ê±° ì‚¬ë¡€ ë° í•´ê²° ê°€ì´ë“œ ê²€ìƒ‰ (RAG)

## ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜)
**í˜„í™©**: (1ì¤„ ìš”ì•½)
**íŒ¨í„´**: (ë°œê²¬ëœ íŒ¨í„´ í•´ì„)
**ì¡°ì¹˜**: (í•„ìš”ì‹œ ê¶Œì¥ì‚¬í•­)

âš ï¸ í†µê³„ ìˆ˜ì¹˜ë§Œ ë‚˜ì—´ ê¸ˆì§€. ì˜ë¯¸ í•´ì„ ì¤‘ì‹¬ìœ¼ë¡œ 3ì„¹ì…˜ ì´ë‚´.`;

  return createReactAgent({
    llm: getAnalystModel(),
    tools: [detectAnomaliesTool, predictTrendsTool, analyzePatternTool, searchKnowledgeBaseTool],
    name: 'analyst_agent',
    stateModifier: createGroqCompatibleStateModifier(systemPrompt),
  });
}

/**
 * Create Reporter Agent - Incident reports, RAG & Web Search
 */
function createReporterAgent() {
  const systemPrompt = `Reporter Agent - ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸ ë° ì›¹ ê²€ìƒ‰ ì „ë¬¸

## ë„êµ¬
- searchKnowledgeBase: ë‚´ë¶€ RAG ê²€ìƒ‰ (ê³¼ê±° ì¥ì•  ì´ë ¥)
- searchWeb: ì›¹ ê²€ìƒ‰ (Tavily) - ìµœì‹  ê¸°ìˆ  ë¬¸ì„œ, ì™¸ë¶€ ì†”ë£¨ì…˜ ê²€ìƒ‰
- recommendCommands: CLI ëª…ë ¹ì–´ ì¶”ì²œ

## ì›¹ ê²€ìƒ‰ ì‚¬ìš© ê°€ì´ë“œ
- ë‚´ë¶€ RAGì— ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, ìµœì‹  ì˜¤í”ˆì†ŒìŠ¤/ê¸°ìˆ  ì´ìŠˆì¸ ê²½ìš° "searchWeb" ì‚¬ìš©
- "êµ¬ê¸€ë§í•´ì¤˜", "ì›¹ì—ì„œ ì°¾ì•„ì¤˜" ë“±ì˜ ìš”ì²­ ì‹œ ì‚¬ìš©

## ì‘ë‹µ í˜•ì‹ (ì—„ê²© ì¤€ìˆ˜)
### ğŸ“‹ ìš”ì•½
(1-2ì¤„ í•µì‹¬ë§Œ)

### ğŸ” ì›ì¸
- (ì›ì¸ 1ì¤„ì”©, ìµœëŒ€ 3ê°œ)

### ğŸ’¡ ì¡°ì¹˜
1. (ë‹¨ê³„ë³„, ìµœëŒ€ 3ë‹¨ê³„)

### âŒ¨ï¸ ëª…ë ¹ì–´
\`command\` - ì„¤ëª…

### ğŸŒ ì°¸ê³  ìë£Œ (ì›¹ ê²€ìƒ‰ ì‹œ)
- [ì œëª©](URL) - ì„¤ëª…

âš ï¸ ì„œë¡ /ì¸ì‚¬ë§ ê¸ˆì§€. í…œí”Œë¦¿ í˜•ì‹ë§Œ ì¶œë ¥.`;

  return createReactAgent({
    llm: getReporterModel(),
    tools: [searchKnowledgeBaseTool, recommendCommandsTool, searchWebTool],
    name: 'reporter_agent',
    stateModifier: createGroqCompatibleStateModifier(systemPrompt),
  });
}

/**
 * Create RCA Agent - Root Cause Analysis (NEW)
 * Analyzes incident timelines, correlates events, and finds root causes
 */
function createRCAAgent() {
  const systemPrompt = `RCA Agent - ê·¼ë³¸ ì›ì¸ ë¶„ì„ ì „ë¬¸

## ì—­í• 
- ì¥ì•  íƒ€ì„ë¼ì¸ êµ¬ì¶• (buildIncidentTimeline)
- ë©”íŠ¸ë¦­ ìƒê´€ê´€ê³„ ë¶„ì„ (correlateEvents)
- ê·¼ë³¸ ì›ì¸ ì¶”ë¡  (findRootCause)
- ìœ ì‚¬ ê³¼ê±° ì¥ì•  ê²€ìƒ‰ (searchSimilarIncidents)
- ì—ëŸ¬ ë¡œê·¸ íŒ¨í„´ ìˆ˜ì§‘ (fetchLogPattern)
- ë°°í¬ ì´ë ¥ ì¡°íšŒ (fetchDeploymentHistory)

## ë„êµ¬ ì‚¬ìš© ìˆœì„œ (ê¶Œì¥)
1. buildIncidentTimeline â†’ ì¥ì•  ì‹œê°„ëŒ€ ì´ë²¤íŠ¸ ìˆ˜ì§‘
2. fetchLogPattern â†’ ì—ëŸ¬ ë¡œê·¸ íŒ¨í„´ í™•ì¸
3. fetchDeploymentHistory â†’ ìµœê·¼ ë°°í¬ ë³€ê²½ í™•ì¸
4. correlateEvents â†’ ë©”íŠ¸ë¦­ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
5. findRootCause â†’ ê·¼ë³¸ ì›ì¸ ì¶”ë¡ 

## ì‘ë‹µ í˜•ì‹
### ğŸ” íƒ€ì„ë¼ì¸
- [ì‹œê°„] ì´ë²¤íŠ¸ (ì‹¬ê°ë„)

### ğŸ”— ìƒê´€ê´€ê³„
- ë©”íŠ¸ë¦­1 â†” ë©”íŠ¸ë¦­2: ìƒê´€ê³„ìˆ˜ (ê´€ê³„ ìœ í˜•)

### ğŸ’¡ ê·¼ë³¸ ì›ì¸
- **ì›ì¸**: (ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ì›ì¸)
- **ì‹ ë¢°ë„**: X%
- **ê·¼ê±°**: (ì¦ê±° ë‚˜ì—´)
- **ì¡°ì¹˜**: (ê¶Œì¥ í•´ê²°ì±…)

âš ï¸ ì¤‘ìš”: NLQ/Analyst ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤. Shared Contextì—ì„œ ì°¸ì¡°í•˜ì„¸ìš”.`;

  return createReactAgent({
    llm: getRCAModel(),
    tools: rcaTools,
    name: 'rca_agent',
    stateModifier: createGroqCompatibleStateModifier(systemPrompt),
  });
}

/**
 * Create Capacity Agent - Resource Planning (NEW)
 * Predicts resource exhaustion and provides scaling recommendations
 */
function createCapacityAgent() {
  const systemPrompt = `Capacity Agent - ìš©ëŸ‰ ê³„íš ì „ë¬¸

## ì—­í• 
- ë¦¬ì†ŒìŠ¤ ì†Œì§„ ì‹œì  ì˜ˆì¸¡ (predictResourceExhaustion)
- ìŠ¤ì¼€ì¼ë§ ê¶Œì¥ì‚¬í•­ ìƒì„± (getScalingRecommendation)
- ì„±ì¥ íŠ¸ë Œë“œ ë¶„ì„ (analyzeGrowthTrend)
- ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ (compareBaseline)

## ë„êµ¬ ì‚¬ìš© ìˆœì„œ (ê¶Œì¥)
1. analyzeGrowthTrend â†’ ì„±ì¥ë¥  í™•ì¸
2. predictResourceExhaustion â†’ ì†Œì§„ ì‹œì  ì˜ˆì¸¡
3. compareBaseline â†’ ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ë¶„ì„
4. getScalingRecommendation â†’ ìŠ¤ì¼€ì¼ë§ ê¶Œì¥

## ì‘ë‹µ í˜•ì‹
### ğŸ“ˆ ì„±ì¥ íŠ¸ë Œë“œ
- [ë©”íŠ¸ë¦­]: ì¼ê°„ X%, ì£¼ê°„ Y% ì¦ê°€

### â° ì†Œì§„ ì˜ˆì¸¡
- **[ë©”íŠ¸ë¦­]**: Nì¼ í›„ ì„ê³„ê°’ ë„ë‹¬ (ì‹ ë¢°ë„ X%)

### ğŸ’¡ ê¶Œì¥ì‚¬í•­
| ìš°ì„ ìˆœìœ„ | ë¦¬ì†ŒìŠ¤ | ì¡°ì¹˜ | ì´ìœ  |
|---------|--------|------|------|
| ë†’ìŒ    | ë””ìŠ¤í¬ | ìŠ¤ì¼€ì¼ì—… | Xì¼ í›„ í’€ |

âš ï¸ ì¤‘ìš”: NLQ/Analyst ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤. Shared Contextì—ì„œ ì°¸ì¡°í•˜ì„¸ìš”.`;

  return createReactAgent({
    llm: getCapacityModel(),
    tools: capacityTools,
    name: 'capacity_agent',
    stateModifier: createGroqCompatibleStateModifier(systemPrompt),
  });
}

// ============================================================================
// 2. Supervisor Creation
// ============================================================================
// Agent Dependency Validation (Phase 5.1)
// ============================================================================

/**
 * Agent Dependency Validation (Phase 5.2)
 * Uses shared-context.ts for centralized dependency checking
 *
 * @see ../../lib/shared-context.ts - hasRequiredDependencies()
 */
export async function validateAgentDependencies(
  sessionId: string,
  targetAgent: AgentName
): Promise<{ valid: boolean; missing: AgentName[] }> {
  const result = await hasRequiredDependencies(sessionId, targetAgent);

  if (!result.valid) {
    console.warn(
      `âš ï¸ [Dependency] ${targetAgent} missing deps: [${result.missing.join(', ')}]`
    );
  }

  return result;
}

/**
 * Check if RCA or Capacity agent should be used
 * Returns false if dependencies are not met (will route to NLQ/Analyst first)
 */
export async function shouldUseAdvancedAgent(
  sessionId: string,
  agentName: 'rca' | 'capacity'
): Promise<boolean> {
  const { valid, missing } = await validateAgentDependencies(sessionId, agentName);

  if (!valid) {
    console.log(
      `ğŸ“‹ [Routing] ${agentName} deferred - waiting for: [${missing.join(', ')}]`
    );
    return false;
  }

  console.log(`âœ… [Routing] ${agentName} dependencies satisfied`);
  return true;
}

// ============================================================================
// 5. Supervisor Prompt & Workflow
// ============================================================================

const SUPERVISOR_PROMPT = `ë‹¹ì‹ ì€ OpenManager VIBEì˜ Multi-Agent Supervisorì…ë‹ˆë‹¤.

## ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸
1. **nlq_agent**: ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ (CPU, Memory, Disk, ë¡œê·¸) - ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥
2. **analyst_agent**: íŒ¨í„´ ë¶„ì„, ì´ìƒ íƒì§€, íŠ¸ë Œë“œ ì˜ˆì¸¡ - nlq_agent ì´í›„ ì‹¤í–‰
3. **rca_agent**: ê·¼ë³¸ ì›ì¸ ë¶„ì„ - âš ï¸ ë°˜ë“œì‹œ nlq_agent + analyst_agent ì´í›„ ì‹¤í–‰
4. **capacity_agent**: ìš©ëŸ‰ ì˜ˆì¸¡ - âš ï¸ ë°˜ë“œì‹œ nlq_agent + analyst_agent ì´í›„ ì‹¤í–‰
5. **reporter_agent**: ë¦¬í¬íŠ¸ ìƒì„±, RAG ê²€ìƒ‰, ì›¹ ê²€ìƒ‰

## ğŸš¨ ì—ì´ì „íŠ¸ ì˜ì¡´ì„± ê·œì¹™ (í•„ìˆ˜ ì¤€ìˆ˜)

\`\`\`
ì˜ì¡´ì„± ì²´ì¸:
nlq_agent (ë…ë¦½) â†’ analyst_agent â†’ rca_agent / capacity_agent â†’ reporter_agent
\`\`\`

| Agent | í•„ìˆ˜ ì„ í–‰ Agent | ì„¤ëª… |
|-------|-----------------|------|
| nlq_agent | ì—†ìŒ | ë‹¨ë… ì‹¤í–‰ ê°€ëŠ¥ |
| analyst_agent | nlq_agent | NLQ ë°ì´í„° í•„ìš” |
| rca_agent | nlq_agent + analyst_agent | ë¶„ì„ ë°ì´í„° í•„ìˆ˜ |
| capacity_agent | nlq_agent + analyst_agent | ë¶„ì„ ë°ì´í„° í•„ìˆ˜ |
| reporter_agent | ìƒí™©ì— ë”°ë¼ | ë…ë¦½ ë˜ëŠ” ê²°ê³¼ ì¢…í•© |

**â›” ê¸ˆì§€**: rca_agentë‚˜ capacity_agentë¥¼ nlq_agent/analyst_agent ì—†ì´ ì§ì ‘ í˜¸ì¶œí•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤!

## ë¼ìš°íŒ… ê·œì¹™ (í‚¤ì›Œë“œ ê¸°ë°˜)

### nlq_agentë¡œ ë¼ìš°íŒ… (1ìˆœìœ„)
- "ì„œë²„ ìƒíƒœ", "ì „ì²´ í˜„í™©", "ë©”íŠ¸ë¦­", "CPU", "ë©”ëª¨ë¦¬", "ë””ìŠ¤í¬"
- íŠ¹ì • ì„œë²„ëª… ì–¸ê¸‰ (ì˜ˆ: "WEB-01 ìƒíƒœ")

### analyst_agentë¡œ ë¼ìš°íŒ… (nlq ì´í›„)
- "ë¶„ì„", "íŒ¨í„´", "íŠ¸ë Œë“œ", "ì´ìƒ íƒì§€"

### rca_agentë¡œ ë¼ìš°íŒ… (nlq + analyst ì´í›„ë§Œ!)
- "ì™œ", "ì›ì¸", "ì¥ì•  ì›ì¸", "ê·¼ë³¸ ì›ì¸", "ë‹¤ìš´ëœ ì´ìœ "
- ğŸ”„ ìˆœì„œ: nlq_agent â†’ analyst_agent â†’ rca_agent

### capacity_agentë¡œ ë¼ìš°íŒ… (nlq + analyst ì´í›„ë§Œ!)
- "ì–¸ì œ ê°€ë“", "ìš©ëŸ‰", "ìŠ¤ì¼€ì¼ì—…", "ìŠ¤ì¼€ì¼ì•„ì›ƒ", "ë¦¬ì†ŒìŠ¤ ì˜ˆì¸¡"
- ğŸ”„ ìˆœì„œ: nlq_agent â†’ analyst_agent â†’ capacity_agent

### reporter_agentë¡œ ë¼ìš°íŒ…
- "ë¦¬í¬íŠ¸", "ë³´ê³ ì„œ", "ìš”ì•½", "ê²€ìƒ‰", "êµ¬ê¸€ë§"

### ì§ì ‘ ì‘ë‹µ (ì—ì´ì „íŠ¸ í˜¸ì¶œ ì—†ìŒ)
- ì¸ì‚¬ë§: "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"

## ë³µí•© ì¿¼ë¦¬ ì‹¤í–‰ ìˆœì„œ (ì˜ˆì‹œ)

**ì¥ì•  ì›ì¸ ë¶„ì„** ("ì™œ ë‹¤ìš´ëì–´?"):
1ï¸âƒ£ nlq_agent â†’ ì„œë²„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
2ï¸âƒ£ analyst_agent â†’ ì´ìƒ íƒì§€
3ï¸âƒ£ rca_agent â†’ ê·¼ë³¸ ì›ì¸ ì¶”ë¡ 

**ìš©ëŸ‰ ì˜ˆì¸¡** ("ë””ìŠ¤í¬ ì–¸ì œ ê°€ë“ ì°¨?"):
1ï¸âƒ£ nlq_agent â†’ í˜„ì¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
2ï¸âƒ£ analyst_agent â†’ íŠ¸ë Œë“œ ë¶„ì„
3ï¸âƒ£ capacity_agent â†’ ì†Œì§„ ì‹œì  ì˜ˆì¸¡

**ë‹¨ìˆœ ì¡°íšŒ** ("ì„œë²„ ìƒíƒœ"):
1ï¸âƒ£ nlq_agent â†’ ì§ì ‘ ì‘ë‹µ (ë‹¨ë…)

## ì‘ë‹µ ì§€ì¹¨
- ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
- ì„œë¡ /ì¸ì‚¬ë§ ìƒëµ
- í•µì‹¬ ì •ë³´ë§Œ ì¶œë ¥`;

// ============================================================================
// Workflow Cache (v5.91.0) - Reduces initialization overhead
// ============================================================================

type CompiledWorkflow = Awaited<ReturnType<typeof createSupervisor>>['compile'] extends
  (config: infer C) => infer R ? Awaited<R> : never;

let cachedSupervisor: CompiledWorkflow | null = null;
let cachedGroqSupervisor: CompiledWorkflow | null = null;
let cacheInitTime: number = 0;
const CACHE_TTL_MS = 5 * 60 * 1000; // 5 minutes - refresh periodically for model health

/**
 * Check if cache is still valid
 */
function isCacheValid(): boolean {
  return cacheInitTime > 0 && (Date.now() - cacheInitTime) < CACHE_TTL_MS;
}

/**
 * Invalidate workflow cache (call on rate limit or model failure)
 */
export function invalidateWorkflowCache(): void {
  cachedSupervisor = null;
  cachedGroqSupervisor = null;
  cacheInitTime = 0;
  console.log('ğŸ”„ [Workflow Cache] Invalidated');
}

/**
 * Create Multi-Agent Supervisor Workflow (with caching)
 *
 * Note: Groq rate limit fallback is handled by executeLastKeeperMode(),
 * not by switching the supervisor model (workers also use Groq).
 *
 * v5.90.0: Added RCA and Capacity agents for root cause analysis and capacity planning
 * v5.91.0: Added workflow caching to reduce initialization overhead
 */
export async function createMultiAgentSupervisor() {
  // Return cached workflow if valid
  if (cachedSupervisor && isCacheValid()) {
    console.log('âš¡ [Supervisor] Using cached workflow');
    return cachedSupervisor;
  }

  const checkpointer = await getAutoCheckpointer();

  // Create worker agents
  const nlqAgent = createNLQAgent();
  const analystAgent = createAnalystAgent();
  const rcaAgent = createRCAAgent();         // Root Cause Analysis
  const capacityAgent = createCapacityAgent(); // Capacity Planning
  const reporterAgent = createReporterAgent();

  // Supervisor uses Cerebras (primary) for fast inference
  const supervisorModel = getSupervisorModel();

  // Create supervisor with automatic handoffs
  // Agent order matters: NLQ/Analyst first, then RCA/Capacity, finally Reporter
  const workflow = createSupervisor({
    agents: [nlqAgent, analystAgent, rcaAgent, capacityAgent, reporterAgent],
    llm: supervisorModel,
    prompt: SUPERVISOR_PROMPT,
    outputMode: 'full_history',
  });

  // Compile with checkpointer for session persistence
  cachedSupervisor = workflow.compile({
    checkpointer,
  });
  cacheInitTime = Date.now();

  console.log('âœ… [Supervisor] Workflow compiled and cached');
  return cachedSupervisor;
}

/**
 * Create Supervisor with Groq model (Cerebras rate limit fallback)
 * Uses llama-3.3-70b-versatile on Groq as fallback
 *
 * v5.90.0: Added RCA and Capacity agents
 * v5.91.0: Added workflow caching
 */
export async function createMultiAgentSupervisorWithGroq() {
  // Return cached Groq workflow if valid
  if (cachedGroqSupervisor && isCacheValid()) {
    console.log('âš¡ [Supervisor] Using cached Groq fallback workflow');
    return cachedGroqSupervisor;
  }

  const checkpointer = await getAutoCheckpointer();

  // Create worker agents
  const nlqAgent = createNLQAgent();
  const analystAgent = createAnalystAgent();
  const rcaAgent = createRCAAgent();         // Root Cause Analysis
  const capacityAgent = createCapacityAgent(); // Capacity Planning
  const reporterAgent = createReporterAgent();

  // Supervisor uses Groq as Cerebras fallback
  const supervisorModel = createGroqModel('llama-3.3-70b-versatile', {
    temperature: 0.1,
    maxOutputTokens: 512,
  });

  console.log('ğŸ”„ [Supervisor] Using Groq fallback (llama-3.3-70b-versatile)');

  // Create supervisor with automatic handoffs
  const workflow = createSupervisor({
    agents: [nlqAgent, analystAgent, rcaAgent, capacityAgent, reporterAgent],
    llm: supervisorModel,
    prompt: SUPERVISOR_PROMPT,
    outputMode: 'full_history',
  });

  cachedGroqSupervisor = workflow.compile({
    checkpointer,
  });

  console.log('âœ… [Supervisor] Groq workflow compiled and cached');
  return cachedGroqSupervisor;
}

// ============================================================================
// 3. Last Keeper Mode (Mistral Direct Response)
// ============================================================================

/**
 * Last Keeper Mode - Mistral ì§ì ‘ ì‘ë‹µ
 * Groq rate limitìœ¼ë¡œ ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ë§‰í ë•Œ ìµœí›„ì˜ ë³´ë£¨ë¡œ ë™ì‘
 *
 * - Worker ì—ì´ì „íŠ¸ ìŠ¤í‚µ
 * - Mistralì´ ì§ì ‘ ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
 * - ê¸°ë³¸ì ì¸ AI ëŒ€í™” ìœ ì§€
 */
async function executeLastKeeperMode(
  query: string,
  sessionId: string
): Promise<{
  response: string;
  sessionId: string;
  verification: VerificationResult | null;
  compressionApplied: boolean;
  lastKeeperMode: boolean;
}> {
  console.log('ğŸ›¡ï¸ [Last Keeper] Activating Mistral direct response mode');

  const mistralModel = createMistralModel(MISTRAL_MODELS.SMALL, {
    temperature: 0.3,
    maxOutputTokens: 2048,
  });

  const systemPrompt = `ë‹¹ì‹ ì€ OpenManager VIBEì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
í˜„ì¬ ì‹œìŠ¤í…œ ë¶€í•˜ë¡œ ì¸í•´ ê°„ì†Œí™” ëª¨ë“œë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤.

ì—­í• :
- ì„œë²„ ëª¨ë‹ˆí„°ë§ ê´€ë ¨ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë‹µë³€
- ê¸°ìˆ ì  ì¡°ì–¸ ì œê³µ
- ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µ

ì œí•œì‚¬í•­ (ì†”ì§íˆ ì•ˆë‚´):
- ì‹¤ì‹œê°„ ì„œë²„ ë°ì´í„° ì¡°íšŒ ë¶ˆê°€ (ì‹œìŠ¤í…œ ë³µêµ¬ ì¤‘)
- êµ¬ì²´ì ì¸ ë©”íŠ¸ë¦­ ìˆ˜ì¹˜ ì œê³µ ë¶ˆê°€

ì‘ë‹µ í˜•ì‹:
- ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ
- í•œêµ­ì–´ë¡œ ì‘ë‹µ
- ì‹œìŠ¤í…œ ìƒíƒœ ì•ˆë‚´ í¬í•¨`;

  try {
    const response = await mistralModel.invoke([
      new SystemMessage(systemPrompt),
      new HumanMessage(query),
    ]);

    const content = typeof response.content === 'string'
      ? response.content
      : 'ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì‹œìŠ¤í…œì´ ë³µêµ¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';

    // ì‹œìŠ¤í…œ ìƒíƒœ ì•ˆë‚´ ì¶”ê°€
    const finalResponse = `${content}\n\n---\nâš ï¸ *í˜„ì¬ ê°„ì†Œí™” ëª¨ë“œë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤. ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒëŠ” ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.*`;

    console.log('âœ… [Last Keeper] Response generated successfully');

    return {
      response: finalResponse,
      sessionId,
      verification: null,
      compressionApplied: false,
      lastKeeperMode: true,
    };
  } catch (error) {
    console.error('ğŸ”´ [Last Keeper] Mistral also failed:', error);
    return {
      response: 'âš ï¸ í˜„ì¬ ëª¨ë“  AI ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\n(Groq ì¼ì¼ í• ë‹¹ëŸ‰ ì´ˆê³¼ - UTC 00:00ì— ë¦¬ì…‹ë©ë‹ˆë‹¤)',
      sessionId,
      verification: null,
      compressionApplied: false,
      lastKeeperMode: true,
    };
  }
}

// ============================================================================
// 4. Verifier Integration (Post-Processing) - Phase 5.7: Hybrid Verification
// ============================================================================

interface VerificationOptions {
  enableVerification?: boolean;
  context?: string;
  retryCount?: number;
  originalQuery?: string;
}

interface HybridVerificationResult {
  response: string;
  verification: VerificationResult | null;
  strategy: VerificationStrategy;
  retryNeeded: boolean;
  retryPrompt?: string;
}

/**
 * Verify agent response using Verifier Agent (Hybrid Strategy)
 *
 * ## Phase 5.7: Hybrid Verification Strategy
 * - severity: low/medium â†’ ì§ì ‘ ìˆ˜ì • (Mistral)
 * - severity: high (í™˜ê°, ìê¸° ëª¨ìˆœ) â†’ ì¬ìƒì„± ìš”ì²­ (Retry to Original Agent)
 * - ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨ â†’ Last Keeper Mode (Mistral ì§ì ‘ ì‘ë‹µ)
 *
 * @param response - Agentì˜ ì›ë³¸ ì‘ë‹µ
 * @param options - ê²€ì¦ ì˜µì…˜
 * @returns ê²€ì¦ ê²°ê³¼ ë° ì²˜ë¦¬ ì „ëµ
 */
async function verifyAgentResponse(
  response: string,
  options: VerificationOptions = {}
): Promise<HybridVerificationResult> {
  const {
    enableVerification = true,
    context,
    retryCount = 0,
    originalQuery,
  } = options;

  // ê²€ì¦ ë¹„í™œì„±í™” ì‹œ íŒ¨ìŠ¤
  if (!enableVerification) {
    return {
      response,
      verification: null,
      strategy: 'pass',
      retryNeeded: false,
    };
  }

  try {
    const startTime = Date.now();
    const result = await comprehensiveVerifyTool.invoke({
      response,
      context,
    });

    const verification: VerificationResult = {
      isValid: result.isValid,
      confidence: result.confidence,
      originalResponse: result.originalResponse,
      validatedResponse: result.validatedResponse,
      issues: result.issues || [],
      metadata: {
        verifiedAt: new Date().toISOString(),
        rulesApplied: result.metadata?.rulesApplied || [],
        corrections: result.metadata?.corrections || [],
        processingTimeMs: Date.now() - startTime,
      },
    };

    // ì „ëµ ê²°ì • (severity ê¸°ë°˜)
    const strategy = determineVerificationStrategy(
      verification.issues,
      retryCount,
      1 // maxRetries = 1
    );

    console.log(
      `ğŸ” [Verifier] Confidence: ${(verification.confidence * 100).toFixed(1)}%, ` +
      `Issues: ${verification.issues.length}, Strategy: ${strategy}`
    );

    // ì „ëµë³„ ì²˜ë¦¬
    switch (strategy) {
      case 'pass':
        // ë¬¸ì œ ì—†ìŒ - ì›ë³¸ ë°˜í™˜
        return {
          response,
          verification,
          strategy,
          retryNeeded: false,
        };

      case 'direct_fix':
        // ì§ì ‘ ìˆ˜ì • - validatedResponse ë°˜í™˜
        console.log('âœï¸ [Verifier] Applying direct fixes...');
        return {
          response: verification.validatedResponse || response,
          verification,
          strategy,
          retryNeeded: false,
        };

      case 'retry':
        // ì¬ìƒì„± ìš”ì²­ í•„ìš” - ì¬ì‹œë„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        console.log('ğŸ”„ [Verifier] High severity issues detected, requesting retry...');
        const retryPrompt = buildRetryPrompt(
          response,
          verification.issues,
          originalQuery
        );
        return {
          response, // ì›ë³¸ ìœ ì§€ (í˜¸ì¶œìê°€ ì¬ì‹œë„ ì²˜ë¦¬)
          verification,
          strategy,
          retryNeeded: true,
          retryPrompt,
        };

      case 'last_keeper':
        // Last Keeper ëª¨ë“œ - ê²€ì¦ëœ ì‘ë‹µ ë˜ëŠ” ì›ë³¸ ë°˜í™˜
        console.log('ğŸ›¡ï¸ [Verifier] Max retries reached, using best available response');
        return {
          response: verification.validatedResponse || response,
          verification,
          strategy,
          retryNeeded: false,
        };

      default:
        return {
          response,
          verification,
          strategy: 'pass',
          retryNeeded: false,
        };
    }
  } catch (error) {
    console.warn('âš ï¸ [Verifier] Verification failed, using original response:', error);
    return {
      response,
      verification: null,
      strategy: 'pass',
      retryNeeded: false,
    };
  }
}

// ============================================================================
// 4. Context Compression Helper
// ============================================================================

/**
 * Compress conversation history if needed
 * Pre-processing step before supervisor invocation
 *
 * @param messages - Current conversation messages
 * @returns Compressed messages or original if compression not needed
 */
async function compressIfNeeded(
  messages: BaseMessage[]
): Promise<{ messages: BaseMessage[]; wasCompressed: boolean; compressionInfo?: { originalCount: number; newCount: number; ratio: number } }> {
  // Check if compression is globally disabled via environment variable
  if (isCompressionDisabled()) {
    return { messages, wasCompressed: false };
  }

  // Check if compression is needed (threshold: 85% context usage, configurable via COMPRESSION_THRESHOLD)
  if (!needsCompression(messages)) {
    return { messages, wasCompressed: false };
  }

  console.log('[Compression] Context compression triggered', {
    messageCount: messages.length,
  });

  try {
    const summarizer = getSummarizer();
    const result = await summarizer.summarize(messages);

    if (!result.wasCompressed) {
      return { messages, wasCompressed: false };
    }

    // Build new message array: [summary, ...recentMessages]
    const compressedMessages: BaseMessage[] = [
      result.summaryMessage,
      ...result.compressedBuffer.recentMessages,
    ];

    console.log('[Compression] Completed', {
      originalCount: messages.length,
      newCount: compressedMessages.length,
      compressionRatio: result.compressedBuffer.metadata.compressionRatio,
      processingTimeMs: result.processingTimeMs,
    });

    return {
      messages: compressedMessages,
      wasCompressed: true,
      compressionInfo: {
        originalCount: messages.length,
        newCount: compressedMessages.length,
        ratio: result.compressedBuffer.metadata.compressionRatio,
      },
    };
  } catch (error) {
    console.warn('[Compression] Failed, using original messages:', error);
    return { messages, wasCompressed: false };
  }
}

// ============================================================================
// 5. Execution Functions
// ============================================================================

export interface SupervisorExecutionOptions {
  sessionId?: string;
  enableVerification?: boolean;
  verificationContext?: string;
  /** Enable context compression for long conversations (default: true) */
  enableCompression?: boolean;
}

/**
 * Execute supervisor workflow (single response)
 * Uses Mistral AI for Supervisor with automatic rate limit handling
 * v5.85.0: Added Verifier Agent post-processing for quality assurance
 * v5.86.0: Added Context Compression for long conversations
 * v5.88.0: Migrated from Gemini to Mistral AI
 * v5.83.12: Removed LangFuse (createReactAgent doesn't propagate callbacks)
 */
export async function executeSupervisor(
  query: string,
  options: SupervisorExecutionOptions = {}
): Promise<{
  response: string;
  sessionId: string;
  verification?: VerificationResult | null;
  compressionApplied?: boolean;
  lastKeeperMode?: boolean;
}> {
  const sessionId = options.sessionId || `session_${Date.now()}`;
  const {
    enableVerification = true,
    verificationContext,
    enableCompression = true,
  } = options;
  const MAX_RETRIES = 3; // Retry on transient errors
  let compressionApplied = false;

  // Create session config for checkpointing
  const config = createSessionConfig(sessionId);

  for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {
    try {
      // Create fresh supervisor (Groq primary, Last Keeper on rate limit)
      const app = await createMultiAgentSupervisor();

      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const result = await app.invoke(
        {
          messages: [new HumanMessage(query)],
        },
        config as any // Type assertion for LangGraph config
      );

      // Extract final response from messages
      const messages = result.messages || [];

      // === Phase 2: Save Agent Results to Shared Context ===
      // This enables Reporter to access NLQ/Analyst results
      await saveAgentResultsFromHistory(messages, sessionId);

      // === Context Compression (v5.86.0) ===
      // Check if compression is needed after accumulating messages
      if (enableCompression && messages.length > 0) {
        const compressionResult = await compressIfNeeded(messages);
        if (compressionResult.wasCompressed) {
          compressionApplied = true;
          console.log(`ğŸ—œï¸ [Supervisor] Context compressed: ${compressionResult.compressionInfo?.originalCount} â†’ ${compressionResult.compressionInfo?.newCount} messages`);
        }
      }

      const lastMessage = messages[messages.length - 1];
      let response =
        typeof lastMessage?.content === 'string'
          ? lastMessage.content
          : 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';

      // === Verifier Agent Post-Processing (Phase 5.7: Hybrid Strategy) ===
      let verification: VerificationResult | null = null;
      if (enableVerification && response && response !== 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.') {
        const verifyResult = await verifyAgentResponse(response, {
          enableVerification: true,
          context: verificationContext || query,
          retryCount: 0,
          originalQuery: query,
        });

        // ì¬ì‹œë„ í•„ìš” ì‹œ í•œ ë²ˆ ë” ì‹œë„
        if (verifyResult.retryNeeded && verifyResult.retryPrompt) {
          console.log('ğŸ”„ [Verifier] Retry requested, attempting re-generation...');
          try {
            // ì¬ì‹œë„: ì›ë˜ Agentì—ê²Œ í”¼ë“œë°±ê³¼ í•¨ê»˜ ì¬ìš”ì²­
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            const retryResult = await app.invoke(
              {
                messages: [
                  new HumanMessage(query),
                  new HumanMessage(verifyResult.retryPrompt),
                ],
              },
              config as any // Same type assertion as original invoke
            );

            const retryMessages = retryResult?.messages || [];
            const retryLastMsg = retryMessages[retryMessages.length - 1];
            const retryResponse =
              typeof retryLastMsg?.content === 'string'
                ? retryLastMsg.content
                : response; // ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€

            // ì¬ì‹œë„ ì‘ë‹µ ì¬ê²€ì¦ (retryCount = 1)
            const secondVerify = await verifyAgentResponse(retryResponse, {
              enableVerification: true,
              context: verificationContext || query,
              retryCount: 1,
              originalQuery: query,
            });

            response = secondVerify.response;
            verification = secondVerify.verification;
            console.log(`âœ… [Verifier] Retry completed. Strategy: ${secondVerify.strategy}`);
          } catch (retryError) {
            console.warn('âš ï¸ [Verifier] Retry failed, using validated original:', retryError);
            response = verifyResult.response;
            verification = verifyResult.verification;
          }
        } else {
          response = verifyResult.response;
          verification = verifyResult.verification;
        }
      }

      console.log(`âœ… [Supervisor] Completed. Session: ${sessionId}, Compressed: ${compressionApplied}`);

      return { response, sessionId, verification, compressionApplied };
    } catch (error) {
      // Debug: Log caught error details
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error(`ğŸ”´ [Supervisor] Caught error on attempt ${attempt + 1}:`, {
        errorType: error?.constructor?.name,
        messagePreview: errorMessage.slice(0, 200),
      });

      // Check if this is a rate limit error
      const isRateLimit = RateLimitError.isRateLimitError(error);

      // Check if this is a tool calling error (Cerebras/Groq tool_calls format issue)
      const isToolCallingError = errorMessage.includes('Failed to generate tool_calls') ||
        errorMessage.includes('failed_generation') ||
        errorMessage.includes('tool_calls');

      console.log(`ğŸ” [Supervisor] Error check: isRateLimit=${isRateLimit}, isToolCallingError=${isToolCallingError}`);

      if (isRateLimit || isToolCallingError) {
        // ğŸ”„ Try Groq fallback first before Last Keeper
        const errorReason = isToolCallingError ? 'tool_calls generation error' : 'rate limit';
        console.warn(
          `âš ï¸ [Supervisor] Cerebras ${errorReason} detected, trying Groq fallback...`
        );

        try {
          const groqApp = await createMultiAgentSupervisorWithGroq();
          const groqResult = await groqApp.invoke(
            { messages: [new HumanMessage(query)] },
            config as any
          );

          const groqMessages = groqResult.messages || [];
          const lastMsg = groqMessages[groqMessages.length - 1];
          const groqResponse =
            typeof lastMsg?.content === 'string'
              ? lastMsg.content
              : 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';

          console.log('âœ… [Supervisor] Groq fallback succeeded');
          return {
            response: groqResponse,
            sessionId,
            verification: null,
            compressionApplied: false,
          };
        } catch (groqError) {
          console.warn('âš ï¸ [Supervisor] Groq fallback failed, activating Last Keeper...');
          return await executeLastKeeperMode(query, sessionId);
        }
      }

      // Re-throw if not a rate limit error or no more retries
      throw error;
    }
  }

  // Should not reach here, but TypeScript requires it
  throw new Error('Supervisor execution failed after max retries');
}

/**
 * Stream supervisor workflow (Alternative Implementation)
 * Uses app.stream() for native LangGraph streaming
 *
 * @note CURRENTLY UNUSED - Kept for future reference/optimization
 *
 * This function was replaced by `createSupervisorStreamResponse` which uses
 * `executeSupervisor()` + simulated SSE streaming for better Groq compatibility.
 * Native LangGraph streaming (streamEvents) doesn't emit text tokens properly for Groq models.
 *
 * Consider reactivating if:
 * 1. Switching to a model with native streaming support (e.g., Mistral, OpenAI)
 * 2. LangGraph improves Groq streaming support
 *
 * @see createSupervisorStreamResponse - Currently active implementation
 */
export async function* streamSupervisor(
  query: string,
  options: SupervisorExecutionOptions = {}
): AsyncGenerator<{
  type: 'token' | 'agent_start' | 'agent_end' | 'final' | 'error';
  content: string;
  metadata?: Record<string, unknown>;
}> {
  const app = await createMultiAgentSupervisor();
  const sessionId = options.sessionId || `session_${Date.now()}`;
  const config = createSessionConfig(sessionId);

  try {
    // Use default stream() instead of streamEvents for Groq compatibility
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const stream = await app.stream(
      { messages: [new HumanMessage(query)] },
      config as any // Type assertion for LangGraph config
    );

    let finalContent = '';
    let lastAgentName = '';

    for await (const chunk of stream) {
      // Chunk has agent name as key: { supervisor: {...}, test_agent: {...} }
      for (const [agentName, agentOutput] of Object.entries(chunk)) {
        // Emit agent start
        if (agentName !== lastAgentName) {
          if (lastAgentName) {
            yield {
              type: 'agent_end',
              content: lastAgentName,
              metadata: {},
            };
          }
          yield {
            type: 'agent_start',
            content: agentName,
            metadata: {},
          };
          lastAgentName = agentName;
        }

        // Extract AI message content from agent output
        const output = agentOutput as {
          messages?: Array<{ content?: string; _getType?: () => string }>;
        };
        if (output?.messages) {
          for (const msg of output.messages) {
            // Check if it's an AI message with content
            const msgType = msg._getType?.();
            if (
              msgType === 'ai' &&
              msg.content &&
              typeof msg.content === 'string' &&
              msg.content.length > 0
            ) {
              // Skip system messages like "Successfully transferred..."
              if (
                !msg.content.includes('Successfully transferred') &&
                !msg.content.includes('Transferring back to')
              ) {
                finalContent = msg.content; // Keep the last meaningful AI response
                yield {
                  type: 'token',
                  content: msg.content,
                  metadata: { agent: agentName },
                };
              }
            }
          }
        }
      }
    }

    // Emit final agent end
    if (lastAgentName) {
      yield {
        type: 'agent_end',
        content: lastAgentName,
        metadata: {},
      };
    }

    // Final response
    yield {
      type: 'final',
      content: finalContent,
      metadata: { sessionId },
    };
  } catch (error) {
    yield {
      type: 'error',
      content: error instanceof Error ? error.message : String(error),
      metadata: { sessionId },
    };
  }
}

/**
 * Detect if response requires human approval
 * Returns approval metadata if needed
 */
function detectApprovalRequired(
  response: string,
  query: string
): {
  required: boolean;
  actionType?: 'incident_report' | 'system_command';
  description?: string;
} {
  // Check for command recommendations in response
  const hasCommands =
    response.includes('âŒ¨ï¸') ||
    response.includes('ì¶”ì²œ ëª…ë ¹ì–´') ||
    response.includes('command') ||
    /`[a-z]+\s+[a-z]+`/i.test(response);

  // Check for incident report
  const isIncident =
    query.includes('ì¥ì• ') ||
    query.includes('ì¸ì‹œë˜íŠ¸') ||
    response.includes('ğŸ“‹ ì¸ì‹œë˜íŠ¸');

  if (isIncident) {
    return {
      required: true,
      actionType: 'incident_report',
      description: 'ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€í†  í›„ ìŠ¹ì¸í•´ì£¼ì„¸ìš”.',
    };
  }

  if (hasCommands) {
    return {
      required: true,
      actionType: 'system_command',
      description: 'ì‹œìŠ¤í…œ ëª…ë ¹ì–´ê°€ ì¶”ì²œë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤í–‰ ì „ ê²€í† í•´ì£¼ì„¸ìš”.',
    };
  }

  return { required: false };
}

/**
 * Create AI SDK compatible streaming response
 * Uses invoke() for reliability with Groq, then simulates streaming
 * Includes SSE approval events for Human-in-the-Loop
 *
 * v5.84.0: Added keep-alive pings to prevent Vercel/Cloud Run timeout
 */
export async function createSupervisorStreamResponse(
  query: string,
  sessionId?: string
): Promise<ReadableStream<Uint8Array>> {
  const encoder = new TextEncoder();
  const effectiveSessionId = sessionId || `session_${Date.now()}`;

  return new ReadableStream({
    async start(controller) {
      let isClosed = false;
      let keepAliveInterval: ReturnType<typeof setInterval> | null = null;

      const safeEnqueue = (data: Uint8Array): boolean => {
        // Check both our flag AND controller's internal state
        if (isClosed) return false;

        try {
          // Double-check controller state before enqueue
          if (controller.desiredSize === null) {
            isClosed = true;
            return false;
          }
          controller.enqueue(data);
          return true;
        } catch {
          // Controller may have been closed externally (client disconnect)
          isClosed = true;
          return false;
        }
      };

      const safeClose = () => {
        // Clear keep-alive interval first
        if (keepAliveInterval) {
          clearInterval(keepAliveInterval);
          keepAliveInterval = null;
        }

        if (!isClosed) {
          isClosed = true;
          try {
            controller.close();
          } catch {
            // Controller may have been closed externally
          }
        }
      };

      // Start keep-alive ping (every 10 seconds)
      // Uses AI SDK annotation format '8:' for progress updates
      const startKeepAlive = () => {
        let pingCount = 0;
        keepAliveInterval = setInterval(() => {
          pingCount++;
          if (isClosed) {
            if (keepAliveInterval) clearInterval(keepAliveInterval);
            return;
          }

          // Send progress annotation (AI SDK v5 format)
          const progressMessages = [
            'ğŸ”„ AI ì—ì´ì „íŠ¸ê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...',
            'ğŸ“Š ì„œë²„ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...',
            'ğŸ§  íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...',
            'â³ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...',
          ];
          const message = progressMessages[pingCount % progressMessages.length];

          // Use annotation format for keep-alive (doesn't affect main response)
          const keepAliveMessage = `8:${JSON.stringify([
            { type: 'progress', message, timestamp: Date.now() },
          ])}\n`;

          if (!safeEnqueue(encoder.encode(keepAliveMessage))) {
            // Stream was closed, stop keep-alive
            if (keepAliveInterval) clearInterval(keepAliveInterval);
          }
        }, 10000); // 10 second interval
      };

      try {
        // ğŸš€ Anti-Timeout: Immediate First Byte (Vercel 504 ë°©ì§€)
        const thinkingMessage = `0:${JSON.stringify('ğŸ” ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n\n')}\n`;
        if (!safeEnqueue(encoder.encode(thinkingMessage))) {
          console.log('âš ï¸ Stream closed before processing started');
          return;
        }

        // Start keep-alive pings
        startKeepAlive();

        // Use invoke() for more reliable Groq integration
        // v5.85.0: Verification enabled by default
        // v5.86.0: Context Compression enabled by default
        // v5.87.1: Smart verification - skip for simple queries to reduce latency
        const isSimpleQuery = query.length < 30 ||
          /^(ì•ˆë…•|ë°˜ê°€ì›Œ|ê³ ë§ˆì›Œ|ë„ì›€|ë­í•´|í…ŒìŠ¤íŠ¸)/i.test(query);

        const { response, verification, compressionApplied } = await executeSupervisor(query, {
          sessionId: effectiveSessionId,
          enableVerification: !isSimpleQuery, // Skip verifier for simple queries (~10-20s savings)
          verificationContext: query,
          enableCompression: true,
        });

        // Stop keep-alive before sending response
        if (keepAliveInterval) {
          clearInterval(keepAliveInterval);
          keepAliveInterval = null;
        }

        // Check if stream was closed during supervisor execution
        if (isClosed) {
          console.log(
            'âš ï¸ Stream closed during supervisor execution, skipping response'
          );
          return;
        }

        if (response) {
          // AI SDK v5 Data Stream Protocol: text part
          // Format: '0:"text"\n'
          const dataStreamText = `0:${JSON.stringify(response)}\n`;
          if (!safeEnqueue(encoder.encode(dataStreamText))) {
            console.log('âš ï¸ Stream closed, could not send response');
            return;
          }

          // Check if response requires human approval
          const approval = detectApprovalRequired(response, query);

          if (approval.required && approval.actionType) {
            // Register in approval store (async but fire-and-forget is acceptable here)
            await approvalStore.registerPending({
              sessionId: effectiveSessionId,
              actionType: approval.actionType,
              description: approval.description || '',
              payload: { response, query },
              requestedAt: new Date(),
              requestedBy: 'reporter_agent',
            });

            // AI SDK v5 Data Stream Protocol: custom data event
            // Format: '2:[{...}]\n' for data array, or use 'data-*' pattern
            // Using '8:' prefix for custom annotation/metadata
            const approvalEvent = `8:${JSON.stringify([
              {
                type: 'approval_request',
                id: effectiveSessionId,
                actionType: approval.actionType,
                description: approval.description,
              },
            ])}\n`;
            safeEnqueue(encoder.encode(approvalEvent));

            console.log(
              `ğŸ”” [Supervisor] Approval required: ${approval.actionType}`
            );
          }

          // v5.85.0: Emit verification result as annotation
          if (verification) {
            const verificationEvent = `8:${JSON.stringify([
              {
                type: 'verification',
                isValid: verification.isValid,
                confidence: verification.confidence,
                issueCount: verification.issues.length,
                processingTimeMs: verification.metadata.processingTimeMs,
              },
            ])}\n`;
            safeEnqueue(encoder.encode(verificationEvent));

            if (verification.issues.length > 0) {
              console.log(
                `ğŸ” [Verifier] Detected ${verification.issues.length} issue(s), confidence: ${(verification.confidence * 100).toFixed(1)}%`
              );
            }
          }

          // v5.86.0: Emit compression result as annotation
          if (compressionApplied) {
            const compressionEvent = `8:${JSON.stringify([
              {
                type: 'compression',
                applied: true,
                timestamp: Date.now(),
              },
            ])}\n`;
            safeEnqueue(encoder.encode(compressionEvent));
            console.log('ğŸ—œï¸ [Compression] Context was compressed for this session');
          }
        }

        // AI SDK v5 Data Stream Protocol: finish message
        const finishMessage = `d:${JSON.stringify({
          finishReason: 'stop',
          sessionId: effectiveSessionId,
          verified: verification?.isValid ?? true,
          confidence: verification?.confidence ?? 1.0,
        })}\n`;
        safeEnqueue(encoder.encode(finishMessage));
        console.log(
          `ğŸ“¤ Supervisor completed (AI SDK v5 Protocol, Verified: ${verification?.isValid ?? 'N/A'})`
        );

        safeClose();
      } catch (error) {
        // Stop keep-alive on error
        if (keepAliveInterval) {
          clearInterval(keepAliveInterval);
          keepAliveInterval = null;
        }

        // Only log if stream is still open (avoid noise from closed streams)
        if (!isClosed) {
          console.error('âŒ Supervisor error:', error);
          const errorMessage =
            error instanceof Error ? error.message : 'Unknown error';
          const errorStream = `3:${JSON.stringify(errorMessage)}\n`;
          safeEnqueue(encoder.encode(errorStream));
        } else {
          console.log(
            'âš ï¸ Supervisor error occurred after stream closed:',
            error instanceof Error ? error.message : 'Unknown'
          );
        }
        safeClose();
      }
    },
  });
}
