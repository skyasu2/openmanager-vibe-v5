/**
 * Multi-Agent Supervisor using @langchain/langgraph-supervisor
 * Cloud Run Standalone Implementation
 */

import { HumanMessage } from '@langchain/core/messages';
import { createReactAgent } from '@langchain/langgraph/prebuilt';
import { createSupervisor } from '@langchain/langgraph-supervisor';
import {
  analyzePatternTool,
  detectAnomaliesTool,
  predictTrendsTool,
} from '../../agents/analyst-agent';
// Import tools from Agents
import { getServerMetricsTool, getServerLogsTool } from '../../agents/nlq-agent';
import {
  recommendCommandsTool,
  searchKnowledgeBaseTool,
} from '../../agents/reporter-agent';

import {
  createSessionConfig,
  getAutoCheckpointer,
} from '../../lib/checkpointer';
import { RateLimitError } from '../../lib/errors';
import { approvalStore } from '../approval/approval-store';
import {
  getAnalystModel,
  getGeminiKeyStatus,
  getNLQModel,
  getReporterModel,
  getSupervisorModel,
  markGeminiKeyExhausted,
} from '../../lib/model-config';

// ============================================================================
// 1. Worker Agent Creation
// ============================================================================

/**
 * Create NLQ Agent - Server metrics queries
 */
function createNLQAgent() {
  return createReactAgent({
    llm: getNLQModel(),
    tools: [getServerMetricsTool, getServerLogsTool],
    name: 'nlq_agent',
    stateModifier: `ë‹¹ì‹ ì€ OpenManager VIBEì˜ NLQ Agentì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ ë˜ëŠ” ë¡œê·¸ ë¶„ì„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ê°€ëŠ¥í•œ ì‘ì—…:
- ì„œë²„ ìƒíƒœ ì¡°íšŒ (CPU, Memory, Disk)
- ì„œë²„ ë¡œê·¸ ë° ì—ëŸ¬ ì´ë ¥ ì¡°íšŒ (DB ê²€ìƒ‰)
- ì „ì²´ ì„œë²„ ìš”ì•½

ì§ˆë¬¸ì´ "ë¡œê·¸ ë³´ì—¬ì¤˜" ë˜ëŠ” "ì—ëŸ¬ í™•ì¸í•´ì¤˜"ì™€ ê´€ë ¨ë˜ë©´ 'getServerLogs' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
ìƒíƒœë‚˜ ë©”íŠ¸ë¦­ ê´€ë ¨ì´ë©´ 'getServerMetrics' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
ì¡°íšŒ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.`,
  });
}

/**
 * Create Analyst Agent - Pattern analysis & anomaly detection
 */
function createAnalystAgent() {
  return createReactAgent({
    llm: getAnalystModel(),
    tools: [detectAnomaliesTool, predictTrendsTool, analyzePatternTool],
    name: 'analyst_agent',
    stateModifier: `ë‹¹ì‹ ì€ OpenManager VIBEì˜ Analyst Agentì…ë‹ˆë‹¤.
ì„œë²„ ì‹œìŠ¤í…œ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ê°€ëŠ¥í•œ ì‘ì—…:
- ì´ìƒ íƒì§€ (detectAnomalies): í†µê³„ì  ì´ìƒì¹˜ ê°ì§€
- íŠ¸ë Œë“œ ì˜ˆì¸¡ (predictTrends): ì„ í˜• íšŒê·€ ê¸°ë°˜ ì˜ˆì¸¡
- íŒ¨í„´ ë¶„ì„ (analyzePattern): ì§ˆë¬¸ ì˜ë„ íŒŒì•…

ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ:
1. í˜„ì¬ ìƒíƒœ ìš”ì•½
2. ë°œê²¬ëœ íŒ¨í„´/ì´ìƒì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…
3. ì ì¬ì  ë¬¸ì œì  ë˜ëŠ” ì£¼ì˜ì‚¬í•­
4. ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­

í•œêµ­ì–´ë¡œ ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.`,
  });
}

/**
 * Create Reporter Agent - Incident reports & RAG
 */
function createReporterAgent() {
  return createReactAgent({
    llm: getReporterModel(),
    tools: [searchKnowledgeBaseTool, recommendCommandsTool],
    name: 'reporter_agent',
    stateModifier: `ë‹¹ì‹ ì€ OpenManager VIBEì˜ Reporter Agentì…ë‹ˆë‹¤.
ì¥ì•  ë¶„ì„ ë° ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ê°€ëŠ¥í•œ ì‘ì—…:
- ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ (searchKnowledgeBase): RAG ê¸°ë°˜ ê³¼ê±° ì¥ì•  ì´ë ¥ ê²€ìƒ‰
- ëª…ë ¹ì–´ ì¶”ì²œ (recommendCommands): CLI ëª…ë ¹ì–´ ì¶”ì²œ

ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸ í˜•ì‹:
### ğŸ“‹ ì¸ì‹œë˜íŠ¸ ìš”ì•½
[ë¬¸ì œ ìƒí™© ìš”ì•½]

### ğŸ” ì›ì¸ ë¶„ì„
[ê°€ëŠ¥í•œ ì›ì¸ë“¤]

### ğŸ’¡ ê¶Œì¥ ì¡°ì¹˜
[ë‹¨ê³„ë³„ í•´ê²° ë°©ì•ˆ]

### âŒ¨ï¸ ì¶”ì²œ ëª…ë ¹ì–´
[ì‹¤í–‰ ê°€ëŠ¥í•œ ëª…ë ¹ì–´ë“¤]

í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.`,
  });
}

// ============================================================================
// 2. Supervisor Creation
// ============================================================================

const SUPERVISOR_PROMPT = `ë‹¹ì‹ ì€ OpenManager VIBEì˜ Multi-Agent Supervisorì…ë‹ˆë‹¤.
ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—…ì„ ìœ„ì„í•©ë‹ˆë‹¤.

## ì—ì´ì „íŠ¸ ëª©ë¡
1. **nlq_agent**: ì„œë²„ ìƒíƒœ/ë©”íŠ¸ë¦­ ì¡°íšŒ (CPU, Memory, Disk)
   - ì˜ˆ: "ì„œë²„ ìƒíƒœ", "CPU ì‚¬ìš©ë¥ ", "ë©”ëª¨ë¦¬ í™•ì¸"

2. **analyst_agent**: íŒ¨í„´ ë¶„ì„, ì´ìƒ íƒì§€, íŠ¸ë Œë“œ ì˜ˆì¸¡
   - ì˜ˆ: "ì´ìƒ ê°ì§€", "íŠ¸ë Œë“œ ë¶„ì„", "íŒ¨í„´ í™•ì¸", "ì¢…í•© ë¶„ì„"

3. **reporter_agent**: ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸, ì¥ì•  ë¶„ì„, RAG ê²€ìƒ‰
   - ì˜ˆ: "ì¥ì•  ë¶„ì„", "ì›ì¸ íŒŒì•…", "í•´ê²° ë°©ë²•", "ê³¼ê±° ì´ë ¥"

## ë¼ìš°íŒ… ê·œì¹™
- ë‹¨ìˆœ ì¡°íšŒ â†’ nlq_agent
- ë¶„ì„/ì˜ˆì¸¡ â†’ analyst_agent
- ì¥ì• /ë¦¬í¬íŠ¸ â†’ reporter_agent
- ì¸ì‚¬ë§/ì¼ë°˜ ëŒ€í™” â†’ ì§ì ‘ ì‘ë‹µ

ì ì ˆí•œ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ì—¬ ì‘ì—…ì„ ìœ„ì„í•˜ì„¸ìš”.`;

/**
 * Create Multi-Agent Supervisor Workflow
 */
export async function createMultiAgentSupervisor() {
  const checkpointer = await getAutoCheckpointer();

  // Create worker agents
  const nlqAgent = createNLQAgent();
  const analystAgent = createAnalystAgent();
  const reporterAgent = createReporterAgent();

  // Create supervisor with automatic handoffs
  const workflow = createSupervisor({
    agents: [nlqAgent, analystAgent, reporterAgent],
    llm: getSupervisorModel(),
    prompt: SUPERVISOR_PROMPT,
    outputMode: 'full_history',
  });

  // Compile with checkpointer for session persistence
  return workflow.compile({
    checkpointer,
  });
}

// ============================================================================
// 3. Execution Functions
// ============================================================================

export interface SupervisorExecutionOptions {
  sessionId?: string;
}

/**
 * Execute supervisor workflow (single response)
 * Includes automatic Gemini API key failover on rate limit
 */
export async function executeSupervisor(
  query: string,
  options: SupervisorExecutionOptions = {}
): Promise<{
  response: string;
  sessionId: string;
}> {
  const sessionId = options.sessionId || `session_${Date.now()}`;
  const config = createSessionConfig(sessionId);
  const MAX_RETRIES = 2; // Primary key + secondary key

  for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {
    try {
      // Create fresh supervisor (uses current active Gemini key)
      const app = await createMultiAgentSupervisor();

      const result = await app.invoke(
        {
          messages: [new HumanMessage(query)],
        },
        config
      );

      // Extract final response from messages
      const messages = result.messages || [];
      const lastMessage = messages[messages.length - 1];
      const response =
        typeof lastMessage?.content === 'string'
          ? lastMessage.content
          : 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';

      console.log(`âœ… [Supervisor] Completed. Session: ${sessionId}`);
      return { response, sessionId };
    } catch (error) {
      // Check if this is a rate limit error
      if (RateLimitError.isRateLimitError(error)) {
        const keyStatus = getGeminiKeyStatus();
        console.error(
          `âš ï¸ [Supervisor] Rate limit hit on attempt ${attempt + 1}/${MAX_RETRIES}`,
          { keyStatus }
        );

        // If we have more keys to try, mark current key as exhausted and retry
        if (attempt < MAX_RETRIES - 1 && keyStatus.totalKeys > 1) {
          markGeminiKeyExhausted();
          console.log('ğŸ”„ [Supervisor] Switching to secondary Gemini key...');
          continue; // Retry with secondary key
        }
      }

      // Re-throw if not a rate limit error or no more retries
      throw error;
    }
  }

  // Should not reach here, but TypeScript requires it
  throw new Error('All Gemini API keys exhausted');
}

/**
 * Stream supervisor workflow (Alternative Implementation)
 * Uses app.stream() for native LangGraph streaming
 *
 * @note CURRENTLY UNUSED - Kept for future reference/optimization
 *
 * This function was replaced by `createSupervisorStreamResponse` which uses
 * `executeSupervisor()` + simulated SSE streaming for better Groq compatibility.
 * Native LangGraph streaming (streamEvents) doesn't emit text tokens properly for Groq models.
 *
 * Consider reactivating if:
 * 1. Switching to a model with native streaming support (e.g., Gemini, OpenAI)
 * 2. LangGraph improves Groq streaming support
 *
 * @see createSupervisorStreamResponse - Currently active implementation
 */
export async function* streamSupervisor(
  query: string,
  options: SupervisorExecutionOptions = {}
): AsyncGenerator<{
  type: 'token' | 'agent_start' | 'agent_end' | 'final' | 'error';
  content: string;
  metadata?: Record<string, unknown>;
}> {
  const app = await createMultiAgentSupervisor();
  const sessionId = options.sessionId || `session_${Date.now()}`;
  const config = createSessionConfig(sessionId);

  try {
    // Use default stream() instead of streamEvents for Groq compatibility
    const stream = await app.stream(
      { messages: [new HumanMessage(query)] },
      config
    );

    let finalContent = '';
    let lastAgentName = '';

    for await (const chunk of stream) {
      // Chunk has agent name as key: { supervisor: {...}, test_agent: {...} }
      for (const [agentName, agentOutput] of Object.entries(chunk)) {
        // Emit agent start
        if (agentName !== lastAgentName) {
          if (lastAgentName) {
            yield {
              type: 'agent_end',
              content: lastAgentName,
              metadata: {},
            };
          }
          yield {
            type: 'agent_start',
            content: agentName,
            metadata: {},
          };
          lastAgentName = agentName;
        }

        // Extract AI message content from agent output
        const output = agentOutput as {
          messages?: Array<{ content?: string; _getType?: () => string }>;
        };
        if (output?.messages) {
          for (const msg of output.messages) {
            // Check if it's an AI message with content
            const msgType = msg._getType?.();
            if (
              msgType === 'ai' &&
              msg.content &&
              typeof msg.content === 'string' &&
              msg.content.length > 0
            ) {
              // Skip system messages like "Successfully transferred..."
              if (
                !msg.content.includes('Successfully transferred') &&
                !msg.content.includes('Transferring back to')
              ) {
                finalContent = msg.content; // Keep the last meaningful AI response
                yield {
                  type: 'token',
                  content: msg.content,
                  metadata: { agent: agentName },
                };
              }
            }
          }
        }
      }
    }

    // Emit final agent end
    if (lastAgentName) {
      yield {
        type: 'agent_end',
        content: lastAgentName,
        metadata: {},
      };
    }

    // Final response
    yield {
      type: 'final',
      content: finalContent,
      metadata: { sessionId },
    };
  } catch (error) {
    yield {
      type: 'error',
      content: error instanceof Error ? error.message : String(error),
      metadata: { sessionId },
    };
  }
}

/**
 * Detect if response requires human approval
 * Returns approval metadata if needed
 */
function detectApprovalRequired(
  response: string,
  query: string
): {
  required: boolean;
  actionType?: 'incident_report' | 'system_command';
  description?: string;
} {
  // Check for command recommendations in response
  const hasCommands =
    response.includes('âŒ¨ï¸') ||
    response.includes('ì¶”ì²œ ëª…ë ¹ì–´') ||
    response.includes('command') ||
    /`[a-z]+\s+[a-z]+`/i.test(response);

  // Check for incident report
  const isIncident =
    query.includes('ì¥ì• ') ||
    query.includes('ì¸ì‹œë˜íŠ¸') ||
    response.includes('ğŸ“‹ ì¸ì‹œë˜íŠ¸');

  if (isIncident) {
    return {
      required: true,
      actionType: 'incident_report',
      description: 'ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€í†  í›„ ìŠ¹ì¸í•´ì£¼ì„¸ìš”.',
    };
  }

  if (hasCommands) {
    return {
      required: true,
      actionType: 'system_command',
      description: 'ì‹œìŠ¤í…œ ëª…ë ¹ì–´ê°€ ì¶”ì²œë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤í–‰ ì „ ê²€í† í•´ì£¼ì„¸ìš”.',
    };
  }

  return { required: false };
}

/**
 * Create AI SDK compatible streaming response
 * Uses invoke() for reliability with Groq, then simulates streaming
 * Includes SSE approval events for Human-in-the-Loop
 */
export async function createSupervisorStreamResponse(
  query: string,
  sessionId?: string
): Promise<ReadableStream<Uint8Array>> {
  const encoder = new TextEncoder();
  const effectiveSessionId = sessionId || `session_${Date.now()}`;

  return new ReadableStream({
    async start(controller) {
      let isClosed = false;

      const safeEnqueue = (data: Uint8Array) => {
        if (!isClosed) {
          controller.enqueue(data);
        }
      };

      const safeClose = () => {
        if (!isClosed) {
          isClosed = true;
          controller.close();
        }
      };

      try {
        // Use invoke() for more reliable Groq integration
        const { response } = await executeSupervisor(query, {
          sessionId: effectiveSessionId,
        });

        if (response) {
          // AI SDK v5 Data Stream Protocol: text part
          // Format: '0:"text"\n'
          const dataStreamText = `0:${JSON.stringify(response)}\n`;
          safeEnqueue(encoder.encode(dataStreamText));

          // Check if response requires human approval
          const approval = detectApprovalRequired(response, query);

          if (approval.required && approval.actionType) {
            // Register in approval store
            approvalStore.registerPending({
              sessionId: effectiveSessionId,
              actionType: approval.actionType,
              description: approval.description || '',
              payload: { response, query },
              requestedAt: new Date(),
              requestedBy: 'reporter_agent',
            });

            // AI SDK v5 Data Stream Protocol: custom data event
            // Format: '2:[{...}]\n' for data array, or use 'data-*' pattern
            // Using '8:' prefix for custom annotation/metadata
            const approvalEvent = `8:${JSON.stringify([
              {
                type: 'approval_request',
                id: effectiveSessionId,
                actionType: approval.actionType,
                description: approval.description,
              },
            ])}\n`;
            safeEnqueue(encoder.encode(approvalEvent));

            console.log(
              `ğŸ”” [Supervisor] Approval required: ${approval.actionType}`
            );
          }
        }

        // AI SDK v5 Data Stream Protocol: finish message
        const finishMessage = `d:${JSON.stringify({
          finishReason: 'stop',
          sessionId: effectiveSessionId,
        })}\n`;
        safeEnqueue(encoder.encode(finishMessage));
        console.log('ğŸ“¤ Supervisor completed (AI SDK v5 Protocol)');

        safeClose();
      } catch (error) {
        console.error('âŒ Supervisor error:', error);
        const errorMessage =
          error instanceof Error ? error.message : 'Unknown error';
        const errorStream = `3:${JSON.stringify(errorMessage)}\n`;
        safeEnqueue(encoder.encode(errorStream));
        safeClose();
      }
    },
  });
}
