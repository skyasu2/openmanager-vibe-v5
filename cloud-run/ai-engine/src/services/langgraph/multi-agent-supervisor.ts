/**
 * Multi-Agent Supervisor using @langchain/langgraph-supervisor
 * Cloud Run Standalone Implementation
 */

import { HumanMessage } from '@langchain/core/messages';
import { createReactAgent } from '@langchain/langgraph/prebuilt';
import { createSupervisor } from '@langchain/langgraph-supervisor';
import {
  analyzePatternTool,
  detectAnomaliesTool,
  predictTrendsTool,
} from '../../agents/analyst-agent';
// Import tools from Agents
import { getServerMetricsTool, getServerLogsTool } from '../../agents/nlq-agent';
import {
  recommendCommandsTool,
  searchKnowledgeBaseTool,
} from '../../agents/reporter-agent';

import {
  createSessionConfig,
  getAutoCheckpointer,
} from '../../lib/checkpointer';
import { RateLimitError } from '../../lib/errors';
import { approvalStore } from '../approval/approval-store';
import {
  getAnalystModel,
  getGeminiKeyStatus,
  getNLQModel,
  getReporterModel,
  getSupervisorModel,
  markGeminiKeyExhausted,
} from '../../lib/model-config';

// ============================================================================
// 1. Worker Agent Creation
// ============================================================================

/**
 * Create NLQ Agent - Server metrics queries
 */
function createNLQAgent() {
  return createReactAgent({
    llm: getNLQModel(),
    tools: [getServerMetricsTool, getServerLogsTool],
    name: 'nlq_agent',
    stateModifier: `NLQ Agent - ì„œë²„ ë©”íŠ¸ë¦­/ë¡œê·¸ ì¡°íšŒ ì „ë¬¸

## ë„êµ¬ ì„ íƒ
- ë¡œê·¸/ì—ëŸ¬ â†’ getServerLogs
- ìƒíƒœ/ë©”íŠ¸ë¦­ â†’ getServerMetrics

## ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜)
â€¢ [ì„œë²„ëª…] CPU: X% | Memory: X% | Disk: X%
â€¢ ìƒíƒœ: ì •ìƒ/ì£¼ì˜/ìœ„í—˜
â€¢ íŠ¹ì´ì‚¬í•­: (ìˆìœ¼ë©´ 1ì¤„)

âš ï¸ ìˆ«ì ë‚˜ì—´ ê¸ˆì§€. 3ì¤„ ì´ë‚´ ìš”ì•½ë§Œ.`,
  });
}

/**
 * Create Analyst Agent - Pattern analysis & anomaly detection
 */
function createAnalystAgent() {
  return createReactAgent({
    llm: getAnalystModel(),
    tools: [detectAnomaliesTool, predictTrendsTool, analyzePatternTool],
    name: 'analyst_agent',
    stateModifier: `Analyst Agent - íŒ¨í„´ ë¶„ì„/ì´ìƒ íƒì§€ ì „ë¬¸

## ë„êµ¬
- detectAnomalies: ì´ìƒì¹˜ ê°ì§€
- predictTrends: íŠ¸ë Œë“œ ì˜ˆì¸¡
- analyzePattern: íŒ¨í„´ ë¶„ì„

## ì‘ë‹µ í˜•ì‹ (í•„ìˆ˜)
**í˜„í™©**: (1ì¤„ ìš”ì•½)
**íŒ¨í„´**: (ë°œê²¬ëœ íŒ¨í„´ í•´ì„)
**ì¡°ì¹˜**: (í•„ìš”ì‹œ ê¶Œì¥ì‚¬í•­)

âš ï¸ í†µê³„ ìˆ˜ì¹˜ë§Œ ë‚˜ì—´ ê¸ˆì§€. ì˜ë¯¸ í•´ì„ ì¤‘ì‹¬ìœ¼ë¡œ 3ì„¹ì…˜ ì´ë‚´.`,
  });
}

/**
 * Create Reporter Agent - Incident reports & RAG
 */
function createReporterAgent() {
  return createReactAgent({
    llm: getReporterModel(),
    tools: [searchKnowledgeBaseTool, recommendCommandsTool],
    name: 'reporter_agent',
    stateModifier: `Reporter Agent - ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸ ì „ë¬¸

## ë„êµ¬
- searchKnowledgeBase: RAG ê²€ìƒ‰
- recommendCommands: CLI ëª…ë ¹ì–´

## ì‘ë‹µ í˜•ì‹ (ì—„ê²© ì¤€ìˆ˜)
### ğŸ“‹ ìš”ì•½
(1-2ì¤„ í•µì‹¬ë§Œ)

### ğŸ” ì›ì¸
- (ì›ì¸ 1ì¤„ì”©, ìµœëŒ€ 3ê°œ)

### ğŸ’¡ ì¡°ì¹˜
1. (ë‹¨ê³„ë³„, ìµœëŒ€ 3ë‹¨ê³„)

### âŒ¨ï¸ ëª…ë ¹ì–´
\`command\` - ì„¤ëª…

âš ï¸ ì„œë¡ /ì¸ì‚¬ë§ ê¸ˆì§€. í…œí”Œë¦¿ í˜•ì‹ë§Œ ì¶œë ¥.`,
  });
}

// ============================================================================
// 2. Supervisor Creation
// ============================================================================

const SUPERVISOR_PROMPT = `ë‹¹ì‹ ì€ OpenManager VIBEì˜ Multi-Agent Supervisorì…ë‹ˆë‹¤.

## ì—ì´ì „íŠ¸ ë¼ìš°íŒ…
- **nlq_agent**: ì„œë²„ ìƒíƒœ/ë©”íŠ¸ë¦­ ì¡°íšŒ (CPU, Memory, Disk)
- **analyst_agent**: íŒ¨í„´ ë¶„ì„, ì´ìƒ íƒì§€, íŠ¸ë Œë“œ ì˜ˆì¸¡
- **reporter_agent**: ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸, ì¥ì•  ë¶„ì„, RAG ê²€ìƒ‰

## ë¼ìš°íŒ… ê·œì¹™
- ë‹¨ìˆœ ì¡°íšŒ â†’ nlq_agent
- ë¶„ì„/ì˜ˆì¸¡ â†’ analyst_agent
- ì¥ì• /ë¦¬í¬íŠ¸ â†’ reporter_agent
- ì¸ì‚¬ë§ â†’ ì§ì ‘ ì‘ë‹µ (1ë¬¸ì¥)

## ì‘ë‹µ ì§€ì¹¨
- ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬ (ì¬ê°€ê³µ ê¸ˆì§€)
- ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§/ì„œë¡  ê¸ˆì§€
- í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ`;

/**
 * Create Multi-Agent Supervisor Workflow
 */
export async function createMultiAgentSupervisor() {
  const checkpointer = await getAutoCheckpointer();

  // Create worker agents
  const nlqAgent = createNLQAgent();
  const analystAgent = createAnalystAgent();
  const reporterAgent = createReporterAgent();

  // Create supervisor with automatic handoffs
  const workflow = createSupervisor({
    agents: [nlqAgent, analystAgent, reporterAgent],
    llm: getSupervisorModel(),
    prompt: SUPERVISOR_PROMPT,
    outputMode: 'full_history',
  });

  // Compile with checkpointer for session persistence
  return workflow.compile({
    checkpointer,
  });
}

// ============================================================================
// 3. Execution Functions
// ============================================================================

export interface SupervisorExecutionOptions {
  sessionId?: string;
}

/**
 * Execute supervisor workflow (single response)
 * Includes automatic Gemini API key failover on rate limit
 */
export async function executeSupervisor(
  query: string,
  options: SupervisorExecutionOptions = {}
): Promise<{
  response: string;
  sessionId: string;
}> {
  const sessionId = options.sessionId || `session_${Date.now()}`;
  const config = createSessionConfig(sessionId);
  const MAX_RETRIES = 2; // Primary key + secondary key

  for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {
    try {
      // Create fresh supervisor (uses current active Gemini key)
      const app = await createMultiAgentSupervisor();

      const result = await app.invoke(
        {
          messages: [new HumanMessage(query)],
        },
        config
      );

      // Extract final response from messages
      const messages = result.messages || [];
      const lastMessage = messages[messages.length - 1];
      const response =
        typeof lastMessage?.content === 'string'
          ? lastMessage.content
          : 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';

      console.log(`âœ… [Supervisor] Completed. Session: ${sessionId}`);
      return { response, sessionId };
    } catch (error) {
      // Check if this is a rate limit error
      if (RateLimitError.isRateLimitError(error)) {
        const keyStatus = getGeminiKeyStatus();
        console.error(
          `âš ï¸ [Supervisor] Rate limit hit on attempt ${attempt + 1}/${MAX_RETRIES}`,
          { keyStatus }
        );

        // If we have more keys to try, mark current key as exhausted and retry
        if (attempt < MAX_RETRIES - 1 && keyStatus.totalKeys > 1) {
          markGeminiKeyExhausted();
          console.log('ğŸ”„ [Supervisor] Switching to secondary Gemini key...');
          continue; // Retry with secondary key
        }
      }

      // Re-throw if not a rate limit error or no more retries
      throw error;
    }
  }

  // Should not reach here, but TypeScript requires it
  throw new Error('All Gemini API keys exhausted');
}

/**
 * Stream supervisor workflow (Alternative Implementation)
 * Uses app.stream() for native LangGraph streaming
 *
 * @note CURRENTLY UNUSED - Kept for future reference/optimization
 *
 * This function was replaced by `createSupervisorStreamResponse` which uses
 * `executeSupervisor()` + simulated SSE streaming for better Groq compatibility.
 * Native LangGraph streaming (streamEvents) doesn't emit text tokens properly for Groq models.
 *
 * Consider reactivating if:
 * 1. Switching to a model with native streaming support (e.g., Gemini, OpenAI)
 * 2. LangGraph improves Groq streaming support
 *
 * @see createSupervisorStreamResponse - Currently active implementation
 */
export async function* streamSupervisor(
  query: string,
  options: SupervisorExecutionOptions = {}
): AsyncGenerator<{
  type: 'token' | 'agent_start' | 'agent_end' | 'final' | 'error';
  content: string;
  metadata?: Record<string, unknown>;
}> {
  const app = await createMultiAgentSupervisor();
  const sessionId = options.sessionId || `session_${Date.now()}`;
  const config = createSessionConfig(sessionId);

  try {
    // Use default stream() instead of streamEvents for Groq compatibility
    const stream = await app.stream(
      { messages: [new HumanMessage(query)] },
      config
    );

    let finalContent = '';
    let lastAgentName = '';

    for await (const chunk of stream) {
      // Chunk has agent name as key: { supervisor: {...}, test_agent: {...} }
      for (const [agentName, agentOutput] of Object.entries(chunk)) {
        // Emit agent start
        if (agentName !== lastAgentName) {
          if (lastAgentName) {
            yield {
              type: 'agent_end',
              content: lastAgentName,
              metadata: {},
            };
          }
          yield {
            type: 'agent_start',
            content: agentName,
            metadata: {},
          };
          lastAgentName = agentName;
        }

        // Extract AI message content from agent output
        const output = agentOutput as {
          messages?: Array<{ content?: string; _getType?: () => string }>;
        };
        if (output?.messages) {
          for (const msg of output.messages) {
            // Check if it's an AI message with content
            const msgType = msg._getType?.();
            if (
              msgType === 'ai' &&
              msg.content &&
              typeof msg.content === 'string' &&
              msg.content.length > 0
            ) {
              // Skip system messages like "Successfully transferred..."
              if (
                !msg.content.includes('Successfully transferred') &&
                !msg.content.includes('Transferring back to')
              ) {
                finalContent = msg.content; // Keep the last meaningful AI response
                yield {
                  type: 'token',
                  content: msg.content,
                  metadata: { agent: agentName },
                };
              }
            }
          }
        }
      }
    }

    // Emit final agent end
    if (lastAgentName) {
      yield {
        type: 'agent_end',
        content: lastAgentName,
        metadata: {},
      };
    }

    // Final response
    yield {
      type: 'final',
      content: finalContent,
      metadata: { sessionId },
    };
  } catch (error) {
    yield {
      type: 'error',
      content: error instanceof Error ? error.message : String(error),
      metadata: { sessionId },
    };
  }
}

/**
 * Detect if response requires human approval
 * Returns approval metadata if needed
 */
function detectApprovalRequired(
  response: string,
  query: string
): {
  required: boolean;
  actionType?: 'incident_report' | 'system_command';
  description?: string;
} {
  // Check for command recommendations in response
  const hasCommands =
    response.includes('âŒ¨ï¸') ||
    response.includes('ì¶”ì²œ ëª…ë ¹ì–´') ||
    response.includes('command') ||
    /`[a-z]+\s+[a-z]+`/i.test(response);

  // Check for incident report
  const isIncident =
    query.includes('ì¥ì• ') ||
    query.includes('ì¸ì‹œë˜íŠ¸') ||
    response.includes('ğŸ“‹ ì¸ì‹œë˜íŠ¸');

  if (isIncident) {
    return {
      required: true,
      actionType: 'incident_report',
      description: 'ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€í†  í›„ ìŠ¹ì¸í•´ì£¼ì„¸ìš”.',
    };
  }

  if (hasCommands) {
    return {
      required: true,
      actionType: 'system_command',
      description: 'ì‹œìŠ¤í…œ ëª…ë ¹ì–´ê°€ ì¶”ì²œë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤í–‰ ì „ ê²€í† í•´ì£¼ì„¸ìš”.',
    };
  }

  return { required: false };
}

/**
 * Create AI SDK compatible streaming response
 * Uses invoke() for reliability with Groq, then simulates streaming
 * Includes SSE approval events for Human-in-the-Loop
 */
export async function createSupervisorStreamResponse(
  query: string,
  sessionId?: string
): Promise<ReadableStream<Uint8Array>> {
  const encoder = new TextEncoder();
  const effectiveSessionId = sessionId || `session_${Date.now()}`;

  return new ReadableStream({
    async start(controller) {
      let isClosed = false;

      const safeEnqueue = (data: Uint8Array) => {
        if (!isClosed) {
          controller.enqueue(data);
        }
      };

      const safeClose = () => {
        if (!isClosed) {
          isClosed = true;
          controller.close();
        }
      };

      try {
        // ğŸš€ Anti-Timeout: Immediate First Byte (Vercel 504 ë°©ì§€)
        const thinkingMessage = `0:${JSON.stringify('ğŸ” ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n\n')}\n`;
        safeEnqueue(encoder.encode(thinkingMessage));

        // Use invoke() for more reliable Groq integration
        const { response } = await executeSupervisor(query, {
          sessionId: effectiveSessionId,
        });

        if (response) {
          // AI SDK v5 Data Stream Protocol: text part
          // Format: '0:"text"\n'
          const dataStreamText = `0:${JSON.stringify(response)}\n`;
          safeEnqueue(encoder.encode(dataStreamText));

          // Check if response requires human approval
          const approval = detectApprovalRequired(response, query);

          if (approval.required && approval.actionType) {
            // Register in approval store
            approvalStore.registerPending({
              sessionId: effectiveSessionId,
              actionType: approval.actionType,
              description: approval.description || '',
              payload: { response, query },
              requestedAt: new Date(),
              requestedBy: 'reporter_agent',
            });

            // AI SDK v5 Data Stream Protocol: custom data event
            // Format: '2:[{...}]\n' for data array, or use 'data-*' pattern
            // Using '8:' prefix for custom annotation/metadata
            const approvalEvent = `8:${JSON.stringify([
              {
                type: 'approval_request',
                id: effectiveSessionId,
                actionType: approval.actionType,
                description: approval.description,
              },
            ])}\n`;
            safeEnqueue(encoder.encode(approvalEvent));

            console.log(
              `ğŸ”” [Supervisor] Approval required: ${approval.actionType}`
            );
          }
        }

        // AI SDK v5 Data Stream Protocol: finish message
        const finishMessage = `d:${JSON.stringify({
          finishReason: 'stop',
          sessionId: effectiveSessionId,
        })}\n`;
        safeEnqueue(encoder.encode(finishMessage));
        console.log('ğŸ“¤ Supervisor completed (AI SDK v5 Protocol)');

        safeClose();
      } catch (error) {
        console.error('âŒ Supervisor error:', error);
        const errorMessage =
          error instanceof Error ? error.message : 'Unknown error';
        const errorStream = `3:${JSON.stringify(errorMessage)}\n`;
        safeEnqueue(encoder.encode(errorStream));
        safeClose();
      }
    },
  });
}
