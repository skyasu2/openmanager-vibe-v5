/**
 * Analyst Agent
 * íŒ¨í„´ ë¶„ì„ ë° ì´ìƒ íƒì§€ ì „ë¬¸ ì—ì´ì „íŠ¸
 */

import { AIMessage } from '@langchain/core/messages';
import { tool } from '@langchain/core/tools';
import { z } from 'zod';
import {
  getAnomalyDetector,
  type MetricDataPoint,
} from '../lib/ai/monitoring/SimpleAnomalyDetector';
import {
  getTrendPredictor,
  type TrendDataPoint,
} from '../lib/ai/monitoring/TrendPredictor';
import { clusterLogsRust } from '../lib/rust-ml-client';
import { AgentExecutionError, getErrorMessage } from '../lib/errors';
import { getAnalystModel } from '../lib/model-config';

import type { AgentStateType, ToolResult } from '../lib/state-definition';
import {
  loadHistoricalContext,
  loadHourlyScenarioData,
} from '../services/scenario/scenario-loader';

// ============================================================================
// 1. Tool Result Types
// ============================================================================

type AnomalyResult =
  | {
      success: true;
      serverId: string;
      serverName: string;
      anomalyCount: number;
      hasAnomalies: boolean;
      results: Record<
        string,
        {
          isAnomaly: boolean;
          severity: string;
          confidence: number;
          currentValue: number;
          threshold: { upper: number; lower: number };
        }
      >;
      timestamp: string;
      _algorithm: string;
      _engine: 'rust' | 'typescript';
    }
  | { success: false; error: string };

type TrendResult =
  | {
      success: true;
      serverId: string;
      serverName: string;
      predictionHorizon: string;
      results: Record<
        string,
        {
          trend: string;
          currentValue: number;
          predictedValue: number;
          changePercent: number;
          confidence: number;
        }
      >;
      summary: { increasingMetrics: string[]; hasRisingTrends: boolean };
      timestamp: string;
      _algorithm: string;
      _engine: 'rust' | 'typescript';
    }
  | { success: false; error: string };

type PatternResult =
  | {
      success: true;
      patterns: string[];
      detectedIntent: string;
      analysisResults: {
        pattern: string;
        confidence: number;
        insights: string;
      }[];
      _mode: string;
    }
  | { success: false; message: string };

type ClusteringResult =
  | {
      success: true;
      serverId: string;
      totalLogs: number;
      clusterCount: number;
      clusters: Array<{
        id: number;
        size: number;
        representative: string;
      }>;
      _engine: string;
    }
  | { success: false; error: string };

// ============================================================================
// 2. Utility Functions
// ============================================================================

// function generateSimulatedHistory(
//   currentValue: number,
//   pointCount: number = 24
// ): MetricDataPoint[] {
//   // Legacy random simulation replaced by loadHistoricalContext
//   // Kept for reference or fallback if needed
//   const now = Date.now();
//   const interval = 5 * 60 * 1000;
//   const history: MetricDataPoint[] = [];

//   for (let i = pointCount - 1; i >= 0; i--) {
//     const variance = currentValue * 0.15;
//     const randomOffset = (Math.random() - 0.5) * 2 * variance;
//     const value = Math.max(0, Math.min(100, currentValue + randomOffset));

//     history.push({
//       timestamp: now - i * interval,
//       value,
//     });
//   }

//   return history;
// }

function toTrendDataPoints(metricPoints: MetricDataPoint[]): TrendDataPoint[] {
  return metricPoints.map((p) => ({ timestamp: p.timestamp, value: p.value }));
}

// ============================================================================
// 3. Tools Definition
// ============================================================================

export const detectAnomaliesTool = tool(
  async ({ serverId, metricType }) => {
    const allServers = await loadHourlyScenarioData();
    const server = serverId
      ? allServers.find((s) => s.id === serverId)
      : allServers[0];

    if (!server) {
      return {
        success: false,
        error: 'ì„œë²„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
      };
    }

    const metrics = ['cpu', 'memory', 'disk'] as const;
    const targetMetrics =
      metricType === 'all' ? metrics : [metricType as (typeof metrics)[number]];

    const results: Record<
      string,
      {
        isAnomaly: boolean;
        severity: string;
        confidence: number;
        currentValue: number;
        threshold: { upper: number; lower: number };
      }
    > = {};

    const usedEngine: 'rust' | 'typescript' = 'typescript';

    // Load actual scenario history for consistency
    // We load past 24 hours (24 points at 1h interval for broad trend, or simpler 24 points?)
    // The previous simulation was 24 points at 5min interval = 2 hours.
    // Let's load past 2 hours data -> 24 points (5 min interval)
    // Actually loadHistoricalContext as implemented loads "past N hours" using hour files.
    // If we want 24 points at 5 min intervals, we need finer/more frequent sampling or just load 2 hours and extract.
    // The implementation of loadHistoricalContext calculates "Now - i hours" which gives 1 point per hour.
    // To match "5 min interval" history, we need a loop of minutes?
    // Let's stick to "24 Hours History" (1 point per hour) for robust daily trend?
    // Or did the user want visual consistency?
    // Dashboard usually shows "Last Hour" or "Last 24 Hours".
    // Let's settle on: AI analyzes "Last 24 Hours" using 1-hour interval points.

    // Use static import
    const historyPoints = await loadHistoricalContext(server.id || '', 24);

    for (const metric of targetMetrics) {
      const currentValue = server[metric as keyof typeof server] as number;

      // Map history to MetricDataPoint
      const history: MetricDataPoint[] = historyPoints.map((h) => ({
        timestamp: h.timestamp,
        value: h[metric] || 0,
      }));

      // Fallback if history load failed
      if (history.length < 5) {
        // generate fallback
        const now = Date.now();
        for (let i = 0; i < 24; i++) {
          history.push({ timestamp: now - i * 3600000, value: currentValue });
        }
      }

      // TypeScript implementation primarily for migration stability
      const detector = getAnomalyDetector();
      const detection = detector.detectAnomaly(currentValue, history);

      results[metric] = {
        isAnomaly: detection.isAnomaly,
        severity: detection.severity,
        confidence: Math.round(detection.confidence * 100) / 100,
        currentValue,
        threshold: {
          upper: Math.round(detection.details.upperThreshold * 100) / 100,
          lower: Math.round(detection.details.lowerThreshold * 100) / 100,
        },
      };
    }

    const anomalyCount = Object.values(results).filter(
      (r) => r.isAnomaly
    ).length;

    return {
      success: true,
      serverId: server.id,
      serverName: server.name,
      anomalyCount,
      hasAnomalies: anomalyCount > 0,
      results,
      timestamp: new Date().toISOString(),
      _algorithm: '26-hour moving average + 2Ïƒ threshold',
      _engine: usedEngine,
    };
  },
  {
    name: 'detectAnomalies',
    description:
      'ì„œë²„ ë©”íŠ¸ë¦­ì˜ ì´ìƒì¹˜ë¥¼ íƒì§€í•©ë‹ˆë‹¤ (í†µê³„ì  ì´ìƒê°ì§€: 26ì‹œê°„ ì´ë™í‰ê·  + 2Ïƒ)',
    schema: z.object({
      serverId: z
        .string()
        .optional()
        .describe('ë¶„ì„í•  ì„œë²„ ID (ì„ íƒ, ë¯¸ì…ë ¥ì‹œ ì²« ë²ˆì§¸ ì„œë²„)'),
      metricType: z
        .enum(['cpu', 'memory', 'disk', 'all'])
        .default('all')
        .describe('ë¶„ì„í•  ë©”íŠ¸ë¦­ íƒ€ì…'),
    }),
  }
);

export const predictTrendsTool = tool(
  async ({ serverId, metricType, predictionHours }) => {
    const allServers = await loadHourlyScenarioData();
    const server = serverId
      ? allServers.find((s) => s.id === serverId)
      : allServers[0];

    if (!server) {
      return {
        success: false,
        error: 'ì„œë²„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
      };
    }

    const metrics = ['cpu', 'memory', 'disk'] as const;
    const targetMetrics =
      metricType === 'all' ? metrics : [metricType as (typeof metrics)[number]];
    const horizon = (predictionHours ?? 1) * 3600 * 1000;

    const results: Record<
      string,
      {
        trend: string;
        currentValue: number;
        predictedValue: number;
        changePercent: number;
        confidence: number;
      }
    > = {};

    const usedEngine: 'rust' | 'typescript' = 'typescript';

    // Use static import
    const historyPoints = await loadHistoricalContext(server.id || '', 24);

    for (const metric of targetMetrics) {
      const currentValue = server[metric as keyof typeof server] as number;

      const history: MetricDataPoint[] = historyPoints.map((h) => ({
        timestamp: h.timestamp,
        value: h[metric] || 0,
      }));

      // Fallback if history load failed
      if (history.length < 5) {
        const now = Date.now();
        for (let i = 0; i < 24; i++) {
          history.push({ timestamp: now - i * 3600000, value: currentValue });
        }
      }

      // TypeScript implementation
      const predictor = getTrendPredictor();
      const trendHistory = toTrendDataPoints(history);
      const prediction = predictor.predictTrend(trendHistory, horizon);

      results[metric] = {
        trend: prediction.trend,
        currentValue,
        predictedValue: Math.round(prediction.prediction * 100) / 100,
        changePercent:
          Math.round(prediction.details.predictedChangePercent * 100) / 100,
        confidence: Math.round(prediction.confidence * 100) / 100,
      };
    }

    const increasingMetrics = Object.entries(results)
      .filter(([, r]) => r.trend === 'increasing')
      .map(([m]) => m);

    return {
      success: true,
      serverId: server.id,
      serverName: server.name,
      predictionHorizon: `${predictionHours ?? 1}ì‹œê°„`,
      results,
      summary: {
        increasingMetrics,
        hasRisingTrends: increasingMetrics.length > 0,
      },
      timestamp: new Date().toISOString(),
      _algorithm: 'Linear Regression with RÂ² confidence',
      _engine: usedEngine,
    };
  },
  {
    name: 'predictTrends',
    description:
      'ì„œë²„ ë©”íŠ¸ë¦­ì˜ íŠ¸ë Œë“œë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤ (ì„ í˜• íšŒê·€ ê¸°ë°˜ 1ì‹œê°„ ì˜ˆì¸¡)',
    schema: z.object({
      serverId: z
        .string()
        .optional()
        .describe('ë¶„ì„í•  ì„œë²„ ID (ì„ íƒ, ë¯¸ì…ë ¥ì‹œ ì²« ë²ˆì§¸ ì„œë²„)'),
      metricType: z
        .enum(['cpu', 'memory', 'disk', 'all'])
        .default('all')
        .describe('ë¶„ì„í•  ë©”íŠ¸ë¦­ íƒ€ì…'),
      predictionHours: z
        .number()
        .optional()
        .default(1)
        .describe('ì˜ˆì¸¡ ì‹œê°„ (ê¸°ë³¸ 1ì‹œê°„)'),
    }),
  }
);

export const analyzePatternTool = tool(
  async ({ query }) => {
    const patterns: string[] = [];
    const q = query.toLowerCase();

    if (/cpu|í”„ë¡œì„¸ì„œ|ì„±ëŠ¥/i.test(q)) patterns.push('system_performance');
    if (/ë©”ëª¨ë¦¬|ram|memory/i.test(q)) patterns.push('memory_status');
    if (/ë””ìŠ¤í¬|ì €ì¥ì†Œ|ìš©ëŸ‰/i.test(q)) patterns.push('storage_info');
    if (/ì„œë²„|ì‹œìŠ¤í…œ|ìƒíƒœ/i.test(q)) patterns.push('server_status');
    if (/íŠ¸ë Œë“œ|ì¶”ì„¸|ì˜ˆì¸¡/i.test(q)) patterns.push('trend_analysis');
    if (/ì´ìƒ|anomaly|alert/i.test(q)) patterns.push('anomaly_detection');

    if (patterns.length === 0) {
      return { success: false, message: 'ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ ì—†ìŒ' };
    }

    const analysisResults = patterns.map((pattern) => ({
      pattern,
      confidence: 0.8 + Math.random() * 0.2,
      insights: getPatternInsights(pattern),
    }));

    return {
      success: true,
      patterns,
      detectedIntent: patterns[0],
      analysisResults,
      _mode: 'pattern-analysis',
    };
  },
  {
    name: 'analyzePattern',
    description: 'ì‚¬ìš©ì ì§ˆë¬¸ì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤',
    schema: z.object({
      query: z.string().describe('ë¶„ì„í•  ì‚¬ìš©ì ì§ˆë¬¸'),
    }),
  }
);

export const clusterLogPatternsTool = tool(
  async ({ serverId, limit = 50 }) => {
    const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
    const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

    if (!supabaseUrl || !supabaseKey) {
      return { success: false, error: 'Supabase credentials missing' };
    }

    try {
      const { createClient } = await import('@supabase/supabase-js');
      const supabase = createClient(supabaseUrl, supabaseKey);

      // 1. Fetch Logs
      let query = supabase
        .from('server_logs')
        .select('message') // Just messages for clustering
        .order('timestamp', { ascending: false })
        .limit(limit);

      if (serverId) {
        query = query.eq('server_id', serverId);
      }

      const { data, error } = await query;
      if (error) throw error;
      if (!data || data.length === 0) {
        return { success: false, error: 'No logs found to analyze' };
      }

      const logMessages = data.map((d) => d.message);

      // 2. Call Rust ML Service (Linfa K-Means)
      const clusterResult = await clusterLogsRust(logMessages);

      if (!clusterResult) {
        // Fallback or simple heuristics if Rust service fails
        return { success: false, error: 'Clustering service unavailable' };
      }

      // 3. Format Result
      return {
        success: true,
        serverId: serverId || 'ALL',
        totalLogs: logMessages.length,
        clusterCount: clusterResult.clusters.length,
        clusters: clusterResult.clusters.map((c) => ({
          id: c.id,
          size: c.size,
          representative: c.representative_log,
        })),
        _engine: 'rust-linfa-kmeans',
      };
    } catch (e) {
      return { success: false, error: String(e) };
    }
  },
  {
    name: 'clusterLogPatterns',
    description:
      'ìµœê·¼ ì„œë²„ ë¡œê·¸ì˜ íŒ¨í„´ì„ ML(K-Means)ë¡œ êµ°ì§‘í™”í•˜ì—¬ ì£¼ìš” ì´ìŠˆ ê·¸ë£¹ì„ ì‹ë³„í•©ë‹ˆë‹¤',
    schema: z.object({
      serverId: z.string().optional().describe('ë¶„ì„í•  ì„œë²„ ID'),
      limit: z.number().optional().default(50).describe('ë¶„ì„í•  ë¡œê·¸ ê°œìˆ˜'),
    }),
  }
);

function getPatternInsights(pattern: string): string {
  const insights: Record<string, string> = {
    system_performance:
      'ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„: CPU ì‚¬ìš©ë¥ , í”„ë¡œì„¸ìŠ¤ ìˆ˜, ë¡œë“œ í‰ê·  í™•ì¸ í•„ìš”',
    memory_status: 'ë©”ëª¨ë¦¬ ìƒíƒœ ë¶„ì„: ì‚¬ìš©ëŸ‰, ìºì‹œ, ìŠ¤ì™‘ ì‚¬ìš©ë¥  í™•ì¸ í•„ìš”',
    storage_info:
      'ìŠ¤í† ë¦¬ì§€ ë¶„ì„: ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰, I/O ëŒ€ê¸°, íŒŒí‹°ì…˜ ìƒíƒœ í™•ì¸ í•„ìš”',
    server_status: 'ì„œë²„ ìƒíƒœ ë¶„ì„: ê°€ë™ ì‹œê°„, ì„œë¹„ìŠ¤ ìƒíƒœ, ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸',
    trend_analysis:
      'íŠ¸ë Œë“œ ë¶„ì„: ì‹œê³„ì—´ ë°ì´í„° ê¸°ë°˜ íŒ¨í„´ ì¸ì‹ ë° ì˜ˆì¸¡ ëª¨ë¸ ì ìš©',
    anomaly_detection: 'ì´ìƒ íƒì§€: í†µê³„ì  ì´ìƒì¹˜ ê°ì§€, ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼ í™•ì¸',
  };
  return insights[pattern] || 'ì¼ë°˜ ë¶„ì„ ìˆ˜í–‰';
}

// ... remaining node code ...
// ... remaining node code ...
type AnalysisIntent = 'anomaly' | 'trend' | 'pattern' | 'log_cluster' | 'comprehensive';

function detectAnalysisIntent(query: string): AnalysisIntent {
  const q = query.toLowerCase();
  const anomalyKeywords =
    /ì´ìƒ|anomaly|ë¹„ì •ìƒ|alert|ê²½ê³ |ê¸‰ì¦|ê¸‰ê°|ìŠ¤íŒŒì´í¬|spike|ë¬¸ì œ/i;
  const trendKeywords =
    /íŠ¸ë Œë“œ|trend|ì¶”ì„¸|ì˜ˆì¸¡|predict|forecast|ì•ìœ¼ë¡œ|ë¯¸ë˜|ì¦ê°€|ê°ì†Œ/i;
  const logKeywords = /ë¡œê·¸|log|êµ°ì§‘|cluser|íŒ¨í„´|pattern|ë°˜ë³µ/i;
  const comprehensiveKeywords = /ì¢…í•©|ì „ì²´|ëª¨ë“ |ìƒì„¸|ë¶„ì„í•´|ë¦¬í¬íŠ¸|report/i;

  const hasAnomaly = anomalyKeywords.test(q);
  const hasTrend = trendKeywords.test(q);
  const hasLog = logKeywords.test(q);
  const hasComprehensive = comprehensiveKeywords.test(q);

  if (hasComprehensive) return 'comprehensive';
  if (hasLog) return 'log_cluster';
  if (hasAnomaly) return 'anomaly';
  if (hasTrend) return 'trend';
  return 'pattern';
}

function extractServerId(query: string): string | undefined {
  const match = query.match(/ì„œë²„\s*(\d+)|server[-_]?(\d+)/i);
  if (match) {
    const num = match[1] || match[2];
    return `server-${num}`;
  }
  return undefined;
}

export async function analystAgentNode(
  state: AgentStateType
): Promise<Partial<AgentStateType>> {
  const lastMessage = state.messages[state.messages.length - 1];
  const userQuery =
    typeof lastMessage?.content === 'string'
      ? lastMessage.content
      : 'Analyze system patterns';

  try {
    const model = getAnalystModel();
    const toolResults: ToolResult[] = [];

    const intent = detectAnalysisIntent(userQuery);
    const serverId = extractServerId(userQuery);

    console.log(
      `ğŸ“Š [Analyst Agent] Intent: ${intent}, ServerId: ${serverId || 'auto'}`
    );

    let anomalyResult: AnomalyResult | null = null;
    let trendResult: TrendResult | null = null;
    let patternResult: PatternResult | null = null;
    let clusterResult: ClusteringResult | null = null;

    // Direct invocation logic for tools if needed, or use bindTools in a real agent node
    // Since this is just a function node, we CAN invoke tools directly.

    if (intent === 'anomaly' || intent === 'comprehensive') {
      anomalyResult = (await detectAnomaliesTool.invoke({
        serverId,
        metricType: 'all',
      })) as AnomalyResult;
      toolResults.push({
        toolName: 'detectAnomalies',
        success: anomalyResult.success,
        data: anomalyResult,
        executedAt: new Date().toISOString(),
      });
    }

    if (intent === 'trend' || intent === 'comprehensive') {
      trendResult = (await predictTrendsTool.invoke({
        serverId,
        metricType: 'all',
        predictionHours: 1,
      })) as TrendResult;
      toolResults.push({
        toolName: 'predictTrends',
        success: trendResult.success,
        data: trendResult,
        executedAt: new Date().toISOString(),
      });
    }



    if (intent === 'log_cluster' || intent === 'comprehensive') {
      clusterResult = (await clusterLogPatternsTool.invoke({
        serverId,
        limit: 50,
      })) as ClusteringResult;
      toolResults.push({
        toolName: 'clusterLogPatterns',
        success: clusterResult.success, // @ts-ignore
        data: clusterResult,
        executedAt: new Date().toISOString(),
      });
    }

    patternResult = (await analyzePatternTool.invoke({
      query: userQuery,
    })) as PatternResult;
    toolResults.push({
      toolName: 'analyzePattern',
      success: patternResult.success,
      data: patternResult,
      executedAt: new Date().toISOString(),
    });

    const analysisPrompt = buildAnalysisPrompt(
      userQuery,
      intent,
      patternResult,
      anomalyResult,
      trendResult,
      clusterResult
    );

    const response = await model.invoke([
      { role: 'user', content: analysisPrompt },
    ]);

    const finalContent =
      typeof response.content === 'string'
        ? response.content
        : 'ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';

    console.log(
      `ğŸ“Š [Analyst Agent] Completed: ${toolResults.map((t) => t.toolName).join(', ')}`
    );

    return {
      messages: [new AIMessage(finalContent)],
      toolResults,
      finalResponse: finalContent,
    };
  } catch (error) {
    const agentError =
      error instanceof AgentExecutionError
        ? error
        : new AgentExecutionError(
            'analyst',
            error instanceof Error ? error : undefined
          );
    console.error('âŒ Analyst Agent Error:', agentError.toJSON());
    return {
      finalResponse: 'íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      toolResults: [
        {
          toolName: 'analyst_error',
          success: false,
          data: null,
          error: getErrorMessage(error),
          executedAt: new Date().toISOString(),
        },
      ],
    };
  }
}

function buildAnalysisPrompt(
  userQuery: string,
  intent: AnalysisIntent,
  patternResult: unknown,
  anomalyResult: unknown | null,
  trendResult: unknown | null,
  clusterResult: unknown | null
): string {
  let prompt = `ë‹¹ì‹ ì€ OpenManager VIBEì˜ Analyst Agentì…ë‹ˆë‹¤.
ì„œë²„ ì‹œìŠ¤í…œ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸: ${userQuery}
ë¶„ì„ ìœ í˜•: ${intent}

`;

  prompt += `## íŒ¨í„´ ë¶„ì„ ê²°ê³¼
${JSON.stringify(patternResult, null, 2)}

`;

  if (anomalyResult) {
    prompt += `## ì´ìƒ íƒì§€ ê²°ê³¼ (26ì‹œê°„ ì´ë™í‰ê·  + 2Ïƒ)
${JSON.stringify(anomalyResult, null, 2)}

`;
  }

  if (trendResult) {
    prompt += `## íŠ¸ë Œë“œ ì˜ˆì¸¡ ê²°ê³¼ (ì„ í˜• íšŒê·€)
${JSON.stringify(trendResult, null, 2)}

`;
  }

  if (clusterResult) {
    prompt += `## ë¡œê·¸ íŒ¨í„´ êµ°ì§‘í™” ê²°ê³¼ (Linfa K-Means)
${JSON.stringify(clusterResult, null, 2)}

`;
  }

  prompt += `ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ:
1. í˜„ì¬ ìƒíƒœ ìš”ì•½
2. ${intent === 'anomaly' ? 'ê°ì§€ëœ ì´ìƒ íŒ¨í„´ ìƒì„¸ ì„¤ëª…' : intent === 'trend' ? 'ì˜ˆì¸¡ íŠ¸ë Œë“œ í•´ì„' : 'ë°œê²¬ëœ íŒ¨í„´ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…'}
3. ì ì¬ì  ë¬¸ì œì  ë˜ëŠ” ì£¼ì˜ì‚¬í•­
4. ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­

í•œêµ­ì–´ë¡œ ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.`;

  return prompt;
}
