/**
 * LlamaIndex.TS RAG Service
 *
 * Replaces custom GraphRAG implementation with LlamaIndex.TS open-source library.
 * Uses Mistral AI for triplet extraction and Supabase pgVector for storage.
 *
 * @version 1.0.0
 * @created 2025-12-31
 * @replaces graph-rag-service.ts (custom implementation)
 */

import { MistralAI } from '@llamaindex/mistral';
import {
  Document,
  Settings,
} from 'llamaindex';
import { createClient, SupabaseClient } from '@supabase/supabase-js';
import { getSupabaseConfig, getMistralApiKey } from './config-parser';

// ============================================================================
// Types
// ============================================================================

export interface LlamaIndexSearchResult {
  id: string;
  title: string;
  content: string;
  score: number;
  sourceType: 'vector' | 'knowledge_graph' | 'graph';
  hopDistance: number;
  metadata?: Record<string, unknown>;
}

export interface KnowledgeTriplet {
  subject: string;
  predicate: string;
  object: string;
  confidence: number;
}

export interface LlamaIndexStats {
  totalDocuments: number;
  totalTriplets: number;
  lastIndexed: string | null;
}

// ============================================================================
// Configuration
// ============================================================================

let isInitialized = false;
let supabaseClient: SupabaseClient | null = null;

/**
 * Initialize LlamaIndex with Mistral AI
 */
export async function initializeLlamaIndex(): Promise<boolean> {
  if (isInitialized) return true;

  try {
    const mistralApiKey = getMistralApiKey();
    if (!mistralApiKey) {
      console.warn('‚ö†Ô∏è [LlamaIndex] Mistral API key missing, using fallback');
      return false;
    }

    // Configure LlamaIndex to use Mistral
    Settings.llm = new MistralAI({
      model: 'mistral-small-latest', // 24B parameters, cost-effective
      apiKey: mistralApiKey,
    });

    // Initialize Supabase client
    const supabaseConfig = getSupabaseConfig();
    if (supabaseConfig) {
      supabaseClient = createClient(
        supabaseConfig.url,
        supabaseConfig.serviceRoleKey
      );
    }

    isInitialized = true;
    console.log('‚úÖ [LlamaIndex] Initialized with Mistral AI');
    return true;
  } catch (error) {
    console.error('‚ùå [LlamaIndex] Initialization failed:', error);
    return false;
  }
}

// ============================================================================
// Triplet Extraction (Knowledge Graph)
// ============================================================================

/**
 * Extract knowledge triplets from text using LLM
 * Replaces heuristic-based detection with LLM-powered extraction
 */
export async function extractTriplets(
  text: string,
  maxTriplets: number = 10
): Promise<KnowledgeTriplet[]> {
  await initializeLlamaIndex();

  if (!Settings.llm) {
    console.warn('‚ö†Ô∏è [LlamaIndex] LLM not configured');
    return [];
  }

  try {
    const prompt = `
Extract up to ${maxTriplets} knowledge triplets from the following text.
Each triplet should be in the format: (subject, predicate, object)

Text:
${text}

Output as JSON array:
[{"subject": "...", "predicate": "...", "object": "...", "confidence": 0.0-1.0}]

Only output the JSON array, no other text.
`;

    const response = await Settings.llm.complete({ prompt });
    const responseText = response.text.trim();

    // Parse JSON response
    const jsonMatch = responseText.match(/\[[\s\S]*\]/);
    if (!jsonMatch) {
      console.warn('‚ö†Ô∏è [LlamaIndex] Failed to parse triplets JSON');
      return [];
    }

    const triplets = JSON.parse(jsonMatch[0]) as KnowledgeTriplet[];
    console.log(`üìä [LlamaIndex] Extracted ${triplets.length} triplets`);
    return triplets;
  } catch (error) {
    console.error('‚ùå [LlamaIndex] Triplet extraction failed:', error);
    return [];
  }
}

// ============================================================================
// Vector Search with Supabase pgVector
// ============================================================================

/**
 * Search knowledge base using vector similarity
 * Uses existing Supabase pgVector infrastructure
 */
export async function searchKnowledgeBase(
  query: string,
  options: {
    similarityThreshold?: number;
    maxResults?: number;
    category?: string;
  } = {}
): Promise<LlamaIndexSearchResult[]> {
  await initializeLlamaIndex();

  const {
    similarityThreshold = 0.3,
    maxResults = 10,
    category,
  } = options;

  if (!supabaseClient) {
    console.warn('‚ö†Ô∏è [LlamaIndex] Supabase not available');
    return [];
  }

  try {
    // Use Supabase RPC for vector search (embeddings generated by Supabase)
    const { data, error } = await supabaseClient.rpc('match_knowledge_base', {
      query_text: query,
      match_threshold: similarityThreshold,
      match_count: maxResults,
    });

    if (error) throw error;

    return (data || []).map((row: Record<string, unknown>) => ({
      id: String(row.id),
      title: String(row.title || ''),
      content: String(row.content || ''),
      score: Number(row.similarity || 0),
      sourceType: 'vector' as const,
      hopDistance: 0,
      metadata: row.metadata as Record<string, unknown>,
    }));
  } catch (error) {
    console.error('‚ùå [LlamaIndex] Search failed:', error);
    return [];
  }
}

// ============================================================================
// Hybrid Search (Vector + Knowledge Graph)
// ============================================================================

/**
 * Hybrid search combining vector similarity and knowledge graph traversal
 * Leverages LlamaIndex's built-in hybrid search capabilities
 */
export async function hybridSearch(
  query: string,
  options: {
    similarityThreshold?: number;
    maxVectorResults?: number;
    maxGraphHops?: number;
    maxTotalResults?: number;
  } = {}
): Promise<LlamaIndexSearchResult[]> {
  await initializeLlamaIndex();

  const {
    similarityThreshold = 0.3,
    maxVectorResults = 5,
    maxGraphHops = 2,
    maxTotalResults = 15,
  } = options;

  if (!supabaseClient) {
    console.warn('‚ö†Ô∏è [LlamaIndex] Supabase not available');
    return [];
  }

  try {
    // 1. Vector search
    const vectorResults = await searchKnowledgeBase(query, {
      similarityThreshold,
      maxResults: maxVectorResults,
    });

    // 2. Graph traversal from vector results (PARALLELIZED)
    // Note: supabaseClient is guaranteed non-null here (checked above)
    const client = supabaseClient!;
    const topVectorResults = vectorResults.slice(0, 3);
    const graphTraversalResults = await Promise.all(
      topVectorResults.map(result =>
        client.rpc('traverse_knowledge_graph', {
          p_start_id: result.id,
          p_start_table: 'knowledge_base',
          p_max_hops: maxGraphHops,
          p_relationship_types: null,
          p_max_results: 5,
        })
      )
    );

    // Collect all unique node IDs from traversal results
    const nodeIds = new Set<string>();
    const nodeMetaMap = new Map<string, { pathWeight: number; hopDistance: number }>();

    for (const { data } of graphTraversalResults) {
      if (data && Array.isArray(data)) {
        for (const node of data) {
          const nodeId = String(node.node_id);
          if (!nodeIds.has(nodeId)) {
            nodeIds.add(nodeId);
            nodeMetaMap.set(nodeId, {
              pathWeight: Number(node.path_weight),
              hopDistance: Number(node.hop_distance || 1),
            });
          }
        }
      }
    }

    // Batch fetch all node contents at once
    const graphResults: LlamaIndexSearchResult[] = [];
    if (nodeIds.size > 0) {
      const { data: entries } = await client
        .from('knowledge_base')
        .select('id, title, content, metadata')
        .in('id', Array.from(nodeIds));

      if (entries) {
        for (const entry of entries) {
          const meta = nodeMetaMap.get(entry.id);
          graphResults.push({
            id: entry.id,
            title: entry.title,
            content: entry.content,
            score: (meta?.pathWeight ?? 1) * 0.8, // Weight graph results lower
            sourceType: 'graph', // Use 'graph' for backward compatibility
            hopDistance: meta?.hopDistance ?? 1,
            metadata: entry.metadata,
          });
        }
      }
    }

    // 3. Combine and deduplicate
    const allResults = [...vectorResults, ...graphResults];
    const seen = new Set<string>();
    const deduplicated = allResults.filter(r => {
      if (seen.has(r.id)) return false;
      seen.add(r.id);
      return true;
    });

    // Sort by score and limit
    return deduplicated
      .sort((a, b) => b.score - a.score)
      .slice(0, maxTotalResults);
  } catch (error) {
    console.error('‚ùå [LlamaIndex] Hybrid search failed:', error);
    return [];
  }
}

// ============================================================================
// Index Documents
// ============================================================================

/**
 * Index new documents into the knowledge base
 * Uses LlamaIndex for document processing and embedding
 */
export async function indexDocuments(
  documents: Array<{ text: string; metadata?: Record<string, unknown> }>
): Promise<{ success: boolean; indexed: number }> {
  await initializeLlamaIndex();

  if (!supabaseClient) {
    return { success: false, indexed: 0 };
  }

  try {
    let indexed = 0;

    for (const doc of documents) {
      // 1. Create LlamaIndex document
      const llamaDoc = new Document({
        text: doc.text,
        metadata: doc.metadata,
      });

      // 2. Extract triplets for knowledge graph
      const triplets = await extractTriplets(doc.text, 5);

      // 3. Store in Supabase (embeddings handled by existing infrastructure)
      const { error } = await supabaseClient.from('knowledge_base').insert({
        content: doc.text,
        title: doc.metadata?.title || 'Untitled',
        category: doc.metadata?.category || 'general',
        tags: doc.metadata?.tags || [],
        metadata: {
          ...doc.metadata,
          triplets: triplets, // Store extracted triplets
          indexed_at: new Date().toISOString(),
          indexed_by: 'llamaindex',
        },
      });

      if (!error) indexed++;
    }

    console.log(`‚úÖ [LlamaIndex] Indexed ${indexed}/${documents.length} documents`);
    return { success: true, indexed };
  } catch (error) {
    console.error('‚ùå [LlamaIndex] Indexing failed:', error);
    return { success: false, indexed: 0 };
  }
}

// ============================================================================
// Stats
// ============================================================================

/**
 * Get LlamaIndex RAG statistics
 */
export async function getStats(): Promise<LlamaIndexStats | null> {
  if (!supabaseClient) return null;

  try {
    const [docsResult, relsResult] = await Promise.all([
      supabaseClient.from('knowledge_base').select('id', { count: 'exact', head: true }),
      supabaseClient.from('knowledge_relationships').select('id, created_at', { count: 'exact' }).order('created_at', { ascending: false }).limit(1),
    ]);

    return {
      totalDocuments: docsResult.count || 0,
      totalTriplets: relsResult.count || 0,
      lastIndexed: relsResult.data?.[0]?.created_at || null,
    };
  } catch (error) {
    console.error('‚ùå [LlamaIndex] Stats fetch failed:', error);
    return null;
  }
}

// ============================================================================
// Backward Compatibility Exports
// ============================================================================

/**
 * Backward-compatible hybridGraphSearch that accepts embedding array
 * Used by reporter-tools.ts
 */
export async function hybridGraphSearch(
  queryEmbedding: number[],
  options: {
    similarityThreshold?: number;
    maxVectorResults?: number;
    maxGraphHops?: number;
    maxTotalResults?: number;
  } = {}
): Promise<LlamaIndexSearchResult[]> {
  await initializeLlamaIndex();

  const {
    similarityThreshold = 0.3,
    maxVectorResults = 5,
    maxGraphHops = 2,
    maxTotalResults = 15,
  } = options;

  if (!supabaseClient) {
    console.warn('‚ö†Ô∏è [LlamaIndex] Supabase not available');
    return [];
  }

  try {
    // 1. Direct vector search with embedding
    const { data: vectorData, error: vectorError } = await supabaseClient.rpc('match_documents', {
      query_embedding: queryEmbedding,
      match_count: maxVectorResults,
      filter: {},
    });

    if (vectorError) throw vectorError;

    const vectorResults: LlamaIndexSearchResult[] = (vectorData || []).map((row: Record<string, unknown>) => ({
      id: String(row.id),
      title: String(row.title || ''),
      content: String(row.content || ''),
      score: Number(row.similarity || 0),
      sourceType: 'vector' as const,
      hopDistance: 0,
      metadata: row.metadata as Record<string, unknown>,
    }));

    // 2. Graph traversal from vector results (PARALLELIZED)
    // Note: supabaseClient is guaranteed non-null here (checked above)
    const client = supabaseClient!;
    const topVectorResults = vectorResults.slice(0, 3);
    const graphTraversalResults = await Promise.all(
      topVectorResults.map(result =>
        client.rpc('traverse_knowledge_graph', {
          p_start_id: result.id,
          p_start_table: 'knowledge_base',
          p_max_hops: maxGraphHops,
          p_relationship_types: null,
          p_max_results: 5,
        })
      )
    );

    // Collect all unique node IDs from traversal results
    const nodeIds = new Set<string>();
    const nodeMetaMap = new Map<string, { pathWeight: number; hopDistance: number }>();

    for (const { data } of graphTraversalResults) {
      if (data && Array.isArray(data)) {
        for (const node of data) {
          const nodeId = String(node.node_id);
          if (!nodeIds.has(nodeId)) {
            nodeIds.add(nodeId);
            nodeMetaMap.set(nodeId, {
              pathWeight: Number(node.path_weight),
              hopDistance: Number(node.hop_distance || 1),
            });
          }
        }
      }
    }

    // Batch fetch all node contents at once
    const graphResults: LlamaIndexSearchResult[] = [];
    if (nodeIds.size > 0) {
      const { data: entries } = await client
        .from('knowledge_base')
        .select('id, title, content, metadata')
        .in('id', Array.from(nodeIds));

      if (entries) {
        for (const entry of entries) {
          const meta = nodeMetaMap.get(entry.id);
          graphResults.push({
            id: entry.id,
            title: entry.title,
            content: entry.content,
            score: (meta?.pathWeight ?? 1) * 0.8,
            sourceType: 'graph',
            hopDistance: meta?.hopDistance ?? 1,
            metadata: entry.metadata,
          });
        }
      }
    }

    // 3. Combine and deduplicate
    const allResults = [...vectorResults, ...graphResults];
    const seen = new Set<string>();
    const deduplicated = allResults.filter(r => {
      if (seen.has(r.id)) return false;
      seen.add(r.id);
      return true;
    });

    return deduplicated
      .sort((a, b) => b.score - a.score)
      .slice(0, maxTotalResults);
  } catch (error) {
    console.error('‚ùå [LlamaIndex] Hybrid graph search failed:', error);
    return [];
  }
}
export const getGraphRAGStats = getStats;

interface ExtractionResult {
  entryId: string;
  relationships: KnowledgeTriplet[];
}

/**
 * Extract relationships from unprocessed knowledge base entries
 * Uses LlamaIndex triplet extraction with Mistral AI
 */
export const extractRelationships = async (options: {
  batchSize?: number;
  onlyUnprocessed?: boolean;
} = {}): Promise<ExtractionResult[]> => {
  await initializeLlamaIndex();

  const { batchSize = 50, onlyUnprocessed = true } = options;

  if (!supabaseClient) {
    console.warn('‚ö†Ô∏è [LlamaIndex] Supabase not available');
    return [];
  }

  try {
    // Fetch unprocessed entries
    let query = supabaseClient
      .from('knowledge_base')
      .select('id, content, metadata')
      .limit(batchSize);

    if (onlyUnprocessed) {
      // Check if triplets were already extracted
      query = query.or('metadata->indexed_by.is.null,metadata->triplets.is.null');
    }

    const { data: entries, error } = await query;

    if (error) throw error;
    if (!entries || entries.length === 0) {
      console.log('‚ÑπÔ∏è [LlamaIndex] No unprocessed entries found');
      return [];
    }

    const results: ExtractionResult[] = [];

    for (const entry of entries) {
      // Extract triplets using LLM
      const triplets = await extractTriplets(entry.content, 5);

      if (triplets.length > 0) {
        // Update entry with extracted triplets
        await supabaseClient
          .from('knowledge_base')
          .update({
            metadata: {
              ...entry.metadata,
              triplets,
              indexed_by: 'llamaindex',
              indexed_at: new Date().toISOString(),
            },
          })
          .eq('id', entry.id);

        results.push({
          entryId: entry.id,
          relationships: triplets,
        });
      }
    }

    console.log(`‚úÖ [LlamaIndex] Extracted relationships from ${results.length} entries`);
    return results;
  } catch (error) {
    console.error('‚ùå [LlamaIndex] Relationship extraction failed:', error);
    return [];
  }
};

export const getRelatedKnowledge = async (
  nodeId: string,
  options: { maxHops?: number; maxResults?: number } = {}
) => {
  await initializeLlamaIndex();

  if (!supabaseClient) return [];

  const { maxHops = 2, maxResults = 10 } = options;

  try {
    const { data } = await supabaseClient.rpc('traverse_knowledge_graph', {
      p_start_id: nodeId,
      p_start_table: 'knowledge_base',
      p_max_hops: maxHops,
      p_relationship_types: null,
      p_max_results: maxResults,
    });

    if (!data) return [];

    // Fetch content for nodes
    const nodeIds = data.map((r: Record<string, unknown>) => r.node_id);
    const { data: entries } = await supabaseClient
      .from('knowledge_base')
      .select('id, title, content')
      .in('id', nodeIds);

    const entryMap = new Map((entries || []).map(e => [e.id, e]));

    return data.map((row: Record<string, unknown>) => {
      const entry = entryMap.get(row.node_id as string);
      return {
        id: String(row.node_id),
        title: entry?.title || '',
        content: entry?.content || '',
        hopDistance: Number(row.hop_distance),
        pathWeight: Number(row.path_weight),
        relationshipPath: (row.relationship_path as string[]) || [],
      };
    });
  } catch (error) {
    console.error('‚ùå [LlamaIndex] Related knowledge fetch error:', error);
    return [];
  }
};
