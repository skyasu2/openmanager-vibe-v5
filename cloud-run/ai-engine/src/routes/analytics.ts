/**
 * Analytics Routes
 *
 * Server analysis, incident reporting, and batch analysis endpoints.
 * Uses specialized AI agents for natural language responses.
 *
 * @version 2.0.0 - Agent Integration
 * @created 2025-12-28
 * @updated 2025-12-30
 */

import { Hono } from 'hono';
import type { Context } from 'hono';
import { randomUUID } from 'crypto';
import {
  detectAnomalies,
  predictTrends,
  analyzePattern,
  searchKnowledgeBase,
  recommendCommands,
  extractKeywordsFromQuery,
} from '../tools-ai-sdk';
import { getCurrentState } from '../data/precomputed-state';
import { handleApiError, jsonSuccess } from '../lib/error-handler';
import { reporterAgent } from '../services/ai-sdk/agents/reporter-agent';
import { analystAgent } from '../services/ai-sdk/agents/analyst-agent';
import {
  syncIncidentsToRAG,
  getRAGInjectionStats,
} from '../lib/incident-rag-injector';

export const analyticsRouter = new Hono();

/**
 * POST /analyze-server - Server Analysis Endpoint
 *
 * Hybrid approach: Tools for structured data + Agent for natural language insights.
 * Returns CloudRunAnalysisResponse format for frontend compatibility.
 *
 * @version 2.1.0 - Hybrid Tool + Agent approach (Frontend compatible)
 */
analyticsRouter.post('/analyze-server', async (c: Context) => {
  try {
    const { serverId, analysisType = 'full', options = {} } = await c.req.json();

    console.log(`ğŸ”¬ [Analyze Server] serverId=${serverId}, type=${analysisType}`);

    // Type for metricType
    type MetricType = 'cpu' | 'memory' | 'disk' | 'all';
    const metricType = ((options.metricType as string) || 'all') as MetricType;
    const startTime = Date.now();

    // 1. Run tools directly for structured data (Frontend expects this format)
    const results: {
      serverId?: string;
      analysisType: string;
      anomalyDetection?: unknown;
      trendPrediction?: unknown;
      patternAnalysis?: unknown;
      aiInsights?: { summary: string; recommendations: string[]; confidence: number };
      _source: string;
      _durationMs?: number;
    } = {
      serverId,
      analysisType,
      _source: 'Hybrid (Tool + Agent)',
    };

    // Execute tools based on analysis type
    if (analysisType === 'anomaly' || analysisType === 'full') {
      results.anomalyDetection = await detectAnomalies.execute!({
        serverId: serverId || undefined,
        metricType,
      }, { toolCallId: 'analyze-server-anomaly', messages: [] });
    }

    if (analysisType === 'trend' || analysisType === 'full') {
      results.trendPrediction = await predictTrends.execute!({
        serverId: serverId || undefined,
        metricType,
        predictionHours: (options.predictionHours as number) || 1,
      }, { toolCallId: 'analyze-server-trend', messages: [] });
    }

    if (analysisType === 'pattern' || analysisType === 'full') {
      results.patternAnalysis = await analyzePattern.execute!({
        query: (options.query as string) || 'ì„œë²„ ìƒíƒœ ì „ì²´ ë¶„ì„',
      }, { toolCallId: 'analyze-server-pattern', messages: [] });
    }

    // 2. Use Agent for natural language insights (if available)
    if (analystAgent) {
      try {
        const anomalyData = results.anomalyDetection as { hasAnomalies?: boolean; anomalyCount?: number } | undefined;
        const trendData = results.trendPrediction as { summary?: { hasRisingTrends?: boolean } } | undefined;

        const prompt = `ë¶„ì„ ê²°ê³¼ë¥¼ í•´ì„í•˜ê³  ê¶Œì¥ ì¡°ì¹˜ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

## ë¶„ì„ ë°ì´í„°
- ì´ìƒ íƒì§€: ${anomalyData?.hasAnomalies ? `${anomalyData.anomalyCount}ê°œ ì´ìƒ ê°ì§€` : 'ì •ìƒ'}
- íŠ¸ë Œë“œ: ${trendData?.summary?.hasRisingTrends ? 'ìƒìŠ¹ ì¶”ì„¸ ìˆìŒ' : 'ì•ˆì •ì '}

## ìš”ì²­ ì‚¬í•­
1. í˜„ì¬ ìƒíƒœì— ëŒ€í•œ ê°„ëµí•œ ìš”ì•½ (2-3ë¬¸ì¥)
2. ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­ (ìµœëŒ€ 3ê°œ)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{"summary": "...", "recommendations": ["...", "..."], "confidence": 0.9}`;

        const agentResult = await analystAgent.generate({ prompt });

        // Try to parse JSON from agent response
        const jsonMatch = agentResult.text.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          try {
            const insights = JSON.parse(jsonMatch[0]);
            results.aiInsights = {
              summary: insights.summary || '',
              recommendations: insights.recommendations || [],
              confidence: insights.confidence || 0.8,
            };
          } catch {
            // If JSON parse fails, use text as summary
            results.aiInsights = {
              summary: agentResult.text.slice(0, 200),
              recommendations: [],
              confidence: 0.7,
            };
          }
        }
      } catch (agentError) {
        console.warn('âš ï¸ [Analyze Server] Agent insight generation failed:', agentError);
        // Continue without agent insights
      }
    }

    const durationMs = Date.now() - startTime;
    results._durationMs = durationMs;

    console.log(`âœ… [Analyze Server] Completed in ${durationMs}ms`);
    return jsonSuccess(c, results);
  } catch (error) {
    return handleApiError(c, error, 'Analyze Server');
  }
});

// Note: parseAnalystResponse and analyzeServerFallback removed in v2.1.0
// Main endpoint now uses hybrid approach (Tools + Agent)

/**
 * POST /incident-report - Incident Report Generation
 *
 * Uses Reporter Agent for natural language report generation.
 * Agent calls tools internally and synthesizes results.
 *
 * @version 2.1.0 - Structured JSON output + Enhanced parsing (ITIL-aligned)
 */
analyticsRouter.post('/incident-report', async (c: Context) => {
  try {
    const { serverId, query, severity, category, metrics, action } = await c.req.json();

    console.log(`ğŸ“‹ [Incident Report] action=${action}, serverId=${serverId}`);

    const startTime = Date.now();

    // 1. Collect real-time data from tools first (parallel execution)
    const [anomalyData, trendData, timelineData] = await Promise.all([
      detectAnomalies.execute!(
        { serverId: serverId || undefined, metricType: 'all' },
        { toolCallId: 'ir-anomaly', messages: [] }
      ),
      predictTrends.execute!(
        { serverId: serverId || undefined, metricType: 'all', predictionHours: 1 },
        { toolCallId: 'ir-trend', messages: [] }
      ),
      serverId
        ? (await import('../tools-ai-sdk/index.js').then((m) =>
            m.buildIncidentTimeline.execute!(
              { serverId, timeRangeHours: 6 },
              { toolCallId: 'ir-timeline', messages: [] }
            )
          ))
        : null,
    ]);

    // 2. Extract structured data from tool results
    const toolBasedData = extractToolBasedData(anomalyData, trendData, timelineData, serverId);

    // Check if Reporter Agent is available
    if (!reporterAgent) {
      console.warn('âš ï¸ [Incident Report] Reporter Agent unavailable, using tool-based fallback');
      return jsonSuccess(c, {
        ...toolBasedData,
        created_at: new Date().toISOString(),
        _source: 'Tool-based Fallback (No Agent)',
        _durationMs: Date.now() - startTime,
      });
    }

    // 3. Build prompt for Reporter Agent with JSON output request
    const metricsContext =
      metrics && metrics.length > 0
        ? `\ní˜„ì¬ ì„œë²„ ë©”íŠ¸ë¦­:\n${metrics
            .map(
              (m: { server_name: string; cpu: number; memory: number; disk: number }) =>
                `- ${m.server_name}: CPU ${m.cpu.toFixed(1)}%, Memory ${m.memory.toFixed(1)}%, Disk ${m.disk.toFixed(1)}%`
            )
            .join('\n')}`
        : '';

    const prompt = `ì„œë²„ ì¥ì•  ë³´ê³ ì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

## ìš”ì²­ ì •ë³´
- ëŒ€ìƒ ì„œë²„: ${serverId || 'ì „ì²´ ì„œë²„'}
- ìƒí™©: ${query || 'í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ë¶„ì„'}
- ì‹¬ê°ë„ íŒíŠ¸: ${severity || 'ìë™ íŒë‹¨'}
- ì¹´í…Œê³ ë¦¬: ${category || 'ì¼ë°˜'}
${metricsContext}

## í˜„ì¬ ìˆ˜ì§‘ëœ ë°ì´í„°
- ì´ìƒ ê°ì§€: ${JSON.stringify(anomalyData).slice(0, 500)}
- íŠ¸ë Œë“œ: ${JSON.stringify(trendData).slice(0, 300)}

## ì¤‘ìš”: ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”

\`\`\`json
{
  "title": "ê°„ê²°í•œ ìƒí™© ìš”ì•½ (ì˜ˆ: ì›¹ ì„œë²„ CPU ê³¼ë¶€í•˜ ê²½ê³ )",
  "severity": "critical|high|medium|low ì¤‘ í•˜ë‚˜",
  "description": "í˜„ì¬ ìƒí™©ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… (2-3ë¬¸ì¥)",
  "affected_servers": ["ì„œë²„ID1", "ì„œë²„ID2"],
  "root_cause": "ê·¼ë³¸ ì›ì¸ ë¶„ì„ ê²°ê³¼",
  "recommendations": [
    {"action": "ì¡°ì¹˜ ë‚´ìš©", "priority": "high|medium|low", "expected_impact": "ì˜ˆìƒ íš¨ê³¼"}
  ],
  "pattern": "ê°ì§€ëœ íŒ¨í„´ ì„¤ëª…"
}
\`\`\`

ìœ„ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.`;

    console.log(`ğŸ¤– [Incident Report] Invoking Reporter Agent with JSON output...`);

    const result = await reporterAgent.generate({
      prompt,
    });

    const durationMs = Date.now() - startTime;
    console.log(`âœ… [Incident Report] Agent completed in ${durationMs}ms`);

    // 4. Parse JSON from agent response
    const agentReport = parseAgentJsonResponse(result.text, toolBasedData);

    // 5. Merge tool-based data with agent response (agent takes precedence for text fields)
    const finalReport = {
      id: toolBasedData.id,
      title: agentReport.title || toolBasedData.title,
      severity: agentReport.severity || toolBasedData.severity,
      description: agentReport.description || toolBasedData.description,
      affected_servers: agentReport.affected_servers.length > 0
        ? agentReport.affected_servers
        : toolBasedData.affected_servers,
      anomalies: toolBasedData.anomalies, // From tool
      system_summary: toolBasedData.system_summary, // From tool
      timeline: toolBasedData.timeline, // From tool
      root_cause_analysis: {
        primary_cause: agentReport.root_cause || 'ë„êµ¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”',
        contributing_factors: [],
      },
      recommendations: agentReport.recommendations.length > 0
        ? agentReport.recommendations
        : toolBasedData.recommendations,
      pattern: agentReport.pattern || toolBasedData.pattern,
      created_at: new Date().toISOString(),
      _agentResponse: result.text,
      _source: 'Reporter Agent + Tool Data (Hybrid)',
      _durationMs: durationMs,
    };

    return jsonSuccess(c, finalReport);
  } catch (error) {
    return handleApiError(c, error, 'Incident Report');
  }
});

/**
 * Extract structured data from tool results
 */
function extractToolBasedData(
  anomalyData: unknown,
  trendData: unknown,
  timelineData: unknown,
  serverId?: string
): {
  id: string;
  title: string;
  severity: string;
  description: string;
  affected_servers: string[];
  anomalies: Array<{ server_id: string; server_name: string; metric: string; value: number; severity: string }>;
  system_summary: { totalServers: number; healthyServers: number; warningServers: number; criticalServers: number };
  timeline: Array<{ timestamp: string; event: string; severity: string }>;
  recommendations: Array<{ action: string; priority: string; expected_impact: string }>;
  pattern: string;
} {
  const id = randomUUID();

  // Parse anomaly data
  const anomaly = anomalyData as {
    hasAnomalies?: boolean;
    anomalyCount?: number;
    results?: Array<{ serverId: string; serverName?: string; metric: string; currentValue: number; severity: string }>;
    summary?: { totalServers?: number; healthyCount?: number; warningCount?: number; criticalCount?: number };
  } | undefined;

  const anomalies: Array<{ server_id: string; server_name: string; metric: string; value: number; severity: string }> = [];
  if (anomaly?.results) {
    for (const r of anomaly.results) {
      anomalies.push({
        server_id: r.serverId,
        server_name: r.serverName || r.serverId,
        metric: r.metric,
        value: r.currentValue,
        severity: r.severity,
      });
    }
  }

  // System summary from anomaly data
  const summary = anomaly?.summary || {};
  const systemSummary = {
    totalServers: summary.totalServers ?? 0,
    healthyServers: summary.healthyCount ?? 0,
    warningServers: summary.warningCount ?? 0,
    criticalServers: summary.criticalCount ?? 0,
  };

  // Parse timeline data
  const tl = timelineData as { events?: Array<{ timestamp: string; description: string; severity: string }> } | null;
  const timeline: Array<{ timestamp: string; event: string; severity: string }> = [];
  if (tl?.events) {
    for (const e of tl.events) {
      timeline.push({
        timestamp: e.timestamp,
        event: e.description,
        severity: e.severity,
      });
    }
  }

  // Determine severity from data
  let severity = 'info';
  if (systemSummary.criticalServers > 0 || anomalies.some((a) => a.severity === 'critical')) {
    severity = 'critical';
  } else if (systemSummary.warningServers > 0 || anomalies.some((a) => a.severity === 'warning' || a.severity === 'medium')) {
    severity = 'warning';
  }

  // Parse trend data for recommendations
  const trend = trendData as { summary?: { hasRisingTrends?: boolean; risingMetrics?: string[] } } | undefined;
  const recommendations: Array<{ action: string; priority: string; expected_impact: string }> = [];
  if (trend?.summary?.hasRisingTrends && trend.summary.risingMetrics) {
    for (const metric of trend.summary.risingMetrics.slice(0, 3)) {
      recommendations.push({
        action: `${metric} ìƒìŠ¹ ì¶”ì„¸ ëª¨ë‹ˆí„°ë§ ê°•í™”`,
        priority: 'medium',
        expected_impact: 'ì‚¬ì „ ì¥ì•  ì˜ˆë°©',
      });
    }
  }

  // Generate title and description
  const title = anomaly?.hasAnomalies
    ? `ì´ìƒ ê°ì§€: ${anomaly.anomalyCount}ê±´ ë°œê²¬`
    : 'ì„œë²„ ìƒíƒœ ì •ìƒ';
  const description = anomaly?.hasAnomalies
    ? `ì´ ${systemSummary.totalServers}ëŒ€ ì„œë²„ ì¤‘ ${anomaly.anomalyCount}ê±´ì˜ ì´ìƒ ì§•í›„ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.`
    : `ì´ ${systemSummary.totalServers}ëŒ€ ì„œë²„ê°€ ì •ìƒ ìƒíƒœì…ë‹ˆë‹¤.`;

  return {
    id,
    title,
    severity,
    description,
    affected_servers: serverId ? [serverId] : anomalies.map((a) => a.server_id),
    anomalies,
    system_summary: systemSummary,
    timeline,
    recommendations,
    pattern: anomaly?.hasAnomalies ? 'ì´ìƒ íŒ¨í„´ ê°ì§€ë¨' : 'ì •ìƒ íŒ¨í„´',
  };
}

/**
 * Parse JSON response from agent
 */
function parseAgentJsonResponse(
  text: string,
  fallback: { title: string; severity: string; affected_servers: string[]; recommendations: Array<{ action: string; priority: string; expected_impact: string }>; pattern: string }
): {
  title: string;
  severity: string;
  description: string;
  affected_servers: string[];
  root_cause: string;
  recommendations: Array<{ action: string; priority: string; expected_impact: string }>;
  pattern: string;
} {
  // Try to extract JSON from response
  const jsonMatch = text.match(/```json\s*([\s\S]*?)\s*```/) || text.match(/\{[\s\S]*\}/);

  if (jsonMatch) {
    try {
      const jsonStr = jsonMatch[1] || jsonMatch[0];
      const parsed = JSON.parse(jsonStr);

      return {
        title: parsed.title || fallback.title,
        severity: parsed.severity || fallback.severity,
        description: parsed.description || '',
        affected_servers: Array.isArray(parsed.affected_servers) ? parsed.affected_servers : fallback.affected_servers,
        root_cause: parsed.root_cause || '',
        recommendations: Array.isArray(parsed.recommendations) ? parsed.recommendations : fallback.recommendations,
        pattern: parsed.pattern || fallback.pattern,
      };
    } catch (e) {
      console.warn('âš ï¸ [Incident Report] JSON parse failed, using regex extraction');
    }
  }

  // Fallback to regex extraction (legacy parser)
  return {
    title: fallback.title,
    severity: fallback.severity,
    description: '',
    affected_servers: fallback.affected_servers,
    root_cause: '',
    recommendations: fallback.recommendations,
    pattern: fallback.pattern,
  };
}

/**
 * Parse Reporter Agent response into structured format
 */
function parseReporterResponse(text: string, serverId?: string): {
  id: string;
  title: string;
  severity: string;
  affectedServers: string[];
  rootCauseAnalysis: { primary_cause: string; contributing_factors: string[] };
  recommendations: Array<{ action: string; priority: string; expected_impact: string }>;
  timeline: Array<{ timestamp: string; event: string; severity: string }>;
  pattern: string;
} {
  const id = randomUUID();

  // Extract title (first line or ## heading)
  const titleMatch = text.match(/^#*\s*(.+?)[\n\r]/m) || text.match(/ì œëª©[:\s]*(.+?)[\n\r]/i);
  const title = titleMatch?.[1]?.trim() || 'ì„œë²„ ìƒíƒœ ë¶„ì„ ë³´ê³ ì„œ';

  // Extract severity
  const severityMatch = text.match(/ì‹¬ê°ë„[:\s]*(critical|high|medium|low|ìœ„í—˜|ë†’ìŒ|ì¤‘ê°„|ë‚®ìŒ)/i);
  let severity = 'medium';
  if (severityMatch) {
    const s = severityMatch[1].toLowerCase();
    if (s === 'critical' || s === 'ìœ„í—˜') severity = 'critical';
    else if (s === 'high' || s === 'ë†’ìŒ') severity = 'high';
    else if (s === 'low' || s === 'ë‚®ìŒ') severity = 'low';
  }

  // Extract affected servers
  const serversMatch = text.match(/ì˜í–¥.*ì„œë²„[:\s]*([^\n]+)/i) || text.match(/ì„œë²„[:\s]*([^\n]*(?:,|ã€)[^\n]*)/i);
  const affectedServers = serversMatch
    ? serversMatch[1].split(/[,ã€\s]+/).filter(Boolean).map(s => s.trim())
    : serverId ? [serverId] : [];

  // Extract root cause
  const causeMatch = text.match(/ê·¼ë³¸\s*ì›ì¸[:\s]*([^\n]+)/i) || text.match(/ì›ì¸[:\s]*([^\n]+)/i);
  const rootCauseAnalysis = {
    primary_cause: causeMatch?.[1]?.trim() || 'ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”',
    contributing_factors: [] as string[],
  };

  // Extract recommendations
  const recommendations: Array<{ action: string; priority: string; expected_impact: string }> = [];
  const recMatches = text.matchAll(/(?:ê¶Œì¥|ì¡°ì¹˜|í•´ê²°)[:\s]*[-â€¢*]?\s*(.+)/gi);
  for (const match of recMatches) {
    if (match[1] && match[1].length > 5) {
      recommendations.push({
        action: match[1].trim(),
        priority: severity === 'critical' ? 'high' : 'medium',
        expected_impact: 'ìƒíƒœ ê°œì„  ì˜ˆìƒ',
      });
    }
  }
  // Also try numbered list
  const numberedRecs = text.matchAll(/\d+\.\s*(.+)/g);
  for (const match of numberedRecs) {
    if (match[1] && match[1].length > 10 && recommendations.length < 5) {
      recommendations.push({
        action: match[1].trim(),
        priority: 'medium',
        expected_impact: 'ìƒíƒœ ê°œì„  ì˜ˆìƒ',
      });
    }
  }

  // Extract pattern
  const patternMatch = text.match(/íŒ¨í„´[:\s]*([^\n]+)/i);
  const pattern = patternMatch?.[1]?.trim() || 'ë¶„ì„ ì™„ë£Œ';

  return {
    id,
    title,
    severity,
    affectedServers,
    rootCauseAnalysis,
    recommendations: recommendations.slice(0, 5),
    timeline: [],
    pattern,
  };
}

/**
 * Fallback when Reporter Agent is unavailable
 */
async function incidentReportFallback(
  c: Context,
  { serverId, query, severity, category }: { serverId?: string; query?: string; severity?: string; category?: string }
) {
  // Type definitions for searchKnowledgeBase
  type KBCategory = 'incident' | 'troubleshooting' | 'security' | 'performance' | 'best_practice';
  type KBSeverity = 'critical' | 'high' | 'medium' | 'low';

  // 1. RAG search
  const ragResult = await searchKnowledgeBase.execute!({
    query: query || 'ì„œë²„ ì¥ì•  ë¶„ì„',
    category: category as KBCategory | undefined,
    severity: severity as KBSeverity | undefined,
    useGraphRAG: true,
  }, { toolCallId: 'incident-report-rag', messages: [] });

  // 2. Extract keywords and recommend commands
  const keywords = extractKeywordsFromQuery(query || '');
  const commandResult = await recommendCommands.execute!(
    { keywords },
    { toolCallId: 'incident-report-commands', messages: [] }
  );

  // 3. Anomaly detection for context
  const anomalyResult = await detectAnomalies.execute!({
    serverId: serverId || undefined,
    metricType: 'all',
  }, { toolCallId: 'incident-report-anomaly', messages: [] });

  console.log(`âœ… [Incident Report Fallback] Generated for ${serverId || 'general'}`);

  return jsonSuccess(c, {
    id: randomUUID(),
    title: 'ì„œë²„ ìƒíƒœ ë¶„ì„ ë³´ê³ ì„œ (Fallback)',
    severity: severity || 'medium',
    affected_servers: serverId ? [serverId] : [],
    root_cause_analysis: { primary_cause: 'ìë™ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”', contributing_factors: [] },
    recommendations: [],
    timeline: [],
    pattern: 'fallback',
    knowledgeBase: ragResult,
    recommendedCommands: commandResult,
    currentStatus: anomalyResult,
    created_at: new Date().toISOString(),
    _source: 'Cloud Run Fallback (Direct Tool)',
  });
}

// Batch processing constants
const BATCH_LIMITS = {
  MAX_SERVERS: 50,
  DEFAULT_CHUNK_SIZE: 10,
} as const;

/**
 * POST /analyze-batch - Batch Server Analysis
 *
 * Uses Precomputed State for O(1) lookup
 * Analyzes multiple servers in parallel with chunking for memory efficiency
 *
 * @limit Max 50 servers per request
 */
analyticsRouter.post('/analyze-batch', async (c: Context) => {
  try {
    const body = await c.req.json().catch(() => ({}));
    const serverIds: string[] = Array.isArray(body.serverIds) ? body.serverIds : [];
    const analysisType = body.analysisType || 'anomaly';

    // Input validation
    if (serverIds.length > BATCH_LIMITS.MAX_SERVERS) {
      return c.json({
        success: false,
        error: `Too many servers requested. Maximum: ${BATCH_LIMITS.MAX_SERVERS}`,
      }, 400);
    }

    console.log(`ğŸ”¬ [Batch Analysis] servers=${serverIds.length}, type=${analysisType}`);

    // Get servers from precomputed state (O(1))
    const state = getCurrentState();
    const targetServers = serverIds.length > 0
      ? state.servers.filter((s) => serverIds.includes(s.id)).slice(0, BATCH_LIMITS.MAX_SERVERS)
      : state.servers.slice(0, BATCH_LIMITS.MAX_SERVERS);

    const results = await Promise.all(
      targetServers.map(async (server) => {
        const anomalyResult = await detectAnomalies.execute!({
          serverId: server.id,
          metricType: 'all',
        }, { toolCallId: `batch-${server.id}`, messages: [] });

        return {
          serverId: server.id,
          serverName: server.name,
          ...anomalyResult,
        };
      })
    );

    return jsonSuccess(c, {
      totalServers: results.length,
      analysisType,
      results,
      _dataSource: 'precomputed-state',
    });
  } catch (error) {
    return handleApiError(c, error, 'Batch Analysis');
  }
});

/**
 * POST /rag/sync-incidents - Sync Incidents to RAG Knowledge Base
 *
 * Injects approved incident reports into knowledge_base for RAG search.
 * Should be called periodically or after batch approvals.
 *
 * @version 1.0.0 - RAG injection
 */
analyticsRouter.post('/rag/sync-incidents', async (c: Context) => {
  try {
    const { limit = 10, daysBack = 30 } = await c.req.json().catch(() => ({}));

    console.log(`ğŸ“¥ [RAG Sync] Starting incident sync (limit=${limit}, days=${daysBack})`);

    const result = await syncIncidentsToRAG({ limit, daysBack });

    if (!result.success && result.synced === 0) {
      return c.json({
        success: false,
        error: result.errors.join('; ') || 'Sync failed',
        timestamp: new Date().toISOString(),
      }, 500);
    }

    return jsonSuccess(c, {
      ...result,
      message: `Synced ${result.synced} incidents to RAG knowledge base`,
      timestamp: new Date().toISOString(),
    });
  } catch (error) {
    return handleApiError(c, error, 'RAG Sync Incidents');
  }
});

/**
 * GET /rag/stats - Get RAG Injection Statistics
 *
 * Returns counts of total incidents, synced incidents, and pending sync.
 */
analyticsRouter.get('/rag/stats', async (c: Context) => {
  try {
    const stats = await getRAGInjectionStats();

    if (!stats) {
      return c.json({
        success: false,
        error: 'Unable to fetch RAG stats (Supabase not available)',
        timestamp: new Date().toISOString(),
      }, 503);
    }

    return jsonSuccess(c, {
      ...stats,
      syncRatio: stats.totalIncidents > 0
        ? Math.round((stats.syncedIncidents / stats.totalIncidents) * 100)
        : 100,
      timestamp: new Date().toISOString(),
    });
  } catch (error) {
    return handleApiError(c, error, 'RAG Stats');
  }
});
