/**
 * ML Provider - Google Cloud Functions ê¸°ë°˜ ì‹¤ì œ ML ë¶„ì„
 *
 * GCP Function: ml-analytics-engine (scikit-learn ê¸°ë°˜)
 *
 * ê¸°ëŠ¥:
 * - ì´ìƒ íƒì§€ (Anomaly Detection) - 3-sigma í†µê³„ ë°©ë²•
 * - íŠ¸ë Œë“œ ë¶„ì„ (Trend Analysis) - ì„ í˜• íšŒê·€
 * - íŒ¨í„´ ì¸ì‹ (Pattern Recognition) - Peak hour, Weekly cycle
 *
 * ìµœì í™”:
 * - 5ë¶„ TTL ìºì‹± (ë¬´ë£Œ í‹°ì–´ ìµœì í™”)
 * - ìµœì†Œ ë°ì´í„° ê²€ì¦ (10ê°œ ë¯¸ë§Œ ì‹œ ë¹ˆ ê²°ê³¼)
 * - ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì„ íƒì  í™œì„±í™”
 */

import type {
  AIScenario,
  IContextProvider,
  MLData,
  ProviderContext,
  ProviderOptions,
} from '@/lib/ai/core/types';

// ============================================================================
// GCP Function API ì¸í„°í˜ì´ìŠ¤
// ============================================================================

interface MetricDataPoint {
  timestamp: string;
  value: number;
  server_id: string;
  metric_type: string;
}

interface MLAnalyticsRequest {
  metrics: MetricDataPoint[];
  context?: {
    analysis_type?:
      | 'anomaly_detection'
      | 'trend_analysis'
      | 'pattern_recognition';
    threshold?: number;
  };
}

interface AnomalyResult {
  is_anomaly: boolean;
  severity: 'low' | 'medium' | 'high';
  confidence: number;
  timestamp: string;
  value: number;
  expected_range: [number, number];
}

interface TrendResult {
  direction: 'increasing' | 'decreasing' | 'stable';
  rate_of_change: number;
  prediction_24h: number;
  confidence: number;
}

interface PatternResult {
  type: string;
  description: string;
  confidence: number;
}

interface MLAnalyticsResponse {
  success: boolean;
  data: {
    anomalies: AnomalyResult[];
    trend: TrendResult;
    patterns: PatternResult[];
    recommendations: string[];
  };
  function_name: string;
  source: string;
  timestamp: string;
  performance: {
    processing_time_ms: number;
    metrics_analyzed: number;
    anomalies_found: number;
  };
}

// ============================================================================
// Cache Entry
// ============================================================================

interface CacheEntry {
  data: MLData;
  timestamp: number;
}

// ============================================================================
// ML Provider
// ============================================================================

export class MLProvider implements IContextProvider {
  readonly name = 'ML Analytics';
  readonly type = 'ml' as const;

  private readonly gcpEndpoint =
    process.env.NEXT_PUBLIC_GCP_ML_ANALYTICS_ENDPOINT ||
    'https://asia-northeast3-openmanager-free-tier.cloudfunctions.net/ml-analytics-engine';

  private cache = new Map<string, CacheEntry>();
  private readonly cacheTTL = 5 * 60 * 1000; // 5ë¶„ (ë¬´ë£Œ í‹°ì–´ ìµœì í™”)

  /**
   * ë©”ì¸ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸: ML ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
   */
  async getContext(
    query: string,
    options?: ProviderOptions
  ): Promise<ProviderContext> {
    const cacheKey = this.getCacheKey(query, options);
    const cached = this.getFromCache(cacheKey);

    if (cached) {
      return {
        type: 'ml',
        data: cached,
        metadata: {
          source: 'gcp-ml-analytics',
          confidence: 0.9,
          cached: true,
        },
      };
    }

    // ë©”íŠ¸ë¦­ ë°ì´í„° ì¤€ë¹„
    const metrics = await this.prepareMetrics(options);

    // âœ… undefined ì²´í¬ ì¶”ê°€ (í…ŒìŠ¤íŠ¸ í™˜ê²½ ëŒ€ì‘)
    if (!metrics || !Array.isArray(metrics) || metrics.length < 10) {
      // ìµœì†Œ ë°ì´í„° ë¶€ì¡± ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
      const dataLength = metrics ? metrics.length : 0;
      console.warn('[MLProvider] Insufficient metrics data:', dataLength);
      return this.getEmptyContext('insufficient_data');
    }

    const request: MLAnalyticsRequest = {
      metrics,
      context: {
        analysis_type: this.getAnalysisType(options),
        threshold: options?.threshold || 0.8,
      },
    };

    try {
      const response = await fetch(this.gcpEndpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(request),
        signal: AbortSignal.timeout(10000), // 10ì´ˆ íƒ€ì„ì•„ì›ƒ
      });

      if (!response.ok) {
        throw new Error(`ML Analytics API error: ${response.status}`);
      }

      const result: MLAnalyticsResponse = await response.json();

      if (!result.success) {
        throw new Error('ML Analytics returned unsuccessful response');
      }

      const mlData: MLData = this.transformToMLData(result, metrics);
      this.setCache(cacheKey, mlData);

      return {
        type: 'ml',
        data: mlData,
        metadata: {
          source: 'gcp-ml-analytics',
          confidence: result.data.trend.confidence,
          cached: false,
          processingTime: result.performance.processing_time_ms,
        },
      };
    } catch (error) {
      console.error('[MLProvider] API call failed:', error);
      return this.getEmptyContext('api_error');
    }
  }

  /**
   * ì‹œë‚˜ë¦¬ì˜¤ë³„ í™œì„±í™” ì—¬ë¶€
   * ML ë¶„ì„ì´ ìœ ìš©í•œ ì‹œë‚˜ë¦¬ì˜¤ë§Œ í™œì„±í™”
   */
  isEnabled(scenario: AIScenario): boolean {
    const enabledScenarios: AIScenario[] = [
      'performance-report',
      'failure-analysis',
      'optimization-advice',
    ];
    return enabledScenarios.includes(scenario);
  }

  // ==========================================================================
  // Private Methods
  // ==========================================================================

  /**
   * GCP ì‘ë‹µì„ MLData íƒ€ì…ìœ¼ë¡œ ë³€í™˜
   */
  private transformToMLData(
    result: MLAnalyticsResponse,
    metrics: MetricDataPoint[]
  ): MLData {
    return {
      anomalies: result.data.anomalies.map((a) => ({
        severity: a.severity,
        description: `ê°’ ${a.value.toFixed(2)}ì´(ê°€) ì˜ˆìƒ ë²”ìœ„ [${a.expected_range[0].toFixed(2)}, ${a.expected_range[1].toFixed(2)}]ë¥¼ ë²—ì–´ë‚¨`,
        metric:
          metrics.find((m) => m.timestamp === a.timestamp)?.metric_type ||
          'unknown',
        value: a.value,
        timestamp: a.timestamp,
      })),
      trends: [
        {
          direction: result.data.trend.direction,
          confidence: result.data.trend.confidence,
          prediction: result.data.trend.prediction_24h,
          timeframe: '24h',
        },
      ],
      patterns: result.data.patterns.map((p) => ({
        type: p.type,
        description: p.description,
        confidence: p.confidence,
      })),
      recommendations: result.data.recommendations,
    };
  }

  /**
   * ë¶„ì„ íƒ€ì… ê²°ì • (options ê¸°ë°˜)
   */
  private getAnalysisType(
    options?: ProviderOptions
  ): 'anomaly_detection' | 'trend_analysis' | 'pattern_recognition' {
    return (
      (options?.analysisType as
        | 'anomaly_detection'
        | 'trend_analysis'
        | 'pattern_recognition') || 'anomaly_detection'
    );
  }

  /**
   * ë©”íŠ¸ë¦­ ë°ì´í„° ì¤€ë¹„
   * ğŸ¯ scenario-loaderì—ì„œ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ë©”íŠ¸ë¦­ ë¡œë”© (Single Source of Truth)
   */
  private async prepareMetrics(
    options?: ProviderOptions
  ): Promise<MetricDataPoint[]> {
    if (options?.metricsData) {
      return options.metricsData as MetricDataPoint[];
    }

    // ğŸ¯ scenario-loaderì—ì„œ í˜„ì¬ ì‹œê°„ëŒ€ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ë¡œë”©
    const { loadHourlyScenarioData } = await import(
      '@/services/scenario/scenario-loader'
    );
    const scenarioMetrics = await loadHourlyScenarioData();

    // EnhancedServerMetrics[] â†’ MetricDataPoint[] ë³€í™˜
    const metrics: MetricDataPoint[] = [];
    const now = new Date();
    const isoTimestamp = now.toISOString();

    for (const serverMetric of scenarioMetrics) {
      // 1ê°œ ì„œë²„ ë©”íŠ¸ë¦­ â†’ 4ê°œ MetricDataPoint (cpu, memory, disk, network)
      metrics.push(
        {
          timestamp: isoTimestamp,
          value: serverMetric.cpu,
          server_id: serverMetric.id,
          metric_type: 'cpu',
        },
        {
          timestamp: isoTimestamp,
          value: serverMetric.memory,
          server_id: serverMetric.id,
          metric_type: 'memory',
        },
        {
          timestamp: isoTimestamp,
          value: serverMetric.disk,
          server_id: serverMetric.id,
          metric_type: 'disk',
        },
        {
          timestamp: isoTimestamp,
          value: serverMetric.network,
          server_id: serverMetric.id,
          metric_type: 'network',
        }
      );
    }

    // GCP ìš”ì²­ ì œí•œ (1,000ê°œ)
    console.log(
      `âœ… Prepared ${metrics.length} metric data points from scenario data`
    );
    return metrics.slice(0, 1000);
  }

  /**
   * ìºì‹œ í‚¤ ìƒì„±
   */
  private getCacheKey(query: string, options?: ProviderOptions): string {
    const metricsHash = options?.metricsData
      ? JSON.stringify(options.metricsData).substring(0, 50)
      : 'no-metrics';
    return `ml:${query}:${metricsHash}`;
  }

  /**
   * ìºì‹œ ì¡°íšŒ
   */
  private getFromCache(key: string): MLData | null {
    const cached = this.cache.get(key);
    if (!cached) return null;

    const now = Date.now();
    if (now - cached.timestamp > this.cacheTTL) {
      this.cache.delete(key);
      return null;
    }

    return cached.data;
  }

  /**
   * ìºì‹œ ì €ì¥
   */
  private setCache(key: string, data: MLData): void {
    this.cache.set(key, { data, timestamp: Date.now() });

    // ìºì‹œ í¬ê¸° ì œí•œ (ìµœëŒ€ 100ê°œ)
    if (this.cache.size > 100) {
      const firstKey = this.cache.keys().next().value;
      if (firstKey) this.cache.delete(firstKey);
    }
  }

  /**
   * ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜ (ì—ëŸ¬ ë˜ëŠ” ë°ì´í„° ë¶€ì¡± ì‹œ)
   */
  private getEmptyContext(
    reason: 'insufficient_data' | 'api_error'
  ): ProviderContext {
    return {
      type: 'ml',
      data: {
        anomalies: [],
        trends: [],
        patterns: [],
        recommendations:
          reason === 'insufficient_data'
            ? ['ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë©”íŠ¸ë¦­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ìµœì†Œ 10ê°œ í•„ìš”)']
            : ['ML ë¶„ì„ ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.'],
      },
      metadata: {
        source: 'gcp-ml-analytics',
        confidence: 0,
        cached: false,
        error: reason,
      },
    };
  }
}
