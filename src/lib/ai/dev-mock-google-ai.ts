/**
 * ğŸ¤– ê°œë°œ í™˜ê²½ ì „ìš© Mock Google AI (Gemini)
 *
 * ê°œë°œ í™˜ê²½ì—ì„œ ì‹¤ì œ Google AI API ì—†ì´ë„ ì™„ì „í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” Mock AI
 * - í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë™ì  ì‘ë‹µ ìƒì„±
 * - í† í° ì‚¬ìš©ëŸ‰ ì‹œë®¬ë ˆì´ì…˜
 * - ëª¨ë¸ë³„ ì°¨ë³„í™”ëœ ì‘ë‹µ
 * - ì„œë²„ ëª¨ë‹ˆí„°ë§ ë„ë©”ì¸ íŠ¹í™”
 * - í•œêµ­ì–´ ì‘ë‹µ ì§€ì›
 */

interface DevMockGoogleAIOptions {
  defaultModel?: string;
  defaultTemperature?: number;
  maxTokens?: number;
  enableLogging?: boolean;
  responseDelay?: number; // ì‹¤ì œ API ì‘ë‹µ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
}

interface MockResponse {
  text: string;
  confidence: number;
  tokensUsed: number;
  processingTime: number;
}

interface ServerMonitoringPatterns {
  [key: string]: {
    keywords: string[];
    responses: string[];
    confidence: number;
  };
}

export class DevMockGoogleAI {
  private options: DevMockGoogleAIOptions;
  private stats = {
    totalRequests: 0,
    totalTokensUsed: 0,
    averageResponseTime: 0,
    modelUsage: new Map<string, number>(),
  };

  // ì„œë²„ ëª¨ë‹ˆí„°ë§ ë„ë©”ì¸ íŠ¹í™” ì‘ë‹µ íŒ¨í„´
  private patterns: ServerMonitoringPatterns = {
    serverStatus: {
      keywords: ['ì„œë²„', 'ìƒíƒœ', 'status', 'health', 'ì •ìƒ', 'í™•ì¸'],
      responses: [
        'í˜„ì¬ ëª¨ë“  ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤. CPU ì‚¬ìš©ë¥  í‰ê·  45%, ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  62%ë¡œ ì•ˆì •ì ì¸ ìƒíƒœì…ë‹ˆë‹¤.',
        '8ê°œ ì„œë²„ ì¤‘ 7ê°œê°€ ì •ìƒ, 1ê°œ ì„œë²„(app-prd-01)ì—ì„œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²½ê³ ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        'ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ: ì–‘í˜¸. ìµœê·¼ 24ì‹œê°„ ê°€ë™ë¥  99.95%ë¥¼ ê¸°ë¡í•˜ê³  ìˆìŠµë‹ˆë‹¤.',
      ],
      confidence: 0.9,
    },
    performance: {
      keywords: ['ì„±ëŠ¥', 'ì†ë„', 'performance', 'cpu', 'memory', 'ë©”ëª¨ë¦¬'],
      responses: [
        'CPU ì„±ëŠ¥ ë¶„ì„: í”¼í¬ ì‹œê°„ëŒ€ í‰ê·  72% ì‚¬ìš©ë¥ , ì•¼ê°„ ì‹œê°„ëŒ€ 15% ì‚¬ìš©ë¥ . ë¶€í•˜ ë¶„ì‚°ì´ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤.',
        'ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´: ì ì§„ì  ì¦ê°€ ì¶”ì„¸ í™•ì¸. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥ì„±ì„ ì¡°ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤.',
        'ì‘ë‹µ ì‹œê°„ ë¶„ì„: í‰ê·  152ms, 95 percentile 320msë¡œ ëª©í‘œì¹˜ ë‚´ì—ì„œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.',
      ],
      confidence: 0.88,
    },
    anomaly: {
      keywords: ['ì´ìƒ', 'ë¬¸ì œ', 'ì˜¤ë¥˜', 'error', 'anomaly', 'ì¥ì• '],
      responses: [
        'ìµœê·¼ 30ë¶„ê°„ db-main-01 ì„œë²„ì—ì„œ ë””ìŠ¤í¬ I/O ê¸‰ì¦ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë°±ì—… ì‘ì—… í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.',
        'ë¹„ì •ìƒì ì¸ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íŒ¨í„´ ê°ì§€: DDoS ê³µê²© ê°€ëŠ¥ì„±ì€ ë‚®ìœ¼ë‚˜ ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ê² ìŠµë‹ˆë‹¤.',
        'ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë²„ì—ì„œ ê°„í—ì ì¸ íƒ€ì„ì•„ì›ƒ ë°œìƒ. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì„¤ì • ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.',
      ],
      confidence: 0.85,
    },
    prediction: {
      keywords: ['ì˜ˆì¸¡', 'ì˜ˆìƒ', 'ì „ë§', 'predict', 'forecast', 'íŠ¸ë Œë“œ'],
      responses: [
        'í˜„ì¬ íŠ¸ë Œë“œ ê¸°ì¤€ 3ì¼ ë‚´ ë””ìŠ¤í¬ ìš©ëŸ‰ 80% ë„ë‹¬ ì˜ˆìƒ. ìš©ëŸ‰ í™•ì¥ì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
        'ë‹¤ìŒ ì£¼ íŠ¸ë˜í”½ ì˜ˆì¸¡: í‰ì†Œ ëŒ€ë¹„ 35% ì¦ê°€ ì˜ˆìƒ. ìŠ¤ì¼€ì¼ ì•„ì›ƒ ì¤€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤.',
        'CPU ì‚¬ìš©ë¥  íŒ¨í„´ ë¶„ì„ ê²°ê³¼, ë§¤ì£¼ í™”ìš”ì¼ ì˜¤í›„ 2-4ì‹œ í”¼í¬ ì˜ˆìƒë©ë‹ˆë‹¤.',
      ],
      confidence: 0.82,
    },
    recommendation: {
      keywords: ['ì¶”ì²œ', 'ê¶Œì¥', 'ê°œì„ ', 'recommend', 'suggest', 'ìµœì í™”'],
      responses: [
        'ê¶Œì¥ ì‚¬í•­: 1) Redis ìºì‹œ TTL 300ì´ˆë¡œ ì¡°ì •, 2) DB ì¸ë±ìŠ¤ ì¬êµ¬ì„±, 3) ë¡œë“œë°¸ëŸ°ì„œ ì•Œê³ ë¦¬ì¦˜ ë³€ê²½',
        'ì„±ëŠ¥ ìµœì í™” ë°©ì•ˆ: Nginx ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ë¥¼ CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° 8ê°œë¡œ ì¦ì„¤í•˜ì„¸ìš”.',
        'ë¹„ìš© ì ˆê° ë°©ì•ˆ: ì•¼ê°„ ì‹œê°„ëŒ€ ìë™ ìŠ¤ì¼€ì¼ ë‹¤ìš´ ì •ì±… ì ìš©ì‹œ ì›” 30% ë¹„ìš© ì ˆê° ê°€ëŠ¥í•©ë‹ˆë‹¤.',
      ],
      confidence: 0.87,
    },
  };

  constructor(options: DevMockGoogleAIOptions = {}) {
    this.options = {
      defaultModel: 'gemini-pro',
      defaultTemperature: 0.7,
      maxTokens: 1000,
      enableLogging: true,
      responseDelay: 200,
      ...options,
    };

    if (this.options.enableLogging) {
      console.log('ğŸ¤– Dev Mock Google AI ì´ˆê¸°í™”ë¨');
    }
  }

  /**
   * í…ìŠ¤íŠ¸ ìƒì„± (generateContent ë©”ì„œë“œ ì‹œë®¬ë ˆì´ì…˜)
   */
  async generateContent(params: {
    contents: Array<{ role: string; parts: Array<{ text: string }> }>;
    generationConfig?: {
      temperature?: number;
      maxOutputTokens?: number;
      topK?: number;
      topP?: number;
    };
  }): Promise<{
    response: {
      text: () => string;
      usageMetadata?: {
        promptTokenCount: number;
        candidatesTokenCount: number;
        totalTokenCount: number;
      };
    };
  }> {
    const startTime = Date.now();
    const prompt = params.contents[0]?.parts[0]?.text || '';
    
    // ì‘ë‹µ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
    if (this.options.responseDelay) {
      await new Promise(resolve => setTimeout(resolve, this.options.responseDelay));
    }

    // í”„ë¡¬í”„íŠ¸ ë¶„ì„ ë° ì‘ë‹µ ìƒì„±
    const response = this.generateResponse(prompt, params.generationConfig);
    
    // í†µê³„ ì—…ë°ì´íŠ¸
    this.updateStats(response, Date.now() - startTime);

    // Google AI API í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
    return {
      response: {
        text: () => response.text,
        usageMetadata: {
          promptTokenCount: Math.ceil(prompt.length / 4),
          candidatesTokenCount: response.tokensUsed,
          totalTokenCount: Math.ceil(prompt.length / 4) + response.tokensUsed,
        },
      },
    };
  }

  /**
   * í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë™ì  ì‘ë‹µ ìƒì„±
   */
  private generateResponse(
    prompt: string,
    config?: any
  ): MockResponse {
    const lowerPrompt = prompt.toLowerCase();
    
    // íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì ì ˆí•œ ì‘ë‹µ ì„ íƒ
    for (const [category, pattern] of Object.entries(this.patterns)) {
      const hasKeyword = pattern.keywords.some(keyword => 
        lowerPrompt.includes(keyword.toLowerCase())
      );
      
      if (hasKeyword) {
        const responseText = this.selectResponse(pattern.responses, prompt);
        const enrichedResponse = this.enrichResponse(responseText, prompt, category);
        
        return {
          text: enrichedResponse,
          confidence: pattern.confidence + (Math.random() * 0.05 - 0.025),
          tokensUsed: Math.ceil(enrichedResponse.length / 4),
          processingTime: Math.random() * 100 + 100,
        };
      }
    }

    // íŒ¨í„´ì— ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” ê²½ìš° ì¼ë°˜ ì‘ë‹µ
    return this.generateGenericResponse(prompt);
  }

  /**
   * ì‘ë‹µ ì„ íƒ (í”„ë¡¬í”„íŠ¸ í•´ì‹œ ê¸°ë°˜)
   */
  private selectResponse(responses: string[], prompt: string): string {
    const hash = prompt.split('').reduce((acc, char) => acc + char.charCodeAt(0), 0);
    return responses[hash % responses.length];
  }

  /**
   * ì‘ë‹µ ë³´ê°• (ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€)
   */
  private enrichResponse(base: string, prompt: string, category: string): string {
    const timestamp = new Date().toLocaleString('ko-KR');
    
    // ì„œë²„ ì´ë¦„ì´ ì–¸ê¸‰ëœ ê²½ìš° íŠ¹ì • ì„œë²„ ì •ë³´ ì¶”ê°€
    const serverMatch = prompt.match(/(web|app|db|file|backup)-[a-z]+-\d+/i);
    if (serverMatch) {
      base = `${serverMatch[0]} ì„œë²„ ë¶„ì„ ê²°ê³¼:\n${base}`;
    }

    // ì‹œê°„ ì •ë³´ ì¶”ê°€
    if (prompt.includes('ìµœê·¼') || prompt.includes('í˜„ì¬')) {
      base += `\n\n(ê¸°ì¤€ ì‹œê°: ${timestamp})`;
    }

    // ì‹ ë¢°ë„ ì •ë³´ ì¶”ê°€ (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
    if (this.options.enableLogging) {
      base += `\n\n[Mock AI: ${category} ì¹´í…Œê³ ë¦¬, ì‹ ë¢°ë„ ${(this.patterns[category].confidence * 100).toFixed(0)}%]`;
    }

    return base;
  }

  /**
   * ì¼ë°˜ ì‘ë‹µ ìƒì„± (íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ)
   */
  private generateGenericResponse(prompt: string): MockResponse {
    const responses = [
      'ì…ë ¥í•˜ì‹  ë‚´ìš©ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì„œë²„ ëª¨ë‹ˆí„°ë§ ê´€ë ¨ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
      'í•´ë‹¹ ìš”ì²­ì— ëŒ€í•œ ë¶„ì„ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ë” ë‚˜ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
      'ì‹œìŠ¤í…œ ì „ë°˜ì ì¸ ìƒíƒœëŠ” ì–‘í˜¸í•©ë‹ˆë‹¤. íŠ¹ì • ë©”íŠ¸ë¦­ì´ë‚˜ ì„œë²„ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹ ê°€ìš”?',
    ];

    const text = responses[Math.floor(Math.random() * responses.length)];
    
    return {
      text,
      confidence: 0.65,
      tokensUsed: Math.ceil(text.length / 4),
      processingTime: Math.random() * 50 + 50,
    };
  }

  /**
   * í†µê³„ ì—…ë°ì´íŠ¸
   */
  private updateStats(response: MockResponse, processingTime: number): void {
    this.stats.totalRequests++;
    this.stats.totalTokensUsed += response.tokensUsed;
    this.stats.averageResponseTime = 
      (this.stats.averageResponseTime * (this.stats.totalRequests - 1) + processingTime) / 
      this.stats.totalRequests;

    const model = this.options.defaultModel || 'gemini-pro';
    this.stats.modelUsage.set(
      model,
      (this.stats.modelUsage.get(model) || 0) + 1
    );
  }

  /**
   * í†µê³„ ì¡°íšŒ
   */
  getStats(): Record<string, any> {
    return {
      ...this.stats,
      modelUsage: Array.from(this.stats.modelUsage.entries()),
      tokensPerRequest: this.stats.totalRequests > 0 
        ? Math.round(this.stats.totalTokensUsed / this.stats.totalRequests)
        : 0,
    };
  }

  /**
   * Mock ì‹œë‚˜ë¦¬ì˜¤ ì¶”ê°€
   */
  addScenario(
    name: string,
    keywords: string[],
    responses: string[],
    confidence: number = 0.85
  ): void {
    this.patterns[name] = { keywords, responses, confidence };
    
    if (this.options.enableLogging) {
      console.log(`ğŸ“ ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ ì¶”ê°€ë¨: ${name}`);
    }
  }

  /**
   * Mock ë¦¬ì…‹
   */
  reset(): void {
    this.stats = {
      totalRequests: 0,
      totalTokensUsed: 0,
      averageResponseTime: 0,
      modelUsage: new Map<string, number>(),
    };
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let devMockGoogleAIInstance: DevMockGoogleAI | null = null;

export function getDevMockGoogleAI(): DevMockGoogleAI {
  if (!devMockGoogleAIInstance) {
    devMockGoogleAIInstance = new DevMockGoogleAI({
      enableLogging: process.env.NODE_ENV === 'development',
      responseDelay: process.env.NODE_ENV === 'test' ? 0 : 200,
    });
  }

  return devMockGoogleAIInstance;
}

// Google Generative AI í˜¸í™˜ ì¸í„°í˜ì´ìŠ¤
export class MockGoogleGenerativeAI {
  private mockAI: DevMockGoogleAI;

  constructor(apiKey?: string) {
    this.mockAI = getDevMockGoogleAI();
    if (process.env.NODE_ENV === 'development') {
      console.log('ğŸ­ Mock Google Generative AI ì´ˆê¸°í™” (API í‚¤ ë¶ˆí•„ìš”)');
    }
  }

  getGenerativeModel(params: { model: string }): {
    generateContent: typeof DevMockGoogleAI.prototype.generateContent;
  } {
    return {
      generateContent: this.mockAI.generateContent.bind(this.mockAI),
    };
  }
}