/**
 * ğŸš€ Vercel Edge Runtime í˜¸í™˜ API ë°°ì¹­ ì‹œìŠ¤í…œ
 *
 * Vercel ë¬´ë£Œ í‹°ì–´ ìµœì í™”:
 * - ë™ì‹œ ìš”ì²­ ìˆ˜ ìµœì†Œí™” (10ê°œ í•¨ìˆ˜ ì œí•œ ê³ ë ¤)
 * - ì½œë“œ ìŠ¤íƒ€íŠ¸ ì§€ì—° ìµœì†Œí™”
 * - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” (128MB ì œí•œ)
 * - Edge Runtime í˜¸í™˜ì„± ë³´ì¥
 */

interface APIRequest {
  id: string;
  endpoint: string;
  options?: RequestInit;
  priority?: 'high' | 'normal' | 'low';
}

interface APIResponse<T = unknown> {
  id: string;
  data?: T;
  error?: string;
  status: number;
  timing: {
    queued: number;
    executed: number;
    duration: number;
  };
}

interface BatchOptions {
  maxBatchSize: number;
  batchDelay: number;
  timeout: number;
  retryAttempts: number;
}

/**
 * ğŸ›¡ï¸ APIResponse íƒ€ì… ê°€ë“œ (Phase 76)
 */
function isValidAPIResponse(value: unknown): value is APIResponse {
  if (!value || typeof value !== 'object') return false;

  const response = value as Partial<APIResponse>;

  return (
    typeof response.id === 'string' &&
    typeof response.status === 'number' &&
    typeof response.timing === 'object' &&
    response.timing !== null &&
    typeof response.timing.queued === 'number' &&
    typeof response.timing.executed === 'number' &&
    typeof response.timing.duration === 'number'
  );
}

/**
 * Vercel Edge Runtime ìµœì í™” API ë°°ì²˜
 * - ë©”ëª¨ë¦¬ íš¨ìœ¨ì : WeakMap ì‚¬ìš©ìœ¼ë¡œ GC ì¹œí™”ì 
 * - íƒ€ì„ì•„ì›ƒ ê´€ë¦¬: Edge í™˜ê²½ì˜ 10ì´ˆ ì œí•œ ê³ ë ¤
 * - ìš°ì„ ìˆœìœ„ í: Critical ìš”ì²­ ìš°ì„  ì²˜ë¦¬
 */
class VercelOptimizedAPIBatcher {
  private readonly options: BatchOptions;
  private readonly queue = new Map<string, APIRequest>();
  private readonly pendingPromises = new Map<
    string,
    {
      resolve: (value: APIResponse<unknown>) => void;
      reject: (error: Error) => void;
      timestamp: number;
    }
  >();

  private batchTimer: NodeJS.Timeout | null = null;
  private isProcessing = false;

  constructor(options: Partial<BatchOptions> = {}) {
    this.options = {
      maxBatchSize: 8, // Vercel ë¬´ë£Œ í‹°ì–´ ìµœì í™” (ë™ì‹œ ìš”ì²­ ì œí•œ)
      batchDelay: 50, // 50ms ì§€ì—°ìœ¼ë¡œ ë°°ì¹­ (UX vs íš¨ìœ¨ì„± ê· í˜•)
      timeout: 8000, // 8ì´ˆ íƒ€ì„ì•„ì›ƒ (Vercel 10ì´ˆ ì œí•œ ê³ ë ¤)
      retryAttempts: 2, // ì¬ì‹œë„ ìµœì†Œí™” (ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¹„ìš©)
      ...options,
    };
  }

  /**
   * API ìš”ì²­ì„ ë°°ì¹˜ì— ì¶”ê°€
   * Vercel Edge í™˜ê²½ì—ì„œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  íì‰
   */
  async request<T = unknown>(request: APIRequest): Promise<APIResponse<T>> {
    return new Promise((resolve, reject) => {
      // ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€: ì˜¤ë˜ëœ ìš”ì²­ ì •ë¦¬
      this.cleanupExpiredRequests();

      // íì— ìš”ì²­ ì¶”ê°€
      this.queue.set(request.id, request);
      this.pendingPromises.set(request.id, {
        resolve: resolve as (value: APIResponse<unknown>) => void,
        reject,
        timestamp: Date.now(),
      });

      // ë°°ì¹­ íƒ€ì´ë¨¸ ì„¤ì • (ìš°ì„ ìˆœìœ„ ê³ ë ¤)
      this.scheduleBatch(request.priority === 'high');
    });
  }

  /**
   * ë°°ì¹˜ ì‹¤í–‰ ìŠ¤ì¼€ì¤„ë§
   * High priority ìš”ì²­ì€ ì¦‰ì‹œ ì‹¤í–‰
   */
  private scheduleBatch(isHighPriority = false): void {
    if (this.isProcessing) return;

    // ê³ ìš°ì„ ìˆœìœ„ì´ê±°ë‚˜ ë°°ì¹˜ í¬ê¸° ë„ë‹¬ ì‹œ ì¦‰ì‹œ ì‹¤í–‰
    const shouldExecuteImmediately =
      isHighPriority || this.queue.size >= this.options.maxBatchSize;

    if (shouldExecuteImmediately) {
      void this.executeBatch();
      return;
    }

    // ê¸°ì¡´ íƒ€ì´ë¨¸ í´ë¦¬ì–´
    if (this.batchTimer) {
      clearTimeout(this.batchTimer);
    }

    // ìƒˆ íƒ€ì´ë¨¸ ì„¤ì •
    this.batchTimer = setTimeout(() => {
      void this.executeBatch();
    }, this.options.batchDelay);
  }

  /**
   * ë°°ì¹˜ ì‹¤í–‰
   * Vercel Edge Runtime ìµœì í™”ëœ ë³‘ë ¬ ì²˜ë¦¬
   */
  private async executeBatch(): Promise<void> {
    if (this.isProcessing || this.queue.size === 0) return;

    this.isProcessing = true;

    // íƒ€ì´ë¨¸ ì •ë¦¬
    if (this.batchTimer) {
      clearTimeout(this.batchTimer);
      this.batchTimer = null;
    }

    // í˜„ì¬ í ë³µì‚¬ í›„ í´ë¦¬ì–´ (ìƒˆ ìš”ì²­ ë°›ì„ ìˆ˜ ìˆë„ë¡)
    const currentBatch = new Map(this.queue);
    this.queue.clear();

    try {
      // ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬ (high > normal > low)
      const sortedRequests = Array.from(currentBatch.values()).sort((a, b) => {
        const priorityOrder = { high: 0, normal: 1, low: 2 };
        return (
          (priorityOrder[a.priority || 'normal'] || 1) -
          (priorityOrder[b.priority || 'normal'] || 1)
        );
      });

      // Vercel Edge í™˜ê²½ ìµœì í™”ëœ ë³‘ë ¬ ì‹¤í–‰
      const results = await this.executeParallelRequests(sortedRequests);

      // ê²°ê³¼ ì²˜ë¦¬
      this.processResults(results);
    } catch (error) {
      // ë°°ì¹˜ ì „ì²´ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ìš”ì²­ì— ì—ëŸ¬ ì „íŒŒ
      this.handleBatchError(currentBatch, error as Error);
    } finally {
      this.isProcessing = false;

      // íì— ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ì´ ìˆìœ¼ë©´ ë‹¤ìŒ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ë§
      if (this.queue.size > 0) {
        this.scheduleBatch();
      }
    }
  }

  /**
   * Vercel Edge Runtime ìµœì í™”ëœ ë³‘ë ¬ ìš”ì²­ ì‹¤í–‰
   * - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  Promise.allSettled ì‚¬ìš©
   * - íƒ€ì„ì•„ì›ƒ ì œì–´ë¡œ ì½œë“œ ìŠ¤íƒ€íŠ¸ ëŒ€ì‘
   */
  private async executeParallelRequests(
    requests: APIRequest[]
  ): Promise<APIResponse[]> {
    const startTime = Date.now();

    const requestPromises = requests.map(
      async (request): Promise<APIResponse> => {
        const requestStart = Date.now();

        try {
          // Vercel í™˜ê²½ ê¸°ë³¸ ì„¤ì • ì ìš©
          const controller = new AbortController();
          const timeoutId = setTimeout(() => {
            controller.abort();
          }, this.options.timeout);

          const response = await fetch(request.endpoint, {
            ...request.options,
            signal: controller.signal,
            // Vercel Edge Runtime ìµœì í™” í—¤ë”
            headers: {
              'Content-Type': 'application/json',
              'Cache-Control': 'no-cache',
              ...request.options?.headers,
            },
          });

          clearTimeout(timeoutId);

          const data = response.headers
            .get('content-type')
            ?.includes('application/json')
            ? await response.json()
            : await response.text();

          return {
            id: request.id,
            data,
            status: response.status,
            timing: {
              queued: requestStart - startTime,
              executed: requestStart,
              duration: Date.now() - requestStart,
            },
          };
        } catch (error) {
          return {
            id: request.id,
            error: error instanceof Error ? error.message : 'Unknown error',
            status: 0,
            timing: {
              queued: requestStart - startTime,
              executed: requestStart,
              duration: Date.now() - requestStart,
            },
          };
        }
      }
    );

    // Promise.allSettledë¡œ ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš©
    const settledResults = await Promise.allSettled(requestPromises);

    return settledResults.map((result, index) => {
      if (result.status === 'fulfilled') {
        return result.value;
      } else {
        return {
          id: requests[index]?.id || 'unknown',
          error: result.reason?.message || 'Request failed',
          status: 0,
          timing: {
            queued: 0,
            executed: Date.now(),
            duration: 0,
          },
        };
      }
    });
  }

  /**
   * ê²°ê³¼ ì²˜ë¦¬ ë° Promise í•´ê²° (Phase 76: ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì¶”ê°€)
   */
  private processResults(results: APIResponse[]): void {
    results.forEach((result) => {
      // ğŸ›¡ï¸ Phase 76: Batcher ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ê²€ì¦
      if (!isValidAPIResponse(result)) {
        console.error('âŒ Batcher ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ë¶ˆì¼ì¹˜:', result);
        // result.idê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ
        return;
      }

      const pending = this.pendingPromises.get(result.id);
      if (pending) {
        pending.resolve(result);
        this.pendingPromises.delete(result.id);
      }
    });
  }

  /**
   * ë°°ì¹˜ ì—ëŸ¬ ì²˜ë¦¬
   */
  private handleBatchError(batch: Map<string, APIRequest>, error: Error): void {
    batch.forEach((request) => {
      const pending = this.pendingPromises.get(request.id);
      if (pending) {
        pending.reject(error);
        this.pendingPromises.delete(request.id);
      }
    });
  }

  /**
   * ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€: ë§Œë£Œëœ ìš”ì²­ ì •ë¦¬
   * Vercel 128MB ë©”ëª¨ë¦¬ ì œí•œ ëŒ€ì‘
   */
  private cleanupExpiredRequests(): void {
    const now = Date.now();
    const expiredIds: string[] = [];

    this.pendingPromises.forEach((pending, id) => {
      if (now - pending.timestamp > this.options.timeout) {
        expiredIds.push(id);
      }
    });

    expiredIds.forEach((id) => {
      const pending = this.pendingPromises.get(id);
      if (pending) {
        pending.reject(new Error('Request timeout'));
        this.pendingPromises.delete(id);
      }
      this.queue.delete(id);
    });
  }

  /**
   * ë°°ì²˜ ì •ë¦¬ (ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ)
   */
  cleanup(): void {
    if (this.batchTimer) {
      clearTimeout(this.batchTimer);
      this.batchTimer = null;
    }

    // ëŒ€ê¸° ì¤‘ì¸ ëª¨ë“  ìš”ì²­ ì·¨ì†Œ
    this.pendingPromises.forEach((pending) => {
      pending.reject(new Error('Batcher cleanup'));
    });

    this.queue.clear();
    this.pendingPromises.clear();
    this.isProcessing = false;
  }

  /**
   * ë°°ì²˜ ìƒíƒœ ì¡°íšŒ (ê°œë°œ/ë””ë²„ê¹…ìš©)
   */
  getStatus() {
    return {
      queueSize: this.queue.size,
      pendingCount: this.pendingPromises.size,
      isProcessing: this.isProcessing,
      hasTimer: this.batchTimer !== null,
    };
  }
}

// Vercel í™˜ê²½ ìµœì í™”ëœ ì‹±ê¸€í†¤ ë°°ì²˜
let globalBatcher: VercelOptimizedAPIBatcher | null = null;

/**
 * ì „ì—­ API ë°°ì²˜ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
 * SSR/í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ ëª¨ë‘ ì•ˆì „
 */
export function getAPIBatcher(): VercelOptimizedAPIBatcher {
  if (!globalBatcher) {
    globalBatcher = new VercelOptimizedAPIBatcher({
      // Vercel ë¬´ë£Œ í‹°ì–´ ìµœì í™” ì„¤ì •
      maxBatchSize: process.env.NODE_ENV === 'production' ? 6 : 8,
      batchDelay: process.env.NODE_ENV === 'production' ? 30 : 50,
      timeout: 8000,
      retryAttempts: 1, // í”„ë¡œë•ì…˜ì—ì„œ ì¬ì‹œë„ ìµœì†Œí™”
    });
  }
  return globalBatcher;
}

/**
 * ì „ì—­ ë°°ì²˜ ì •ë¦¬ (ì•± ì¢…ë£Œ ì‹œ)
 */
export function cleanupGlobalBatcher(): void {
  if (globalBatcher) {
    globalBatcher.cleanup();
    globalBatcher = null;
  }
}

export type { APIRequest, APIResponse, BatchOptions };
export { VercelOptimizedAPIBatcher };
