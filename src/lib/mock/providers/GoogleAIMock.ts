/**
 * ğŸ¤– Google AI Mock Provider
 *
 * Google Generative AIì˜ ê°„ì†Œí™”ëœ Mock êµ¬í˜„
 */

import { MockBase } from '../core/MockBase';
import scenarios from '../data/scenarios.json';

export class GoogleAIMock extends MockBase {
  private currentModel: string = 'gemini-pro';

  constructor() {
    super('GoogleAI', {
      responseDelay: 100,
      enableStats: true,
    });
  }

  /**
   * ëª¨ë¸ ì„¤ì •
   */
  setModel(model: string): void {
    this.currentModel = model;
    this.logger.info(`ëª¨ë¸ ë³€ê²½: ${model}`);
  }

  /**
   * ì½˜í…ì¸  ìƒì„±
   */
  async generateContent(prompt: string): Promise<{
    text: string;
    model: string;
    tokensUsed: number;
  }> {
    return this.execute('generateContent', async () => {
      const response = this.findBestResponse(prompt);
      const tokensUsed = this.estimateTokens(prompt + response);

      return {
        text: response,
        model: this.currentModel,
        tokensUsed,
      };
    });
  }

  /**
   * ìŠ¤íŠ¸ë¦¼ ìƒì„±
   */
  async *generateContentStream(prompt: string): AsyncGenerator<string> {
    await this.simulateDelay();

    const response = this.findBestResponse(prompt);
    const words = response.split(' ');

    for (const word of words) {
      yield word + ' ';
      await new Promise((resolve) => setTimeout(resolve, 20));
    }
  }

  /**
   * ìµœì  ì‘ë‹µ ì°¾ê¸°
   */
  private findBestResponse(prompt: string): string {
    const lowerPrompt = prompt.toLowerCase();

    // ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë§¤ì¹­ë˜ëŠ” ì‘ë‹µ ì°¾ê¸°
    for (const [key, scenario] of Object.entries(scenarios.googleAI)) {
      const hasKeyword = scenario.keywords.some((keyword) =>
        lowerPrompt.includes(keyword.toLowerCase())
      );

      if (hasKeyword) {
        const randomIndex = Math.floor(
          Math.random() * scenario.responses.length
        );
        return scenario.responses[randomIndex];
      }
    }

    // ê¸°ë³¸ ì‘ë‹µ
    return this.generateDefaultResponse(prompt);
  }

  /**
   * ê¸°ë³¸ ì‘ë‹µ ìƒì„±
   */
  private generateDefaultResponse(prompt: string): string {
    if (prompt.includes('ë¶„ì„')) {
      return 'ìš”ì²­í•˜ì‹  ë‚´ìš©ì„ ë¶„ì„í•œ ê²°ê³¼, í˜„ì¬ ì‹œìŠ¤í…œì€ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.';
    }
    if (prompt.includes('ì¶”ì²œ') || prompt.includes('ì œì•ˆ')) {
      return 'í˜„ì¬ ìƒí™©ì„ ê³ ë ¤í•  ë•Œ, ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.';
    }
    return 'ìš”ì²­ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”.';
  }

  /**
   * í† í° ì¶”ì •
   */
  private estimateTokens(text: string): number {
    // ê°„ë‹¨í•œ í† í° ì¶”ì • (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•¨)
    return Math.ceil(text.length / 4);
  }

  /**
   * Mock ë¦¬ì…‹
   */
  reset(): void {
    this.currentModel = 'gemini-pro';
    this.stats.reset();
    this.logger.info('Google AI Mock ë¦¬ì…‹ë¨');
  }
}
