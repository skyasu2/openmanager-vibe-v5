/**
 * ğŸ­ Mock ì‹œë‚˜ë¦¬ì˜¤ í†µí•© ëª¨ë“ˆ
 * 
 * ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•©í•˜ê³  ê¸°ì¡´ Mock ì‹œìŠ¤í…œê³¼ ì—°ê²°
 */

export * from './server-monitoring-scenarios';
export * from './korean-nlp-scenarios';
export * from './ml-analytics-scenarios';

import { 
  ServerScenario, 
  ScenarioRunner,
  SCENARIO_LIBRARY as SERVER_SCENARIOS 
} from './server-monitoring-scenarios';

import { 
  KoreanNLPScenario,
  TECHNICAL_MIXED_CASES,
  BUSINESS_CONTEXT_CASES,
  COMPLEX_MIXED_CASES,
  EDGE_CASES,
  generateRandomKoreanQuery
} from './korean-nlp-scenarios';

import {
  MLAnalyticsPattern,
  ML_PATTERN_LIBRARY,
  generateMetricsByWorkload,
  detectAnomalies,
  generatePredictions
} from './ml-analytics-scenarios';

import { DevMockGoogleAI } from '@/lib/ai/dev-mock-google-ai';
import { DevMockSupabase } from '@/lib/supabase/dev-mock-supabase';
import { DevMockGCPFunctions } from '@/lib/gcp/dev-mock-gcp-functions';

/**
 * ì‹œë‚˜ë¦¬ì˜¤ ë§¤ë‹ˆì €
 * ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê´€ë¦¬í•˜ê³  Mock ì‹œìŠ¤í…œì— ì ìš©
 */
export class MockScenarioManager {
  private serverScenarioRunner?: ScenarioRunner;
  private activeScenarios: Map<string, any> = new Map();
  private mockInstances: {
    googleAI?: DevMockGoogleAI;
    supabase?: DevMockSupabase;
    gcpFunctions?: DevMockGCPFunctions;
  } = {};

  constructor() {
    console.log('ğŸ¬ Mock ì‹œë‚˜ë¦¬ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”');
  }

  /**
   * Mock ì¸ìŠ¤í„´ìŠ¤ ë“±ë¡
   */
  registerMockInstance(type: 'googleAI' | 'supabase' | 'gcpFunctions', instance: unknown) {
    this.mockInstances[type] = instance;
    console.log(`âœ… ${type} Mock ì¸ìŠ¤í„´ìŠ¤ ë“±ë¡ë¨`);
  }

  /**
   * ì„œë²„ ëª¨ë‹ˆí„°ë§ ì‹œë‚˜ë¦¬ì˜¤ ì‹œì‘
   */
  startServerScenario(scenarioId: keyof typeof SERVER_SCENARIOS) {
    const scenario = SERVER_SCENARIOS[scenarioId];
    if (!scenario) {
      console.error(`âŒ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: ${scenarioId}`);
      return;
    }

    this.serverScenarioRunner = new ScenarioRunner(scenario);
    this.serverScenarioRunner.start();
    this.activeScenarios.set('server', scenario);

    console.log(`ğŸ¬ ì„œë²„ ì‹œë‚˜ë¦¬ì˜¤ ì‹œì‘: ${scenario.name}`);

    // Supabase Mockì— ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ì ìš©
    if (this.mockInstances.supabase) {
      this.applyServerScenarioToSupabase(scenario);
    }

    // ì£¼ê¸°ì ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
    const updateInterval = setInterval(() => {
      if (!this.serverScenarioRunner || this.serverScenarioRunner.isComplete()) {
        clearInterval(updateInterval);
        console.log('âœ… ì„œë²„ ì‹œë‚˜ë¦¬ì˜¤ ì™„ë£Œ');
        return;
      }

      const state = this.serverScenarioRunner.getCurrentState();
      this.updateMockData(state);
    }, 5000); // 5ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
  }

  /**
   * Korean NLP ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
   */
  async testKoreanNLPScenarios(category?: 'technical' | 'business' | 'mixed' | 'edge-case') {
    if (!this.mockInstances.gcpFunctions) {
      console.error('âŒ GCP Functions Mockì´ ë“±ë¡ë˜ì§€ ì•ŠìŒ');
      return;
    }

    let scenarios: KoreanNLPScenario[] = [];
    
    if (!category) {
      scenarios = [
        ...TECHNICAL_MIXED_CASES,
        ...BUSINESS_CONTEXT_CASES,
        ...COMPLEX_MIXED_CASES,
        ...EDGE_CASES,
      ];
    } else {
      scenarios = [
        ...TECHNICAL_MIXED_CASES,
        ...BUSINESS_CONTEXT_CASES,
        ...COMPLEX_MIXED_CASES,
        ...EDGE_CASES,
      ].filter(s => s.category === category);
    }

    console.log(`ğŸ§ª Korean NLP ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹œì‘ (${scenarios.length}ê°œ)`);

    const results = [];
    for (const scenario of scenarios) {
      const result = await this.mockInstances.gcpFunctions.analyzeKoreanNLP(
        scenario.input,
        scenario.context
      );

      results.push({
        scenario,
        result,
        success: result.success,
      });

      console.log(`ğŸ“ ${scenario.id}: ${result.success ? 'âœ…' : 'âŒ'}`);
    }

    return results;
  }

  /**
   * ML Analytics íŒ¨í„´ ì ìš©
   */
  applyMLAnalyticsPattern(
    serverType: 'web' | 'api' | 'database' | 'cache' | 'ml',
    patternId?: string
  ) {
    const patterns = ML_PATTERN_LIBRARY[serverType];
    if (!patterns || patterns.length === 0) {
      console.error(`âŒ ${serverType}ì— ëŒ€í•œ ML íŒ¨í„´ì´ ì—†ìŒ`);
      return;
    }

    const pattern = patternId 
      ? patterns.find(p => p.id === patternId)
      : patterns[0];

    if (!pattern) {
      console.error(`âŒ ML íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: ${patternId}`);
      return;
    }

    this.activeScenarios.set('ml', pattern);
    console.log(`ğŸ¤– ML íŒ¨í„´ ì ìš©: ${pattern.name}`);

    // ë©”íŠ¸ë¦­ ìƒì„± ë° ì ìš©
    this.generateAndApplyMLMetrics(pattern);
  }

  /**
   * ëœë¤ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
   */
  startRandomScenario() {
    const scenarioTypes = ['server', 'nlp', 'ml'];
    const randomType = scenarioTypes[Math.floor(Math.random() * scenarioTypes.length)];

    switch (randomType) {
      case 'server':
        const serverScenarios = Object.keys(SERVER_SCENARIOS) as Array<keyof typeof SERVER_SCENARIOS>;
        const randomServerScenario = serverScenarios[Math.floor(Math.random() * serverScenarios.length)];
        this.startServerScenario(randomServerScenario);
        break;

      case 'nlp':
        this.testKoreanNLPScenarios();
        break;

      case 'ml':
        const serverTypes = ['web', 'api', 'database', 'cache', 'ml'] as const;
        const randomServerType = serverTypes[Math.floor(Math.random() * serverTypes.length)];
        this.applyMLAnalyticsPattern(randomServerType);
        break;
    }
  }

  /**
   * í˜„ì¬ í™œì„± ì‹œë‚˜ë¦¬ì˜¤ ìƒíƒœ ì¡°íšŒ
   */
  getActiveScenarios() {
    const scenarios: Record<string, any> = {};
    
    if (this.serverScenarioRunner) {
      scenarios.server = {
        ...this.activeScenarios.get('server'),
        currentState: this.serverScenarioRunner.getCurrentState(),
      };
    }

    if (this.activeScenarios.has('ml')) {
      scenarios.ml = this.activeScenarios.get('ml');
    }

    return scenarios;
  }

  /**
   * ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ì§€
   */
  stopAllScenarios() {
    if (this.serverScenarioRunner) {
      this.serverScenarioRunner.stop();
    }
    this.activeScenarios.clear();
    console.log('ğŸ›‘ ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ì§€ë¨');
  }

  /**
   * Private: ì„œë²„ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ Supabase Mockì— ì ìš©
   */
  private applyServerScenarioToSupabase(scenario: ServerScenario) {
    if (!this.mockInstances.supabase) return;

    // ì‹œë‚˜ë¦¬ì˜¤ì˜ ì„œë²„ ìƒíƒœë¥¼ Mock ë°ì´í„°ë¡œ ë³€í™˜
    const mockServers = scenario.servers.map(state => ({
      id: state.serverId,
      name: state.serverId,
      type: state.serverId.includes('web') ? 'web' : 
            state.serverId.includes('api') ? 'api' : 
            state.serverId.includes('db') ? 'database' : 'other',
      status: state.status,
      cpu: state.metrics.cpu,
      memory: state.metrics.memory,
      disk: state.metrics.disk,
      network: state.metrics.network,
      response_time: state.metrics.responseTime,
      last_updated: new Date().toISOString(),
      alerts: state.alerts || [],
    }));

    // ì¤‘ë³µ ì œê±° (ê°™ì€ ì„œë²„ IDì˜ ìµœì‹  ìƒíƒœë§Œ ìœ ì§€)
    const uniqueServers = new Map();
    mockServers.forEach(server => {
      uniqueServers.set(server.id, server);
    });

    this.mockInstances.supabase.addMockData('servers', Array.from(uniqueServers.values()));
  }

  /**
   * Private: Mock ë°ì´í„° ì—…ë°ì´íŠ¸
   */
  private updateMockData(state: ReturnType<ScenarioRunner['getCurrentState']>) {
    if (!this.mockInstances.supabase) return;

    // í˜„ì¬ ìƒíƒœì˜ ì„œë²„ë“¤ì„ ì—…ë°ì´íŠ¸
    state.servers.forEach((serverState, serverId) => {
      const updateData = {
        status: serverState.status,
        cpu: serverState.metrics.cpu,
        memory: serverState.metrics.memory,
        disk: serverState.metrics.disk,
        network: serverState.metrics.network,
        response_time: serverState.metrics.responseTime,
        last_updated: new Date().toISOString(),
        alerts: serverState.alerts || [],
      };

      // Supabase Mockì˜ update ì‹œë®¬ë ˆì´ì…˜
      console.log(`ğŸ“Š ì„œë²„ ì—…ë°ì´íŠ¸: ${serverId}`, updateData);
    });

    // ìµœê·¼ ì´ë²¤íŠ¸ ë¡œê¹…
    state.recentEvents.forEach(event => {
      console.log(`ğŸ”” ì´ë²¤íŠ¸: [${event.severity}] ${event.message}`);
    });
  }

  /**
   * Private: ML ë©”íŠ¸ë¦­ ìƒì„± ë° ì ìš©
   */
  private generateAndApplyMLMetrics(pattern: MLAnalyticsPattern) {
    const now = new Date();
    const metrics: Array<{ timestamp: Date; value: number; type: string }> = [];

    // 24ì‹œê°„ ë™ì•ˆì˜ ë©”íŠ¸ë¦­ ìƒì„±
    for (let h = -24; h <= 0; h++) {
      const timestamp = new Date(now.getTime() + h * 60 * 60 * 1000);
      
      pattern.metrics.forEach(metricPattern => {
        const baseValue = (metricPattern.baselineRange.min + metricPattern.baselineRange.max) / 2;
        const value = generateMetricsByWorkload(
          pattern.workloadType,
          baseValue,
          timestamp
        );

        metrics.push({
          timestamp,
          value,
          type: metricPattern.metricType,
        });
      });
    }

    // ì´ìƒ ì§•í›„ ê°ì§€
    const anomalies = detectAnomalies(metrics, pattern);
    
    // ì˜ˆì¸¡ ìƒì„±
    const predictions = generatePredictions(metrics, pattern, 24);

    // GCP Functions Mockì— ì ìš©
    if (this.mockInstances.gcpFunctions) {
      console.log(`ğŸ“ˆ ML ë¶„ì„ ê²°ê³¼: ${anomalies.length}ê°œ ì´ìƒ ì§•í›„, ${predictions.length}ê°œ ì˜ˆì¸¡`);
    }
  }
}

/**
 * ì‹œë‚˜ë¦¬ì˜¤ í—¬í¼ í•¨ìˆ˜ë“¤
 */

// í˜„ì‹¤ì ì¸ ì„œë²„ ë©”íŠ¸ë¦­ ìƒì„±
export function generateRealisticServerMetrics(
  serverType: 'web' | 'api' | 'database' | 'cache',
  timeOfDay: number // 0-23
): {
  cpu: number;
  memory: number;
  disk: number;
  network: number;
  responseTime: number;
} {
  const baseMetrics = {
    web: { cpu: 40, memory: 50, disk: 30, network: 60, responseTime: 100 },
    api: { cpu: 50, memory: 60, disk: 20, network: 70, responseTime: 50 },
    database: { cpu: 30, memory: 70, disk: 80, network: 40, responseTime: 20 },
    cache: { cpu: 20, memory: 80, disk: 10, network: 50, responseTime: 5 },
  };

  const base = baseMetrics[serverType];
  
  // ì‹œê°„ëŒ€ë³„ ë¶€í•˜ íŒ¨í„´
  let timeMultiplier = 1;
  if (timeOfDay >= 9 && timeOfDay <= 11) timeMultiplier = 1.3; // ì˜¤ì „ í”¼í¬
  if (timeOfDay >= 12 && timeOfDay <= 13) timeMultiplier = 1.5; // ì ì‹¬ í”¼í¬
  if (timeOfDay >= 14 && timeOfDay <= 17) timeMultiplier = 1.2; // ì˜¤í›„
  if (timeOfDay >= 20 && timeOfDay <= 22) timeMultiplier = 1.4; // ì €ë… í”¼í¬
  if (timeOfDay >= 2 && timeOfDay <= 5) timeMultiplier = 0.5; // ìƒˆë²½

  // ëœë¤ ë³€ë™ ì¶”ê°€
  const randomFactor = 0.8 + Math.random() * 0.4; // 0.8 ~ 1.2

  return {
    cpu: Math.min(95, base.cpu * timeMultiplier * randomFactor),
    memory: Math.min(95, base.memory * timeMultiplier * randomFactor * 0.9), // ë©”ëª¨ë¦¬ëŠ” ëœ ë³€ë™
    disk: Math.min(95, base.disk * (1 + Math.random() * 0.1)), // ë””ìŠ¤í¬ëŠ” ê±°ì˜ ì¼ì •
    network: Math.min(95, base.network * timeMultiplier * randomFactor),
    responseTime: Math.max(1, base.responseTime * timeMultiplier * randomFactor),
  };
}

// ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì•Œë¦¼ ìƒì„±
export function generateScenarioAlerts(
  scenario: ServerScenario,
  currentTime: number
): Array<{
  serverId: string;
  severity: 'info' | 'warning' | 'error' | 'critical';
  message: string;
  timestamp: Date;
}> {
  const alerts: Array<{
    serverId: string;
    severity: 'info' | 'warning' | 'error' | 'critical';
    message: string;
    timestamp: Date;
  }> = [];

  scenario.events
    .filter(event => event.timeOffset <= currentTime)
    .forEach(event => {
      alerts.push({
        serverId: event.serverId,
        severity: event.severity,
        message: event.message,
        timestamp: new Date(),
      });
    });

  return alerts;
}

// ì „ì—­ ì‹œë‚˜ë¦¬ì˜¤ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
export const scenarioManager = new MockScenarioManager();