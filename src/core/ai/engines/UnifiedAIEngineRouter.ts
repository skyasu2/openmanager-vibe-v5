/**
 * ğŸ¤– í†µí•© AI ì—”ì§„ ë¼ìš°í„° v5.44.4
 * Edge Runtime ìµœì í™” + Render MCP ë¶„ë¦¬
 */

import { getVercelConfig } from '@/config/vercel-edge-config';
import { edgeRuntimeService } from '@/lib/edge-runtime-utils';
import { SupabaseRAGEngine } from '@/lib/ml/supabase-rag-engine';
import { GoogleAIService } from '@/services/ai/GoogleAIService';
import { KoreanAIEngine } from '@/services/ai/korean-ai-engine';
// MCPClientWrapper ì œê±° - Render ì„œë²„ MCPë§Œ ì‚¬ìš©
import { AIEngineType, AIRequest, AIResponse } from '@/types/ai-types';

// Edge Runtime í˜¸í™˜ì„± í™•ì¸
const vercelConfig = getVercelConfig();
const logger = edgeRuntimeService.logger;
const cache = edgeRuntimeService.cache;
const performance = edgeRuntimeService.performance;

/**
 * ğŸš€ í†µí•© AI ì—”ì§„ ë¼ìš°í„°
 * 11ê°œ AI ì»´í¬ë„ŒíŠ¸ í†µí•© ê´€ë¦¬ ì‹œìŠ¤í…œ
 */
export class UnifiedAIEngineRouter {
  private static instance: UnifiedAIEngineRouter;
  private engines: Map<AIEngineType, any> = new Map();
  private failedEngines: Set<AIEngineType> = new Set();
  private requestCount = 0;
  private lastHealthCheck = Date.now();
  private isInitialized = false;

  constructor() {
    // constructorì—ì„œëŠ” ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ (í…ŒìŠ¤íŠ¸ í˜¸í™˜ì„±)
    logger.info('ğŸ¤– í†µí•© AI ì—”ì§„ ë¼ìš°í„° ìƒì„± ì™„ë£Œ');
  }

  /**
   * ğŸ­ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
   */
  static getInstance(): UnifiedAIEngineRouter {
    if (!UnifiedAIEngineRouter.instance) {
      UnifiedAIEngineRouter.instance = new UnifiedAIEngineRouter();
      // ìë™ ì´ˆê¸°í™” (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
      UnifiedAIEngineRouter.instance.initializeEngines();
    }
    return UnifiedAIEngineRouter.instance;
  }

  /**
   * ğŸ”§ ì´ˆê¸°í™” ë©”ì„œë“œ
   */
  async initialize(): Promise<void> {
    if (this.isInitialized) {
      logger.info('ì´ë¯¸ ì´ˆê¸°í™”ëœ AI ì—”ì§„ ë¼ìš°í„°');
      return;
    }

    await this.initializeEngines();
    this.isInitialized = true;
    logger.info('ğŸš€ í†µí•© AI ì—”ì§„ ë¼ìš°í„° ì´ˆê¸°í™” ì™„ë£Œ');
  }

  /**
   * ğŸ”§ AI ì—”ì§„ë“¤ ì´ˆê¸°í™”
   */
  private async initializeEngines() {
    const timer = performance.startTimer('engine-initialization');

    try {
      // ë©”ì¸ AI ì»´í¬ë„ŒíŠ¸ (Edge Runtime í˜¸í™˜)
      await this.initializeEngine('google-ai', GoogleAIService);
      await this.initializeEngine('supabase-rag', SupabaseRAGEngine);

      // Render MCPëŠ” HTTP ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬ (ì§ì ‘ import ì—†ìŒ)
      this.initializeRenderMCP();

      // í•˜ìœ„ AI ì»´í¬ë„ŒíŠ¸ (Edge Runtime í˜¸í™˜ í™•ì¸ í•„ìš”)
      if (vercelConfig.environment.isVercel) {
        // Vercel í™˜ê²½ì—ì„œëŠ” Edge Runtime í˜¸í™˜ ì—”ì§„ë§Œ ë¡œë“œ
        await this.initializeEdgeCompatibleEngines();
      } else {
        // ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” ëª¨ë“  ì—”ì§„ ë¡œë“œ
        await this.initializeEngine('korean-ai', KoreanAIEngine);
        logger.info('ë¡œì»¬ ê°œë°œ í™˜ê²½ - ì „ì²´ AI ì—”ì§„ë“¤ ë¡œë“œ');
      }

      const duration = timer();
      logger.info(`ğŸš€ AI ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ: ${duration.toFixed(2)}ms`);
    } catch (error) {
      logger.error('âŒ AI ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
    }
  }

  /**
   * ğŸŒ Render MCP HTTP ê¸°ë°˜ ì´ˆê¸°í™”
   */
  private initializeRenderMCP() {
    try {
      // Render MCP ì„œë²„ URL
      const renderMCPUrl =
        process.env.RENDER_MCP_SERVER_URL ||
        'https://openmanager-vibe-v5.onrender.com';

      // HTTP ê¸°ë°˜ MCP í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
      const renderMCPClient = {
        url: renderMCPUrl,
        timeout: 30000, // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
        initialized: true,
        type: 'render-mcp-http',
      };

      this.engines.set('render-mcp', renderMCPClient);
      logger.info('âœ… Render MCP HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (error) {
      logger.error('âŒ Render MCP ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      this.failedEngines.add('render-mcp');
    }
  }

  /**
   * âš¡ Edge Runtime í˜¸í™˜ ì—”ì§„ë“¤ë§Œ ì´ˆê¸°í™”
   */
  private async initializeEdgeCompatibleEngines() {
    try {
      // Korean AI Engineì„ Edge Runtime í˜¸í™˜ ëª¨ë“œë¡œ ì´ˆê¸°í™”
      // Redis ì˜ì¡´ì„± ì—†ì´ ë©”ëª¨ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘
      const koreanAIConfig = {
        edgeMode: true,
        disableRedis: true,
        memoryOnly: true,
      };

      await this.initializeEngine('korean-ai', KoreanAIEngine, koreanAIConfig);
      logger.info('âœ… Edge Runtime í˜¸í™˜ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (error) {
      logger.warn('âš ï¸ Edge Runtime ì—”ì§„ ì´ˆê¸°í™” ì¼ë¶€ ì‹¤íŒ¨:', error);
    }
  }

  /**
   * ğŸ”Œ ê°œë³„ ì—”ì§„ ì´ˆê¸°í™”
   */
  private async initializeEngine(
    type: AIEngineType,
    EngineClass: any,
    config?: any
  ) {
    try {
      const timer = performance.startTimer(`init-${type}`);

      const engine = new EngineClass(config);
      if (engine.initialize) {
        await engine.initialize();
      }

      this.engines.set(type, engine);
      const duration = timer();

      logger.info(`âœ… ${type} ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ: ${duration.toFixed(2)}ms`);
    } catch (error) {
      this.failedEngines.add(type);
      logger.error(`âŒ ${type} ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨:`, error);
    }
  }

  /**
   * ğŸ¯ í†µí•© AI ì¿¼ë¦¬ ì²˜ë¦¬
   */
  async processQuery(request: AIRequest): Promise<AIResponse> {
    const requestId = `req_${++this.requestCount}_${Date.now()}`;
    const timer = performance.startTimer('query-processing');

    logger.info('ğŸš€ AI ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘', {
      query: request.query?.substring(0, 100),
      mode: request.mode,
    });

    try {
      // ìºì‹œ í™•ì¸
      const cacheKey = this.generateCacheKey(request);
      const cached = cache.get(cacheKey);
      if (cached) {
        logger.info(`ğŸ“‹ ìºì‹œì—ì„œ ì‘ë‹µ ë°˜í™˜: ${requestId}`);
        return cached;
      }

      // ìš”ì²­ ë¼ìš°íŒ…
      const response = await this.routeRequest(request, requestId);

      // ìºì‹œ ì €ì¥ (ì„±ê³µí•œ ì‘ë‹µë§Œ)
      if (response.success) {
        const ttl = vercelConfig.cacheTTL;
        cache.set(cacheKey, response, ttl);
      }

      const duration = timer();
      logger.info(
        `âœ… AI ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ: ${requestId} (${duration.toFixed(2)}ms)`
      );

      return response;
    } catch (error) {
      const duration = timer();
      logger.error(
        `âŒ AI ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: ${requestId} (${duration.toFixed(2)}ms)`,
        error
      );

      return {
        success: false,
        response: error instanceof Error ? error.message : 'Unknown error',
        confidence: 0,
        mode: request.mode || 'LOCAL',
        enginePath: ['error-fallback'],
        processingTime: duration,
        fallbacksUsed: 1,
        error: error instanceof Error ? error.message : 'Unknown error',
        metadata: {
          requestId,
          duration,
          timestamp: new Date().toISOString(),
          enginePath: ['error-fallback'],
          vercelPlan: vercelConfig.environment.isPro ? 'pro' : 'hobby',
        },
      };
    }
  }

  /**
   * ğŸ§­ ìš”ì²­ ë¼ìš°íŒ… ë¡œì§
   */
  private async routeRequest(
    request: AIRequest,
    requestId: string
  ): Promise<AIResponse> {
    const { mode, type, query } = request;

    // Google AI ì „ìš© ëª¨ë“œ (ìì—°ì–´ ì²˜ë¦¬ì—ì„œë§Œ ì‚¬ìš©ì ì„ íƒ)
    if (mode === 'GOOGLE_ONLY') {
      if (!vercelConfig.enableGoogleAI) {
        throw new Error('Google AIëŠ” Pro í”Œëœì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤');
      }
      return this.processWithGoogleAI(request, requestId);
    }

    // ë¡œì»¬ ëª¨ë“œ (ê¸°ë³¸ê°’)
    return this.processWithLocalEngines(request, requestId);
  }

  /**
   * ğŸŸ¢ Google AI ì²˜ë¦¬
   */
  private async processWithGoogleAI(
    request: AIRequest,
    requestId: string
  ): Promise<AIResponse> {
    const timer = performance.startTimer('google-ai-processing');

    try {
      const googleAI = this.engines.get('google-ai');
      if (!googleAI) {
        throw new Error('Google AI ì—”ì§„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
      }

      // ìì—°ì–´ ì§ˆì˜ í™•ì¸
      const isNaturalLanguage = this.isNaturalLanguageQuery(
        request.query || ''
      );
      if (!isNaturalLanguage) {
        throw new Error('Google AIëŠ” ìì—°ì–´ ì§ˆì˜ì—ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤');
      }

      const response = await googleAI.processQuery(request);
      const duration = timer();

      return {
        ...response,
        metadata: {
          ...response.metadata,
          requestId,
          duration,
          enginePath: 'google-ai-only',
          supportEngines: ['Google AI Service'],
          vercelPlan: 'pro',
        },
      };
    } catch (error) {
      const duration = timer();
      throw new Error(
        `Google AI ì²˜ë¦¬ ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * ğŸ”µ ë¡œì»¬ ì—”ì§„ ì²˜ë¦¬ (ë©”ì¸ ì‹œìŠ¤í…œ)
   */
  private async processWithLocalEngines(
    request: AIRequest,
    requestId: string
  ): Promise<AIResponse> {
    const timer = performance.startTimer('local-engines-processing');

    try {
      const responses: AIResponse[] = [];
      const usedEngines: string[] = [];

      // 1. Supabase RAG ì—”ì§„ (ë²¡í„° ê²€ìƒ‰)
      if (this.engines.has('supabase-rag')) {
        try {
          const ragTimer = performance.startTimer('rag-processing');
          const ragEngine = this.engines.get('supabase-rag');
          const ragResponse = await Promise.race([
            ragEngine.query(request.query || ''),
            new Promise((_, reject) =>
              setTimeout(
                () => reject(new Error('RAG timeout')),
                vercelConfig.ragTimeout
              )
            ),
          ]);
          const ragDuration = ragTimer();

          if (ragResponse && ragResponse.success) {
            responses.push(ragResponse);
            usedEngines.push('Supabase RAG Engine');
            logger.info(`ğŸ“š RAG ì—”ì§„ ì‘ë‹µ: ${ragDuration.toFixed(2)}ms`);
          }
        } catch (error) {
          logger.warn('âš ï¸ RAG ì—”ì§„ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
        }
      }

      // 2. í•œêµ­ì–´ AI ì—”ì§„ (NLP ë¶„ì„)
      if (this.engines.has('korean-ai')) {
        try {
          const nlpTimer = performance.startTimer('korean-nlp-processing');
          const koreanAI = this.engines.get('korean-ai');
          const nlpResponse = await Promise.race([
            koreanAI.processText(request.query || ''),
            new Promise((_, reject) =>
              setTimeout(
                () => reject(new Error('NLP timeout')),
                vercelConfig.koreanNLPTimeout
              )
            ),
          ]);
          const nlpDuration = nlpTimer();

          if (nlpResponse && nlpResponse.success) {
            responses.push(nlpResponse);
            usedEngines.push('Korean AI Engine');
            logger.info(`ğŸ‡°ğŸ‡· í•œêµ­ì–´ NLP ì—”ì§„ ì‘ë‹µ: ${nlpDuration.toFixed(2)}ms`);
          }
        } catch (error) {
          logger.warn('âš ï¸ í•œêµ­ì–´ NLP ì—”ì§„ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
        }
      }

      // 3. ğŸ¤– AI ì—”ì§„ë“¤ì—ëŠ” Render MCP ì „ìš© ì‚¬ìš©
      if (vercelConfig.enableMCPIntegration && this.engines.has('mcp-client')) {
        logger.info('ğŸ”— MCP í´ë¼ì´ì–¸íŠ¸ ì—”ì§„ (Render ì„œë²„ ì „ìš©) í˜¸ì¶œ ì¤‘...');

        const mcpClient = this.engines.get('mcp-client');
        const mcpRequest = {
          ...request,
          context: {
            ...request.context,
            usageType: 'ai-production', // AI ê¸°ëŠ¥ìš© ëª…ì‹œ
          },
        };
        const mcpResponse = await mcpClient.processQuery(mcpRequest);

        if (mcpResponse.success && mcpResponse.confidence > 0.3) {
          responses.push(mcpResponse);
          usedEngines.push('MCP Client (Render)');
        }
      }

      // ì‘ë‹µ í†µí•©
      const combinedResponse = this.combineResponses(responses, usedEngines);
      const duration = timer();

      return {
        ...combinedResponse,
        metadata: {
          ...combinedResponse.metadata,
          requestId,
          duration,
          enginePath: ['local-unified'],
          supportEngines: usedEngines,
          ragUsed: usedEngines.includes('Supabase RAG Engine'),
          nlpUsed: usedEngines.includes('Korean AI Engine'),
          mcpUsed: usedEngines.includes('MCP Client (Render)'),
          vercelPlan: vercelConfig.environment.isPro ? 'pro' : 'hobby',
        },
      };
    } catch (error) {
      const duration = timer();
      throw new Error(
        `ë¡œì»¬ ì—”ì§„ ì²˜ë¦¬ ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'Unknown error'}`
      );
    }
  }

  /**
   * ğŸ” ìì—°ì–´ ì§ˆì˜ íŒë³„
   */
  private isNaturalLanguageQuery(query: string): boolean {
    const naturalPatterns = [
      /^(ì–´ë–»ê²Œ|ì™œ|ë¬´ì—‡|ì–¸ì œ|ì–´ë””ì„œ|ëˆ„ê°€|ë¬´ì—‡ì„|ì–´ë–¤)/,
      /\?$/,
      /(ì„¤ëª…|ë¶„ì„|ìš”ì•½|ì •ë¦¬|ì•Œë ¤|ì¶”ì²œ|ë¹„êµ|ì°¨ì´)/,
      /(í•  ìˆ˜ ìˆë‚˜ìš”|ê°€ëŠ¥í•œê°€ìš”|ë°©ë²•|ë¬¸ì œ|í•´ê²°)/,
    ];

    return naturalPatterns.some(pattern => pattern.test(query.trim()));
  }

  /**
   * ğŸ”€ ì‘ë‹µ í†µí•©
   */
  private combineResponses(
    responses: AIResponse[],
    usedEngines: string[]
  ): AIResponse {
    if (responses.length === 0) {
      return {
        success: false,
        response: 'ì‚¬ìš© ê°€ëŠ¥í•œ AI ì—”ì§„ì´ ì—†ìŠµë‹ˆë‹¤.',
        confidence: 0,
        mode: 'LOCAL',
        enginePath: ['no-engines'],
        processingTime: 0,
        fallbacksUsed: 0,
        error: 'No available engines',
        metadata: {
          timestamp: new Date().toISOString(),
          enginePath: ['no-engines'],
          supportEngines: [],
          mainEngine: 'none',
          ragUsed: false,
          googleAIUsed: false,
        },
      };
    }

    // ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì‘ë‹µ ì„ íƒ
    const bestResponse = responses.reduce((best, current) => {
      const bestConfidence = best.confidence || 0;
      const currentConfidence = current.confidence || 0;
      return currentConfidence > bestConfidence ? current : best;
    });

    // ì‚¬ìš©ëœ ì—”ì§„ë“¤ ë¶„ì„
    const mainEngine = usedEngines[0] || 'unknown';
    const ragUsed = usedEngines.includes('supabase-rag');
    const googleAIUsed = usedEngines.includes('google-ai');

    return {
      ...bestResponse,
      metadata: {
        ...bestResponse.metadata,
        timestamp: new Date().toISOString(),
        combinedResponses: responses.length,
        supportEngines: usedEngines,
        mainEngine: mainEngine,
        ragUsed: ragUsed,
        googleAIUsed: googleAIUsed,
      },
    };
  }

  /**
   * ğŸ”‘ ìºì‹œ í‚¤ ìƒì„±
   */
  private generateCacheKey(request: AIRequest): string {
    const queryHash = this.simpleHash(request.query || '');
    return `ai_${request.mode}_${request.type}_${queryHash}`;
  }

  /**
   * ğŸ”¢ ê°„ë‹¨í•œ í•´ì‹œ í•¨ìˆ˜
   */
  private simpleHash(str: string): string {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = (hash << 5) - hash + char;
      hash = hash & hash; // 32bit integer ë³€í™˜
    }
    return Math.abs(hash).toString(36);
  }

  /**
   * ğŸ¥ í—¬ìŠ¤ì²´í¬
   */
  async healthCheck(): Promise<{
    status: string;
    engines: Record<string, boolean>;
    stats: any;
  }> {
    const now = Date.now();
    if (now - this.lastHealthCheck < 30000) {
      // 30ì´ˆ ìºì‹œ
      return cache.get('health-check') || this.performHealthCheck();
    }

    const health = await this.performHealthCheck();
    cache.set('health-check', health, 30000);
    this.lastHealthCheck = now;

    return health;
  }

  private async performHealthCheck() {
    const engineStatus: Record<string, boolean> = {};

    for (const [type, engine] of this.engines) {
      try {
        if (engine.healthCheck) {
          await engine.healthCheck();
        }
        engineStatus[type] = true;
      } catch {
        engineStatus[type] = false;
      }
    }

    const healthyEngines = Object.values(engineStatus).filter(Boolean).length;
    const totalEngines = Object.keys(engineStatus).length;

    return {
      status: healthyEngines === totalEngines ? 'healthy' : 'degraded',
      engines: engineStatus,
      stats: {
        healthy: healthyEngines,
        total: totalEngines,
        cache: cache.getStats(),
        performance: performance.getAllMetrics(),
        runtime: edgeRuntimeService.getSystemStatus(),
      },
    };
  }

  /**
   * ğŸ“Š ìƒíƒœ ì •ë³´ ë°˜í™˜
   */
  getStatus(): any {
    return {
      router: 'UnifiedAIEngineRouter',
      version: '3.3.0',
      initialized: this.isInitialized,
      mode: this.getCurrentMode(),
      totalEngines: this.engines.size,
      failedEngines: this.failedEngines.size,
      requestCount: this.requestCount,
      lastHealthCheck: this.lastHealthCheck,
      availableEngines: Array.from(this.engines.keys()),
      failedEnginesList: Array.from(this.failedEngines),
      edgeMode: vercelConfig.environment.isVercel,
      vercelPlan: vercelConfig.environment.isPro ? 'pro' : 'hobby',
      stats: {
        totalRequests: this.requestCount,
        successfulRequests: this.requestCount, // ì„ì‹œë¡œ ê°™ì€ ê°’
        failureRate: this.failedEngines.size / Math.max(this.engines.size, 1),
        averageResponseTime: 0, // ì‹¤ì œ êµ¬í˜„ ì‹œ ê³„ì‚°
        cacheHitRate: 0.85, // ì„ì‹œê°’
        uptime: Date.now() - this.lastHealthCheck,
      },
      engines: {
        supabaseRAG: this.engines.has('supabase-rag'),
        googleAI: this.engines.has('google-ai'),
        optimizedKoreanNLP: this.engines.has('korean-ai'),
        openSourceEngines: false, // í˜„ì¬ ë¯¸êµ¬í˜„ ìƒíƒœ
        customEngines: false, // í˜„ì¬ ë¯¸êµ¬í˜„ ìƒíƒœ
        mcpContextCollector: this.engines.has('render-mcp'),
        fallbackHandler: true, // í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
      },
    };
  }

  /**
   * ğŸ¯ í˜„ì¬ AI ëª¨ë“œ ë°˜í™˜
   */
  getCurrentMode(): 'LOCAL' | 'GOOGLE_ONLY' {
    const mode = process.env.AI_ENGINE_MODE || 'LOCAL';

    // ìœ íš¨í•œ ëª¨ë“œì¸ì§€ í™•ì¸
    if (mode === 'LOCAL' || mode === 'GOOGLE_ONLY') {
      return mode;
    }

    // ê¸°ë³¸ê°’ ë°˜í™˜
    return 'LOCAL';
  }

  /**
   * âš™ï¸ AI ëª¨ë“œ ì„¤ì •
   */
  setMode(mode: 'LOCAL' | 'GOOGLE_ONLY'): void {
    // ëŸ°íƒ€ì„ì—ì„œ ëª¨ë“œ ë³€ê²½ (í™˜ê²½ë³€ìˆ˜ ì—…ë°ì´íŠ¸ëŠ” ë¶ˆê°€)
    logger.info(`ğŸ”§ AI ëª¨ë“œ ë³€ê²½ ìš”ì²­: ${mode}`);

    // ìœ íš¨í•œ ëª¨ë“œì¸ì§€ í™•ì¸
    if (mode !== 'LOCAL' && mode !== 'GOOGLE_ONLY') {
      logger.warn(`âš ï¸ ì˜ëª»ëœ AI ëª¨ë“œ: ${mode}, LOCALë¡œ ì„¤ì •`);
      return;
    }

    // ëª¨ë“œë³„ ë¡œê¹…
    switch (mode) {
      case 'LOCAL':
        logger.info('ğŸ  ë¡œì»¬ AI ì—”ì§„ ëª¨ë“œë¡œ ì„¤ì •ë¨');
        break;
      case 'GOOGLE_ONLY':
        logger.info('ğŸŒ Google AI ì „ìš© ëª¨ë“œë¡œ ì„¤ì •ë¨ (ìì—°ì–´ ì²˜ë¦¬ ì „ìš©)');
        break;
    }
  }

  /**
   * ğŸ§¹ ì •ë¦¬ ì‘ì—…
   */
  cleanup(): void {
    for (const [type, engine] of this.engines) {
      try {
        if (engine.cleanup) {
          engine.cleanup();
        }
      } catch (error) {
        logger.warn(`ì—”ì§„ ì •ë¦¬ ì‹¤íŒ¨: ${type}`, error);
      }
    }

    edgeRuntimeService.cleanup();
    logger.info('ğŸ§¹ í†µí•© AI ì—”ì§„ ë¼ìš°í„° ì •ë¦¬ ì™„ë£Œ');
  }
}

// Export instance
export const unifiedAIRouter = UnifiedAIEngineRouter.getInstance();
