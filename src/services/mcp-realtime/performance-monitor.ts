/**
 * ğŸš€ MCP ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ v3.0
 *
 * ëª©í‘œ: < 100ms ì‘ë‹µì‹œê°„, 99.5% API ì„±ê³µë¥  ë‹¬ì„±
 * - ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„
 * - ë³‘ëª©ì  ìë™ ê°ì§€ ë° ìµœì í™” ì œì•ˆ
 * - ë¬´ë£Œ í‹°ì–´ ìì› íš¨ìœ¨ì„± ì¶”ì 
 * - ì˜ˆì¸¡ì  ì„±ëŠ¥ ê´€ë¦¬
 */

import { Redis } from '@upstash/redis';
import type { SupabaseClient } from '@supabase/supabase-js';
import type { MCPServerName } from '../mcp-monitor/types';

// ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¸í„°í˜ì´ìŠ¤
export interface PerformanceMetrics {
  timestamp: number;
  serverId: MCPServerName;

  // ì‘ë‹µì‹œê°„ ë©”íŠ¸ë¦­
  responseTime: {
    current: number;
    average: number;
    p50: number;
    p95: number;
    p99: number;
  };

  // ì²˜ë¦¬ëŸ‰ ë©”íŠ¸ë¦­
  throughput: {
    requestsPerSecond: number;
    successfulRequests: number;
    failedRequests: number;
    totalRequests: number;
  };

  // ìì› ì‚¬ìš©ëŸ‰
  resources: {
    memory: {
      used: number;
      available: number;
      utilizationPercent: number;
    };
    cpu: {
      utilizationPercent: number;
      loadAverage: number;
    };
    network: {
      bytesIn: number;
      bytesOut: number;
      connectionsActive: number;
    };
  };

  // í’ˆì§ˆ ë©”íŠ¸ë¦­
  quality: {
    successRate: number;
    errorRate: number;
    availabilityPercent: number;
    healthScore: number; // 0-100
  };

  // ë¹„ìš© íš¨ìœ¨ì„± (ë¬´ë£Œ í‹°ì–´)
  efficiency: {
    costPerRequest: number;
    resourceEfficiency: number; // 0-100
    tierUtilization: {
      vercel: number;
      gcp: number;
      supabase: number;
      redis: number;
    };
  };
}

// ğŸ¯ ì„±ëŠ¥ ëª©í‘œ ë° ì„ê³„ê°’
export interface PerformanceTargets {
  responseTime: {
    target: number; // 100ms
    warning: number; // 150ms
    critical: number; // 500ms
  };
  successRate: {
    target: number; // 99.5%
    warning: number; // 99.0%
    critical: number; // 95.0%
  };
  throughput: {
    target: number; // ìš”ì²­/ì´ˆ
    warning: number;
    critical: number;
  };
  resources: {
    memory: {
      warning: number; // 80%
      critical: number; // 90%
    };
    cpu: {
      warning: number; // 70%
      critical: number; // 85%
    };
  };
  efficiency: {
    minResourceEfficiency: number; // 85%
    maxCostPerRequest: number; // $0.001
  };
}

// ğŸ“ˆ ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
export interface PerformanceTrend {
  serverId: MCPServerName;
  timeWindow: string;
  trend: 'improving' | 'stable' | 'degrading' | 'critical';

  metrics: {
    responseTime: {
      current: number;
      change: number; // % ë³€í™”
      trend: 'up' | 'down' | 'stable';
    };
    successRate: {
      current: number;
      change: number;
      trend: 'up' | 'down' | 'stable';
    };
    throughput: {
      current: number;
      change: number;
      trend: 'up' | 'down' | 'stable';
    };
  };

  predictions: {
    nextHour: {
      responseTime: number;
      successRate: number;
      confidence: number; // 0-100
    };
    nextDay: {
      responseTime: number;
      successRate: number;
      confidence: number;
    };
  };

  bottlenecks: Array<{
    component: 'redis' | 'supabase' | 'gcp' | 'vercel' | 'network';
    severity: 'low' | 'medium' | 'high' | 'critical';
    impact: number; // 0-100
    description: string;
    recommendation: string;
  }>;
}

// ğŸ”§ ì„±ëŠ¥ ìµœì í™” ì„¤ì •
interface PerformanceMonitorConfig {
  collection: {
    intervalMs: number; // 5000 (5ì´ˆ)
    batchSize: number; // 100
    maxHistoryPoints: number; // 1000
    retentionDays: number; // 7
  };

  analysis: {
    trendWindowMinutes: number; // 15
    anomalyThreshold: number; // 2 í‘œì¤€í¸ì°¨
    predictionWindowHours: number; // 24
  };

  optimization: {
    autoOptimization: boolean; // true
    autoScaling: boolean; // false (ë¬´ë£Œ í‹°ì–´)
    cacheOptimization: boolean; // true
  };

  alerting: {
    realTimeAlerts: boolean; // true
    performanceThresholds: PerformanceTargets;
  };
}

/**
 * MCP ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
 */
export class MCPPerformanceMonitor {
  private redis: Redis;
  private supabase: SupabaseClient;
  private config: PerformanceMonitorConfig;

  // ì„±ëŠ¥ ë°ì´í„° ì €ì¥ì†Œ
  private metricsHistory: Map<MCPServerName, PerformanceMetrics[]> = new Map();
  private currentMetrics: Map<MCPServerName, PerformanceMetrics> = new Map();

  // ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ íƒ€ì´ë¨¸
  private monitoringTimer: NodeJS.Timeout | null = null;
  private cleanupTimer: NodeJS.Timeout | null = null;

  // ì„±ëŠ¥ í†µê³„
  private performanceStats = {
    totalRequests: 0,
    successfulRequests: 0,
    avgResponseTime: 0,
    peakResponseTime: 0,
    startTime: Date.now(),
  };

  constructor(
    redis: Redis,
    supabase: SupabaseClient,
    config?: Partial<PerformanceMonitorConfig>
  ) {
    this.redis = redis;
    this.supabase = supabase;
    this.config = {
      collection: {
        intervalMs: 5000, // 5ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
        batchSize: 100,
        maxHistoryPoints: 1000,
        retentionDays: 7,
      },
      analysis: {
        trendWindowMinutes: 15,
        anomalyThreshold: 2,
        predictionWindowHours: 24,
      },
      optimization: {
        autoOptimization: true,
        autoScaling: false, // ë¬´ë£Œ í‹°ì–´ì—ì„œëŠ” ë¹„í™œì„±í™”
        cacheOptimization: true,
      },
      alerting: {
        realTimeAlerts: true,
        performanceThresholds: {
          responseTime: { target: 100, warning: 150, critical: 500 },
          successRate: { target: 99.5, warning: 99.0, critical: 95.0 },
          throughput: { target: 100, warning: 50, critical: 10 },
          resources: {
            memory: { warning: 80, critical: 90 },
            cpu: { warning: 70, critical: 85 },
          },
          efficiency: {
            minResourceEfficiency: 85,
            maxCostPerRequest: 0.001,
          },
        },
      },
      ...config,
    };

    this.startMonitoring();
  }

  /**
   * ğŸš€ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘
   */
  private startMonitoring(): void {
    // ê¸°ì¡´ íƒ€ì´ë¨¸ ì •ë¦¬
    if (this.monitoringTimer) clearInterval(this.monitoringTimer);
    if (this.cleanupTimer) clearInterval(this.cleanupTimer);

    // ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ (5ì´ˆ ê°„ê²©)
    this.monitoringTimer = setInterval(async () => {
      try {
        await this.collectPerformanceMetrics();
      } catch (error) {
        console.error(
          'âŒ [PerformanceMonitor] Metrics collection failed:',
          error
        );
      }
    }, this.config.collection.intervalMs);

    // ì •ë¦¬ ì‘ì—… (1ì‹œê°„ ê°„ê²©)
    this.cleanupTimer = setInterval(
      async () => {
        try {
          await this.performCleanup();
        } catch (error) {
          console.error('âŒ [PerformanceMonitor] Cleanup failed:', error);
        }
      },
      60 * 60 * 1000
    ); // 1ì‹œê°„

    console.log('ğŸš€ [PerformanceMonitor] Monitoring started');
  }

  /**
   * ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
   */
  private async collectPerformanceMetrics(): Promise<void> {
    const timestamp = Date.now();
    const serverIds = await this.getActiveServerIds();

    const metricsPromises = serverIds.map(async (serverId) => {
      try {
        const metrics = await this.collectServerMetrics(serverId, timestamp);

        // í˜„ì¬ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        this.currentMetrics.set(serverId, metrics);

        // íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        this.updateMetricsHistory(serverId, metrics);

        // Redisì— ìºì‹±
        await this.cacheMetrics(serverId, metrics);

        // ì„ê³„ê°’ ì²´í¬
        await this.checkThresholds(metrics);

        return metrics;
      } catch (error) {
        console.error(
          `âŒ [PerformanceMonitor] Failed to collect metrics for ${serverId}:`,
          error
        );
        return null;
      }
    });

    const results = await Promise.all(metricsPromises);
    const validMetrics = results.filter(Boolean) as PerformanceMetrics[];

    // ë°°ì¹˜ë¡œ Supabaseì— ì €ì¥
    if (validMetrics.length > 0) {
      await this.batchStoreMetrics(validMetrics);
    }

    console.log(
      `âœ… [PerformanceMonitor] Collected metrics for ${validMetrics.length} servers`
    );
  }

  /**
   * ğŸ¯ ë‹¨ì¼ ì„œë²„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
   */
  private async collectServerMetrics(
    serverId: MCPServerName,
    timestamp: number
  ): Promise<PerformanceMetrics> {
    const startTime = Date.now();

    // ê¸°ë³¸ ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
    const [redisStats, healthCheck, resourceUsage] = await Promise.all([
      this.getRedisPerformanceStats(serverId),
      this.performHealthCheck(serverId),
      this.getResourceUsage(serverId),
    ]);

    const responseTime = Date.now() - startTime;

    // íˆìŠ¤í† ë¦¬ì—ì„œ í†µê³„ ê³„ì‚°
    const history = this.metricsHistory.get(serverId) || [];
    const recentMetrics = history.slice(-20); // ìµœê·¼ 20ê°œ ë°ì´í„° í¬ì¸íŠ¸

    return {
      timestamp,
      serverId,

      responseTime: {
        current: responseTime,
        average: this.calculateAverage(recentMetrics, 'responseTime'),
        p50: this.calculatePercentile(recentMetrics, 'responseTime', 50),
        p95: this.calculatePercentile(recentMetrics, 'responseTime', 95),
        p99: this.calculatePercentile(recentMetrics, 'responseTime', 99),
      },

      throughput: {
        requestsPerSecond: this.calculateRequestsPerSecond(recentMetrics),
        successfulRequests: healthCheck.successfulRequests || 0,
        failedRequests: healthCheck.failedRequests || 0,
        totalRequests:
          (healthCheck.successfulRequests || 0) +
          (healthCheck.failedRequests || 0),
      },

      resources: {
        memory: {
          used: resourceUsage.memory.used,
          available: resourceUsage.memory.available,
          utilizationPercent:
            (resourceUsage.memory.used / resourceUsage.memory.available) * 100,
        },
        cpu: {
          utilizationPercent: resourceUsage.cpu.utilizationPercent,
          loadAverage: resourceUsage.cpu.loadAverage,
        },
        network: {
          bytesIn: resourceUsage.network.bytesIn,
          bytesOut: resourceUsage.network.bytesOut,
          connectionsActive: resourceUsage.network.connectionsActive,
        },
      },

      quality: {
        successRate: healthCheck.successRate || 0,
        errorRate: healthCheck.errorRate || 0,
        availabilityPercent: healthCheck.availabilityPercent || 0,
        healthScore: this.calculateHealthScore(healthCheck, resourceUsage),
      },

      efficiency: {
        costPerRequest: this.calculateCostPerRequest(serverId, resourceUsage),
        resourceEfficiency: this.calculateResourceEfficiency(resourceUsage),
        tierUtilization: {
          vercel: resourceUsage.tierUsage?.vercel || 0,
          gcp: resourceUsage.tierUsage?.gcp || 0,
          supabase: resourceUsage.tierUsage?.supabase || 0,
          redis: resourceUsage.tierUsage?.redis || 0,
        },
      },
    };
  }

  /**
   * ğŸ“ˆ ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
   */
  async analyzePerformanceTrend(
    serverId: MCPServerName,
    timeWindow: '5m' | '15m' | '1h' | '6h' | '24h' = '1h'
  ): Promise<PerformanceTrend> {
    const cacheKey = `performance_trend:${serverId}:${timeWindow}`;

    // ìºì‹œëœ íŠ¸ë Œë“œ í™•ì¸
    const cached = await this.redis.get<PerformanceTrend>(cacheKey);
    if (cached) {
      return cached;
    }

    const history = this.metricsHistory.get(serverId) || [];
    const windowMs = this.parseTimeWindow(timeWindow);
    const cutoff = Date.now() - windowMs;

    const recentMetrics = history.filter((m) => m.timestamp >= cutoff);

    if (recentMetrics.length === 0) {
      throw new Error(
        `No metrics available for ${serverId} in ${timeWindow} window`
      );
    }

    // íŠ¸ë Œë“œ ê³„ì‚°
    const trend = this.calculateTrend(recentMetrics);

    // ë³‘ëª©ì  ë¶„ì„
    const bottlenecks = await this.identifyBottlenecks(serverId, recentMetrics);

    // ì˜ˆì¸¡ ìƒì„±
    const predictions = this.generatePredictions(recentMetrics);

    const result: PerformanceTrend = {
      serverId,
      timeWindow,
      trend: this.classifyOverallTrend(trend),
      metrics: {
        responseTime: {
          current: trend.responseTime.current,
          change: trend.responseTime.change,
          trend: trend.responseTime.direction,
        },
        successRate: {
          current: trend.successRate.current,
          change: trend.successRate.change,
          trend: trend.successRate.direction,
        },
        throughput: {
          current: trend.throughput.current,
          change: trend.throughput.change,
          trend: trend.throughput.direction,
        },
      },
      predictions,
      bottlenecks,
    };

    // ê²°ê³¼ ìºì‹± (5ë¶„)
    await this.redis.setex(cacheKey, 300, result);

    return result;
  }

  /**
   * ğŸš¨ ì‹¤ì‹œê°„ ì„±ëŠ¥ ì•Œë¦¼ ì²´í¬
   */
  private async checkThresholds(metrics: PerformanceMetrics): Promise<void> {
    if (!this.config.alerting.realTimeAlerts) return;

    const { performanceThresholds } = this.config.alerting;
    const alerts: Array<{ level: 'warning' | 'critical'; message: string }> =
      [];

    // ì‘ë‹µì‹œê°„ ì²´í¬
    if (
      metrics.responseTime.current > performanceThresholds.responseTime.critical
    ) {
      alerts.push({
        level: 'critical',
        message: `ì‘ë‹µì‹œê°„ ì„ê³„ê°’ ì´ˆê³¼: ${metrics.responseTime.current}ms (ì„ê³„ê°’: ${performanceThresholds.responseTime.critical}ms)`,
      });
    } else if (
      metrics.responseTime.current > performanceThresholds.responseTime.warning
    ) {
      alerts.push({
        level: 'warning',
        message: `ì‘ë‹µì‹œê°„ ê²½ê³ : ${metrics.responseTime.current}ms (ëª©í‘œ: ${performanceThresholds.responseTime.target}ms)`,
      });
    }

    // ì„±ê³µë¥  ì²´í¬
    if (
      metrics.quality.successRate < performanceThresholds.successRate.critical
    ) {
      alerts.push({
        level: 'critical',
        message: `API ì„±ê³µë¥  ì„ê³„ê°’ ë¯¸ë‹¬: ${metrics.quality.successRate}% (ì„ê³„ê°’: ${performanceThresholds.successRate.critical}%)`,
      });
    } else if (
      metrics.quality.successRate < performanceThresholds.successRate.warning
    ) {
      alerts.push({
        level: 'warning',
        message: `API ì„±ê³µë¥  ê²½ê³ : ${metrics.quality.successRate}% (ëª©í‘œ: ${performanceThresholds.successRate.target}%)`,
      });
    }

    // ìì› ì‚¬ìš©ëŸ‰ ì²´í¬
    if (
      metrics.resources.memory.utilizationPercent >
      performanceThresholds.resources.memory.critical
    ) {
      alerts.push({
        level: 'critical',
        message: `ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì„ê³„ê°’ ì´ˆê³¼: ${metrics.resources.memory.utilizationPercent}% (ì„ê³„ê°’: ${performanceThresholds.resources.memory.critical}%)`,
      });
    }

    // ì•Œë¦¼ ë°œì†¡
    if (alerts.length > 0) {
      await this.sendPerformanceAlerts(metrics.serverId, alerts);
    }
  }

  /**
   * ğŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ë°ì´í„°
   */
  async getDashboardData(): Promise<{
    overview: {
      totalServers: number;
      healthyServers: number;
      degradedServers: number;
      criticalServers: number;
      avgResponseTime: number;
      overallSuccessRate: number;
    };
    trends: Array<{
      serverId: MCPServerName;
      status: 'healthy' | 'warning' | 'critical';
      responseTime: number;
      successRate: number;
      trend: 'up' | 'down' | 'stable';
    }>;
    alerts: Array<{
      serverId: MCPServerName;
      level: 'warning' | 'critical';
      message: string;
      timestamp: number;
    }>;
    efficiency: {
      resourceUtilization: number;
      costEfficiency: number;
      recommendations: string[];
    };
  }> {
    const activeServers = Array.from(this.currentMetrics.keys());
    const currentMetrics = Array.from(this.currentMetrics.values());

    // ì „ì²´ ê°œìš” ê³„ì‚°
    const overview = {
      totalServers: activeServers.length,
      healthyServers: currentMetrics.filter((m) => m.quality.healthScore >= 80)
        .length,
      degradedServers: currentMetrics.filter(
        (m) => m.quality.healthScore >= 60 && m.quality.healthScore < 80
      ).length,
      criticalServers: currentMetrics.filter((m) => m.quality.healthScore < 60)
        .length,
      avgResponseTime: this.calculateAverage(currentMetrics, 'responseTime'),
      overallSuccessRate: this.calculateAverage(currentMetrics, 'successRate'),
    };

    // ì„œë²„ë³„ íŠ¸ë Œë“œ
    const trends = await Promise.all(
      activeServers.map(async (serverId) => {
        const metrics = this.currentMetrics.get(serverId)!;
        const trend = await this.analyzePerformanceTrend(serverId, '15m');

        return {
          serverId,
          status: this.getServerStatus(metrics),
          responseTime: metrics.responseTime.current,
          successRate: metrics.quality.successRate,
          trend: trend.metrics.responseTime.trend,
        };
      })
    );

    // ìµœê·¼ ì•Œë¦¼ ì¡°íšŒ
    const alerts = await this.getRecentAlerts();

    // íš¨ìœ¨ì„± ë¶„ì„
    const efficiency = this.analyzeOverallEfficiency(currentMetrics);

    return {
      overview,
      trends,
      alerts,
      efficiency,
    };
  }

  /**
   * ğŸ”§ ì„±ëŠ¥ ìµœì í™” ì œì•ˆ ìƒì„±
   */
  async generateOptimizationRecommendations(serverId?: MCPServerName): Promise<
    Array<{
      category: 'cache' | 'database' | 'network' | 'resources' | 'architecture';
      priority: 'high' | 'medium' | 'low';
      title: string;
      description: string;
      expectedImprovement: string;
      implementation: string;
      estimatedEffort: 'low' | 'medium' | 'high';
    }>
  > {
    const recommendations: Array<any> = [];

    const metrics = serverId
      ? ([this.currentMetrics.get(serverId)].filter(
          Boolean
        ) as PerformanceMetrics[])
      : Array.from(this.currentMetrics.values());

    if (metrics.length === 0) {
      return [];
    }

    // ìºì‹œ ìµœì í™” ë¶„ì„
    const cacheRecommendations = this.analyzeCacheOptimization(metrics);
    recommendations.push(...cacheRecommendations);

    // ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ë¶„ì„
    const dbRecommendations = this.analyzeDatabaseOptimization(metrics);
    recommendations.push(...dbRecommendations);

    // ë„¤íŠ¸ì›Œí¬ ìµœì í™” ë¶„ì„
    const networkRecommendations = this.analyzeNetworkOptimization(metrics);
    recommendations.push(...networkRecommendations);

    // ìì› ìµœì í™” ë¶„ì„
    const resourceRecommendations = this.analyzeResourceOptimization(metrics);
    recommendations.push(...resourceRecommendations);

    // ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
    return recommendations.sort((a, b) => {
      const priorityOrder = { high: 3, medium: 2, low: 1 };
      return priorityOrder[b.priority] - priorityOrder[a.priority];
    });
  }

  // === Private Helper Methods ===

  private async getActiveServerIds(): Promise<MCPServerName[]> {
    try {
      const keys = await this.redis.keys('mcp:server:*');
      return keys.map((k) => k.replace('mcp:server:', '') as MCPServerName);
    } catch (error) {
      console.error('Failed to get active server IDs:', error);
      return [];
    }
  }

  private async getRedisPerformanceStats(
    serverId: MCPServerName
  ): Promise<any> {
    try {
      // Upstash Redis doesn't support info command directly
      // Use memory usage estimation instead
      const info = { memory: { used_memory: 0 } };
      return this.parseRedisInfo(info);
    } catch (error) {
      return { hits: 0, misses: 0, memory: 0 };
    }
  }

  private async performHealthCheck(serverId: MCPServerName): Promise<any> {
    try {
      const key = `mcp:health:${serverId}`;
      const health = await this.redis.get(key);
      return health || { successRate: 100, errorRate: 0 };
    } catch (error) {
      return { successRate: 0, errorRate: 100 };
    }
  }

  private async getResourceUsage(serverId: MCPServerName): Promise<any> {
    // ë¬´ë£Œ í‹°ì–´ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì •
    return {
      memory: { used: 150, available: 256 },
      cpu: { utilizationPercent: 45, loadAverage: 0.8 },
      network: { bytesIn: 1024, bytesOut: 2048, connectionsActive: 10 },
      tierUsage: { vercel: 30, gcp: 15, supabase: 3, redis: 40 },
    };
  }

  private calculateHealthScore(healthCheck: any, resourceUsage: any): number {
    const successWeight = 0.4;
    const responseWeight = 0.3;
    const resourceWeight = 0.3;

    const successScore = healthCheck.successRate || 0;
    const responseScore = Math.max(
      0,
      100 - (healthCheck.avgResponseTime || 0) / 10
    );
    const resourceScore = Math.max(
      0,
      100 - resourceUsage.memory.utilizationPercent
    );

    return Math.round(
      successScore * successWeight +
        responseScore * responseWeight +
        resourceScore * resourceWeight
    );
  }

  private calculateCostPerRequest(
    serverId: MCPServerName,
    resourceUsage: any
  ): number {
    // ë¬´ë£Œ í‹°ì–´ì—ì„œì˜ ì˜ˆìƒ ë¹„ìš© (ê¸°íšŒë¹„ìš©)
    const baseCost = 0.0001; // $0.0001 per request
    const utilizationMultiplier = resourceUsage.memory.utilizationPercent / 100;
    return baseCost * (1 + utilizationMultiplier);
  }

  private calculateResourceEfficiency(resourceUsage: any): number {
    const memoryEfficiency = Math.max(
      0,
      100 - resourceUsage.memory.utilizationPercent
    );
    const cpuEfficiency = Math.max(
      0,
      100 - resourceUsage.cpu.utilizationPercent
    );
    return Math.round((memoryEfficiency + cpuEfficiency) / 2);
  }

  private updateMetricsHistory(
    serverId: MCPServerName,
    metrics: PerformanceMetrics
  ): void {
    if (!this.metricsHistory.has(serverId)) {
      this.metricsHistory.set(serverId, []);
    }

    const history = this.metricsHistory.get(serverId)!;
    history.push(metrics);

    // ìµœëŒ€ íˆìŠ¤í† ë¦¬ í¬ì¸íŠ¸ ìœ ì§€
    if (history.length > this.config.collection.maxHistoryPoints) {
      history.splice(
        0,
        history.length - this.config.collection.maxHistoryPoints
      );
    }
  }

  private async cacheMetrics(
    serverId: MCPServerName,
    metrics: PerformanceMetrics
  ): Promise<void> {
    const key = `performance:${serverId}:latest`;
    await this.redis.setex(key, 300, metrics); // 5ë¶„ ìºì‹œ
  }

  private async batchStoreMetrics(
    metrics: PerformanceMetrics[]
  ): Promise<void> {
    try {
      const records = metrics.map((m) => ({
        server_id: m.serverId,
        timestamp: new Date(m.timestamp).toISOString(),
        response_time: m.responseTime.current,
        success_rate: m.quality.successRate,
        memory_usage: m.resources.memory.utilizationPercent,
        health_score: m.quality.healthScore,
        created_at: new Date().toISOString(),
      }));

      await this.supabase.from('performance_metrics').insert(records);
    } catch (error) {
      console.error('Failed to store performance metrics:', error);
    }
  }

  private calculateAverage(metrics: any[], field: string): number {
    if (metrics.length === 0) return 0;

    const sum = metrics.reduce((acc, m) => {
      if (field === 'responseTime') return acc + m.responseTime.current;
      if (field === 'successRate') return acc + m.quality.successRate;
      return acc;
    }, 0);

    return Math.round(sum / metrics.length);
  }

  private calculatePercentile(
    metrics: any[],
    field: string,
    percentile: number
  ): number {
    if (metrics.length === 0) return 0;

    const values = metrics
      .map((m) => {
        if (field === 'responseTime') return m.responseTime.current;
        return 0;
      })
      .sort((a, b) => a - b);

    const index = Math.ceil((percentile / 100) * values.length) - 1;
    return values[Math.max(0, index)] || 0;
  }

  private calculateRequestsPerSecond(metrics: any[]): number {
    if (metrics.length < 2) return 0;

    const latest = metrics[metrics.length - 1];
    const previous = metrics[metrics.length - 2];

    const timeDiff = (latest.timestamp - previous.timestamp) / 1000;
    const requestDiff =
      latest.throughput.totalRequests - previous.throughput.totalRequests;

    return timeDiff > 0 ? Math.round(requestDiff / timeDiff) : 0;
  }

  private parseTimeWindow(timeWindow: string): number {
    const windows = {
      '5m': 5 * 60 * 1000,
      '15m': 15 * 60 * 1000,
      '1h': 60 * 60 * 1000,
      '6h': 6 * 60 * 60 * 1000,
      '24h': 24 * 60 * 60 * 1000,
    };
    return windows[timeWindow as keyof typeof windows] || windows['1h'];
  }

  private parseRedisInfo(info: string): any {
    // Redis INFO ëª…ë ¹ì–´ ê²°ê³¼ íŒŒì‹±
    const lines = info.split('\r\n');
    const stats: any = {};

    lines.forEach((line) => {
      if (line.includes(':')) {
        const [key, value] = line.split(':');
        stats[key] = isNaN(Number(value)) ? value : Number(value);
      }
    });

    return {
      hits: stats.keyspace_hits || 0,
      misses: stats.keyspace_misses || 0,
      memory: stats.used_memory || 0,
    };
  }

  private calculateTrend(metrics: PerformanceMetrics[]): any {
    if (metrics.length < 2) {
      return {
        responseTime: { current: 0, change: 0, direction: 'stable' as const },
        successRate: { current: 0, change: 0, direction: 'stable' as const },
        throughput: { current: 0, change: 0, direction: 'stable' as const },
      };
    }

    const latest = metrics[metrics.length - 1];
    const previous = metrics[0];

    return {
      responseTime: {
        current: latest.responseTime.current,
        change:
          ((latest.responseTime.current - previous.responseTime.current) /
            previous.responseTime.current) *
          100,
        direction:
          latest.responseTime.current > previous.responseTime.current
            ? 'up'
            : latest.responseTime.current < previous.responseTime.current
              ? 'down'
              : 'stable',
      },
      successRate: {
        current: latest.quality.successRate,
        change: latest.quality.successRate - previous.quality.successRate,
        direction:
          latest.quality.successRate > previous.quality.successRate
            ? 'up'
            : latest.quality.successRate < previous.quality.successRate
              ? 'down'
              : 'stable',
      },
      throughput: {
        current: latest.throughput.requestsPerSecond,
        change:
          ((latest.throughput.requestsPerSecond -
            previous.throughput.requestsPerSecond) /
            Math.max(previous.throughput.requestsPerSecond, 1)) *
          100,
        direction:
          latest.throughput.requestsPerSecond >
          previous.throughput.requestsPerSecond
            ? 'up'
            : latest.throughput.requestsPerSecond <
                previous.throughput.requestsPerSecond
              ? 'down'
              : 'stable',
      },
    };
  }

  private classifyOverallTrend(
    trend: any
  ): 'improving' | 'stable' | 'degrading' | 'critical' {
    const responseTimeGetting = trend.responseTime.direction;
    const successRateGetting = trend.successRate.direction;

    if (responseTimeGetting === 'down' && successRateGetting === 'up')
      return 'improving';
    if (responseTimeGetting === 'up' && successRateGetting === 'down')
      return 'degrading';
    if (
      Math.abs(trend.responseTime.change) > 50 ||
      Math.abs(trend.successRate.change) > 10
    )
      return 'critical';
    return 'stable';
  }

  private async identifyBottlenecks(
    serverId: MCPServerName,
    metrics: PerformanceMetrics[]
  ): Promise<Array<any>> {
    const bottlenecks: Array<any> = [];

    const latest = metrics[metrics.length - 1];

    // Redis ë³‘ëª©ì  ì²´í¬
    if (latest.resources.memory.utilizationPercent > 85) {
      bottlenecks.push({
        component: 'redis',
        severity: 'high',
        impact: 80,
        description: 'Redis ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 85%ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤',
        recommendation: 'TTL ì„¤ì • ìµœì í™” ë° ë¶ˆí•„ìš”í•œ í‚¤ ì •ë¦¬ í•„ìš”',
      });
    }

    // Supabase ë³‘ëª©ì  ì²´í¬ (ì‘ë‹µì‹œê°„ ê¸°ë°˜)
    if (latest.responseTime.current > 200) {
      bottlenecks.push({
        component: 'supabase',
        severity: 'medium',
        impact: 60,
        description: 'ë°ì´í„°ë² ì´ìŠ¤ ì‘ë‹µì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤',
        recommendation: 'ì¿¼ë¦¬ ìµœì í™” ë° ì¸ë±ìŠ¤ ì¶”ê°€ ê²€í† ',
      });
    }

    return bottlenecks;
  }

  private generatePredictions(metrics: PerformanceMetrics[]): any {
    if (metrics.length < 3) {
      return {
        nextHour: { responseTime: 100, successRate: 99, confidence: 50 },
        nextDay: { responseTime: 100, successRate: 99, confidence: 30 },
      };
    }

    // ê°„ë‹¨í•œ ì„ í˜• íšŒê·€ ì˜ˆì¸¡
    const latest = metrics[metrics.length - 1];
    const trend = this.calculateTrend(metrics);

    return {
      nextHour: {
        responseTime: Math.max(
          50,
          latest.responseTime.current + trend.responseTime.change * 0.1
        ),
        successRate: Math.min(
          100,
          Math.max(
            90,
            latest.quality.successRate + trend.successRate.change * 0.1
          )
        ),
        confidence: 75,
      },
      nextDay: {
        responseTime: Math.max(
          50,
          latest.responseTime.current + trend.responseTime.change * 0.5
        ),
        successRate: Math.min(
          100,
          Math.max(
            85,
            latest.quality.successRate + trend.successRate.change * 0.5
          )
        ),
        confidence: 60,
      },
    };
  }

  private getServerStatus(
    metrics: PerformanceMetrics
  ): 'healthy' | 'warning' | 'critical' {
    if (metrics.quality.healthScore >= 80) return 'healthy';
    if (metrics.quality.healthScore >= 60) return 'warning';
    return 'critical';
  }

  private async getRecentAlerts(): Promise<Array<any>> {
    try {
      const { data } = await this.supabase
        .from('performance_alerts')
        .select('*')
        .gte(
          'created_at',
          new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString()
        )
        .order('created_at', { ascending: false })
        .limit(10);

      return data || [];
    } catch (error) {
      return [];
    }
  }

  private analyzeOverallEfficiency(metrics: PerformanceMetrics[]): any {
    const avgResourceUtilization = this.calculateAverage(
      metrics,
      'resourceUtilization'
    );
    const avgCostEfficiency =
      metrics.reduce((acc, m) => acc + m.efficiency.resourceEfficiency, 0) /
      metrics.length;

    const recommendations: string[] = [];

    if (avgResourceUtilization > 80) {
      recommendations.push('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í•„ìš”');
    }
    if (avgCostEfficiency < 85) {
      recommendations.push('ìì› íš¨ìœ¨ì„± ê°œì„  ê¶Œì¥');
    }

    return {
      resourceUtilization: avgResourceUtilization,
      costEfficiency: avgCostEfficiency,
      recommendations,
    };
  }

  private analyzeCacheOptimization(metrics: PerformanceMetrics[]): Array<any> {
    const recommendations: Array<any> = [];

    const avgMemoryUsage = this.calculateAverage(metrics, 'memoryUsage');

    if (avgMemoryUsage > 80) {
      recommendations.push({
        category: 'cache',
        priority: 'high',
        title: 'Redis ë©”ëª¨ë¦¬ ìµœì í™”',
        description:
          'ìºì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. TTL ì„¤ì •ê³¼ ìºì‹œ ì •ì±…ì„ ê²€í† í•˜ì„¸ìš”.',
        expectedImprovement: 'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 30% ê°ì†Œ, ì‘ë‹µì‹œê°„ 20% ê°œì„ ',
        implementation: 'TTL ë‹¨ì¶•, ë¶ˆí•„ìš”í•œ í‚¤ ì •ë¦¬, ì••ì¶• í™œì„±í™”',
        estimatedEffort: 'medium',
      });
    }

    return recommendations;
  }

  private analyzeDatabaseOptimization(
    metrics: PerformanceMetrics[]
  ): Array<any> {
    const recommendations: Array<any> = [];

    const avgResponseTime = this.calculateAverage(metrics, 'responseTime');

    if (avgResponseTime > 200) {
      recommendations.push({
        category: 'database',
        priority: 'high',
        title: 'Supabase ì¿¼ë¦¬ ìµœì í™”',
        description: 'ë°ì´í„°ë² ì´ìŠ¤ ì‘ë‹µì‹œê°„ì´ ëª©í‘œì¹˜ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.',
        expectedImprovement: 'ì‘ë‹µì‹œê°„ 40% ë‹¨ì¶•',
        implementation: 'ì¸ë±ìŠ¤ ì¶”ê°€, ì¿¼ë¦¬ ìµœì í™”, ë°°ì¹˜ ì²˜ë¦¬ ê°œì„ ',
        estimatedEffort: 'high',
      });
    }

    return recommendations;
  }

  private analyzeNetworkOptimization(
    metrics: PerformanceMetrics[]
  ): Array<any> {
    return []; // ë„¤íŠ¸ì›Œí¬ ìµœì í™” ë¡œì§
  }

  private analyzeResourceOptimization(
    metrics: PerformanceMetrics[]
  ): Array<any> {
    return []; // ìì› ìµœì í™” ë¡œì§
  }

  private async sendPerformanceAlerts(
    serverId: MCPServerName,
    alerts: Array<{ level: 'warning' | 'critical'; message: string }>
  ): Promise<void> {
    try {
      const records = alerts.map((alert) => ({
        server_id: serverId,
        level: alert.level,
        message: alert.message,
        created_at: new Date().toISOString(),
      }));

      await this.supabase.from('performance_alerts').insert(records);

      console.log(
        `ğŸš¨ [PerformanceMonitor] ${alerts.length} alerts sent for ${serverId}`
      );
    } catch (error) {
      console.error('Failed to send performance alerts:', error);
    }
  }

  private async performCleanup(): Promise<void> {
    const cutoff =
      Date.now() - this.config.collection.retentionDays * 24 * 60 * 60 * 1000;

    // ë©”ëª¨ë¦¬ì—ì„œ ì˜¤ë˜ëœ ë°ì´í„° ì œê±°
    for (const [serverId, history] of this.metricsHistory.entries()) {
      const filtered = history.filter((m) => m.timestamp >= cutoff);
      this.metricsHistory.set(serverId, filtered);
    }

    console.log('ğŸ§¹ [PerformanceMonitor] Cleanup completed');
  }

  /**
   * ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  async cleanup(): Promise<void> {
    if (this.monitoringTimer) clearInterval(this.monitoringTimer);
    if (this.cleanupTimer) clearInterval(this.cleanupTimer);

    this.metricsHistory.clear();
    this.currentMetrics.clear();

    console.log('âœ… [PerformanceMonitor] Cleanup completed');
  }
}

// íŒ©í† ë¦¬ í•¨ìˆ˜
export function createPerformanceMonitor(
  redis: Redis,
  supabase: SupabaseClient,
  config?: Partial<PerformanceMonitorConfig>
): MCPPerformanceMonitor {
  return new MCPPerformanceMonitor(redis, supabase, config);
}

// íƒ€ì… ìµìŠ¤í¬íŠ¸
export type { PerformanceMonitorConfig, PerformanceTargets, PerformanceTrend };
