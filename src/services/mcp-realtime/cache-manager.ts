/**
 * ğŸ”´ MCP ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ìºì‹œ ê´€ë¦¬ì v2.0
 *
 * Upstash Redis ê¸°ë°˜ ê³ ì„±ëŠ¥ ìºì‹± ì „ëµ
 * - ë¬´ë£Œ í‹°ì–´ 256MB ë©”ëª¨ë¦¬ ìµœì í™”
 * - ì‘ë‹µì‹œê°„ ëª©í‘œ: <100ms (ìºì‹œ íˆíŠ¸), <300ms (ìºì‹œ ë¯¸ìŠ¤)
 * - ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ TTL ìµœì í™” (15ì´ˆ ê°„ê²©)
 * - ë°°ì¹˜ ì²˜ë¦¬ ë° íŒŒì´í”„ë¼ì¸ ìµœì í™”
 */

import { Redis } from '@upstash/redis';
import type {
  MCPServerMetrics,
  HealthCheckResult,
  MonitoringEvent,
  SystemHealthSummary,
  CircuitBreakerStats,
  MCPServerName,
} from '../mcp-monitor/types';

// ğŸ”‘ MCP ì „ìš© ìºì‹œ í‚¤ íŒ¨í„´
export const MCP_CACHE_KEYS = {
  // ì„œë²„ ë©”íŠ¸ë¦­ (15ì´ˆ ê°±ì‹ )
  SERVER_METRICS: (serverId: MCPServerName) => `mcp:metrics:${serverId}`,
  SERVER_HEALTH: (serverId: MCPServerName) => `mcp:health:${serverId}`,

  // ì‹œìŠ¤í…œ ìƒíƒœ (1ë¶„ ê°„ê²©)
  SYSTEM_SUMMARY: 'mcp:system:summary',
  ALL_METRICS: 'mcp:metrics:all',

  // ì„±ëŠ¥ ì¶”ì„¸ (5ë¶„ ìœˆë„ìš°)
  PERFORMANCE_TREND: (serverId: MCPServerName, window: string) =>
    `mcp:trend:${serverId}:${window}`,

  // ì´ë²¤íŠ¸ ë° ì•Œë¦¼ (30ì´ˆ)
  RECENT_EVENTS: 'mcp:events:recent',
  ACTIVE_ALERTS: 'mcp:alerts:active',

  // Circuit Breaker ìƒíƒœ (ì‹¤ì‹œê°„)
  CIRCUIT_BREAKER: (serverId: MCPServerName) => `mcp:cb:${serverId}`,

  // ì§‘ê³„ í†µê³„ (15ë¶„)
  HOURLY_STATS: (serverId: MCPServerName) => `mcp:stats:hourly:${serverId}`,
  DAILY_STATS: (serverId: MCPServerName) => `mcp:stats:daily:${serverId}`,

  // ì—°ê²° í’€ ë° ì„¸ì…˜
  CONNECTION_POOL: 'mcp:pool:connections',
  SESSION_STATE: (sessionId: string) => `mcp:session:${sessionId}`,
} as const;

// â° TTL ì „ëµ (ë¬´ë£Œ í‹°ì–´ ë©”ëª¨ë¦¬ ìµœì í™”)
export const MCP_TTL_STRATEGY = {
  // ì‹¤ì‹œê°„ ë°ì´í„° (ì§§ì€ TTL)
  REALTIME_METRICS: 15, // 15ì´ˆ - ëª¨ë‹ˆí„°ë§ ê°„ê²©ê³¼ ë™ê¸°í™”
  HEALTH_CHECK: 30, // 30ì´ˆ - í—¬ìŠ¤ì²´í¬ ê°„ê²©ì˜ 2ë°°
  CIRCUIT_BREAKER: 10, // 10ì´ˆ - ì¦‰ê°ì ì¸ ìƒíƒœ ë³€ê²½ ê°ì§€

  // ì‹œìŠ¤í…œ ë ˆë²¨ (ì¤‘ê°„ TTL)
  SYSTEM_SUMMARY: 60, // 1ë¶„ - ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ
  RECENT_EVENTS: 30, // 30ì´ˆ - ìµœì‹  ì´ë²¤íŠ¸
  ACTIVE_ALERTS: 45, // 45ì´ˆ - í™œì„± ì•Œë¦¼

  // ë¶„ì„ ë°ì´í„° (ê¸´ TTL)
  PERFORMANCE_TREND: 300, // 5ë¶„ - ì„±ëŠ¥ ì¶”ì„¸ ë¶„ì„
  HOURLY_STATS: 900, // 15ë¶„ - ì‹œê°„ë³„ í†µê³„
  DAILY_STATS: 3600, // 1ì‹œê°„ - ì¼ë³„ í†µê³„

  // ì„¸ì…˜ ê´€ë¦¬ (ê°€ë³€ TTL)
  CONNECTION_POOL: 120, // 2ë¶„ - ì—°ê²° í’€ ìƒíƒœ
  SESSION_STATE: 600, // 10ë¶„ - ì‚¬ìš©ì ì„¸ì…˜
} as const;

// ğŸ“Š ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­
interface CachePerformanceMetrics {
  hits: number;
  misses: number;
  sets: number;
  deletes: number;
  errors: number;
  hitRate: number;
  avgResponseTime: number;
  memoryUsage: number;
  lastUpdate: number;
}

// ğŸ¯ ë°°ì¹˜ ì‘ì—… ì„¤ì •
interface BatchConfig {
  maxBatchSize: number;
  flushInterval: number;
  compressionThreshold: number;
  retryAttempts: number;
}

const BATCH_CONFIG: BatchConfig = {
  maxBatchSize: 50, // ìµœëŒ€ 50ê°œ ì‘ì—… ë°°ì¹˜
  flushInterval: 100, // 100ms í›„ ìë™ í”ŒëŸ¬ì‹œ
  compressionThreshold: 1024, // 1KB ì´ìƒ ì••ì¶• ê³ ë ¤
  retryAttempts: 2, // ìµœëŒ€ 2íšŒ ì¬ì‹œë„
};

/**
 * MCP ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ìºì‹œ ê´€ë¦¬ì
 */
export class MCPCacheManager {
  private redis: Redis;
  private metrics: CachePerformanceMetrics;
  private batchQueue: Array<{
    operation: string;
    key: string;
    value?: any;
    ttl?: number;
  }> = [];
  private batchTimer: NodeJS.Timeout | null = null;
  private memoryMonitor: NodeJS.Timeout | null = null;

  constructor(redis: Redis) {
    this.redis = redis;
    this.metrics = this.initializeMetrics();
    this.startBackgroundTasks();
  }

  /**
   * ğŸš€ ì„œë²„ ë©”íŠ¸ë¦­ ìºì‹± (ê³ ì„±ëŠ¥ ë°°ì¹˜ ì²˜ë¦¬)
   */
  async cacheServerMetrics(metrics: MCPServerMetrics[]): Promise<void> {
    const startTime = Date.now();

    try {
      // ê°œë³„ ì„œë²„ ë©”íŠ¸ë¦­ ìºì‹±
      const individualOps = metrics.map((metric) => ({
        operation: 'setex',
        key: MCP_CACHE_KEYS.SERVER_METRICS(metric.serverId),
        value: metric,
        ttl: MCP_TTL_STRATEGY.REALTIME_METRICS,
      }));

      // ì „ì²´ ë©”íŠ¸ë¦­ ë°°ì—´ ìºì‹±
      const allMetricsOp = {
        operation: 'setex',
        key: MCP_CACHE_KEYS.ALL_METRICS,
        value: metrics,
        ttl: MCP_TTL_STRATEGY.REALTIME_METRICS,
      };

      // ì‹œìŠ¤í…œ ìš”ì•½ ìƒì„± ë° ìºì‹±
      const summary = this.generateSystemSummary(metrics);
      const summaryOp = {
        operation: 'setex',
        key: MCP_CACHE_KEYS.SYSTEM_SUMMARY,
        value: summary,
        ttl: MCP_TTL_STRATEGY.SYSTEM_SUMMARY,
      };

      // ë°°ì¹˜ ì²˜ë¦¬ë¡œ í•œ ë²ˆì— ì‹¤í–‰
      await this.executeBatch([...individualOps, allMetricsOp, summaryOp]);

      this.metrics.sets += metrics.length + 2;
      console.log(
        `âœ… [MCPCacheManager] ${metrics.length} server metrics cached (${Date.now() - startTime}ms)`
      );
    } catch (error) {
      this.metrics.errors++;
      console.error('âŒ [MCPCacheManager] Metrics caching failed:', error);
      throw error;
    }
  }

  /**
   * ğŸ¥ í—¬ìŠ¤ì²´í¬ ê²°ê³¼ ìºì‹±
   */
  async cacheHealthCheck(
    serverId: MCPServerName,
    result: HealthCheckResult
  ): Promise<void> {
    const key = MCP_CACHE_KEYS.SERVER_HEALTH(serverId);
    await this.setWithMetrics(key, result, MCP_TTL_STRATEGY.HEALTH_CHECK);
  }

  /**
   * ğŸ”„ Circuit Breaker ìƒíƒœ ìºì‹±
   */
  async cacheCircuitBreakerState(
    serverId: MCPServerName,
    stats: CircuitBreakerStats
  ): Promise<void> {
    const key = MCP_CACHE_KEYS.CIRCUIT_BREAKER(serverId);
    await this.setWithMetrics(key, stats, MCP_TTL_STRATEGY.CIRCUIT_BREAKER);
  }

  /**
   * ğŸ“¢ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ìºì‹±
   */
  async cacheRecentEvents(events: MonitoringEvent[]): Promise<void> {
    // ìµœì‹  20ê°œ ì´ë²¤íŠ¸ë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ì ˆì•½)
    const recentEvents = events.slice(0, 20);
    await this.setWithMetrics(
      MCP_CACHE_KEYS.RECENT_EVENTS,
      recentEvents,
      MCP_TTL_STRATEGY.RECENT_EVENTS
    );
  }

  /**
   * ğŸ“ˆ ì„±ëŠ¥ ì¶”ì„¸ ìºì‹± (ì‹œê°„ ìœˆë„ìš°ë³„)
   */
  async cachePerformanceTrend(
    serverId: MCPServerName,
    window: '5m' | '15m' | '1h' | '24h',
    trendData: any
  ): Promise<void> {
    const key = MCP_CACHE_KEYS.PERFORMANCE_TREND(serverId, window);
    await this.setWithMetrics(
      key,
      trendData,
      MCP_TTL_STRATEGY.PERFORMANCE_TREND
    );
  }

  /**
   * ğŸ” ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ (ìºì‹œ ìš°ì„ )
   */
  async getServerMetrics(
    serverId: MCPServerName
  ): Promise<MCPServerMetrics | null> {
    const key = MCP_CACHE_KEYS.SERVER_METRICS(serverId);
    return this.getWithMetrics<MCPServerMetrics>(key);
  }

  /**
   * ğŸ“Š ëª¨ë“  ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ
   */
  async getAllMetrics(): Promise<MCPServerMetrics[] | null> {
    return this.getWithMetrics<MCPServerMetrics[]>(MCP_CACHE_KEYS.ALL_METRICS);
  }

  /**
   * ğŸ¯ ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½ ì¡°íšŒ
   */
  async getSystemSummary(): Promise<SystemHealthSummary | null> {
    return this.getWithMetrics<SystemHealthSummary>(
      MCP_CACHE_KEYS.SYSTEM_SUMMARY
    );
  }

  /**
   * âš¡ ë‹¤ì¤‘ í‚¤ ì¡°íšŒ (ë°°ì¹˜ GET)
   */
  async getMultipleMetrics(
    serverIds: MCPServerName[]
  ): Promise<(MCPServerMetrics | null)[]> {
    const keys = serverIds.map((id) => MCP_CACHE_KEYS.SERVER_METRICS(id));
    return this.mgetWithMetrics<MCPServerMetrics>(keys);
  }

  /**
   * ğŸ§¹ ì„ íƒì  ìºì‹œ ë¬´íš¨í™” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
   */
  async invalidateServerCache(serverId: MCPServerName): Promise<void> {
    const keysToDelete = [
      MCP_CACHE_KEYS.SERVER_METRICS(serverId),
      MCP_CACHE_KEYS.SERVER_HEALTH(serverId),
      MCP_CACHE_KEYS.CIRCUIT_BREAKER(serverId),
    ];

    try {
      const pipeline = this.redis.pipeline();
      keysToDelete.forEach((key) => pipeline.del(key));
      await pipeline.exec();

      this.metrics.deletes += keysToDelete.length;
      console.log(`ğŸ§¹ [MCPCacheManager] Server ${serverId} cache invalidated`);
    } catch (error) {
      this.metrics.errors++;
      console.error(
        `âŒ [MCPCacheManager] Cache invalidation failed for ${serverId}:`,
        error
      );
    }
  }

  /**
   * ğŸ”¥ ë©”ëª¨ë¦¬ ì••ë°• ì‹œ ê¸´ê¸‰ ì •ë¦¬
   */
  async emergencyCleanup(): Promise<void> {
    console.warn('ğŸš¨ [MCPCacheManager] Emergency cleanup initiated');

    try {
      // ê°€ì¥ ì˜¤ë˜ëœ ì„±ëŠ¥ ì¶”ì„¸ ë°ì´í„°ë¶€í„° ì œê±°
      const servers = await this.redis.keys('mcp:trend:*');
      if (servers.length > 0) {
        const pipeline = this.redis.pipeline();
        servers
          .slice(0, Math.min(20, servers.length))
          .forEach((key) => pipeline.del(key));
        await pipeline.exec();
      }

      // í†µê³„ ìºì‹œ ì •ë¦¬
      const statsKeys = await this.redis.keys('mcp:stats:*');
      if (statsKeys.length > 0) {
        const pipeline = this.redis.pipeline();
        statsKeys
          .slice(0, Math.min(10, statsKeys.length))
          .forEach((key) => pipeline.del(key));
        await pipeline.exec();
      }

      console.log('âœ… [MCPCacheManager] Emergency cleanup completed');
    } catch (error) {
      console.error('âŒ [MCPCacheManager] Emergency cleanup failed:', error);
    }
  }

  /**
   * ğŸ“Š ìºì‹œ ì„±ëŠ¥ í†µê³„ ì¡°íšŒ
   */
  getPerformanceMetrics(): CachePerformanceMetrics & {
    recommendations: string[];
    memoryEfficiency: number;
  } {
    const recommendations: string[] = [];
    const memoryEfficiency = this.calculateMemoryEfficiency();

    // ì„±ëŠ¥ ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­
    if (this.metrics.hitRate < 75) {
      recommendations.push('ìºì‹œ íˆíŠ¸ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. TTL ì „ëµì„ ì¬ê²€í† í•˜ì„¸ìš”.');
    }

    if (this.metrics.avgResponseTime > 50) {
      recommendations.push('ìºì‹œ ì‘ë‹µì‹œê°„ì´ ë†’ìŠµë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ì„¸ìš”.');
    }

    if (this.metrics.memoryUsage > 200) {
      recommendations.push('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ê¸´ê¸‰ ì •ë¦¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.');
    }

    if (memoryEfficiency < 0.8) {
      recommendations.push(
        'ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. ì••ì¶• ë˜ëŠ” TTL ë‹¨ì¶•ì„ ê³ ë ¤í•˜ì„¸ìš”.'
      );
    }

    return {
      ...this.metrics,
      recommendations,
      memoryEfficiency,
    };
  }

  /**
   * ğŸ”§ Private: ë©”íŠ¸ë¦­ê³¼ í•¨ê»˜ SET ì‹¤í–‰
   */
  private async setWithMetrics<T>(
    key: string,
    value: T,
    ttl: number
  ): Promise<void> {
    const startTime = Date.now();

    try {
      await this.redis.setex(key, ttl, value);
      this.metrics.sets++;
      this.updateAvgResponseTime(Date.now() - startTime);
    } catch (error) {
      this.metrics.errors++;
      throw error;
    }
  }

  /**
   * ğŸ”§ Private: ë©”íŠ¸ë¦­ê³¼ í•¨ê»˜ GET ì‹¤í–‰
   */
  private async getWithMetrics<T>(key: string): Promise<T | null> {
    const startTime = Date.now();

    try {
      const data = await this.redis.get<T>(key);

      if (data !== null) {
        this.metrics.hits++;
      } else {
        this.metrics.misses++;
      }

      this.updateHitRate();
      this.updateAvgResponseTime(Date.now() - startTime);

      return data;
    } catch (error) {
      this.metrics.errors++;
      return null;
    }
  }

  /**
   * ğŸ”§ Private: ë‹¤ì¤‘ GET with ë©”íŠ¸ë¦­
   */
  private async mgetWithMetrics<T>(keys: string[]): Promise<(T | null)[]> {
    const startTime = Date.now();

    try {
      const pipeline = this.redis.pipeline();
      keys.forEach((key) => pipeline.get(key));
      const results = await pipeline.exec();

      // í†µê³„ ì—…ë°ì´íŠ¸
      results.forEach((result) => {
        if (result) {
          this.metrics.hits++;
        } else {
          this.metrics.misses++;
        }
      });

      this.updateHitRate();
      this.updateAvgResponseTime(Date.now() - startTime);

      return results as (T | null)[];
    } catch (error) {
      this.metrics.errors++;
      return keys.map(() => null);
    }
  }

  /**
   * ğŸ”§ Private: ë°°ì¹˜ ì‹¤í–‰
   */
  private async executeBatch(
    operations: Array<{
      operation: string;
      key: string;
      value?: any;
      ttl?: number;
    }>
  ): Promise<void> {
    if (operations.length === 0) return;

    const startTime = Date.now();

    try {
      const pipeline = this.redis.pipeline();

      operations.forEach(({ operation, key, value, ttl }) => {
        if (operation === 'setex' && ttl) {
          pipeline.setex(key, ttl, value);
        } else if (operation === 'set') {
          pipeline.set(key, value);
        } else if (operation === 'del') {
          pipeline.del(key);
        }
      });

      await pipeline.exec();
      console.log(
        `âš¡ [MCPCacheManager] Batch executed: ${operations.length} ops (${Date.now() - startTime}ms)`
      );
    } catch (error) {
      console.error('âŒ [MCPCacheManager] Batch execution failed:', error);
      throw error;
    }
  }

  /**
   * ğŸ”§ Private: ì‹œìŠ¤í…œ ìš”ì•½ ìƒì„±
   */
  private generateSystemSummary(
    metrics: MCPServerMetrics[]
  ): SystemHealthSummary {
    const totalServers = metrics.length;
    const healthyServers = metrics.filter((m) => m.status === 'healthy').length;
    const degradedServers = metrics.filter(
      (m) => m.status === 'degraded'
    ).length;
    const unhealthyServers = metrics.filter(
      (m) => m.status === 'unhealthy'
    ).length;

    const avgResponseTime =
      metrics.length > 0
        ? metrics.reduce((sum, m) => sum + m.responseTime, 0) / metrics.length
        : 0;

    const criticalIssues: string[] = [];
    const warnings: string[] = [];

    // ì„ê³„ ìƒí™© ê°ì§€
    metrics.forEach((metric) => {
      if (metric.status === 'unhealthy') {
        criticalIssues.push(`Server ${metric.serverId} is unhealthy`);
      }
      if (metric.errorRate > 10) {
        warnings.push(
          `High error rate on ${metric.serverId}: ${metric.errorRate}%`
        );
      }
      if (metric.responseTime > 1000) {
        warnings.push(
          `Slow response time on ${metric.serverId}: ${metric.responseTime}ms`
        );
      }
    });

    // ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ê²°ì •
    let systemStatus: 'healthy' | 'degraded' | 'unhealthy';
    if (criticalIssues.length > 0 || unhealthyServers > totalServers * 0.3) {
      systemStatus = 'unhealthy';
    } else if (warnings.length > 0 || degradedServers > totalServers * 0.2) {
      systemStatus = 'degraded';
    } else {
      systemStatus = 'healthy';
    }

    return {
      timestamp: Date.now(),
      totalServers,
      healthyServers,
      degradedServers,
      unhealthyServers,
      averageResponseTime: avgResponseTime,
      systemStatus,
      criticalIssues,
      warnings,
    };
  }

  /**
   * ğŸ”§ Private: ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
   */
  private initializeMetrics(): CachePerformanceMetrics {
    return {
      hits: 0,
      misses: 0,
      sets: 0,
      deletes: 0,
      errors: 0,
      hitRate: 0,
      avgResponseTime: 0,
      memoryUsage: 0,
      lastUpdate: Date.now(),
    };
  }

  /**
   * ğŸ”§ Private: íˆíŠ¸ìœ¨ ì—…ë°ì´íŠ¸
   */
  private updateHitRate(): void {
    const total = this.metrics.hits + this.metrics.misses;
    this.metrics.hitRate = total > 0 ? (this.metrics.hits / total) * 100 : 0;
  }

  /**
   * ğŸ”§ Private: í‰ê·  ì‘ë‹µì‹œê°„ ì—…ë°ì´íŠ¸
   */
  private updateAvgResponseTime(responseTime: number): void {
    const total = this.metrics.hits + this.metrics.misses + this.metrics.sets;
    this.metrics.avgResponseTime =
      (this.metrics.avgResponseTime * (total - 1) + responseTime) / total;
  }

  /**
   * ğŸ”§ Private: ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê³„ì‚°
   */
  private calculateMemoryEfficiency(): number {
    // íˆíŠ¸ìœ¨ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê¸°ë°˜ìœ¼ë¡œ íš¨ìœ¨ì„± ê³„ì‚°
    const hitRateWeight = 0.7;
    const memoryWeight = 0.3;

    const hitRateScore = this.metrics.hitRate / 100;
    const memoryScore = Math.max(0, 1 - this.metrics.memoryUsage / 256); // 256MB ê¸°ì¤€

    return hitRateWeight * hitRateScore + memoryWeight * memoryScore;
  }

  /**
   * ğŸ”§ Private: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘
   */
  private startBackgroundTasks(): void {
    // 5ë¶„ë§ˆë‹¤ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
    this.memoryMonitor = setInterval(
      () => {
        // ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • (ì‹¤ì œ INFO ëª…ë ¹ ë¶ˆê°€)
        this.metrics.memoryUsage = Math.min(256, this.metrics.sets * 0.002); // 2KB per key estimate
        this.metrics.lastUpdate = Date.now();

        // ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì²´í¬
        if (this.metrics.memoryUsage > 200) {
          console.warn(
            `âš ï¸ [MCPCacheManager] High memory usage: ${this.metrics.memoryUsage}MB`
          );
        }
      },
      5 * 60 * 1000
    );
  }

  /**
   * ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  async cleanup(): Promise<void> {
    if (this.batchTimer) {
      clearTimeout(this.batchTimer);
    }

    if (this.memoryMonitor) {
      clearInterval(this.memoryMonitor);
    }

    // ëŒ€ê¸° ì¤‘ì¸ ë°°ì¹˜ ì‘ì—… ì™„ë£Œ
    if (this.batchQueue.length > 0) {
      await this.executeBatch(this.batchQueue);
      this.batchQueue = [];
    }

    console.log('âœ… [MCPCacheManager] Cleanup completed');
  }
}

/**
 * íŒ©í† ë¦¬ í•¨ìˆ˜ - ì‹±ê¸€í†¤ íŒ¨í„´
 */
export function createMCPCacheManager(redis: Redis): MCPCacheManager {
  return new MCPCacheManager(redis);
}
