/**
 * MCP ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ìì—°ì–´ ì§ˆì˜ ì—”ì§„
 *
 * ì£¼ìš” ê¸°ëŠ¥:
 * - í•œêµ­ì–´/ì˜ì–´ ìì—°ì–´ ì§ˆì˜ ì²˜ë¦¬
 * - MCP ë©”íŠ¸ë¦­ ë°ì´í„° ê¸°ë°˜ ë‹µë³€ ìƒì„±
 * - ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ë° ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
 * - ì‹¤ì‹œê°„ ë°ì´í„° ì‹œê°í™” ì œì•ˆ
 */

import type {
  MCPServerMetrics,
  MCPServerName,
  MonitoringDashboard,
  SystemHealthSummary,
} from '../mcp-monitor/types';
import type { AnomalyDetectionResult } from './ai-anomaly-detector';
import type { PredictionResult } from './performance-predictor';
import type { IntelligentAlert } from './intelligent-alerting';
import { UnifiedAIEngineRouter } from '../ai/UnifiedAIEngineRouter';
import { getErrorMessage } from '../../types/type-utils';

/**
 * ìì—°ì–´ ì§ˆì˜ ìš”ì²­
 */
export interface NLPQueryRequest {
  query: string;
  language: 'ko' | 'en' | 'auto';
  context?: {
    serverId?: MCPServerName;
    timeRange?: {
      start: number;
      end: number;
    };
    focusMetrics?: (keyof MCPServerMetrics)[];
    conversationHistory?: NLPConversation[];
  };
  preferences?: {
    responseFormat: 'detailed' | 'summary' | 'actionable';
    includeVisualization: boolean;
    includeRecommendations: boolean;
    maxResponseLength: number;
  };
}

/**
 * ìì—°ì–´ ì§ˆì˜ ì‘ë‹µ
 */
export interface NLPQueryResponse {
  success: boolean;
  query: string;
  answer: string;
  confidence: number; // 0-1
  language: 'ko' | 'en';

  // ë¶„ì„ ê²°ê³¼
  analysis: {
    intent: string;
    entities: {
      type: 'server' | 'metric' | 'time' | 'threshold' | 'action';
      value: string;
      confidence: number;
    }[];
    complexity: 'simple' | 'medium' | 'complex';
    queryType:
      | 'status'
      | 'trend'
      | 'comparison'
      | 'troubleshooting'
      | 'prediction';
  };

  // ë°ì´í„° ê´€ë ¨
  dataUsed: {
    servers: MCPServerName[];
    metricsAccessed: string[];
    timeRange: {
      start: number;
      end: number;
    };
    dataPoints: number;
  };

  // ì¶”ê°€ ì œì•ˆ
  suggestions: {
    relatedQueries: string[];
    visualizations: {
      type: 'chart' | 'graph' | 'heatmap' | 'table';
      title: string;
      description: string;
      data: any;
    }[];
    actions: {
      type: 'investigate' | 'optimize' | 'alert' | 'scale';
      description: string;
      priority: 'low' | 'medium' | 'high';
    }[];
  };

  // ë©”íƒ€ë°ì´í„°
  metadata: {
    processingTime: number;
    aiEngine: string;
    tokensUsed?: number;
    cacheHit: boolean;
  };
}

/**
 * ëŒ€í™” ê¸°ë¡
 */
interface NLPConversation {
  id: string;
  timestamp: number;
  query: string;
  response: string;
  context: any;
}

/**
 * ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼
 */
interface QueryAnalysis {
  intent: string;
  entities: NLPQueryResponse['analysis']['entities'];
  complexity: NLPQueryResponse['analysis']['complexity'];
  queryType: NLPQueryResponse['analysis']['queryType'];
  language: 'ko' | 'en';
  confidence: number;
}

/**
 * ë°ì´í„° ì»¨í…ìŠ¤íŠ¸
 */
interface DataContext {
  servers: Map<MCPServerName, MCPServerMetrics[]>;
  anomalies: Map<MCPServerName, AnomalyDetectionResult[]>;
  predictions: Map<MCPServerName, PredictionResult[]>;
  alerts: IntelligentAlert[];
  systemHealth: SystemHealthSummary;
}

/**
 * ìì—°ì–´ ì§ˆì˜ ì—”ì§„
 */
export class NLPQueryEngine {
  private static instance: NLPQueryEngine;

  // AI ì—”ì§„
  private aiRouter: UnifiedAIEngineRouter;

  // ë°ì´í„° ìºì‹œ
  private dataContext: DataContext = {
    servers: new Map(),
    anomalies: new Map(),
    predictions: new Map(),
    alerts: [],
    systemHealth: {
      timestamp: 0,
      totalServers: 0,
      healthyServers: 0,
      degradedServers: 0,
      unhealthyServers: 0,
      averageResponseTime: 0,
      systemStatus: 'healthy',
      criticalIssues: [],
      warnings: [],
    },
  };

  // ì‘ë‹µ ìºì‹œ
  private responseCache: Map<string, NLPQueryResponse> = new Map();

  // ëŒ€í™” íˆìŠ¤í† ë¦¬
  private conversations: Map<string, NLPConversation[]> = new Map();

  // ì„¤ì •ê°’
  private readonly config = {
    // ìºì‹œ TTL (10ë¶„)
    cacheTTL: 10 * 60 * 1000,

    // ìµœëŒ€ ëŒ€í™” íˆìŠ¤í† ë¦¬
    maxConversationHistory: 10,

    // ì‘ë‹µ ê¸¸ì´ ì œí•œ
    maxResponseLength: 2000,

    // ì–¸ì–´ ê°ì§€ ì„ê³„ê°’
    languageDetectionThreshold: 0.7,

    // AI ì—”ì§„ ì„¤ì •
    aiConfig: {
      maxTokens: 1000,
      temperature: 0.3,
      enableKoreanNLP: true,
    },

    // ì¿¼ë¦¬ íŒ¨í„´
    queryPatterns: {
      status: [/ìƒíƒœ|status|health|í˜„ì¬/i, /ì–´ë–»ê²Œ|how.*doing|ê´œì°®|fine/i],
      trend: [
        /íŠ¸ë Œë“œ|trend|ë³€í™”|change|ì¶”ì´/i,
        /ì¦ê°€|ê°ì†Œ|increase|decrease|growing/i,
      ],
      comparison: [
        /ë¹„êµ|compare|ì°¨ì´|difference|vs/i,
        /ë³´ë‹¤|than|ë”|more|less/i,
      ],
      troubleshooting: [
        /ë¬¸ì œ|problem|issue|ì—ëŸ¬|error/i,
        /ì™œ|why|ì›ì¸|cause|ì´ìœ |reason/i,
      ],
      prediction: [/ì˜ˆì¸¡|predict|ë¯¸ë˜|future|ì•ìœ¼ë¡œ/i, /ë |will|ì˜ˆìƒ|expect/i],
    },
  };

  private constructor() {
    this.aiRouter = UnifiedAIEngineRouter.getInstance();
    this.startPeriodicCacheCleanup();
  }

  public static getInstance(): NLPQueryEngine {
    if (!NLPQueryEngine.instance) {
      NLPQueryEngine.instance = new NLPQueryEngine();
    }
    return NLPQueryEngine.instance;
  }

  /**
   * ğŸ—£ï¸ ìì—°ì–´ ì§ˆì˜ ì²˜ë¦¬
   */
  public async processQuery(
    request: NLPQueryRequest
  ): Promise<NLPQueryResponse> {
    const startTime = Date.now();

    try {
      // 1. ìºì‹œ í™•ì¸
      const cacheKey = this.generateCacheKey(request);
      const cached = this.responseCache.get(cacheKey);

      if (
        cached &&
        Date.now() - cached.metadata.processingTime < this.config.cacheTTL
      ) {
        return {
          ...cached,
          metadata: { ...cached.metadata, cacheHit: true },
        };
      }

      // 2. ì¿¼ë¦¬ ë¶„ì„
      const analysis = await this.analyzeQuery(request.query, request.language);

      // 3. ë°ì´í„° ìˆ˜ì§‘
      const relevantData = await this.collectRelevantData(
        analysis,
        request.context
      );

      // 4. AI ì—”ì§„ìœ¼ë¡œ ë‹µë³€ ìƒì„±
      const aiResponse = await this.generateAIResponse(
        request,
        analysis,
        relevantData
      );

      // 5. ì‹œê°í™” ì œì•ˆ ìƒì„±
      const visualizations = this.generateVisualizationSuggestions(
        analysis,
        relevantData
      );

      // 6. ì•¡ì…˜ ì œì•ˆ ìƒì„±
      const actions = this.generateActionSuggestions(analysis, relevantData);

      // 7. ê´€ë ¨ ì§ˆì˜ ìƒì„±
      const relatedQueries = this.generateRelatedQueries(
        analysis,
        request.language || analysis.language
      );

      const response: NLPQueryResponse = {
        success: true,
        query: request.query,
        answer: aiResponse.answer,
        confidence: Math.min(analysis.confidence, aiResponse.confidence),
        language: analysis.language,
        analysis,
        dataUsed: {
          servers: Array.from(relevantData.servers.keys()),
          metricsAccessed: this.extractMetricsFromData(relevantData),
          timeRange: request.context?.timeRange || {
            start: Date.now() - 24 * 60 * 60 * 1000,
            end: Date.now(),
          },
          dataPoints: this.countDataPoints(relevantData),
        },
        suggestions: {
          relatedQueries,
          visualizations,
          actions,
        },
        metadata: {
          processingTime: Date.now() - startTime,
          aiEngine: aiResponse.engine,
          tokensUsed: aiResponse.tokensUsed,
          cacheHit: false,
        },
      };

      // 8. ì‘ë‹µ ìºì‹±
      this.responseCache.set(cacheKey, response);

      // 9. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
      this.saveConversation(request, response);

      return response;
    } catch (error) {
      console.error('ìì—°ì–´ ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', getErrorMessage(error));

      return {
        success: false,
        query: request.query,
        answer:
          request.language === 'ko'
            ? 'ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
            : 'Sorry, an error occurred while processing your query.',
        confidence: 0,
        language: request.language || 'ko',
        analysis: {
          intent: 'error',
          entities: [],
          complexity: 'simple',
          queryType: 'status',
        },
        dataUsed: {
          servers: [],
          metricsAccessed: [],
          timeRange: { start: 0, end: 0 },
          dataPoints: 0,
        },
        suggestions: {
          relatedQueries: [],
          visualizations: [],
          actions: [],
        },
        metadata: {
          processingTime: Date.now() - startTime,
          aiEngine: 'error',
          cacheHit: false,
        },
      };
    }
  }

  /**
   * ğŸ” ì¿¼ë¦¬ ë¶„ì„
   */
  private async analyzeQuery(
    query: string,
    language: 'ko' | 'en' | 'auto' = 'auto'
  ): Promise<QueryAnalysis> {
    // 1. ì–¸ì–´ ê°ì§€
    const detectedLanguage =
      language === 'auto' ? this.detectLanguage(query) : language;

    // 2. ì˜ë„ ë¶„ì„
    const intent = this.analyzeIntent(query);

    // 3. ì—”í‹°í‹° ì¶”ì¶œ
    const entities = this.extractEntities(query, detectedLanguage);

    // 4. ë³µì¡ë„ í‰ê°€
    const complexity = this.assessComplexity(query, entities);

    // 5. ì¿¼ë¦¬ íƒ€ì… ë¶„ë¥˜
    const queryType = this.classifyQueryType(query);

    // 6. ì‹ ë¢°ë„ ê³„ì‚°
    const confidence = this.calculateAnalysisConfidence(
      intent,
      entities,
      queryType
    );

    return {
      intent,
      entities,
      complexity,
      queryType,
      language: detectedLanguage,
      confidence,
    };
  }

  /**
   * ğŸŒ ì–¸ì–´ ê°ì§€
   */
  private detectLanguage(query: string): 'ko' | 'en' {
    const koreanChars =
      query.match(/[\u3131-\u314e\u314f-\u3163\uac00-\ud7a3]/g) || [];
    const koreanRatio = koreanChars.length / query.length;

    return koreanRatio > this.config.languageDetectionThreshold ? 'ko' : 'en';
  }

  /**
   * ğŸ¯ ì˜ë„ ë¶„ì„
   */
  private analyzeIntent(query: string): string {
    const lowerQuery = query.toLowerCase();

    // í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ì„
    if (
      lowerQuery.includes('ìƒíƒœ') ||
      lowerQuery.includes('status') ||
      lowerQuery.includes('health')
    ) {
      return 'check_status';
    }
    if (
      lowerQuery.includes('ë¬¸ì œ') ||
      lowerQuery.includes('error') ||
      lowerQuery.includes('issue')
    ) {
      return 'troubleshoot';
    }
    if (
      lowerQuery.includes('ì˜ˆì¸¡') ||
      lowerQuery.includes('predict') ||
      lowerQuery.includes('future')
    ) {
      return 'predict_performance';
    }
    if (lowerQuery.includes('ë¹„êµ') || lowerQuery.includes('compare')) {
      return 'compare_servers';
    }
    if (lowerQuery.includes('íŠ¸ë Œë“œ') || lowerQuery.includes('trend')) {
      return 'analyze_trend';
    }

    return 'general_inquiry';
  }

  /**
   * ğŸ·ï¸ ì—”í‹°í‹° ì¶”ì¶œ
   */
  private extractEntities(
    query: string,
    language: 'ko' | 'en'
  ): NLPQueryResponse['analysis']['entities'] {
    const entities: NLPQueryResponse['analysis']['entities'] = [];

    // ì„œë²„ ì´ë¦„ ì¶”ì¶œ
    const serverPattern =
      language === 'ko' ? /ì„œë²„|server/gi : /server|instance|node/gi;
    if (serverPattern.test(query)) {
      entities.push({
        type: 'server',
        value: 'generic_server',
        confidence: 0.8,
      });
    }

    // ë©”íŠ¸ë¦­ ì¶”ì¶œ
    const metricPatterns = {
      ko: {
        responseTime: /ì‘ë‹µ.*ì‹œê°„|latency|ë ˆì´í„´ì‹œ/gi,
        errorRate: /ì—ëŸ¬.*ìœ¨|ì˜¤ë¥˜.*ìœ¨|ì‹¤íŒ¨.*ìœ¨/gi,
        successRate: /ì„±ê³µ.*ìœ¨|ê°€ìš©.*ë¥ /gi,
        memoryUsage: /ë©”ëª¨ë¦¬|memory/gi,
      },
      en: {
        responseTime: /response.*time|latency/gi,
        errorRate: /error.*rate|failure.*rate/gi,
        successRate: /success.*rate|availability/gi,
        memoryUsage: /memory.*usage|memory/gi,
      },
    };

    const patterns = metricPatterns[language];
    Object.entries(patterns).forEach(([metric, pattern]) => {
      if (pattern.test(query)) {
        entities.push({
          type: 'metric',
          value: metric,
          confidence: 0.9,
        });
      }
    });

    // ì‹œê°„ í‘œí˜„ ì¶”ì¶œ
    const timePatterns =
      language === 'ko'
        ? /(\d+)(ë¶„|ì‹œê°„|ì¼|ì£¼|ê°œì›”)/g
        : /(\d+)\s*(minute|hour|day|week|month)s?/gi;

    const timeMatches = query.match(timePatterns);
    if (timeMatches) {
      entities.push({
        type: 'time',
        value: timeMatches[0],
        confidence: 0.95,
      });
    }

    return entities;
  }

  /**
   * ğŸ”¢ ë³µì¡ë„ í‰ê°€
   */
  private assessComplexity(
    query: string,
    entities: NLPQueryResponse['analysis']['entities']
  ): 'simple' | 'medium' | 'complex' {
    let complexityScore = 0;

    // ì¿¼ë¦¬ ê¸¸ì´
    if (query.length > 100) complexityScore += 1;
    if (query.length > 200) complexityScore += 1;

    // ì—”í‹°í‹° ìˆ˜
    complexityScore += entities.length;

    // ë…¼ë¦¬ ì—°ì‚°ì
    const logicalOperators = /and|or|but|however|ê·¸ë¦¬ê³ |ë˜ëŠ”|í•˜ì§€ë§Œ/gi;
    if (logicalOperators.test(query)) complexityScore += 2;

    // ë¹„êµ í‘œí˜„
    const comparisonTerms = /ë³´ë‹¤|than|compare|vs|ëŒ€ë¹„/gi;
    if (comparisonTerms.test(query)) complexityScore += 1;

    if (complexityScore <= 2) return 'simple';
    if (complexityScore <= 5) return 'medium';
    return 'complex';
  }

  /**
   * ğŸ“Š ì¿¼ë¦¬ íƒ€ì… ë¶„ë¥˜
   */
  private classifyQueryType(
    query: string
  ): NLPQueryResponse['analysis']['queryType'] {
    const patterns = this.config.queryPatterns;

    for (const [type, typePatterns] of Object.entries(patterns)) {
      if (typePatterns.some((pattern) => pattern.test(query))) {
        return type as NLPQueryResponse['analysis']['queryType'];
      }
    }

    return 'status'; // ê¸°ë³¸ê°’
  }

  /**
   * ğŸ“Š ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°
   */
  private calculateAnalysisConfidence(
    intent: string,
    entities: NLPQueryResponse['analysis']['entities'],
    queryType: string
  ): number {
    let confidence = 0.5; // ê¸°ë³¸ ì‹ ë¢°ë„

    // ì˜ë„ê°€ ëª…í™•í•œ ê²½ìš°
    if (intent !== 'general_inquiry') confidence += 0.2;

    // ì—”í‹°í‹°ê°€ ë§ì„ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„
    confidence += Math.min(0.3, entities.length * 0.1);

    // ì—”í‹°í‹° ì‹ ë¢°ë„ í‰ê· 
    if (entities.length > 0) {
      const avgEntityConfidence =
        entities.reduce((sum, e) => sum + e.confidence, 0) / entities.length;
      confidence += avgEntityConfidence * 0.2;
    }

    return Math.min(1, confidence);
  }

  /**
   * ğŸ“Š ê´€ë ¨ ë°ì´í„° ìˆ˜ì§‘
   */
  private async collectRelevantData(
    analysis: QueryAnalysis,
    context?: NLPQueryRequest['context']
  ): Promise<DataContext> {
    const relevantData: DataContext = {
      servers: new Map(),
      anomalies: new Map(),
      predictions: new Map(),
      alerts: [],
      systemHealth: this.dataContext.systemHealth,
    };

    // ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì„œë²„ í•„í„°ë§
    let targetServers = context?.serverId
      ? [context.serverId]
      : Array.from(this.dataContext.servers.keys());

    // ì¿¼ë¦¬ íƒ€ì…ì— ë”°ë¥¸ ë°ì´í„° ìˆ˜ì§‘
    switch (analysis.queryType) {
      case 'status':
        // í˜„ì¬ ìƒíƒœ ë°ì´í„°
        targetServers.forEach((serverId) => {
          const serverData = this.dataContext.servers.get(serverId);
          if (serverData) {
            relevantData.servers.set(serverId, serverData.slice(-10)); // ìµœê·¼ 10ê°œ
          }
        });
        break;

      case 'trend':
        // íŠ¸ë Œë“œ ë¶„ì„ìš© ë°ì´í„° (ë” ë§ì€ ê¸°ë¡)
        targetServers.forEach((serverId) => {
          const serverData = this.dataContext.servers.get(serverId);
          if (serverData) {
            relevantData.servers.set(serverId, serverData.slice(-100)); // ìµœê·¼ 100ê°œ
          }
        });
        break;

      case 'troubleshooting':
        // ë¬¸ì œ í•´ê²°ìš© ë°ì´í„° (ì´ìƒ ì§•í›„ + ì•Œë¦¼)
        targetServers.forEach((serverId) => {
          const serverData = this.dataContext.servers.get(serverId);
          const anomalies = this.dataContext.anomalies.get(serverId);

          if (serverData)
            relevantData.servers.set(serverId, serverData.slice(-50));
          if (anomalies) relevantData.anomalies.set(serverId, anomalies);
        });

        relevantData.alerts = this.dataContext.alerts.filter((alert) =>
          targetServers.includes(alert.serverId)
        );
        break;

      case 'prediction':
        // ì˜ˆì¸¡ìš© ë°ì´í„°
        targetServers.forEach((serverId) => {
          const predictions = this.dataContext.predictions.get(serverId);
          if (predictions) {
            relevantData.predictions.set(serverId, predictions);
          }
        });
        break;
    }

    return relevantData;
  }

  /**
   * ğŸ¤– AI ì‘ë‹µ ìƒì„±
   */
  private async generateAIResponse(
    request: NLPQueryRequest,
    analysis: QueryAnalysis,
    data: DataContext
  ): Promise<{
    answer: string;
    confidence: number;
    engine: string;
    tokensUsed?: number;
  }> {
    // í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    const prompt = this.buildPrompt(request, analysis, data);

    // AI ì—”ì§„ í˜¸ì¶œ
    const response = await this.aiRouter.route({
      query: prompt,
      context: {
        servers: Array.from(data.servers.keys()),
        analysis: analysis,
        language: analysis.language,
      },
    });

    if (!response.success) {
      throw new Error('AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨');
    }

    return {
      answer: response.response,
      confidence: response.confidence,
      engine: response.engine,
      tokensUsed: response.metadata?.tokensUsed as number,
    };
  }

  /**
   * ğŸ“ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
   */
  private buildPrompt(
    request: NLPQueryRequest,
    analysis: QueryAnalysis,
    data: DataContext
  ): string {
    const isKorean = analysis.language === 'ko';

    let prompt = isKorean
      ? `MCP ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n`
      : `Please answer questions about the MCP monitoring system.\n\n`;

    // ì‚¬ìš©ì ì§ˆì˜
    prompt += isKorean
      ? `ì‚¬ìš©ì ì§ˆë¬¸: ${request.query}\n\n`
      : `User Question: ${request.query}\n\n`;

    // ë¶„ì„ ê²°ê³¼
    prompt += isKorean
      ? `ë¶„ì„ ê²°ê³¼:\n- ì˜ë„: ${analysis.intent}\n- ë³µì¡ë„: ${analysis.complexity}\n- ì¿¼ë¦¬ íƒ€ì…: ${analysis.queryType}\n\n`
      : `Analysis:\n- Intent: ${analysis.intent}\n- Complexity: ${analysis.complexity}\n- Query Type: ${analysis.queryType}\n\n`;

    // ê´€ë ¨ ë°ì´í„° ìš”ì•½
    if (data.servers.size > 0) {
      prompt += isKorean
        ? `ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë²„ ë°ì´í„°:\n`
        : `Available Server Data:\n`;
      data.servers.forEach((metrics, serverId) => {
        const latest = metrics[metrics.length - 1];
        if (latest) {
          prompt += `- ${serverId}: ì‘ë‹µì‹œê°„ ${latest.responseTime}ms, ì—ëŸ¬ìœ¨ ${latest.errorRate}%, ì„±ê³µë¥  ${latest.successRate}%\n`;
        }
      });
      prompt += '\n';
    }

    // ì´ìƒ ì§•í›„ ì •ë³´
    if (data.anomalies.size > 0) {
      prompt += isKorean ? `ê°ì§€ëœ ì´ìƒ ì§•í›„:\n` : `Detected Anomalies:\n`;
      data.anomalies.forEach((anomalies, serverId) => {
        anomalies.forEach((anomaly) => {
          prompt += `- ${serverId}: ${anomaly.description}\n`;
        });
      });
      prompt += '\n';
    }

    // ì˜ˆì¸¡ ì •ë³´
    if (data.predictions.size > 0) {
      prompt += isKorean ? `ì„±ëŠ¥ ì˜ˆì¸¡:\n` : `Performance Predictions:\n`;
      data.predictions.forEach((predictions, serverId) => {
        predictions.forEach((prediction) => {
          prompt += `- ${serverId}: ${prediction.trend.direction} íŠ¸ë Œë“œ, ì‹ ë¢°ë„ ${(prediction.accuracy.r2 * 100).toFixed(1)}%\n`;
        });
      });
      prompt += '\n';
    }

    // ì‘ë‹µ ì§€ì¹¨
    prompt += isKorean
      ? `ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”:\n1. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ\n2. ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ì‹œ ê°„ë‹¨í•œ ì„¤ëª… ì¶”ê°€\n3. ê°€ëŠ¥í•œ ê²½ìš° ìˆ˜ì¹˜ ë°ì´í„° í¬í•¨\n4. ê¶Œì¥ì‚¬í•­ì´ë‚˜ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n5. ${request.preferences?.maxResponseLength || this.config.maxResponseLength}ì ì´ë‚´ë¡œ ì‘ì„±`
      : `Please follow these guidelines:\n1. Provide specific and practical information\n2. Include brief explanations for technical terms\n3. Include numerical data when available\n4. Suggest recommendations or next steps\n5. Keep response under ${request.preferences?.maxResponseLength || this.config.maxResponseLength} characters`;

    return prompt;
  }

  /**
   * ğŸ“Š ì‹œê°í™” ì œì•ˆ ìƒì„±
   */
  private generateVisualizationSuggestions(
    analysis: QueryAnalysis,
    data: DataContext
  ): NLPQueryResponse['suggestions']['visualizations'] {
    const visualizations: NLPQueryResponse['suggestions']['visualizations'] =
      [];

    // ì¿¼ë¦¬ íƒ€ì…ì— ë”°ë¥¸ ì‹œê°í™” ì œì•ˆ
    switch (analysis.queryType) {
      case 'status':
        if (data.servers.size > 0) {
          visualizations.push({
            type: 'chart',
            title: 'ì„œë²„ ìƒíƒœ ëŒ€ì‹œë³´ë“œ',
            description: 'ê° ì„œë²„ì˜ ì£¼ìš” ë©”íŠ¸ë¦­ í˜„í™©ì„ í•œëˆˆì— í™•ì¸',
            data: this.prepareStatusChartData(data.servers),
          });
        }
        break;

      case 'trend':
        if (data.servers.size > 0) {
          visualizations.push({
            type: 'graph',
            title: 'ì„±ëŠ¥ íŠ¸ë Œë“œ ê·¸ë˜í”„',
            description: 'ì‹œê°„ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë³€í™” ì¶”ì´',
            data: this.prepareTrendGraphData(data.servers),
          });
        }
        break;

      case 'comparison':
        if (data.servers.size > 1) {
          visualizations.push({
            type: 'table',
            title: 'ì„œë²„ ë¹„êµ í…Œì´ë¸”',
            description: 'ì„œë²„ ê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ',
            data: this.prepareComparisonTableData(data.servers),
          });
        }
        break;

      case 'troubleshooting':
        if (data.anomalies.size > 0) {
          visualizations.push({
            type: 'heatmap',
            title: 'ì´ìƒ ì§•í›„ íˆíŠ¸ë§µ',
            description: 'ì„œë²„ë³„ ì´ìƒ ì§•í›„ ë°œìƒ íŒ¨í„´',
            data: this.prepareAnomalyHeatmapData(data.anomalies),
          });
        }
        break;
    }

    return visualizations;
  }

  /**
   * ğŸ’¡ ì•¡ì…˜ ì œì•ˆ ìƒì„±
   */
  private generateActionSuggestions(
    analysis: QueryAnalysis,
    data: DataContext
  ): NLPQueryResponse['suggestions']['actions'] {
    const actions: NLPQueryResponse['suggestions']['actions'] = [];

    // ì´ìƒ ì§•í›„ ê¸°ë°˜ ì•¡ì…˜
    data.anomalies.forEach((anomalies, serverId) => {
      anomalies.forEach((anomaly) => {
        if (anomaly.severity === 'critical' || anomaly.severity === 'high') {
          actions.push({
            type: 'investigate',
            description: `${serverId} ì„œë²„ì˜ ${anomaly.anomalyType} ì´ìƒ ì§•í›„ ê¸´ê¸‰ ì¡°ì‚¬`,
            priority: 'high',
          });
        }
      });
    });

    // ì„±ëŠ¥ ê¸°ë°˜ ì•¡ì…˜
    data.servers.forEach((metrics, serverId) => {
      const latest = metrics[metrics.length - 1];
      if (latest) {
        if (latest.responseTime > 1000) {
          actions.push({
            type: 'optimize',
            description: `${serverId} ì„œë²„ ì‘ë‹µ ì‹œê°„ ìµœì í™” (í˜„ì¬ ${latest.responseTime}ms)`,
            priority: 'medium',
          });
        }

        if (latest.errorRate > 5) {
          actions.push({
            type: 'investigate',
            description: `${serverId} ì„œë²„ ë†’ì€ ì—ëŸ¬ìœ¨ ì¡°ì‚¬ (í˜„ì¬ ${latest.errorRate}%)`,
            priority: 'high',
          });
        }
      }
    });

    // ì˜ˆì¸¡ ê¸°ë°˜ ì•¡ì…˜
    data.predictions.forEach((predictions, serverId) => {
      predictions.forEach((prediction) => {
        if (prediction.alerts.length > 0) {
          const criticalAlert = prediction.alerts.find(
            (alert) => alert.severity === 'critical'
          );
          if (criticalAlert) {
            actions.push({
              type: 'scale',
              description: `${serverId} ì„œë²„ ìš©ëŸ‰ í™•ì¥ ì¤€ë¹„ (${Math.round(criticalAlert.timeToAlert)}ë¶„ í›„ ì„ê³„ê°’ ë„ë‹¬ ì˜ˆìƒ)`,
              priority: 'high',
            });
          }
        }
      });
    });

    return actions.slice(0, 5); // ìµœëŒ€ 5ê°œ ì•¡ì…˜
  }

  /**
   * ğŸ”— ê´€ë ¨ ì§ˆì˜ ìƒì„±
   */
  private generateRelatedQueries(
    analysis: QueryAnalysis,
    language: 'ko' | 'en'
  ): string[] {
    const queries: string[] = [];

    const templates =
      language === 'ko'
        ? {
            status: [
              'ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœëŠ” ì–´ë–»ìŠµë‹ˆê¹Œ?',
              'ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ì„œë²„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?',
              'í˜„ì¬ ì—ëŸ¬ê°€ ë°œìƒí•˜ê³  ìˆëŠ” ì„œë²„ê°€ ìˆìŠµë‹ˆê¹Œ?',
            ],
            trend: [
              'ì§€ë‚œ ì£¼ ëŒ€ë¹„ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í–ˆìŠµë‹ˆê¹Œ?',
              'ì‘ë‹µ ì‹œê°„ì´ ê³„ì† ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆê¹Œ?',
              'í”¼í¬ ì‹œê°„ëŒ€ëŠ” ì–¸ì œì…ë‹ˆê¹Œ?',
            ],
            troubleshooting: [
              'ê°€ì¥ ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?',
              'ì´ ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?',
              'ìœ ì‚¬í•œ ë¬¸ì œê°€ ê³¼ê±°ì— ì–´ë–»ê²Œ í•´ê²°ë˜ì—ˆìŠµë‹ˆê¹Œ?',
            ],
            prediction: [
              'ë‹¤ìŒ ì£¼ ì„±ëŠ¥ ì˜ˆì¸¡ì€ ì–´ë–»ìŠµë‹ˆê¹Œ?',
              'ì–¸ì œ ìš©ëŸ‰ì„ í™•ì¥í•´ì•¼ í•©ë‹ˆê¹Œ?',
              'ì˜ˆìƒë˜ëŠ” ì¥ì•  ì‹œì ì€ ì–¸ì œì…ë‹ˆê¹Œ?',
            ],
          }
        : {
            status: [
              'What is the overall system status?',
              'Which server has the best performance?',
              'Are there any servers currently experiencing errors?',
            ],
            trend: [
              'How has performance changed compared to last week?',
              'Is response time continuously increasing?',
              'When are the peak hours?',
            ],
            troubleshooting: [
              'What are the most frequent issues?',
              'What is the root cause of this problem?',
              'How were similar issues resolved in the past?',
            ],
            prediction: [
              'What is the performance prediction for next week?',
              'When should we scale up capacity?',
              'When is the expected failure point?',
            ],
          };

    const queryType = analysis.queryType;
    if (templates[queryType]) {
      queries.push(...templates[queryType]);
    }

    return queries.slice(0, 3); // ìµœëŒ€ 3ê°œ ê´€ë ¨ ì§ˆì˜
  }

  /**
   * ğŸ“Š ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ ê³„ì‚°
   */
  private countDataPoints(data: DataContext): number {
    let count = 0;

    data.servers.forEach((metrics) => {
      count += metrics.length;
    });

    data.anomalies.forEach((anomalies) => {
      count += anomalies.length;
    });

    data.predictions.forEach((predictions) => {
      count += predictions.length;
    });

    count += data.alerts.length;

    return count;
  }

  /**
   * ğŸ“Š ë©”íŠ¸ë¦­ ì¶”ì¶œ
   */
  private extractMetricsFromData(data: DataContext): string[] {
    const metrics = new Set<string>();

    // ì„œë²„ ë©”íŠ¸ë¦­
    if (data.servers.size > 0) {
      metrics.add('responseTime');
      metrics.add('errorRate');
      metrics.add('successRate');
      metrics.add('requestCount');
    }

    // ì´ìƒ ì§•í›„ ë©”íŠ¸ë¦­
    data.anomalies.forEach((anomalies) => {
      anomalies.forEach((anomaly) => {
        anomaly.affectedMetrics.forEach((metric) => metrics.add(metric));
      });
    });

    return Array.from(metrics);
  }

  /**
   * ğŸ“Š ìƒíƒœ ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
   */
  private prepareStatusChartData(
    servers: Map<MCPServerName, MCPServerMetrics[]>
  ): any {
    const chartData: any[] = [];

    servers.forEach((metrics, serverId) => {
      const latest = metrics[metrics.length - 1];
      if (latest) {
        chartData.push({
          server: serverId,
          responseTime: latest.responseTime,
          errorRate: latest.errorRate,
          successRate: latest.successRate,
        });
      }
    });

    return chartData;
  }

  /**
   * ğŸ“ˆ íŠ¸ë Œë“œ ê·¸ë˜í”„ ë°ì´í„° ì¤€ë¹„
   */
  private prepareTrendGraphData(
    servers: Map<MCPServerName, MCPServerMetrics[]>
  ): any {
    const graphData: any = {};

    servers.forEach((metrics, serverId) => {
      graphData[serverId] = metrics.map((m) => ({
        timestamp: m.timestamp,
        responseTime: m.responseTime,
        errorRate: m.errorRate,
        successRate: m.successRate,
      }));
    });

    return graphData;
  }

  /**
   * ğŸ“Š ë¹„êµ í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
   */
  private prepareComparisonTableData(
    servers: Map<MCPServerName, MCPServerMetrics[]>
  ): any {
    const tableData: any[] = [];

    servers.forEach((metrics, serverId) => {
      const latest = metrics[metrics.length - 1];
      const avg = this.calculateAverageMetrics(metrics);

      if (latest) {
        tableData.push({
          server: serverId,
          current: {
            responseTime: latest.responseTime,
            errorRate: latest.errorRate,
            successRate: latest.successRate,
          },
          average: avg,
        });
      }
    });

    return tableData;
  }

  /**
   * ğŸ”¥ ì´ìƒ ì§•í›„ íˆíŠ¸ë§µ ë°ì´í„° ì¤€ë¹„
   */
  private prepareAnomalyHeatmapData(
    anomalies: Map<MCPServerName, AnomalyDetectionResult[]>
  ): any {
    const heatmapData: any[] = [];

    anomalies.forEach((serverAnomalies, serverId) => {
      const anomalyCount = serverAnomalies.length;
      const severityScore =
        serverAnomalies.reduce((sum, anomaly) => {
          return sum + this.mapSeverityToNumber(anomaly.severity);
        }, 0) / anomalyCount;

      heatmapData.push({
        server: serverId,
        anomalyCount,
        severityScore,
        timestamp: Date.now(),
      });
    });

    return heatmapData;
  }

  /**
   * ğŸ“Š í‰ê·  ë©”íŠ¸ë¦­ ê³„ì‚°
   */
  private calculateAverageMetrics(metrics: MCPServerMetrics[]): any {
    if (metrics.length === 0) return null;

    const sum = metrics.reduce(
      (acc, m) => ({
        responseTime: acc.responseTime + m.responseTime,
        errorRate: acc.errorRate + m.errorRate,
        successRate: acc.successRate + m.successRate,
      }),
      { responseTime: 0, errorRate: 0, successRate: 0 }
    );

    return {
      responseTime: sum.responseTime / metrics.length,
      errorRate: sum.errorRate / metrics.length,
      successRate: sum.successRate / metrics.length,
    };
  }

  /**
   * ğŸ”¢ ì‹¬ê°ë„ë¥¼ ìˆ«ìë¡œ ë§¤í•‘
   */
  private mapSeverityToNumber(severity: string): number {
    switch (severity) {
      case 'critical':
        return 4;
      case 'high':
        return 3;
      case 'medium':
        return 2;
      case 'low':
        return 1;
      default:
        return 0;
    }
  }

  /**
   * ğŸ’¾ ëŒ€í™” ì €ì¥
   */
  private saveConversation(
    request: NLPQueryRequest,
    response: NLPQueryResponse
  ): void {
    const sessionId = 'default'; // ì¶”í›„ ì„¸ì…˜ ê´€ë¦¬ êµ¬í˜„

    const conversation: NLPConversation = {
      id: `conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      timestamp: Date.now(),
      query: request.query,
      response: response.answer,
      context: request.context,
    };

    const history = this.conversations.get(sessionId) || [];
    history.push(conversation);

    // ìµœëŒ€ íˆìŠ¤í† ë¦¬ ìˆ˜ ì œí•œ
    if (history.length > this.config.maxConversationHistory) {
      history.shift();
    }

    this.conversations.set(sessionId, history);
  }

  /**
   * ğŸ”‘ ìºì‹œ í‚¤ ìƒì„±
   */
  private generateCacheKey(request: NLPQueryRequest): string {
    const contextStr = JSON.stringify(request.context || {});
    const prefsStr = JSON.stringify(request.preferences || {});

    return `nlp_${request.query}_${request.language}_${contextStr}_${prefsStr}`.slice(
      0,
      100
    );
  }

  /**
   * ğŸ§¹ ì£¼ê¸°ì  ìºì‹œ ì •ë¦¬
   */
  private startPeriodicCacheCleanup(): void {
    setInterval(
      () => {
        const now = Date.now();

        // ì‘ë‹µ ìºì‹œ ì •ë¦¬
        this.responseCache.forEach((response, key) => {
          if (now - response.metadata.processingTime > this.config.cacheTTL) {
            this.responseCache.delete(key);
          }
        });

        // ëŒ€í™” íˆìŠ¤í† ë¦¬ ì •ë¦¬ (7ì¼ ì´ìƒ ëœ ê²ƒ)
        const cutoff = now - 7 * 24 * 60 * 60 * 1000;
        this.conversations.forEach((history, sessionId) => {
          const filtered = history.filter((conv) => conv.timestamp > cutoff);
          this.conversations.set(sessionId, filtered);
        });
      },
      60 * 60 * 1000
    ); // 1ì‹œê°„ë§ˆë‹¤
  }

  /**
   * ğŸ“Š ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
   */
  public updateDataContext(newContext: Partial<DataContext>): void {
    Object.assign(this.dataContext, newContext);
  }

  /**
   * ğŸ“Š ì§ˆì˜ í†µê³„ ì¡°íšŒ
   */
  public getQueryStats(): {
    totalQueries: number;
    queriesByLanguage: Record<string, number>;
    queriesByType: Record<string, number>;
    averageConfidence: number;
    cacheHitRate: number;
  } {
    const allConversations = Array.from(this.conversations.values()).flat();
    const queriesByLanguage: Record<string, number> = {};
    const queriesByType: Record<string, number> = {};

    // í†µê³„ ê³„ì‚°ì€ ì‘ë‹µ ìºì‹œì—ì„œ ì¶”ì¶œ
    const responses = Array.from(this.responseCache.values());
    responses.forEach((response) => {
      queriesByLanguage[response.language] =
        (queriesByLanguage[response.language] || 0) + 1;
      queriesByType[response.analysis.queryType] =
        (queriesByType[response.analysis.queryType] || 0) + 1;
    });

    const averageConfidence =
      responses.length > 0
        ? responses.reduce((sum, r) => sum + r.confidence, 0) / responses.length
        : 0;

    const cacheHits = responses.filter((r) => r.metadata.cacheHit).length;
    const cacheHitRate =
      responses.length > 0 ? cacheHits / responses.length : 0;

    return {
      totalQueries: allConversations.length,
      queriesByLanguage,
      queriesByType,
      averageConfidence,
      cacheHitRate,
    };
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë‚´ë³´ë‚´ê¸°
export const nlpQueryEngine = NLPQueryEngine.getInstance();
