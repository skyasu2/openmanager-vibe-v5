/**
 * ğŸš€ Upstash Redis ìµœì í™” ìºì‹œ ì„œë¹„ìŠ¤ v1.0
 *
 * ë ˆì´í„´ì‹œ ìµœì í™” ë° ìºì‹œ íˆíŠ¸ìœ¨ í–¥ìƒì„ ìœ„í•œ ì „ë¬¸ ìºì‹œ ì„œë¹„ìŠ¤
 * - ë°°ì¹˜ ì²˜ë¦¬ ë° íŒŒì´í”„ë¼ì¸ ìµœì í™”
 * - ì§€ëŠ¥í˜• TTL ì „ëµ
 * - 256MB ë©”ëª¨ë¦¬ ì œí•œ ìµœì í™”
 * - Edge Runtime ì™„ë²½ í˜¸í™˜
 */

import { Redis } from '@upstash/redis';
import type { EnhancedServerMetrics } from '@/types/server';

// ìºì‹œ í‚¤ íŒ¨í„´ ì •ì˜
const CACHE_KEYS = {
  // ì„œë²„ ê´€ë ¨
  SERVER_LIST: 'servers:list',
  SERVER_DETAIL: (id: string) => `server:${id}`,
  SERVER_METRICS: (id: string) => `metrics:${id}`,
  SERVER_SUMMARY: 'servers:summary',

  // AI ë¶„ì„ ê´€ë ¨
  AI_ANALYSIS: (id: string) => `ai:analysis:${id}`,
  AI_PREDICTION: (id: string) => `ai:prediction:${id}`,

  // ì‹¤ì‹œê°„ ë°ì´í„°
  REALTIME: (key: string) => `realtime:${key}`,

  // ì‚¬ìš©ì ì„¸ì…˜
  SESSION: (id: string) => `session:${id}`,

  // ì‹œìŠ¤í…œ ìƒíƒœ
  SYSTEM_STATE: 'system:state',
  HEALTH_CHECK: 'system:health',
} as const;

// TTL ì „ëµ (ì´ˆ ë‹¨ìœ„)
const TTL_STRATEGY = {
  // ì§§ì€ TTL (ì‹¤ì‹œê°„ì„± ì¤‘ìš”)
  REALTIME: 30, // 30ì´ˆ
  SERVER_METRICS: 60, // 1ë¶„

  // ì¤‘ê°„ TTL (ìì£¼ ë³€ê²½)
  SERVER_LIST: 300, // 5ë¶„
  SERVER_DETAIL: 300, // 5ë¶„
  AI_ANALYSIS: 600, // 10ë¶„

  // ê¸´ TTL (ê±°ì˜ ë³€ê²½ ì—†ìŒ)
  SERVER_SUMMARY: 900, // 15ë¶„
  AI_PREDICTION: 1800, // 30ë¶„
  SESSION: 86400, // 24ì‹œê°„
  SYSTEM_STATE: 3600, // 1ì‹œê°„

  // ì˜êµ¬ ì €ì¥ (ìˆ˜ë™ ë¬´íš¨í™”)
  HEALTH_CHECK: -1, // ë¬´ì œí•œ
} as const;

// ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì •
const MEMORY_CONFIG = {
  MAX_MEMORY_MB: 256, // Upstash ë¬´ë£Œ í‹°ì–´ í•œê³„
  WARNING_THRESHOLD_MB: 200, // ê²½ê³  ì„ê³„ê°’ (78%)
  CRITICAL_THRESHOLD_MB: 230, // ìœ„í—˜ ì„ê³„ê°’ (90%)
  EVICTION_BATCH_SIZE: 100, // í•œ ë²ˆì— ì œê±°í•  í‚¤ ìˆ˜
  COMPRESSION_THRESHOLD_BYTES: 1024, // 1KB ì´ìƒ ì••ì¶•
} as const;

// ì„±ëŠ¥ ìµœì í™” ì„¤ì •
const PERFORMANCE_CONFIG = {
  PIPELINE_BATCH_SIZE: 50, // íŒŒì´í”„ë¼ì¸ ë°°ì¹˜ í¬ê¸°
  PIPELINE_TIMEOUT_MS: 100, // íŒŒì´í”„ë¼ì¸ ëŒ€ê¸° ì‹œê°„
  MAX_RETRIES: 2, // ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
  RETRY_DELAY_MS: 50, // ì¬ì‹œë„ ì§€ì—° ì‹œê°„
  CONNECTION_TIMEOUT_MS: 3000, // ì—°ê²° íƒ€ì„ì•„ì›ƒ
} as const;

// ìºì‹œ í†µê³„
interface CacheStats {
  hits: number;
  misses: number;
  sets: number;
  deletes: number;
  errors: number;
  hitRate: number;
  memoryUsageMB: number;
  lastReset: number;
}

/**
 * Upstash Redis ìµœì í™” ìºì‹œ ì„œë¹„ìŠ¤
 */
export class UpstashCacheService {
  private redis: Redis;
  private stats: CacheStats;
  private pipeline: Array<{ operation: string; args: any[] }> = [];
  private pipelineTimer: NodeJS.Timeout | null = null;
  private memoryMonitorTimer: NodeJS.Timeout | null = null;

  constructor(redis: Redis) {
    this.redis = redis;
    this.stats = {
      hits: 0,
      misses: 0,
      sets: 0,
      deletes: 0,
      errors: 0,
      hitRate: 0,
      memoryUsageMB: 0,
      lastReset: Date.now(),
    };

    // ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    this.startMemoryMonitoring();
  }

  /**
   * ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ (ìµœì í™”ëœ ë²„ì „)
   */
  async get<T>(key: string): Promise<T | null> {
    try {
      const startTime = Date.now();
      const data = await this.redis.get<T>(key);

      if (data !== null) {
        this.stats.hits++;
        console.log(`âœ… Cache HIT: ${key} (${Date.now() - startTime}ms)`);
      } else {
        this.stats.misses++;
        console.log(`âŒ Cache MISS: ${key}`);
      }

      this.updateHitRate();
      return data;
    } catch (error) {
      this.stats.errors++;
      console.error(`âŒ Cache GET error for ${key}:`, error);
      return null;
    }
  }

  /**
   * ìºì‹œì— ë°ì´í„° ì €ì¥ (ì••ì¶• ë° TTL ìµœì í™”)
   */
  async set<T>(key: string, value: T, ttl?: number): Promise<void> {
    try {
      const startTime = Date.now();
      const ttlSeconds = ttl ?? this.getOptimalTTL(key);

      // í° ë°ì´í„°ëŠ” ì••ì¶•
      const dataStr = JSON.stringify(value);
      const shouldCompress =
        dataStr.length > MEMORY_CONFIG.COMPRESSION_THRESHOLD_BYTES;

      if (shouldCompress) {
        // Edge Runtimeì—ì„œëŠ” ì••ì¶• ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ë°ì´í„° í¬ê¸° ê²½ê³ ë§Œ
        console.warn(`âš ï¸ Large data (${dataStr.length} bytes) for key: ${key}`);
      }

      await this.redis.setex(key, ttlSeconds, value);
      this.stats.sets++;

      console.log(
        `âœ… Cache SET: ${key} (TTL: ${ttlSeconds}s, ${Date.now() - startTime}ms)`
      );
    } catch (error) {
      this.stats.errors++;
      console.error(`âŒ Cache SET error for ${key}:`, error);
    }
  }

  /**
   * ë°°ì¹˜ GET ì‘ì—… (íŒŒì´í”„ë¼ì¸ ìµœì í™”)
   */
  async mget<T>(keys: string[]): Promise<(T | null)[]> {
    try {
      const startTime = Date.now();
      const pipeline = this.redis.pipeline();

      keys.forEach(key => pipeline.get(key));
      const results = await pipeline.exec();

      // í†µê³„ ì—…ë°ì´íŠ¸
      results.forEach((result, index) => {
        if (result) {
          this.stats.hits++;
        } else {
          this.stats.misses++;
        }
      });

      this.updateHitRate();
      console.log(
        `âœ… Batch GET: ${keys.length} keys (${Date.now() - startTime}ms)`
      );

      return results as (T | null)[];
    } catch (error) {
      this.stats.errors++;
      console.error('âŒ Batch GET error:', error);
      return keys.map(() => null);
    }
  }

  /**
   * ë°°ì¹˜ SET ì‘ì—… (íŒŒì´í”„ë¼ì¸ ìµœì í™”)
   */
  async mset(
    items: Array<{ key: string; value: any; ttl?: number }>
  ): Promise<void> {
    try {
      const startTime = Date.now();
      const pipeline = this.redis.pipeline();

      items.forEach(({ key, value, ttl }) => {
        const ttlSeconds = ttl ?? this.getOptimalTTL(key);
        pipeline.setex(key, ttlSeconds, value);
      });

      await pipeline.exec();
      this.stats.sets += items.length;

      console.log(
        `âœ… Batch SET: ${items.length} items (${Date.now() - startTime}ms)`
      );
    } catch (error) {
      this.stats.errors++;
      console.error('âŒ Batch SET error:', error);
    }
  }

  /**
   * ì§€ì—°ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë ˆì´í„´ì‹œ ìµœì í™”)
   */
  async deferredSet<T>(key: string, value: T, ttl?: number): Promise<void> {
    this.pipeline.push({
      operation: 'setex',
      args: [key, ttl ?? this.getOptimalTTL(key), value],
    });

    // íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜ˆì•½
    if (!this.pipelineTimer) {
      this.pipelineTimer = setTimeout(() => {
        this.flushPipeline();
      }, PERFORMANCE_CONFIG.PIPELINE_TIMEOUT_MS);
    }

    // ë°°ì¹˜ í¬ê¸° ì´ˆê³¼ ì‹œ ì¦‰ì‹œ ì‹¤í–‰
    if (this.pipeline.length >= PERFORMANCE_CONFIG.PIPELINE_BATCH_SIZE) {
      await this.flushPipeline();
    }
  }

  /**
   * íŒŒì´í”„ë¼ì¸ í”ŒëŸ¬ì‹œ
   */
  private async flushPipeline(): Promise<void> {
    if (this.pipeline.length === 0) return;

    try {
      const startTime = Date.now();
      const pipeline = this.redis.pipeline();

      this.pipeline.forEach(({ operation, args }) => {
        (pipeline as any)[operation](...args);
      });

      await pipeline.exec();
      this.stats.sets += this.pipeline.length;

      console.log(
        `âœ… Pipeline flush: ${this.pipeline.length} ops (${Date.now() - startTime}ms)`
      );

      this.pipeline = [];
    } catch (error) {
      this.stats.errors++;
      console.error('âŒ Pipeline flush error:', error);
    } finally {
      if (this.pipelineTimer) {
        clearTimeout(this.pipelineTimer);
        this.pipelineTimer = null;
      }
    }
  }

  /**
   * ì„œë²„ ë©”íŠ¸ë¦­ ìºì‹± (ìµœì í™” ë²„ì „)
   */
  async cacheServerMetrics(servers: EnhancedServerMetrics[]): Promise<void> {
    const items: Array<{ key: string; value: any; ttl?: number }> = servers.map(server => ({
      key: CACHE_KEYS.SERVER_DETAIL(server.id),
      value: server,
      ttl: TTL_STRATEGY.SERVER_DETAIL,
    }));

    // ì„œë²„ ëª©ë¡ë„ í•¨ê»˜ ìºì‹±
    items.push({
      key: CACHE_KEYS.SERVER_LIST,
      value: servers,
      ttl: TTL_STRATEGY.SERVER_LIST,
    });

    // ìš”ì•½ ì •ë³´ ìƒì„± ë° ìºì‹±
    const summary = {
      totalServers: servers.length,
      onlineServers: servers.filter(s => s.status === 'online').length,
      avgCpuUsage:
        servers.reduce((sum, s) => sum + (s.metrics?.cpu?.usage || 0), 0) /
        servers.length,
      avgMemoryUsage:
        servers.reduce((sum, s) => sum + (s.metrics?.memory?.usage || 0), 0) /
        servers.length,
      timestamp: Date.now(),
    };

    items.push({
      key: CACHE_KEYS.SERVER_SUMMARY,
      value: summary,
      ttl: TTL_STRATEGY.SERVER_SUMMARY,
    });

    await this.mset(items);
  }

  /**
   * ìºì‹œëœ ì„œë²„ ëª©ë¡ ì¡°íšŒ
   */
  async getCachedServers(): Promise<{
    servers: EnhancedServerMetrics[];
    timestamp: number;
  } | null> {
    const servers = await this.get<EnhancedServerMetrics[]>(
      CACHE_KEYS.SERVER_LIST
    );
    if (!servers) return null;

    return {
      servers,
      timestamp: Date.now(),
    };
  }

  /**
   * ìºì‹œëœ ì„œë²„ ìš”ì•½ ì¡°íšŒ
   */
  async getCachedSummary(): Promise<any> {
    return this.get(CACHE_KEYS.SERVER_SUMMARY);
  }

  /**
   * ìºì‹œëœ ê°œë³„ ì„œë²„ ì¡°íšŒ
   */
  async getCachedServer(
    serverId: string
  ): Promise<EnhancedServerMetrics | null> {
    return this.get(CACHE_KEYS.SERVER_DETAIL(serverId));
  }

  /**
   * ìºì‹œ ë¬´íš¨í™” (íŒ¨í„´ ë§¤ì¹­)
   */
  async invalidateCache(pattern?: string): Promise<void> {
    try {
      if (!pattern) {
        // ì „ì²´ ìºì‹œ ë¬´íš¨í™” (ìœ„í—˜!)
        console.warn('âš ï¸ Full cache invalidation requested');
        await this.redis.flushdb();
        this.stats.deletes++;
        return;
      }

      // íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ í‚¤ ì‚­ì œ (UpstashëŠ” SCAN ë¯¸ì§€ì›)
      // ëŒ€ì‹  ì•Œë ¤ì§„ íŒ¨í„´ìœ¼ë¡œ í‚¤ ìƒì„± í›„ ì‚­ì œ
      const keysToDelete: string[] = [];

      if (pattern.includes('server')) {
        // ì„œë²„ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
        keysToDelete.push(CACHE_KEYS.SERVER_LIST, CACHE_KEYS.SERVER_SUMMARY);
      }

      if (keysToDelete.length > 0) {
        const pipeline = this.redis.pipeline();
        keysToDelete.forEach(key => pipeline.del(key));
        await pipeline.exec();
        this.stats.deletes += keysToDelete.length;
      }
    } catch (error) {
      this.stats.errors++;
      console.error('âŒ Cache invalidation error:', error);
    }
  }

  /**
   * ìµœì  TTL ê²°ì • (í‚¤ íŒ¨í„´ ê¸°ë°˜)
   */
  private getOptimalTTL(key: string): number {
    // ì‹¤ì‹œê°„ ë°ì´í„°
    if (key.includes('realtime')) return TTL_STRATEGY.REALTIME;
    if (key.includes('metrics')) return TTL_STRATEGY.SERVER_METRICS;

    // ì„œë²„ ë°ì´í„°
    if (key.includes('server:')) return TTL_STRATEGY.SERVER_DETAIL;
    if (key.includes('servers:list')) return TTL_STRATEGY.SERVER_LIST;
    if (key.includes('servers:summary')) return TTL_STRATEGY.SERVER_SUMMARY;

    // AI ë°ì´í„°
    if (key.includes('ai:analysis')) return TTL_STRATEGY.AI_ANALYSIS;
    if (key.includes('ai:prediction')) return TTL_STRATEGY.AI_PREDICTION;

    // ì„¸ì…˜ ë° ì‹œìŠ¤í…œ
    if (key.includes('session')) return TTL_STRATEGY.SESSION;
    if (key.includes('system')) return TTL_STRATEGY.SYSTEM_STATE;

    // ê¸°ë³¸ê°’
    return 300; // 5ë¶„
  }

  /**
   * íˆíŠ¸ìœ¨ ì—…ë°ì´íŠ¸
   */
  private updateHitRate(): void {
    const total = this.stats.hits + this.stats.misses;
    this.stats.hitRate = total > 0 ? (this.stats.hits / total) * 100 : 0;
  }

  /**
   * ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘
   */
  private startMemoryMonitoring(): void {
    // 5ë¶„ë§ˆë‹¤ ë©”ëª¨ë¦¬ ì²´í¬
    this.memoryMonitorTimer = setInterval(
      async () => {
        await this.checkMemoryUsage();
      },
      5 * 60 * 1000
    );
  }

  /**
   * ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ ë° ê´€ë¦¬
   */
  private async checkMemoryUsage(): Promise<void> {
    try {
      // UpstashëŠ” INFO ëª…ë ¹ ë¯¸ì§€ì›, ëŒ€ì‹  ì¶”ì •ì¹˜ ì‚¬ìš©
      const estimatedUsageMB = this.stats.sets * 0.001; // ëŒ€ëµì ì¸ ì¶”ì •
      this.stats.memoryUsageMB = estimatedUsageMB;

      if (estimatedUsageMB > MEMORY_CONFIG.CRITICAL_THRESHOLD_MB) {
        console.error(`ğŸš¨ Critical memory usage: ${estimatedUsageMB}MB`);
        await this.evictOldKeys();
      } else if (estimatedUsageMB > MEMORY_CONFIG.WARNING_THRESHOLD_MB) {
        console.warn(`âš ï¸ High memory usage: ${estimatedUsageMB}MB`);
      }
    } catch (error) {
      console.error('âŒ Memory check error:', error);
    }
  }

  /**
   * ì˜¤ë˜ëœ í‚¤ ì œê±° (ë©”ëª¨ë¦¬ ê´€ë¦¬)
   */
  private async evictOldKeys(): Promise<void> {
    // TTLì´ ì§§ì€ í‚¤ë“¤ë¶€í„° ìš°ì„  ì œê±°
    const shortLivedPatterns = ['realtime:', 'metrics:'];

    try {
      // UpstashëŠ” íŒ¨í„´ ì‚­ì œ ë¯¸ì§€ì›, ê°œë³„ ì‚­ì œ í•„ìš”
      console.log('ğŸ§¹ Starting memory eviction...');
      // ì‹¤ì œ êµ¬í˜„ì€ ì•Œë ¤ì§„ í‚¤ ëª©ë¡ ê´€ë¦¬ í•„ìš”
    } catch (error) {
      console.error('âŒ Eviction error:', error);
    }
  }

  /**
   * ìºì‹œ í†µê³„ ì¡°íšŒ
   */
  getStats(): CacheStats & { recommendations: string[] } {
    const recommendations: string[] = [];

    // íˆíŠ¸ìœ¨ ê°œì„  ì œì•ˆ
    if (this.stats.hitRate < 70) {
      recommendations.push(
        'ìºì‹œ íˆíŠ¸ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. TTLì„ ëŠ˜ë¦¬ê±°ë‚˜ ìºì‹œ í‚¤ ì „ëµì„ ê²€í† í•˜ì„¸ìš”.'
      );
    }

    // ì—ëŸ¬ìœ¨ ì²´í¬
    const errorRate =
      (this.stats.errors /
        (this.stats.hits + this.stats.misses + this.stats.sets)) *
      100;
    if (errorRate > 5) {
      recommendations.push('ì—ëŸ¬ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. Redis ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.');
    }

    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
    if (this.stats.memoryUsageMB > MEMORY_CONFIG.WARNING_THRESHOLD_MB) {
      recommendations.push(
        'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ ìºì‹œë¥¼ ì •ë¦¬í•˜ì„¸ìš”.'
      );
    }

    return {
      ...this.stats,
      recommendations,
    };
  }

  /**
   * í†µê³„ ë¦¬ì…‹
   */
  resetStats(): void {
    this.stats = {
      hits: 0,
      misses: 0,
      sets: 0,
      deletes: 0,
      errors: 0,
      hitRate: 0,
      memoryUsageMB: this.stats.memoryUsageMB, // ë©”ëª¨ë¦¬ëŠ” ìœ ì§€
      lastReset: Date.now(),
    };
  }

  /**
   * ì„œë¹„ìŠ¤ ì¢…ë£Œ ì‹œ ì •ë¦¬
   */
  async cleanup(): Promise<void> {
    // ëŒ€ê¸° ì¤‘ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    await this.flushPipeline();

    // íƒ€ì´ë¨¸ ì •ë¦¬
    if (this.memoryMonitorTimer) {
      clearInterval(this.memoryMonitorTimer);
    }

    console.log('âœ… UpstashCacheService cleaned up');
  }
}

/**
 * ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•¨ìˆ˜
 */
export function createUpstashCacheService(redis: Redis): UpstashCacheService {
  return new UpstashCacheService(redis);
}

// ìºì‹œ í‚¤ ìƒìˆ˜ export (ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©)
export { CACHE_KEYS, TTL_STRATEGY };
