/**
 * ğŸ§  AI ì—”ì§„ìš© ë°ì´í„° ì „ì²˜ë¦¬ê¸°
 *
 * RealServerDataGenerator + Redis 24ì‹œê°„ ë°ì´í„°ë¥¼ í•©ì³ì„œ
 * AIìš© StandardServerMetrics[] íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ ì „ì²˜ë¦¬ê¸°
 */

import {
  StandardServerMetrics,
  SystemIntegrationAdapter,
} from '@/modules/ai-agent/adapters/SystemIntegrationAdapter';
import { ServerInstance } from '@/types/data-generator';
import { RealServerDataGenerator, type RealServerDataGeneratorType } from './RealServerDataGenerator';

export interface ProcessedAIData {
  metrics: StandardServerMetrics[];
  aggregatedStats: {
    totalServers: number;
    avgCpuUsage: number;
    avgMemoryUsage: number;
    avgDiskUsage: number;
    networkThroughput: number;
    healthScore: number;
    anomalyCount: number;
  };
  trends: {
    cpuTrend: 'increasing' | 'decreasing' | 'stable';
    memoryTrend: 'increasing' | 'decreasing' | 'stable';
    diskTrend: 'increasing' | 'decreasing' | 'stable';
    networkTrend: 'increasing' | 'decreasing' | 'stable';
  };
  timestamp: string;
  source: 'ai-engine-processor';
}

export interface AIHistoricalData {
  serverId: string;
  timeSeriesData: Array<{
    timestamp: Date;
    metrics: {
      cpu: { usage: number; loadAverage: number[] };
      memory: { usage: number; available: number };
      disk: { usage: number; iops: { read: number; write: number } };
      network: { bytesReceived: number; bytesSent: number };
    };
    anomalies: Array<{
      type: 'cpu_spike' | 'memory_leak' | 'disk_full' | 'network_congestion';
      severity: 'low' | 'medium' | 'high';
      confidence: number;
    }>;
  }>;
}

export class AIEngineProcessor {
  private static instance: AIEngineProcessor | null = null;
  private dataGenerator: RealServerDataGeneratorType;
  private lastProcessTime = 0;
  private readonly CACHE_DURATION = 45000; // 45ì´ˆ ìºì‹œ (40-50ì´ˆ ë²”ìœ„)
  private cachedData: ProcessedAIData | null = null;

  private constructor() {
    this.dataGenerator = RealServerDataGenerator.getInstance();
  }

  public static getInstance(): AIEngineProcessor {
    if (!AIEngineProcessor.instance) {
      AIEngineProcessor.instance = new AIEngineProcessor();
    }
    return AIEngineProcessor.instance;
  }

  /**
   * ğŸ§  ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜: AI ë¶„ì„ìš© ë°ì´í„° ì „ì²˜ë¦¬
   */
  public async getProcessedAIData(
    options: {
      includeTimeSeries?: boolean;
      enableAnomalyDetection?: boolean;
      forceRefresh?: boolean;
    } = {}
  ): Promise<ProcessedAIData> {
    const now = Date.now();

    if (
      !options.forceRefresh &&
      this.cachedData &&
      now - this.lastProcessTime < this.CACHE_DURATION
    ) {
      console.log('ğŸ§  AI ì—”ì§„ ë°ì´í„° ìºì‹œ ì‚¬ìš©');
      return this.cachedData;
    }

    try {
      console.log('ğŸ”„ AI ì—”ì§„ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘');

      const rawServers = await this.getRealTimeServerData();
      const aiMetrics = await this.transformToAIMetrics(rawServers);

      if (options.enableAnomalyDetection) {
        await this.detectAnomalies(aiMetrics);
      }

      const aggregatedStats = this.calculateAggregatedStats(aiMetrics);
      const trends = this.analyzeTrends(aiMetrics);

      const result: ProcessedAIData = {
        metrics: aiMetrics,
        aggregatedStats,
        trends,
        timestamp: new Date().toISOString(),
        source: 'ai-engine-processor',
      };

      this.cachedData = result;
      this.lastProcessTime = now;

      console.log(`âœ… AI ì—”ì§„ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: ${aiMetrics.length}ê°œ ì„œë²„`);
      return result;
    } catch (error) {
      console.error('âŒ AI ì—”ì§„ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨:', error);

      if (this.cachedData) {
        console.log('ğŸ›¡ï¸ ìºì‹œëœ AI ë°ì´í„°ë¡œ í´ë°±');
        return this.cachedData;
      }

      return this.getEmptyAIData();
    }
  }

  private async getRealTimeServerData(): Promise<ServerInstance[]> {
    try {
      if (this.dataGenerator.getAllServers().length === 0) {
        await this.dataGenerator.initialize();
        this.dataGenerator.startAutoGeneration();
        await new Promise(resolve => setTimeout(resolve, 1000));
      }

      const servers = this.dataGenerator.getAllServers();
      console.log(`ğŸ§  AIìš© ì‹¤ì‹œê°„ ì„œë²„ ë°ì´í„° ìˆ˜ì§‘: ${servers.length}ê°œ`);
      return servers;
    } catch (error) {
      console.error('âŒ AIìš© ì‹¤ì‹œê°„ ì„œë²„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨:', error);
      return [];
    }
  }

  private async transformToAIMetrics(
    rawServers: ServerInstance[]
  ): Promise<StandardServerMetrics[]> {
    const processedMetrics: StandardServerMetrics[] = [];

    // ğŸ”„ SystemIntegrationAdapter ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    const systemAdapter = SystemIntegrationAdapter.getInstance();

    for (const serverInstance of rawServers) {
      try {
        // ğŸ¯ SystemIntegrationAdapterì˜ ë³€í™˜ í•¨ìˆ˜ ì¬ì‚¬ìš©
        const baseMetrics = await systemAdapter.getServerMetrics(
          serverInstance.id,
          false
        );

        if (baseMetrics) {
          // ê¸°ì¡´ ë©”íŠ¸ë¦­ì´ ìˆìœ¼ë©´ ì‚¬ìš©
          processedMetrics.push(baseMetrics);
        } else {
          // ì—†ìœ¼ë©´ í˜„ì¬ ë°ì´í„°ë¡œ ìƒˆë¡œ ìƒì„±
          const newMetrics =
            this.createStandardMetricsFromServerInstance(serverInstance);
          processedMetrics.push(newMetrics);
        }

        // íˆìŠ¤í† ë¦¬ ë°ì´í„°ì™€ í†µí•© (ì´ìƒ ê°ì§€ ë“±)
        // const serverHistory = await this.getHistoricalData(serverInstance.id);
        // if (serverHistory) {
        //     await this.enhanceMetricsWithHistory(processedMetrics[processedMetrics.length - 1], serverHistory);
        // }
      } catch (error) {
        console.error(`âŒ ì„œë²„ ${serverInstance.id} AI ì²˜ë¦¬ ì‹¤íŒ¨:`, error);

        // í´ë°±: ê¸°ë³¸ ë³€í™˜ ì ìš©
        try {
          const fallbackMetrics =
            this.createStandardMetricsFromServerInstance(serverInstance);
          processedMetrics.push(fallbackMetrics);
        } catch (fallbackError) {
          console.error(
            `âŒ ì„œë²„ ${serverInstance.id} í´ë°± ì²˜ë¦¬ë„ ì‹¤íŒ¨:`,
            fallbackError
          );
        }
      }
    }

    return processedMetrics;
  }

  /**
   * ğŸ¯ ServerInstanceë¥¼ StandardServerMetricsë¡œ ë³€í™˜ (í´ë°±ìš©)
   */
  private createStandardMetricsFromServerInstance(
    serverInstance: ServerInstance
  ): StandardServerMetrics {
    return {
      serverId: serverInstance.id,
      hostname: serverInstance.name,
      timestamp: new Date(),
      status: this.mapServerStatus(serverInstance.status),
      metrics: {
        cpu: {
          usage: serverInstance.metrics?.cpu || 0,
          loadAverage: [0, 0, 0],
          cores: serverInstance.specs?.cpu?.cores || 4,
        },
        memory: {
          total:
            (serverInstance.specs?.memory?.total || 8) * 1024 * 1024 * 1024,
          used: Math.floor(
            ((serverInstance.specs?.memory?.total || 8) *
              1024 *
              1024 *
              1024 *
              (serverInstance.metrics?.memory || 0)) /
            100
          ),
          available: Math.floor(
            ((serverInstance.specs?.memory?.total || 8) *
              1024 *
              1024 *
              1024 *
              (100 - (serverInstance.metrics?.memory || 0))) /
            100
          ),
          usage: serverInstance.metrics?.memory || 0,
        },
        disk: {
          total:
            (serverInstance.specs?.disk?.total || 100) * 1024 * 1024 * 1024,
          used: Math.floor(
            ((serverInstance.specs?.disk?.total || 100) *
              1024 *
              1024 *
              1024 *
              (serverInstance.metrics?.disk || 0)) /
            100
          ),
          available: Math.floor(
            ((serverInstance.specs?.disk?.total || 100) *
              1024 *
              1024 *
              1024 *
              (100 - (serverInstance.metrics?.disk || 0))) /
            100
          ),
          usage: serverInstance.metrics?.disk || 0,
          iops: {
            read: 0,
            write: 0,
          },
        },
        network: {
          interface: 'eth0',
          bytesReceived: serverInstance.metrics?.network?.in || 0,
          bytesSent: serverInstance.metrics?.network?.out || 0,
          packetsReceived: 0,
          packetsSent: 0,
          errorsReceived: 0,
          errorsSent: 0,
        },
      },
      services: [],
      metadata: {
        location: serverInstance.location || 'Unknown',
        environment:
          ((serverInstance.environment === 'development'
            ? 'development'
            : serverInstance.environment) as
            | 'production'
            | 'staging'
            | 'development') || 'production',
        provider: 'onpremise',
      },
    };
  }

  /**
   * ğŸ¯ ì„œë²„ ìƒíƒœ ë§¤í•‘
   */
  private mapServerStatus(
    status: string
  ): 'online' | 'warning' | 'critical' | 'offline' {
    switch (status) {
      case 'running':
        return 'online';
      case 'warning':
        return 'warning';
      case 'error':
      case 'critical':
        return 'critical';
      case 'stopped':
      case 'maintenance':
        return 'offline';
      default:
        return 'offline';
    }
  }

  private async detectAnomalies(
    metrics: StandardServerMetrics[]
  ): Promise<void> {
    try {
      for (const metric of metrics) {
        const anomalies: any[] = [];

        if (metric.metrics.cpu.usage > 90) {
          anomalies.push({
            type: 'cpu_spike',
            severity: 'high',
            confidence: 0.9,
          });
        }

        if (metric.metrics.memory.usage > 95) {
          anomalies.push({
            type: 'memory_leak',
            severity: 'high',
            confidence: 0.85,
          });
        }

        if (anomalies.length > 0) {
          console.log(`ğŸš¨ ì„œë²„ ${metric.serverId} ì´ìƒ ê°ì§€:`, anomalies);
        }
      }
    } catch (error) {
      console.error('âŒ ì´ìƒ ê°ì§€ ì‹¤íŒ¨:', error);
    }
  }

  private calculateAggregatedStats(
    metrics: StandardServerMetrics[]
  ): ProcessedAIData['aggregatedStats'] {
    if (metrics.length === 0) {
      return {
        totalServers: 0,
        avgCpuUsage: 0,
        avgMemoryUsage: 0,
        avgDiskUsage: 0,
        networkThroughput: 0,
        healthScore: 0,
        anomalyCount: 0,
      };
    }

    const totalServers = metrics.length;
    const avgCpuUsage =
      metrics.reduce((sum, m) => sum + m.metrics.cpu.usage, 0) / totalServers;
    const avgMemoryUsage =
      metrics.reduce((sum, m) => sum + m.metrics.memory.usage, 0) /
      totalServers;
    const avgDiskUsage =
      metrics.reduce((sum, m) => sum + m.metrics.disk.usage, 0) / totalServers;
    const networkThroughput = metrics.reduce(
      (sum, m) =>
        sum + m.metrics.network.bytesReceived + m.metrics.network.bytesSent,
      0
    );

    const healthScore = Math.max(
      0,
      100 - (avgCpuUsage + avgMemoryUsage + avgDiskUsage) / 3
    );
    const anomalyCount = metrics.filter(
      m =>
        m.metrics.cpu.usage > 85 ||
        m.metrics.memory.usage > 85 ||
        m.metrics.disk.usage > 85
    ).length;

    return {
      totalServers,
      avgCpuUsage: Math.round(avgCpuUsage * 10) / 10,
      avgMemoryUsage: Math.round(avgMemoryUsage * 10) / 10,
      avgDiskUsage: Math.round(avgDiskUsage * 10) / 10,
      networkThroughput: Math.round(networkThroughput / 1024 / 1024),
      healthScore: Math.round(healthScore * 10) / 10,
      anomalyCount,
    };
  }

  private analyzeTrends(
    metrics: StandardServerMetrics[]
  ): ProcessedAIData['trends'] {
    return {
      cpuTrend: 'stable',
      memoryTrend: 'stable',
      diskTrend: 'stable',
      networkTrend: 'stable',
    };
  }

  private getEmptyAIData(): ProcessedAIData {
    return {
      metrics: [],
      aggregatedStats: {
        totalServers: 0,
        avgCpuUsage: 0,
        avgMemoryUsage: 0,
        avgDiskUsage: 0,
        networkThroughput: 0,
        healthScore: 0,
        anomalyCount: 0,
      },
      trends: {
        cpuTrend: 'stable',
        memoryTrend: 'stable',
        diskTrend: 'stable',
        networkTrend: 'stable',
      },
      timestamp: new Date().toISOString(),
      source: 'ai-engine-processor',
    };
  }

  public clearCache(): void {
    this.cachedData = null;
    this.lastProcessTime = 0;
    console.log('ğŸ—‘ï¸ AI ì—”ì§„ í”„ë¡œì„¸ì„œ ìºì‹œ ì´ˆê¸°í™”');
  }

  public getStatus() {
    return {
      isInitialized: true,
      hasCachedData: !!this.cachedData,
      lastProcessTime: this.lastProcessTime,
      cacheAge: this.lastProcessTime ? Date.now() - this.lastProcessTime : null,
      dataGeneratorStatus: this.dataGenerator.getStatus(),
    };
  }
}
