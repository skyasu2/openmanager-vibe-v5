/**
 * ğŸš€ í†µí•© ë°ì´í„° ì „ì²˜ë¦¬ ì—”ì§„ v1.0
 *
 * ëª©ì : ì„œë²„ë°ì´í„° ìƒì„±ê¸°ì˜ ì „ì²˜ë¦¬ë¥¼ í†µí•©í•˜ì—¬ ëª¨ë‹ˆí„°ë§ê³¼ AI ì—ì´ì „íŠ¸ê°€
 *      íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìµœì í™”ëœ ë°ì´í„° ì œê³µ
 *
 * íŠ¹ì§•:
 * - ê³µí†µ ì „ì²˜ë¦¬ ë¡œì§ í†µí•©
 * - ëª©ì ë³„ íŠ¹í™” ì²˜ë¦¬ (monitoring/ai/both)
 * - ìŠ¤ë§ˆíŠ¸ ìºì‹± ì‹œìŠ¤í…œ
 * - AI ë©”íŠ¸ë¦­ ì •ê·œí™”
 * - ì„±ëŠ¥ ìµœì í™”
 */

import { transformServerInstanceToServer } from '@/adapters/server-data-adapter';
import {
  IntegrationConfig,
  StandardServerMetrics,
  SystemIntegrationAdapter,
} from '@/modules/ai-agent/adapters/SystemIntegrationAdapter';
import { ServerInstance } from '@/types/data-generator';
import { Server } from '@/types/server';
import { RealServerDataGenerator, type RealServerDataGeneratorType } from './RealServerDataGenerator';

// ğŸ¯ í†µí•© ì²˜ë¦¬ ì˜µì…˜
export interface ProcessingOptions {
  includeHistorical?: boolean;
  enableAnomalyDetection?: boolean;
  forceRefresh?: boolean;
  timeRange?: { start: Date; end: Date };
  normalizationMode?: 'standard' | 'minmax' | 'robust';
  cacheTTL?: number;
}

// ğŸ¯ AI ìµœì í™” ë©”íŠ¸ë¦­ (ì •ê·œí™” + ì»¨í…ìŠ¤íŠ¸)
export interface AIOptimizedMetrics extends StandardServerMetrics {
  // ì •ê·œí™”ëœ ë©”íŠ¸ë¦­ (0-1 ìŠ¤ì¼€ì¼)
  normalizedMetrics: {
    cpu: number; // 0-1
    memory: number; // 0-1
    disk: number; // 0-1
    network: number; // 0-1
    overall: number; // ì¢…í•© ê±´ê°•ë„
  };

  // AI ì»¨í…ìŠ¤íŠ¸ ì •ë³´
  context: {
    serverRole: 'web' | 'api' | 'database' | 'cache' | 'queue';
    environment: 'production' | 'staging' | 'development';
    businessCriticality: 'low' | 'medium' | 'high' | 'critical';
    dependencies: string[];
  };

  // ì‚¬ì „ ê³„ì‚°ëœ AI íŠ¹ì„±
  aiFeatures: {
    anomalyScore: number; // 0-1 ì´ìƒ ì ìˆ˜
    trendVector: number[]; // íŠ¸ë Œë“œ ë²¡í„° [cpu, memory, disk, network]
    patternSignature: string; // íŒ¨í„´ ì‹œê·¸ë‹ˆì²˜ í•´ì‹œ
    riskLevel: 'low' | 'medium' | 'high' | 'critical';
    confidenceScore: number; // 0-1 ì‹ ë¢°ë„ ì ìˆ˜
  };
}

// ğŸ¯ í†µí•© ì²˜ë¦¬ ê²°ê³¼
export interface UnifiedProcessedData {
  // ê³µí†µ ë°ì´í„°
  rawServers: ServerInstance[];
  timestamp: string;
  source: 'unified-processor';

  // ëª¨ë‹ˆí„°ë§ìš© ë°ì´í„°
  monitoring?: {
    servers: Server[];
    stats: {
      total: number;
      healthy: number;
      warning: number;
      critical: number;
      offline: number;
      averageCpu: number;
      averageMemory: number;
      averageDisk: number;
      averageNetwork: number;
    };
  };

  // AIìš© ë°ì´í„°
  ai?: {
    metrics: AIOptimizedMetrics[];
    aggregatedStats: {
      totalServers: number;
      avgNormalizedCpu: number;
      avgNormalizedMemory: number;
      avgNormalizedDisk: number;
      avgNormalizedNetwork: number;
      overallHealthScore: number;
      anomalyCount: number;
      riskDistribution: Record<string, number>;
    };
    trends: {
      cpuTrend: 'increasing' | 'decreasing' | 'stable';
      memoryTrend: 'increasing' | 'decreasing' | 'stable';
      diskTrend: 'increasing' | 'decreasing' | 'stable';
      networkTrend: 'increasing' | 'decreasing' | 'stable';
      overallTrend: 'improving' | 'degrading' | 'stable';
    };
    insights: {
      criticalServers: string[];
      anomalousServers: string[];
      recommendations: string[];
      predictedIssues: Array<{
        serverId: string;
        issueType: string;
        probability: number;
        timeToIssue: number; // minutes
      }>;
    };
  };

  // ë©”íƒ€ë°ì´í„°
  metadata: {
    processingTime: number;
    cacheHit: boolean;
    dataQuality: number; // 0-1
    completeness: number; // 0-1
  };
}

// ğŸ§  ìŠ¤ë§ˆíŠ¸ ìºì‹œ ë§¤ë‹ˆì € (ë² ë¥´ì…€ ìµœì í™”)
class SmartCacheManager {
  private cache = new Map<
    string,
    { data: any; timestamp: number; ttl: number }
  >();
  private readonly DEFAULT_TTL = 30000; // 30ì´ˆ
  private readonly MAX_CACHE_SIZE = 50; // ë² ë¥´ì…€ ë©”ëª¨ë¦¬ ì œí•œ ê³ ë ¤

  set(key: string, data: any, ttl?: number): void {
    // ìºì‹œ í¬ê¸° ì œí•œ (ë² ë¥´ì…€ ë©”ëª¨ë¦¬ ê´€ë¦¬)
    if (this.cache.size >= this.MAX_CACHE_SIZE) {
      this.evictOldest();
    }

    this.cache.set(key, {
      data,
      timestamp: Date.now(),
      ttl: ttl || this.DEFAULT_TTL,
    });
  }

  get(key: string): any | null {
    const cached = this.cache.get(key);
    if (!cached) return null;

    const isExpired = Date.now() - cached.timestamp > cached.ttl;
    if (isExpired) {
      this.cache.delete(key);
      return null;
    }

    return cached.data;
  }

  has(key: string): boolean {
    return this.get(key) !== null;
  }

  clear(): void {
    this.cache.clear();
  }

  // ë² ë¥´ì…€ í™˜ê²½ì„ ìœ„í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬
  private evictOldest(): void {
    if (this.cache.size === 0) return;

    let oldestKey = '';
    let oldestTime = Date.now();

    for (const [key, value] of this.cache.entries()) {
      if (value.timestamp < oldestTime) {
        oldestTime = value.timestamp;
        oldestKey = key;
      }
    }

    if (oldestKey) {
      this.cache.delete(oldestKey);
    }
  }

  getStats() {
    return {
      size: this.cache.size,
      maxSize: this.MAX_CACHE_SIZE,
      keys: Array.from(this.cache.keys()).slice(0, 10), // ë² ë¥´ì…€ ì‘ë‹µ í¬ê¸° ì œí•œ
    };
  }
}

// ë² ë¥´ì…€ ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì„ ìœ„í•œ ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
let globalProcessorInstance: UnifiedDataProcessor | null = null;

export class UnifiedDataProcessor {
  private dataGenerator: RealServerDataGeneratorType;
  private systemAdapter: SystemIntegrationAdapter;
  private cacheManager: SmartCacheManager;
  private processingStats = {
    totalProcessed: 0,
    totalCacheHits: 0,
    totalProcessingTime: 0,
    averageProcessingTime: 0,
  };

  constructor() {
    console.log('ğŸ”„ í†µí•© ë°ì´í„° ì²˜ë¦¬ê¸° ì´ˆê¸°í™”');
    this.dataGenerator = RealServerDataGenerator.getInstance();

    // ë² ë¥´ì…€ í™˜ê²½ì— ìµœì í™”ëœ ê¸°ë³¸ ì„¤ì •
    const defaultConfig: IntegrationConfig = {
      database: {
        type: 'supabase',
        url: process.env.SUPABASE_URL || 'http://localhost:54321',
        apiKey: process.env.SUPABASE_ANON_KEY,
        maxConnections: 5,
        timeout: 15000,
      },
      redis: {
        enabled: false, // ë² ë¥´ì…€ì—ì„œëŠ” ê¸°ë³¸ ë¹„í™œì„±í™”
        url: process.env.REDIS_URL || 'redis://localhost:6379',
        ttl: 300,
        maxRetries: 2,
      },
      monitoring: {
        enableRealtime: true,
        collectionInterval: 30000,
        retentionPeriod: 86400000, // 24ì‹œê°„
        enableAggregation: true,
      },
      aiAgent: {
        enablePythonAnalysis: false,
        enableMCP: false,
        enableCaching: false,
        maxConcurrentRequests: 5,
      },
    };

    this.systemAdapter = SystemIntegrationAdapter.getInstance(defaultConfig);
    this.cacheManager = new SmartCacheManager();
  }

  // ë² ë¥´ì…€ í™˜ê²½ì— ìµœì í™”ëœ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
  public static getInstance(): UnifiedDataProcessor {
    if (!globalProcessorInstance) {
      globalProcessorInstance = new UnifiedDataProcessor();
    }
    return globalProcessorInstance;
  }

  // ë² ë¥´ì…€ í™˜ê²½ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ì¬ì„¤ì •ì´ í•„ìš”í•œ ê²½ìš°
  public static resetInstance(): void {
    globalProcessorInstance = null;
  }

  /**
   * ğŸš€ ë©”ì¸ í†µí•© ì²˜ë¦¬ í•¨ìˆ˜
   */
  public async processData(
    purpose: 'monitoring' | 'ai' | 'both',
    options: ProcessingOptions = {}
  ): Promise<UnifiedProcessedData> {
    const startTime = Date.now();
    const cacheKey = this.generateCacheKey(purpose, options);

    // ìºì‹œ í™•ì¸
    if (!options.forceRefresh && this.cacheManager.has(cacheKey)) {
      console.log(`ğŸ“¦ í†µí•© ì²˜ë¦¬ ìºì‹œ ì‚¬ìš©: ${purpose}`);
      this.processingStats.totalCacheHits++;

      const cachedData = this.cacheManager.get(cacheKey);
      cachedData.metadata.cacheHit = true;
      return cachedData;
    }

    try {
      console.log(`ğŸ”„ í†µí•© ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: ${purpose}`);

      // 1. ê³µí†µ ì „ì²˜ë¦¬
      const baseData = await this.applyCommonProcessing(options);

      // 2. ëª©ì ë³„ íŠ¹í™” ì²˜ë¦¬
      let result: UnifiedProcessedData;
      switch (purpose) {
        case 'monitoring':
          result = await this.applyMonitoringProcessing(baseData, options);
          break;
        case 'ai':
          result = await this.applyAIProcessing(baseData, options);
          break;
        case 'both':
          result = await this.applyBothProcessing(baseData, options);
          break;
        default:
          throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ì²˜ë¦¬ ëª©ì : ${purpose}`);
      }

      // 3. ë©”íƒ€ë°ì´í„° ì¶”ê°€
      const processingTime = Date.now() - startTime;
      result.metadata = {
        processingTime,
        cacheHit: false,
        dataQuality: this.calculateDataQuality(result),
        completeness: this.calculateCompleteness(result),
      };

      // 4. ìºì‹œ ì €ì¥
      const cacheTTL = options.cacheTTL || (purpose === 'ai' ? 45000 : 35000);
      this.cacheManager.set(cacheKey, result, cacheTTL);

      // 5. í†µê³„ ì—…ë°ì´íŠ¸
      this.updateProcessingStats(processingTime);

      console.log(`âœ… í†µí•© ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: ${purpose} (${processingTime}ms)`);
      return result;
    } catch (error) {
      console.error(`âŒ í†µí•© ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: ${purpose}`, error);

      // í´ë°±: ìºì‹œëœ ë°ì´í„° ë˜ëŠ” ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
      const fallbackData =
        this.cacheManager.get(cacheKey) ||
        (await this.getEmptyProcessedData(purpose));
      fallbackData.metadata = {
        processingTime: Date.now() - startTime,
        cacheHit: true,
        dataQuality: 0.5,
        completeness: 0.5,
      };

      return fallbackData;
    }
  }

  /**
   * ğŸ”„ ê³µí†µ ì „ì²˜ë¦¬ ë¡œì§
   */
  private async applyCommonProcessing(options: ProcessingOptions): Promise<{
    rawServers: ServerInstance[];
    timestamp: string;
  }> {
    // ë°ì´í„° ìƒì„±ê¸° ì´ˆê¸°í™” í™•ì¸
    if (this.dataGenerator.getAllServers().length === 0) {
      await this.dataGenerator.initialize();
      this.dataGenerator.startAutoGeneration();
      await new Promise(resolve => setTimeout(resolve, 1000));
    }

    const rawServers = this.dataGenerator.getAllServers();
    console.log(`ğŸ“Š ê³µí†µ ì „ì²˜ë¦¬: ${rawServers.length}ê°œ ì„œë²„ ë°ì´í„° ìˆ˜ì§‘`);

    return {
      rawServers,
      timestamp: new Date().toISOString(),
    };
  }

  /**
   * ğŸ“Š ëª¨ë‹ˆí„°ë§ ì „ìš© ì²˜ë¦¬
   */
  private async applyMonitoringProcessing(
    baseData: { rawServers: ServerInstance[]; timestamp: string },
    options: ProcessingOptions
  ): Promise<UnifiedProcessedData> {
    const servers: Server[] = [];

    // ServerInstance â†’ Server ë³€í™˜
    for (const serverInstance of baseData.rawServers) {
      try {
        const server = transformServerInstanceToServer(serverInstance);
        servers.push(server);
      } catch (error) {
        console.error(`âŒ ì„œë²„ ë³€í™˜ ì‹¤íŒ¨: ${serverInstance.id}`, error);
      }
    }

    // í†µê³„ ê³„ì‚°
    const stats = this.calculateMonitoringStats(servers);

    return {
      rawServers: baseData.rawServers,
      timestamp: baseData.timestamp,
      source: 'unified-processor',
      monitoring: {
        servers,
        stats,
      },
      metadata: {
        processingTime: 0,
        cacheHit: false,
        dataQuality: 0,
        completeness: 0,
      },
    };
  }

  /**
   * ğŸ§  AI ì „ìš© ì²˜ë¦¬
   */
  private async applyAIProcessing(
    baseData: { rawServers: ServerInstance[]; timestamp: string },
    options: ProcessingOptions
  ): Promise<UnifiedProcessedData> {
    const aiMetrics: AIOptimizedMetrics[] = [];

    // ServerInstance â†’ AIOptimizedMetrics ë³€í™˜
    for (const serverInstance of baseData.rawServers) {
      try {
        const optimizedMetric = await this.createAIOptimizedMetric(
          serverInstance,
          options
        );
        aiMetrics.push(optimizedMetric);
      } catch (error) {
        console.error(`âŒ AI ë©”íŠ¸ë¦­ ìƒì„± ì‹¤íŒ¨: ${serverInstance.id}`, error);
      }
    }

    // AI ì§‘ê³„ í†µê³„ ê³„ì‚°
    const aggregatedStats = this.calculateAIAggregatedStats(aiMetrics);

    // íŠ¸ë Œë“œ ë¶„ì„
    const trends = this.analyzeAITrends(aiMetrics);

    // AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
    const insights = await this.generateAIInsights(aiMetrics);

    return {
      rawServers: baseData.rawServers,
      timestamp: baseData.timestamp,
      source: 'unified-processor',
      ai: {
        metrics: aiMetrics,
        aggregatedStats,
        trends,
        insights,
      },
      metadata: {
        processingTime: 0,
        cacheHit: false,
        dataQuality: 0,
        completeness: 0,
      },
    };
  }

  /**
   * ğŸ”„ ëª¨ë‹ˆí„°ë§ + AI í†µí•© ì²˜ë¦¬
   */
  private async applyBothProcessing(
    baseData: { rawServers: ServerInstance[]; timestamp: string },
    options: ProcessingOptions
  ): Promise<UnifiedProcessedData> {
    // ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
    const [monitoringResult, aiResult] = await Promise.all([
      this.applyMonitoringProcessing(baseData, options),
      this.applyAIProcessing(baseData, options),
    ]);

    return {
      rawServers: baseData.rawServers,
      timestamp: baseData.timestamp,
      source: 'unified-processor',
      monitoring: monitoringResult.monitoring,
      ai: aiResult.ai,
      metadata: {
        processingTime: 0,
        cacheHit: false,
        dataQuality: 0,
        completeness: 0,
      },
    };
  }

  /**
   * ğŸ¯ AI ìµœì í™” ë©”íŠ¸ë¦­ ìƒì„±
   */
  private async createAIOptimizedMetric(
    serverInstance: ServerInstance,
    options: ProcessingOptions
  ): Promise<AIOptimizedMetrics> {
    // ê¸°ë³¸ StandardServerMetrics ìƒì„±
    const baseMetrics =
      await this.createStandardMetricsFromServerInstance(serverInstance);

    // ì •ê·œí™”ëœ ë©”íŠ¸ë¦­ ê³„ì‚°
    const normalizedMetrics = this.normalizeMetrics(
      baseMetrics,
      options.normalizationMode || 'minmax'
    );

    // ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ë¡ 
    const context = this.inferServerContext(serverInstance);

    // AI íŠ¹ì„± ê³„ì‚°
    const aiFeatures = await this.calculateAIFeatures(
      baseMetrics,
      normalizedMetrics
    );

    return {
      ...baseMetrics,
      normalizedMetrics,
      context,
      aiFeatures,
    };
  }

  /**
   * ğŸ“ ë©”íŠ¸ë¦­ ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼)
   */
  private normalizeMetrics(
    metrics: StandardServerMetrics,
    mode: 'standard' | 'minmax' | 'robust'
  ) {
    const cpu = Math.min(metrics.metrics.cpu.usage / 100, 1);
    const memory = Math.min(metrics.metrics.memory.usage / 100, 1);
    const disk = Math.min(metrics.metrics.disk.usage / 100, 1);

    // ë„¤íŠ¸ì›Œí¬ëŠ” ìƒëŒ€ì  ì •ê·œí™” (í˜„ì¬ ì„œë²„ë“¤ ì¤‘ ìµœëŒ€ê°’ ê¸°ì¤€)
    const networkBytes =
      metrics.metrics.network.bytesReceived + metrics.metrics.network.bytesSent;
    const network = Math.min(networkBytes / (1024 * 1024 * 100), 1); // 100MB ê¸°ì¤€

    // ì¢…í•© ê±´ê°•ë„ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
    const overall = cpu * 0.3 + memory * 0.3 + disk * 0.25 + network * 0.15;

    return {
      cpu,
      memory,
      disk,
      network,
      overall,
    };
  }

  /**
   * ğŸ·ï¸ ì„œë²„ ì»¨í…ìŠ¤íŠ¸ ì¶”ë¡ 
   */
  private inferServerContext(serverInstance: ServerInstance) {
    // ì„œë²„ ì´ë¦„ê³¼ íƒ€ì…ì„ ê¸°ë°˜ìœ¼ë¡œ ì—­í•  ì¶”ë¡ 
    const serverName = serverInstance.name.toLowerCase();
    const serverType = serverInstance.type.toLowerCase();

    let serverRole: 'web' | 'api' | 'database' | 'cache' | 'queue' = 'web';
    if (
      serverName.includes('db') ||
      serverName.includes('database') ||
      ['mysql', 'postgresql', 'mongodb', 'oracle', 'mssql'].includes(serverType)
    ) {
      serverRole = 'database';
    } else if (
      serverName.includes('api') ||
      serverName.includes('service') ||
      ['nodejs', 'springboot', 'django', 'dotnet', 'php'].includes(serverType)
    ) {
      serverRole = 'api';
    } else if (
      serverName.includes('cache') ||
      serverName.includes('redis') ||
      serverType === 'redis'
    ) {
      serverRole = 'cache';
    } else if (
      serverName.includes('queue') ||
      serverName.includes('worker') ||
      ['rabbitmq', 'kafka'].includes(serverType)
    ) {
      serverRole = 'queue';
    }

    // í™˜ê²½ ì¶”ë¡ 
    let environment: 'production' | 'staging' | 'development' =
      serverInstance.environment || 'production';
    if (serverName.includes('dev') || serverName.includes('test')) {
      environment = 'development';
    } else if (serverName.includes('staging') || serverName.includes('stage')) {
      environment = 'staging';
    }

    // ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ìš”ë„ ì¶”ë¡  (ì„œë²„ ì—­í• ê³¼ í™˜ê²½ ê¸°ë°˜)
    let businessCriticality: 'low' | 'medium' | 'high' | 'critical' = 'medium';
    if (environment === 'production') {
      if (serverRole === 'database') {
        businessCriticality = 'critical';
      } else if (serverRole === 'api' || serverRole === 'web') {
        businessCriticality = 'high';
      }
    } else if (environment === 'development') {
      businessCriticality = 'low';
    }

    return {
      serverRole,
      environment,
      businessCriticality,
      dependencies: [], // í–¥í›„ í™•ì¥
    };
  }

  /**
   * ğŸ§  AI íŠ¹ì„± ê³„ì‚°
   */
  private async calculateAIFeatures(
    baseMetrics: StandardServerMetrics,
    normalizedMetrics: {
      cpu: number;
      memory: number;
      disk: number;
      network: number;
      overall: number;
    }
  ) {
    // ì´ìƒ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ì„ê³„ê°’ ê¸°ë°˜)
    let anomalyScore = 0;
    if (normalizedMetrics.cpu > 0.8) anomalyScore += 0.3;
    if (normalizedMetrics.memory > 0.9) anomalyScore += 0.4;
    if (normalizedMetrics.disk > 0.85) anomalyScore += 0.3;
    anomalyScore = Math.min(anomalyScore, 1);

    // íŠ¸ë Œë“œ ë²¡í„° (í˜„ì¬ëŠ” í˜„ì¬ê°’ìœ¼ë¡œ ì„¤ì •, í–¥í›„ íˆìŠ¤í† ë¦¬ ë°ì´í„° í™œìš©)
    const trendVector = [
      normalizedMetrics.cpu,
      normalizedMetrics.memory,
      normalizedMetrics.disk,
      normalizedMetrics.network,
    ];

    // íŒ¨í„´ ì‹œê·¸ë‹ˆì²˜ ìƒì„±
    const patternSignature = this.generatePatternSignature(normalizedMetrics);

    // ìœ„í—˜ ìˆ˜ì¤€ ê³„ì‚°
    let riskLevel: 'low' | 'medium' | 'high' | 'critical' = 'low';
    if (anomalyScore > 0.7) riskLevel = 'critical';
    else if (anomalyScore > 0.5) riskLevel = 'high';
    else if (anomalyScore > 0.3) riskLevel = 'medium';

    // ì‹ ë¢°ë„ ì ìˆ˜ (ë°ì´í„° í’ˆì§ˆ ê¸°ë°˜)
    const confidenceScore = 0.95; // í˜„ì¬ëŠ” ê³ ì •ê°’, í–¥í›„ ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ ê¸°ë°˜

    return {
      anomalyScore,
      trendVector,
      patternSignature,
      riskLevel,
      confidenceScore,
    };
  }

  /**
   * ğŸ”– íŒ¨í„´ ì‹œê·¸ë‹ˆì²˜ ìƒì„±
   */
  private generatePatternSignature(normalizedMetrics: {
    cpu: number;
    memory: number;
    disk: number;
    network: number;
  }): string {
    // ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ íŒ¨í„´ ì‹œê·¸ë‹ˆì²˜
    const values = [
      Math.round(normalizedMetrics.cpu * 10),
      Math.round(normalizedMetrics.memory * 10),
      Math.round(normalizedMetrics.disk * 10),
      Math.round(normalizedMetrics.network * 10),
    ];

    return `pattern_${values.join('_')}`;
  }

  /**
   * ğŸ“Š ëª¨ë‹ˆí„°ë§ í†µê³„ ê³„ì‚°
   */
  private calculateMonitoringStats(servers: Server[]) {
    const total = servers.length;
    let healthy = 0,
      warning = 0,
      critical = 0,
      offline = 0;
    let totalCpu = 0,
      totalMemory = 0,
      totalDisk = 0,
      totalNetwork = 0;

    servers.forEach(server => {
      switch (server.status) {
        case 'online':
          healthy++;
          break;
        case 'warning':
          warning++;
          break;
        case 'critical':
          critical++;
          break;
        case 'offline':
          offline++;
          break;
      }

      totalCpu += server.cpu;
      totalMemory += server.memory;
      totalDisk += server.disk;
      totalNetwork += server.network || 0;
    });

    return {
      total,
      healthy,
      warning,
      critical,
      offline,
      averageCpu: total > 0 ? totalCpu / total : 0,
      averageMemory: total > 0 ? totalMemory / total : 0,
      averageDisk: total > 0 ? totalDisk / total : 0,
      averageNetwork: total > 0 ? totalNetwork / total : 0,
    };
  }

  /**
   * ğŸ§  AI ì§‘ê³„ í†µê³„ ê³„ì‚°
   */
  private calculateAIAggregatedStats(metrics: AIOptimizedMetrics[]) {
    const totalServers = metrics.length;
    if (totalServers === 0) {
      return {
        totalServers: 0,
        avgNormalizedCpu: 0,
        avgNormalizedMemory: 0,
        avgNormalizedDisk: 0,
        avgNormalizedNetwork: 0,
        overallHealthScore: 0,
        anomalyCount: 0,
        riskDistribution: { low: 0, medium: 0, high: 0, critical: 0 },
      };
    }

    let totalNormalizedCpu = 0,
      totalNormalizedMemory = 0;
    let totalNormalizedDisk = 0,
      totalNormalizedNetwork = 0;
    let totalHealthScore = 0,
      anomalyCount = 0;
    const riskDistribution = { low: 0, medium: 0, high: 0, critical: 0 };

    metrics.forEach(metric => {
      totalNormalizedCpu += metric.normalizedMetrics.cpu;
      totalNormalizedMemory += metric.normalizedMetrics.memory;
      totalNormalizedDisk += metric.normalizedMetrics.disk;
      totalNormalizedNetwork += metric.normalizedMetrics.network;
      totalHealthScore += metric.normalizedMetrics.overall;

      if (metric.aiFeatures.anomalyScore > 0.5) anomalyCount++;
      riskDistribution[metric.aiFeatures.riskLevel]++;
    });

    return {
      totalServers,
      avgNormalizedCpu: totalNormalizedCpu / totalServers,
      avgNormalizedMemory: totalNormalizedMemory / totalServers,
      avgNormalizedDisk: totalNormalizedDisk / totalServers,
      avgNormalizedNetwork: totalNormalizedNetwork / totalServers,
      overallHealthScore: totalHealthScore / totalServers,
      anomalyCount,
      riskDistribution,
    };
  }

  /**
   * ğŸ“ˆ AI íŠ¸ë Œë“œ ë¶„ì„
   */
  private analyzeAITrends(metrics: AIOptimizedMetrics[]) {
    // í˜„ì¬ëŠ” ë‹¨ìˆœ í‰ê·  ê¸°ë°˜, í–¥í›„ íˆìŠ¤í† ë¦¬ ë°ì´í„°ë¡œ ì‹¤ì œ íŠ¸ë Œë“œ ë¶„ì„
    const avgCpu =
      metrics.reduce((sum, m) => sum + m.normalizedMetrics.cpu, 0) /
      metrics.length;
    const avgMemory =
      metrics.reduce((sum, m) => sum + m.normalizedMetrics.memory, 0) /
      metrics.length;
    const avgDisk =
      metrics.reduce((sum, m) => sum + m.normalizedMetrics.disk, 0) /
      metrics.length;
    const avgNetwork =
      metrics.reduce((sum, m) => sum + m.normalizedMetrics.network, 0) /
      metrics.length;
    const avgOverall =
      metrics.reduce((sum, m) => sum + m.normalizedMetrics.overall, 0) /
      metrics.length;

    return {
      cpuTrend: (avgCpu > 0.7
        ? 'increasing'
        : avgCpu < 0.3
          ? 'decreasing'
          : 'stable') as 'increasing' | 'decreasing' | 'stable',
      memoryTrend: (avgMemory > 0.7
        ? 'increasing'
        : avgMemory < 0.3
          ? 'decreasing'
          : 'stable') as 'increasing' | 'decreasing' | 'stable',
      diskTrend: (avgDisk > 0.7
        ? 'increasing'
        : avgDisk < 0.3
          ? 'decreasing'
          : 'stable') as 'increasing' | 'decreasing' | 'stable',
      networkTrend: (avgNetwork > 0.7
        ? 'increasing'
        : avgNetwork < 0.3
          ? 'decreasing'
          : 'stable') as 'increasing' | 'decreasing' | 'stable',
      overallTrend: (avgOverall > 0.7
        ? 'degrading'
        : avgOverall < 0.3
          ? 'improving'
          : 'stable') as 'improving' | 'degrading' | 'stable',
    };
  }

  /**
   * ğŸ’¡ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
   */
  private async generateAIInsights(metrics: AIOptimizedMetrics[]) {
    const criticalServers = metrics
      .filter(m => m.aiFeatures.riskLevel === 'critical')
      .map(m => m.serverId);

    const anomalousServers = metrics
      .filter(m => m.aiFeatures.anomalyScore > 0.6)
      .map(m => m.serverId);

    const recommendations: string[] = [];
    if (criticalServers.length > 0) {
      recommendations.push(
        `${criticalServers.length}ê°œ ì„œë²„ê°€ ìœ„í—˜ ìƒíƒœì…ë‹ˆë‹¤. ì¦‰ì‹œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.`
      );
    }
    if (anomalousServers.length > 0) {
      recommendations.push(
        `${anomalousServers.length}ê°œ ì„œë²„ì—ì„œ ì´ìƒ íŒ¨í„´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.`
      );
    }

    const predictedIssues = metrics
      .filter(m => m.aiFeatures.anomalyScore > 0.4)
      .map(m => ({
        serverId: m.serverId,
        issueType:
          m.aiFeatures.riskLevel === 'high'
            ? 'resource_exhaustion'
            : 'performance_degradation',
        probability: m.aiFeatures.anomalyScore,
        timeToIssue: Math.round((1 - m.aiFeatures.anomalyScore) * 120), // ìµœëŒ€ 2ì‹œê°„
      }));

    return {
      criticalServers,
      anomalousServers,
      recommendations,
      predictedIssues,
    };
  }

  // ... ê¸°íƒ€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
  private createStandardMetricsFromServerInstance(
    serverInstance: ServerInstance
  ): StandardServerMetrics {
    return {
      serverId: serverInstance.id,
      hostname: serverInstance.name, // ServerInstanceëŠ” name ì†ì„± ì‚¬ìš©
      timestamp: new Date(),
      status: this.mapServerStatus(serverInstance.status),
      metrics: {
        cpu: {
          usage: serverInstance.metrics.cpu,
          loadAverage: [
            serverInstance.metrics.cpu / 100,
            serverInstance.metrics.cpu / 100,
            serverInstance.metrics.cpu / 100,
          ],
          cores: serverInstance.specs.cpu.cores || 4,
        },
        memory: {
          total: serverInstance.specs.memory.total,
          used:
            (serverInstance.metrics.memory / 100) *
            serverInstance.specs.memory.total,
          available:
            ((100 - serverInstance.metrics.memory) / 100) *
            serverInstance.specs.memory.total,
          usage: serverInstance.metrics.memory,
        },
        disk: {
          total: serverInstance.specs.disk.total,
          used:
            (serverInstance.metrics.disk / 100) *
            serverInstance.specs.disk.total,
          available:
            ((100 - serverInstance.metrics.disk) / 100) *
            serverInstance.specs.disk.total,
          usage: serverInstance.metrics.disk,
          iops: { read: serverInstance.specs.disk.iops || 100, write: 50 },
        },
        network: {
          bytesReceived: serverInstance.metrics.network.in * 1024 * 1024,
          bytesSent: serverInstance.metrics.network.out * 1024 * 1024,
          packetsReceived: 1000,
          packetsSent: 800,
          interface: 'eth0', // ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤
          errorsReceived: 0,
          errorsSent: 0,
        },
      },
      services: [
        {
          name: 'nginx',
          status: 'running',
          port: 80,
          pid: 1234,
          uptime: 86400,
          memoryUsage: 128 * 1024 * 1024, // 128MB
          cpuUsage: 5.5,
        },
      ],
      metadata: {
        location: serverInstance.location || 'unknown',
        environment: serverInstance.environment || 'production',
        provider: 'onpremise',
        cluster: undefined,
        zone: undefined,
        instanceType: serverInstance.type || undefined,
      },
    };
  }

  private mapServerStatus(
    status: string
  ): 'online' | 'warning' | 'critical' | 'offline' {
    switch (status.toLowerCase()) {
      case 'online':
        return 'online';
      case 'warning':
        return 'warning';
      case 'critical':
        return 'critical';
      case 'offline':
        return 'offline';
      default:
        return 'online';
    }
  }

  private generateCacheKey(
    purpose: string,
    options: ProcessingOptions
  ): string {
    const optionsHash = JSON.stringify(options);
    return `unified_${purpose}_${Buffer.from(optionsHash).toString('base64').slice(0, 10)}`;
  }

  private calculateDataQuality(data: UnifiedProcessedData): number {
    // ê°„ë‹¨í•œ ë°ì´í„° í’ˆì§ˆ ê³„ì‚°
    const hasRawData = data.rawServers.length > 0;
    const hasProcessedData =
      data.monitoring?.servers.length || data.ai?.metrics.length || 0;
    return hasRawData && hasProcessedData ? 0.95 : 0.5;
  }

  private calculateCompleteness(data: UnifiedProcessedData): number {
    // ë°ì´í„° ì™„ì „ì„± ê³„ì‚°
    const expectedFields = (data.monitoring ? 4 : 0) + (data.ai ? 4 : 0);
    const actualFields = (data.monitoring ? 4 : 0) + (data.ai ? 4 : 0);
    return expectedFields > 0 ? actualFields / expectedFields : 1;
  }

  private updateProcessingStats(processingTime: number): void {
    this.processingStats.totalProcessed++;
    this.processingStats.totalProcessingTime += processingTime;
    this.processingStats.averageProcessingTime =
      this.processingStats.totalProcessingTime /
      this.processingStats.totalProcessed;
  }

  private async getEmptyProcessedData(
    purpose: string
  ): Promise<UnifiedProcessedData> {
    return {
      rawServers: [],
      timestamp: new Date().toISOString(),
      source: 'unified-processor',
      monitoring:
        purpose === 'monitoring' || purpose === 'both'
          ? {
            servers: [],
            stats: {
              total: 0,
              healthy: 0,
              warning: 0,
              critical: 0,
              offline: 0,
              averageCpu: 0,
              averageMemory: 0,
              averageDisk: 0,
              averageNetwork: 0,
            },
          }
          : undefined,
      ai:
        purpose === 'ai' || purpose === 'both'
          ? {
            metrics: [],
            aggregatedStats: {
              totalServers: 0,
              avgNormalizedCpu: 0,
              avgNormalizedMemory: 0,
              avgNormalizedDisk: 0,
              avgNormalizedNetwork: 0,
              overallHealthScore: 0,
              anomalyCount: 0,
              riskDistribution: { low: 0, medium: 0, high: 0, critical: 0 },
            },
            trends: {
              cpuTrend: 'stable',
              memoryTrend: 'stable',
              diskTrend: 'stable',
              networkTrend: 'stable',
              overallTrend: 'stable',
            },
            insights: {
              criticalServers: [],
              anomalousServers: [],
              recommendations: [],
              predictedIssues: [],
            },
          }
          : undefined,
      metadata: {
        processingTime: 0,
        cacheHit: false,
        dataQuality: 0,
        completeness: 0,
      },
    };
  }

  // ğŸ”§ ê´€ë¦¬ ë©”ì„œë“œë“¤
  public clearCache(): void {
    this.cacheManager.clear();
    console.log('ğŸ§¹ í†µí•© ì²˜ë¦¬ ìºì‹œ í´ë¦¬ì–´ ì™„ë£Œ');
  }

  public getStatus() {
    return {
      cacheStats: this.cacheManager.getStats(),
      processingStats: this.processingStats,
      isReady: this.dataGenerator.getAllServers().length > 0,
    };
  }

  public getProcessingStats() {
    return { ...this.processingStats };
  }
}
