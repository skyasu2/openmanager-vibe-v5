/**
 * ðŸ¤– Unified Metrics Manager AI Analyzer
 *
 * AI analysis and recommendation functionality:
 * - Server health analysis
 * - Performance prediction
 * - Anomaly detection
 * - Recommendation generation
 */

import type {
  AIAnalysisResult,
  MetricsPerformanceData,
  UnifiedServerMetrics,
} from './UnifiedMetricsManager.types';

export const AIAnalyzer = {
  /**
   * ðŸ¤– Perform AI analysis on servers
   */
  async performAIAnalysis(
    servers: UnifiedServerMetrics[],
    metrics: MetricsPerformanceData
  ): Promise<void> {
    console.log('ðŸ¤– AI ë¶„ì„ ì‹œìž‘...');
    const startTime = Date.now();

    try {
      // ì„œë²„ë³„ AI ë¶„ì„ ìˆ˜í–‰
      const analysisPromises = servers.map(async (server) => {
        const analysis = await this.analyzeServer(server);

        // AI ë¶„ì„ ê²°ê³¼ë¥¼ ì„œë²„ ê°ì²´ì— ì¶”ê°€
        server.ai_analysis = {
          prediction_score: analysis.prediction_score,
          anomaly_score: analysis.anomaly_score,
          recommendation: analysis.recommendation,
        };

        return analysis;
      });

      await Promise.all(analysisPromises);

      // ì „ì²´ ì‹œìŠ¤í…œ ë¶„ì„
      const systemAnalysis = this.analyzeSystemHealth(servers);
      console.log('ðŸ“Š ì‹œìŠ¤í…œ ë¶„ì„ ê²°ê³¼:', systemAnalysis);

      const processingTime = Date.now() - startTime;
      metrics.avg_processing_time =
        (metrics.avg_processing_time + processingTime) / 2;
      metrics.ai_analysis_count++;

      console.log(`ðŸ¤– AI ë¶„ì„ ì™„ë£Œ (${processingTime}ms)`);
    } catch (error) {
      console.error('âŒ AI ë¶„ì„ ì‹¤íŒ¨:', error);
      metrics.errors_count++;
    }
  },

  /**
   * ðŸ“Š Individual server analysis
   */
  async analyzeServer(server: UnifiedServerMetrics) {
    // Simulate AI analysis processing time
    await new Promise((resolve) => setTimeout(resolve, Math.random() * 50));

    const prediction_score = this.calculatePredictionScore(server);
    const anomaly_score = this.calculateAnomalyScore(server);
    const recommendation = this.generateRecommendation(server);

    return {
      prediction_score,
      anomaly_score,
      recommendation,
    };
  },

  /**
   * ðŸŽ¯ Calculate prediction score for server performance
   */
  calculatePredictionScore(server: UnifiedServerMetrics): number {
    let score = 100; // Start with perfect score

    // CPU usage impact
    if (server.node_cpu_usage_percent > 80) {
      score -= (server.node_cpu_usage_percent - 80) * 2;
    }

    // Memory usage impact
    if (server.node_memory_usage_percent > 85) {
      score -= (server.node_memory_usage_percent - 85) * 3;
    }

    // Response time impact
    if (server.http_request_duration_seconds > 1.0) {
      score -= (server.http_request_duration_seconds - 1.0) * 20;
    }

    // Error rate impact
    const errorRate =
      server.http_requests_total > 0
        ? server.http_requests_errors_total / server.http_requests_total
        : 0;

    if (errorRate > 0.01) {
      // More than 1% error rate
      score -= errorRate * 100 * 50;
    }

    return Math.max(0, Math.min(100, score));
  },

  /**
   * ðŸš¨ Calculate anomaly score for unusual behavior detection
   */
  calculateAnomalyScore(server: UnifiedServerMetrics): number {
    let anomalyScore = 0;

    // Check for unusual patterns
    // Look for extreme values or unusual combinations
    if (
      server.node_cpu_usage_percent > 95 &&
      server.node_memory_usage_percent < 20
    ) {
      anomalyScore += 30; // High CPU, low memory - unusual
    }

    if (
      server.node_memory_usage_percent > 95 &&
      server.node_cpu_usage_percent < 10
    ) {
      anomalyScore += 25; // Memory leak pattern
    }

    if (server.http_request_duration_seconds > 5.0) {
      anomalyScore += 40; // Extremely slow response
    }

    // Network anomalies
    const networkRatio =
      server.node_network_transmit_rate_mbps > 0
        ? server.node_network_receive_rate_mbps /
          server.node_network_transmit_rate_mbps
        : 0;

    if (networkRatio > 10 || networkRatio < 0.1) {
      anomalyScore += 20; // Unusual network pattern
    }

    return Math.min(100, anomalyScore);
  },

  /**
   * ðŸ’¡ Generate actionable recommendations
   */
  generateRecommendation(server: UnifiedServerMetrics): string {
    const recommendations: string[] = [];

    // CPU recommendations
    if (server.node_cpu_usage_percent > 85) {
      recommendations.push(
        'ðŸ”´ CPU ì‚¬ìš©ë¥ ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. ìŠ¤ì¼€ì¼ ì•„ì›ƒì„ ì¦‰ì‹œ ê³ ë ¤í•˜ì„¸ìš”.'
      );
    } else if (server.node_cpu_usage_percent > 75) {
      recommendations.push('ðŸŸ¡ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ì„¸ìš”.');
    }

    // Memory recommendations
    if (server.node_memory_usage_percent > 90) {
      recommendations.push(
        'ðŸ”´ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ìœ„í—˜ ìˆ˜ì¤€ìž…ë‹ˆë‹¤. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.'
      );
    } else if (server.node_memory_usage_percent > 80) {
      recommendations.push(
        'ðŸŸ¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.'
      );
    }

    // Performance recommendations
    if (server.http_request_duration_seconds > 2.0) {
      recommendations.push(
        'ðŸ”´ ì‘ë‹µ ì‹œê°„ì´ ë§¤ìš° ëŠë¦½ë‹ˆë‹¤. ì„±ëŠ¥ íŠœë‹ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.'
      );
    } else if (server.http_request_duration_seconds > 1.0) {
      recommendations.push('ðŸŸ¡ ì‘ë‹µ ì‹œê°„ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }

    // Error rate recommendations
    const errorRate =
      server.http_requests_total > 0
        ? server.http_requests_errors_total / server.http_requests_total
        : 0;

    if (errorRate > 0.05) {
      recommendations.push(
        'ðŸ”´ ì—ëŸ¬ìœ¨ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤ (5% ì´ìƒ). ì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
      );
    } else if (errorRate > 0.01) {
      recommendations.push(
        'ðŸŸ¡ ì—ëŸ¬ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤ (1% ì´ìƒ). ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.'
      );
    }

    // Disk usage recommendations
    if (server.node_disk_usage_percent > 85) {
      recommendations.push(
        'ðŸŸ¡ ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë””ìŠ¤í¬ ì •ë¦¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.'
      );
    }

    // Network recommendations
    if (server.node_network_receive_rate_mbps > 80) {
      recommendations.push('ðŸŸ¡ ë„¤íŠ¸ì›Œí¬ ìž…ë ¥ íŠ¸ëž˜í”½ì´ ë†’ìŠµë‹ˆë‹¤.');
    }

    return recommendations.length > 0
      ? recommendations
          .slice(0, 3)
          .join(' ') // Max 3 recommendations
      : 'âœ… ì„œë²„ê°€ ì •ìƒ ìƒíƒœìž…ë‹ˆë‹¤.';
  },

  /**
   * ðŸ¥ Analyze overall system health
   */
  analyzeSystemHealth(servers: UnifiedServerMetrics[]): AIAnalysisResult {
    if (servers.length === 0) {
      return {
        analysis: 'no_servers',
        server_count: 0,
        avg_cpu: '0.0',
        avg_memory: '0.0',
        critical_servers: 0,
        health_score: '0.0',
        timestamp: new Date().toISOString(),
      };
    }

    const totalServers = servers.length;
    const avgCpu =
      servers.reduce((sum, s) => sum + s.node_cpu_usage_percent, 0) /
      totalServers;
    const avgMemory =
      servers.reduce((sum, s) => sum + s.node_memory_usage_percent, 0) /
      totalServers;
    const criticalServers = servers.filter(
      (s) => s.status === 'critical'
    ).length;

    return {
      analysis: 'typescript_enhanced',
      server_count: totalServers,
      avg_cpu: avgCpu.toFixed(1),
      avg_memory: avgMemory.toFixed(1),
      critical_servers: criticalServers,
      health_score: (
        ((totalServers - criticalServers) / totalServers) *
        100
      ).toFixed(1),
      timestamp: new Date().toISOString(),
    };
  },

  /**
   * ðŸ”® Predict future server state
   */
  predictServerState(
    server: UnifiedServerMetrics,
    timeHorizonMinutes: number = 30
  ): Partial<UnifiedServerMetrics> {
    // Simple linear trend prediction based on current state
    const trendFactor = timeHorizonMinutes / 60; // Convert to hours

    let cpuTrend = 0;
    let memoryTrend = 0;

    // Predict trends based on current load
    if (server.node_cpu_usage_percent > 70) {
      cpuTrend = 2 * trendFactor; // High CPU tends to increase
    } else if (server.node_cpu_usage_percent < 30) {
      cpuTrend = -1 * trendFactor; // Low CPU might decrease slightly
    }

    if (server.node_memory_usage_percent > 80) {
      memoryTrend = 3 * trendFactor; // Memory leaks tend to grow
    }

    return {
      node_cpu_usage_percent: Math.min(
        100,
        Math.max(0, server.node_cpu_usage_percent + cpuTrend)
      ),
      node_memory_usage_percent: Math.min(
        100,
        Math.max(0, server.node_memory_usage_percent + memoryTrend)
      ),
    };
  },

  /**
   * ðŸ“ˆ Calculate server efficiency score
   */
  calculateEfficiencyScore(server: UnifiedServerMetrics): number {
    // Efficiency is inversely related to resource usage
    const cpuEfficiency = 100 - server.node_cpu_usage_percent;
    const memoryEfficiency = 100 - server.node_memory_usage_percent;
    const responseTimeEfficiency =
      server.http_request_duration_seconds < 1.0
        ? 100 - server.http_request_duration_seconds * 50
        : 50;

    return (cpuEfficiency + memoryEfficiency + responseTimeEfficiency) / 3;
  },
};
