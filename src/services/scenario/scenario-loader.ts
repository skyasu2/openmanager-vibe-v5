/**
 * ğŸ¯ **Single Source of Truth** - 24ì‹œê°„ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ë¡œë”
 *
 * **v5.85.0 ê°œì„ **: Dashboard/AI Engine ë°ì´í„° ë™ê¸°í™”
 * - âœ… JSON íŒŒì¼ ê¸°ë°˜ (10ë¶„ ê°„ê²©)
 * - âœ… Dashboardì™€ AI Engine ë™ì¼ ë°ì´í„° ì‚¬ìš©
 * - âœ… ë³€í˜•ì€ sync ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë¯¸ë¦¬ ì ìš©
 *
 * @see scripts/data/sync-hourly-data.ts - JSON ìƒì„± ìŠ¤í¬ë¦½íŠ¸
 * @see docs/reference/architecture/data/data-architecture.md - ì•„í‚¤í…ì²˜ ë¬¸ì„œ
 */

// Enhanced Server Metrics ì¸í„°í˜ì´ìŠ¤ (route.tsì™€ ë™ê¸°í™” í•„ìš”)
import { logger } from '@/lib/logging';
export interface EnhancedServerMetrics {
  id: string;
  name: string;
  hostname: string;
  status:
    | 'online'
    | 'offline'
    | 'warning'
    | 'critical'
    | 'maintenance'
    | 'unknown';
  cpu: number;
  cpu_usage: number;
  memory: number;
  memory_usage: number;
  disk: number;
  disk_usage: number;
  network: number;
  network_in: number;
  network_out: number;
  uptime: number;
  responseTime: number;
  last_updated: string;
  location: string;
  alerts: never[]; // í•­ìƒ ë¹ˆ ë°°ì—´
  ip: string;
  os: string;
  type: string;
  role: string;
  environment: string;
  provider: string;
  specs: {
    cpu_cores: number;
    memory_gb: number;
    disk_gb: number;
    network_speed: string;
  };
  lastUpdate: string;
  services: unknown[]; // ì™¸ë¶€ ë°ì´í„°, ëŸ°íƒ€ì„ì—ì„œ ê²€ì¦ë¨
  systemInfo: {
    os: string;
    uptime: string;
    processes: number;
    zombieProcesses: number;
    loadAverage: string;
    lastUpdate: string;
  };
  networkInfo: {
    interface: string;
    receivedBytes: string;
    sentBytes: string;
    receivedErrors: number;
    sentErrors: number;
    status:
      | 'online'
      | 'offline'
      | 'warning'
      | 'critical'
      | 'maintenance'
      | 'unknown';
  };
}

/**
 * JSON íŒŒì¼ ë°ì´í„° êµ¬ì¡° (sync ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ê¸°í™”)
 */
interface HourlyJsonData {
  hour: number;
  scrapeConfig: {
    scrapeInterval: string;
    evaluationInterval: string;
    source: string;
  };
  _scenario?: string;
  dataPoints: Array<{
    timestampMs: number;
    targets: Record<string, PrometheusTargetData>;
  }>;
  metadata: {
    version: string;
    format: string;
    totalDataPoints: number;
    intervalMinutes: number;
    serverCount: number;
    affectedServers: number;
  };
}

interface PrometheusTargetData {
  job: string;
  instance: string;
  labels: {
    hostname: string;
    datacenter: string;
    environment: string;
    server_type: string;
    os: string;
    os_version: string;
  };
  metrics: {
    up: 0 | 1;
    node_cpu_usage_percent: number;
    node_memory_usage_percent: number;
    node_filesystem_usage_percent: number;
    node_network_transmit_bytes_rate: number;
    node_load1: number;
    node_load5: number;
    node_boot_time_seconds: number;
    node_procs_running: number;
    node_http_request_duration_milliseconds: number;
  };
  nodeInfo: {
    cpu_cores: number;
    memory_total_bytes: number;
    disk_total_bytes: number;
  };
  logs: string[];
}

interface RawServerData {
  id: string;
  name: string;
  hostname: string;
  type: string;
  location: string;
  environment: string;
  status: 'online' | 'warning' | 'critical' | 'offline';
  cpu: number;
  memory: number;
  disk: number;
  network: number;
  responseTime: number;
  uptime: number;
  ip: string;
  os: string;
  specs: {
    cpu_cores: number;
    memory_gb: number;
    disk_gb: number;
  };
  services: string[];
  processes: number;
}

/**
 * PrometheusTargetData â†’ RawServerData ë³€í™˜
 */
function targetToRawServerData(target: PrometheusTargetData): RawServerData {
  const serverId = target.instance.replace(/:9100$/, '');
  const cpu = target.metrics.node_cpu_usage_percent;
  const memory = target.metrics.node_memory_usage_percent;
  const disk = target.metrics.node_filesystem_usage_percent;
  const network = target.metrics.node_network_transmit_bytes_rate;

  let status: RawServerData['status'] = 'online';
  if (target.metrics.up === 0) {
    status = 'offline';
  } else if (cpu >= 90 || memory >= 90 || disk >= 90 || network >= 85) {
    status = 'critical';
  } else if (cpu >= 80 || memory >= 80 || disk >= 80 || network >= 70) {
    status = 'warning';
  }

  return {
    id: serverId,
    name: target.labels.hostname.replace('.openmanager.kr', ''),
    hostname: target.labels.hostname,
    type: target.labels.server_type,
    location: target.labels.datacenter,
    environment: target.labels.environment,
    status,
    cpu,
    memory,
    disk,
    network,
    responseTime: target.metrics.node_http_request_duration_milliseconds,
    uptime: Math.round(
      Date.now() / 1000 - target.metrics.node_boot_time_seconds
    ),
    ip: '',
    os: `${target.labels.os} ${target.labels.os_version}`,
    specs: {
      cpu_cores: target.nodeInfo.cpu_cores,
      memory_gb: Math.round(
        target.nodeInfo.memory_total_bytes / (1024 * 1024 * 1024)
      ),
      disk_gb: Math.round(
        target.nodeInfo.disk_total_bytes / (1024 * 1024 * 1024)
      ),
    },
    services: [],
    processes: target.metrics.node_procs_running,
  };
}

// JSON ìºì‹œ (ë©”ëª¨ë¦¬ ìµœì í™”)
const jsonCache: Map<number, { data: HourlyJsonData; timestamp: number }> =
  new Map();
const CACHE_TTL = 60000; // 1ë¶„ ìºì‹œ

/**
 * JSON íŒŒì¼ ë¡œë“œ (ë¸Œë¼ìš°ì €/ì„œë²„ í˜¸í™˜)
 */
async function loadHourlyJsonFile(
  hour: number
): Promise<HourlyJsonData | null> {
  const paddedHour = hour.toString().padStart(2, '0');

  // ìºì‹œ í™•ì¸
  const cached = jsonCache.get(hour);
  if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
    return cached.data;
  }

  try {
    // ë¸Œë¼ìš°ì €/ì„œë²„ ëª¨ë‘ fetch ì‚¬ìš©
    const response = await fetch(`/hourly-data/hour-${paddedHour}.json`);
    if (!response.ok) {
      logger.error(`[ScenarioLoader] JSON ë¡œë“œ ì‹¤íŒ¨: ${response.status}`);
      return null;
    }

    const data = (await response.json()) as HourlyJsonData;

    // ìºì‹œ ì €ì¥
    jsonCache.set(hour, { data, timestamp: Date.now() });

    return data;
  } catch (error) {
    logger.error('[ScenarioLoader] JSON íŒŒì‹± ì˜¤ë¥˜:', error);
    return null;
  }
}

/**
 * ğŸ¯ Load Server Data from JSON Files (SSOT)
 *
 * Dashboardì™€ AI Engineì´ ë™ì¼í•œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
 * - ë°ì´í„° ì†ŒìŠ¤: `/hourly-data/hour-XX.json`
 * - ê°„ê²©: 10ë¶„ (6ê°œ dataPoints/ì‹œê°„)
 * - ë³€í˜•: sync ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë¯¸ë¦¬ ì ìš©ë¨
 *
 * @returns {Promise<EnhancedServerMetrics[]>} 15ê°œ ì„œë²„ ë©”íŠ¸ë¦­ìŠ¤
 */
export async function loadHourlyScenarioData(): Promise<
  EnhancedServerMetrics[]
> {
  try {
    // ğŸ‡°ğŸ‡· KST (Asia/Seoul) ê¸°ì¤€ ì‹œê°„ ì‚¬ìš©
    const koreaTime = new Date().toLocaleString('en-US', {
      timeZone: 'Asia/Seoul',
    });
    const koreaDate = new Date(koreaTime);

    const currentHour = koreaDate.getHours(); // 0-23
    const currentMinute = koreaDate.getMinutes(); // 0-59

    // JSON íŒŒì¼ ë¡œë“œ
    const hourlyData = await loadHourlyJsonFile(currentHour);
    if (!hourlyData) {
      logger.error(`[ScenarioLoader] hour-${currentHour} ë°ì´í„° ì—†ìŒ`);
      return [];
    }

    // 10ë¶„ ê°„ê²© dataPoint ì„ íƒ (0-5 ì¸ë±ìŠ¤)
    const dataPointIndex = Math.floor(currentMinute / 10);
    const clampedIndex = Math.min(
      dataPointIndex,
      hourlyData.dataPoints.length - 1
    );
    const dataPoint = hourlyData.dataPoints[clampedIndex];

    if (!dataPoint?.targets) {
      logger.error(`[ScenarioLoader] dataPoint[${clampedIndex}] ì—†ìŒ`);
      return [];
    }

    // PrometheusTarget â†’ RawServerData â†’ EnhancedServerMetrics ë³€í™˜
    return Object.values(dataPoint.targets).map((target) =>
      convertToEnhancedMetrics(targetToRawServerData(target), currentHour)
    );
  } catch (error) {
    logger.error('[ScenarioLoader] ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜:', error);
    return [];
  }
}

/**
 * RawServerData â†’ EnhancedServerMetrics ë³€í™˜
 */
function convertToEnhancedMetrics(
  serverData: RawServerData,
  currentHour: number
): EnhancedServerMetrics {
  const cpu = serverData.cpu ?? 0;
  const memory = serverData.memory ?? 0;
  const disk = serverData.disk ?? 0;
  const network = serverData.network ?? 0;
  const status = serverData.status ?? 'online';

  return {
    id: serverData.id,
    name: serverData.name,
    hostname: serverData.hostname,
    status,
    cpu,
    cpu_usage: cpu,
    memory,
    memory_usage: memory,
    disk,
    disk_usage: disk,
    network,
    network_in: Math.round(network * 0.6),
    network_out: Math.round(network * 0.4),
    uptime: serverData.uptime ?? 2592000,
    responseTime: serverData.responseTime ?? 150,
    last_updated: new Date().toISOString(),
    location: serverData.location,
    alerts: [],
    ip: serverData.ip,
    os: serverData.os,
    type: serverData.type,
    role: mapTypeToRole(serverData.type),
    environment: serverData.environment,
    provider: `DataCenter-${currentHour.toString().padStart(2, '0')}`,
    specs: {
      cpu_cores: serverData.specs?.cpu_cores ?? 8,
      memory_gb: serverData.specs?.memory_gb ?? 16,
      disk_gb: serverData.specs?.disk_gb ?? 200,
      network_speed: '1Gbps',
    },
    lastUpdate: new Date().toISOString(),
    services: serverData.services ?? [],
    systemInfo: {
      os: serverData.os,
      uptime: `${Math.floor((serverData.uptime ?? 2592000) / 3600)}h`,
      processes: serverData.processes ?? 120,
      zombieProcesses: status === 'critical' ? 3 : status === 'warning' ? 1 : 0,
      loadAverage: `${(cpu / 20).toFixed(2)}, ${((cpu - 5) / 20).toFixed(2)}, ${((cpu - 10) / 20).toFixed(2)}`,
      lastUpdate: new Date().toISOString(),
    },
    networkInfo: {
      interface: 'eth0',
      receivedBytes: `${(network * 0.6).toFixed(1)} MB`,
      sentBytes: `${(network * 0.4).toFixed(1)} MB`,
      receivedErrors: status === 'critical' ? 2 : 0,
      sentErrors: status === 'critical' ? 1 : 0,
      status,
    },
  };
}

/**
 * ì„œë²„ íƒ€ì… â†’ ì—­í•  ë§¤í•‘
 */
function mapTypeToRole(type: string): string {
  const roleMap: Record<string, string> = {
    web: 'web',
    application: 'api',
    database: 'database',
    cache: 'cache',
    storage: 'storage',
    loadbalancer: 'loadbalancer',
  };
  return roleMap[type] || type;
}

/**
 * ìºì‹œ ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸/ë””ë²„ê¹…ìš©)
 */
export function clearJsonCache(): void {
  jsonCache.clear();
}

/**
 * ğŸ¯ í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
 *
 * @returns {Promise<{scenario: string, hour: number} | null>}
 */
export async function getCurrentScenario(): Promise<{
  scenario: string;
  hour: number;
} | null> {
  try {
    const koreaTime = new Date().toLocaleString('en-US', {
      timeZone: 'Asia/Seoul',
    });
    const koreaDate = new Date(koreaTime);
    const currentHour = koreaDate.getHours();

    const hourlyData = await loadHourlyJsonFile(currentHour);
    if (!hourlyData) return null;

    return {
      scenario: hourlyData._scenario || '', // _scenarioì—ì„œ ì½ì–´ì„œ ë‚´ë¶€ scenarioë¡œ ë§¤í•‘
      hour: currentHour,
    };
  } catch {
    return null;
  }
}

/**
 * ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ë¡œê·¸ ìƒì„± (ì‹¤ì œ syslog í˜•ì‹)
 *
 * ìƒìš© ë¡œê·¸ ìˆ˜ì§‘ í”„ë¡œê·¸ë¨ê³¼ ìœ ì‚¬í•œ í˜•íƒœì˜ ë¡œê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 * - syslog í˜•ì‹: hostname process[pid]: message
 * - ë‹¤ì–‘í•œ ì†ŒìŠ¤: nginx, docker, kernel, systemd, mysqld, redis ë“±
 * - ì‹¤ì œ ì—ëŸ¬ ì½”ë“œ í¬í•¨
 *
 * @param scenario - í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…
 * @param serverMetrics - ì„œë²„ ë©”íŠ¸ë¦­ (cpu, memory, disk, network)
 * @param serverId - ì„œë²„ ID (hostnameìœ¼ë¡œ ì‚¬ìš©)
 * @returns ë¡œê·¸ ë°°ì—´
 */
export function generateScenarioLogs(
  scenario: string,
  serverMetrics: { cpu: number; memory: number; disk: number; network: number },
  serverId: string
): Array<{
  timestamp: string;
  level: 'info' | 'warn' | 'error';
  message: string;
  source: string;
}> {
  const logs: Array<{
    timestamp: string;
    level: 'info' | 'warn' | 'error';
    message: string;
    source: string;
  }> = [];

  const now = new Date();
  const { cpu, memory, disk, network } = serverMetrics;
  const hostname = serverId.split('.')[0] || serverId;

  // ëœë¤ PID ìƒì„± í—¬í¼
  const pid = (base: number) => base + Math.floor(Math.random() * 1000);

  // ì‹œë‚˜ë¦¬ì˜¤ í‚¤ì›Œë“œ ë§¤ì¹­
  const scenarioLower = scenario.toLowerCase();

  // 1. ì •ìƒ ìš´ì˜ ì‹œë‚˜ë¦¬ì˜¤
  if (scenarioLower.includes('ì •ìƒ')) {
    logs.push({
      timestamp: new Date(now.getTime() - 30000).toISOString(),
      level: 'info',
      message: `${hostname} systemd[1]: Started Daily apt download activities.`,
      source: 'systemd',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 45000).toISOString(),
      level: 'info',
      message: `${hostname} CRON[${pid(20000)}]: (root) CMD (/usr/lib/apt/apt.systemd.daily install)`,
      source: 'cron',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 60000).toISOString(),
      level: 'info',
      message: `${hostname} nginx[${pid(1000)}]: 10.0.0.1 - - "GET /health HTTP/1.1" 200 15 "-" "kube-probe/1.28"`,
      source: 'nginx',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 90000).toISOString(),
      level: 'info',
      message: `${hostname} dockerd[${pid(800)}]: time="2026-01-03T10:00:00.000000000Z" level=info msg="Container health status: healthy"`,
      source: 'docker',
    });
  }

  // 2. CPU ê³¼ë¶€í•˜ ì‹œë‚˜ë¦¬ì˜¤
  if (
    scenarioLower.includes('cpu') ||
    scenarioLower.includes('ê³¼ë¶€í•˜') ||
    scenarioLower.includes('api')
  ) {
    logs.push({
      timestamp: new Date(now.getTime() - 15000).toISOString(),
      level: 'error',
      message: `${hostname} kernel: [${pid(50000)}.${pid(100)}] CPU${Math.floor(Math.random() * 8)}: Package temperature above threshold, cpu clock throttled`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 30000).toISOString(),
      level: 'error',
      message: `${hostname} nginx[${pid(1000)}]: upstream timed out (110: Connection timed out) while reading response header from upstream`,
      source: 'nginx',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 45000).toISOString(),
      level: 'warn',
      message: `${hostname} java[${pid(5000)}]: GC overhead limit exceeded - heap usage at ${cpu.toFixed(0)}%`,
      source: 'java',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 60000).toISOString(),
      level: 'warn',
      message: `${hostname} haproxy[${pid(2000)}]: backend api_servers has no server available! (qcur=${Math.floor(cpu * 2)})`,
      source: 'haproxy',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 90000).toISOString(),
      level: 'info',
      message: `${hostname} systemd[1]: node-exporter.service: Watchdog timeout (limit 30s)!`,
      source: 'systemd',
    });
  }

  // 3. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì‹œë‚˜ë¦¬ì˜¤
  if (
    scenarioLower.includes('ë©”ëª¨ë¦¬') ||
    scenarioLower.includes('memory') ||
    scenarioLower.includes('oom') ||
    scenarioLower.includes('redis') ||
    scenarioLower.includes('ìºì‹œ')
  ) {
    logs.push({
      timestamp: new Date(now.getTime() - 10000).toISOString(),
      level: 'error',
      message: `${hostname} kernel: Out of memory: Killed process ${pid(10000)} (java) total-vm:${Math.floor(memory * 100)}kB, anon-rss:${Math.floor(memory * 80)}kB`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 25000).toISOString(),
      level: 'error',
      message: `${hostname} redis-server[${pid(3000)}]: # WARNING: Memory usage ${memory.toFixed(0)}% of max. Consider increasing maxmemory.`,
      source: 'redis',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 40000).toISOString(),
      level: 'warn',
      message: `${hostname} dockerd[${pid(800)}]: container ${serverId.substring(0, 12)} OOMKilled=true (memory limit: 2GiB)`,
      source: 'docker',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 55000).toISOString(),
      level: 'warn',
      message: `${hostname} java[${pid(5000)}]: java.lang.OutOfMemoryError: GC overhead limit exceeded`,
      source: 'java',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 80000).toISOString(),
      level: 'info',
      message: `${hostname} java[${pid(5000)}]: [GC (Allocation Failure) ${Math.floor(memory * 50)}K->${Math.floor(memory * 30)}K(${Math.floor(memory * 100)}K), 0.${pid(100)} secs]`,
      source: 'java',
    });
  }

  // 4. ë””ìŠ¤í¬ I/O ì‹œë‚˜ë¦¬ì˜¤
  if (
    scenarioLower.includes('ë””ìŠ¤í¬') ||
    scenarioLower.includes('disk') ||
    scenarioLower.includes('ë°±ì—…') ||
    scenarioLower.includes('i/o')
  ) {
    logs.push({
      timestamp: new Date(now.getTime() - 20000).toISOString(),
      level: 'error',
      message: `${hostname} kernel: [${pid(80000)}.${pid(100)}] EXT4-fs warning (device sda1): ext4_dx_add_entry:2461: Directory (ino: ${pid(100000)}) index full, reach max htree level :2`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 35000).toISOString(),
      level: 'error',
      message: `${hostname} mysqld[${pid(4000)}]: [ERROR] InnoDB: Write to file ./ib_logfile0 failed at offset ${pid(1000000)}. ${disk.toFixed(0)}% disk used.`,
      source: 'mysql',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 50000).toISOString(),
      level: 'warn',
      message: `${hostname} rsync[${pid(15000)}]: rsync: write failed on "/backup/db-${hostname}.sql": No space left on device (28)`,
      source: 'rsync',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 70000).toISOString(),
      level: 'info',
      message: `${hostname} systemd[1]: Starting Daily Backup Service...`,
      source: 'systemd',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 120000).toISOString(),
      level: 'info',
      message: `${hostname} pg_dump[${pid(18000)}]: pg_dump: archiving data for table "public.logs" (${Math.floor(disk * 10)}MB)`,
      source: 'postgres',
    });
  }

  // 5. ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ì‹œë‚˜ë¦¬ì˜¤
  if (
    scenarioLower.includes('ë„¤íŠ¸ì›Œí¬') ||
    scenarioLower.includes('network') ||
    scenarioLower.includes('íŒ¨í‚·') ||
    scenarioLower.includes('lb') ||
    scenarioLower.includes('ë¡œë“œë°¸ëŸ°ì„œ')
  ) {
    logs.push({
      timestamp: new Date(now.getTime() - 12000).toISOString(),
      level: 'error',
      message: `${hostname} kernel: [${pid(90000)}.${pid(100)}] nf_conntrack: nf_conntrack: table full, dropping packet`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 28000).toISOString(),
      level: 'error',
      message: `${hostname} nginx[${pid(1000)}]: connect() failed (111: Connection refused) while connecting to upstream`,
      source: 'nginx',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 42000).toISOString(),
      level: 'warn',
      message: `${hostname} haproxy[${pid(2000)}]: Server api_backend/server1 is DOWN, reason: Layer4 timeout, check duration: 5001ms`,
      source: 'haproxy',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 65000).toISOString(),
      level: 'warn',
      message: `${hostname} kernel: [${pid(90000)}.${pid(100)}] TCP: request_sock_TCP: Possible SYN flooding on port 80. Sending cookies.`,
      source: 'kernel',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 95000).toISOString(),
      level: 'info',
      message: `${hostname} sshd[${pid(22000)}]: Received disconnect from 10.0.0.${Math.floor(network / 10)} port ${pid(40000)}: 11: disconnected by user`,
      source: 'sshd',
    });
  }

  // ê¸°ë³¸ ë¡œê·¸ (ì‹œë‚˜ë¦¬ì˜¤ ë§¤ì¹­ ì—†ëŠ” ê²½ìš°)
  if (logs.length === 0) {
    logs.push({
      timestamp: new Date(now.getTime() - 30000).toISOString(),
      level: 'info',
      message: `${hostname} systemd[1]: Started Session ${pid(100)} of user root.`,
      source: 'systemd',
    });
    logs.push({
      timestamp: new Date(now.getTime() - 60000).toISOString(),
      level: 'info',
      message: `${hostname} nginx[${pid(1000)}]: 10.0.0.1 - - "GET / HTTP/1.1" 200 612 "-" "curl/7.68.0"`,
      source: 'nginx',
    });
  }

  // ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹  ë¨¼ì €)
  return logs.sort(
    (a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime()
  );
}
