/**
 * ğŸš€ ê°œì„ ëœ AI ì¿¼ë¦¬ ì—”ì§„
 *
 * âœ… ìŠ¤ë§ˆíŠ¸ ëª¨ë“œ ì „í™˜ (ì¿¼ë¦¬ ë³µì¡ë„ ê¸°ë°˜)
 * âœ… ë¹„ë™ê¸° ì´ˆê¸°í™” ë° lazy loading
 * âœ… í†µí•© ìºì‹± ë ˆì´ì–´
 * âœ… ë³‘ë ¬ ì²˜ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
 * âœ… ì»¤ë„¥ì…˜ í’€ë§
 */

import type { SupabaseRAGEngine } from './supabase-rag-engine';
import { getSupabaseRAGEngine } from './supabase-rag-engine';
import { CloudContextLoader } from '@/services/mcp/CloudContextLoader';
import { QueryComplexityAnalyzer } from './QueryComplexityAnalyzer';
import { GoogleGenerativeAI, GenerativeModel } from '@google/generative-ai';
import type {
  AIQueryContext,
  AIQueryOptions,
  MCPContext,
  AIMetadata,
} from '@/types/ai-service-types';

// AI ì—”ì§„ ì‘ë‹µ íƒ€ì…
interface AIEngineResponse {
  success: boolean;
  response: string;
  engine: 'local-rag' | 'google-ai';
  confidence: number;
  metadata?: {
    ragResults?: number;
    cached?: boolean;
    mcpUsed?: boolean;
    sources?: string[];
  };
  processingTime: number;
}

interface CacheEntry {
  response: string;
  engine: 'local-rag' | 'google-ai';
  confidence: number;
  metadata?: AIMetadata;
  timestamp: number;
  ttl: number;
}

export interface PerformanceMetrics {
  cacheHitRate: number;
  avgResponseTime: number;
  engineUsage: {
    local: number;
    googleAI: number;
  };
  autoSwitchCount: number;
}

export class ImprovedQueryEngine {
  private ragEngine: SupabaseRAGEngine;
  private contextLoader: CloudContextLoader;
  private googleAI: GoogleGenerativeAI | null = null;
  private googleAIModel: GenerativeModel | null = null;

  // ì´ˆê¸°í™” ìƒíƒœ
  private initPromise: Promise<void> | null = null;
  private isInitialized = false;

  // í†µí•© ìºì‹œ
  private memoryCache = new Map<string, CacheEntry>();
  private readonly MAX_CACHE_SIZE = 100;
  private readonly DEFAULT_TTL = 300000; // 5ë¶„

  // ì„±ëŠ¥ ë©”íŠ¸ë¦­
  private metrics: PerformanceMetrics = {
    cacheHitRate: 0,
    avgResponseTime: 0,
    engineUsage: { local: 0, googleAI: 0 },
    autoSwitchCount: 0,
  };

  // ìš”ì²­ í (rate limiting)
  private requestQueue: Array<() => Promise<void>> = [];
  private isProcessingQueue = false;
  private readonly MAX_CONCURRENT_REQUESTS = 3;

  constructor() {
    this.ragEngine = getSupabaseRAGEngine();
    this.contextLoader = CloudContextLoader.getInstance();

    // ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹œì‘
    this.startLazyInitialization();
  }

  /**
   * ğŸš€ Lazy ì´ˆê¸°í™”
   */
  private startLazyInitialization(): void {
    this.initPromise = this.performInitialization();
  }

  private async performInitialization(): Promise<void> {
    try {
      console.log('ğŸš€ ImprovedQueryEngine ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹œì‘...');

      // ë³‘ë ¬ ì´ˆê¸°í™”
      const initTasks = [
        this.initializeRAGEngine(),
        this.initializeGoogleAI(),
        this.loadFrequentQueries(),
      ];

      await Promise.allSettled(initTasks);

      this.isInitialized = true;
      console.log('âœ… ImprovedQueryEngine ì´ˆê¸°í™” ì™„ë£Œ');

      // ì£¼ê¸°ì  ìºì‹œ ì •ë¦¬
      this.startCacheMaintenance();
    } catch (error) {
      console.error('âŒ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      this.isInitialized = true; // ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    }
  }

  /**
   * ğŸ§  RAG ì—”ì§„ ì´ˆê¸°í™”
   */
  private async initializeRAGEngine(): Promise<void> {
    try {
      await this.ragEngine.initialize();
    } catch (error) {
      console.warn('âš ï¸ RAG ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨, ë‚˜ì¤‘ì— ì¬ì‹œë„:', error);
    }
  }

  /**
   * ğŸŒ Google AI ì´ˆê¸°í™”
   */
  private async initializeGoogleAI(): Promise<void> {
    try {
      const apiKey =
        process.env.GOOGLE_AI_API_KEY ||
        process.env.NEXT_PUBLIC_GOOGLE_AI_API_KEY;

      if (apiKey) {
        this.googleAI = new GoogleGenerativeAI(apiKey);
        this.googleAIModel = this.googleAI.getGenerativeModel({
          model: 'gemini-pro',
        });
        console.log('âœ… Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ');
      }
    } catch (error) {
      console.warn('âš ï¸ Google AI ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
    }
  }

  /**
   * ğŸ“Š ìì£¼ ì‚¬ìš©ë˜ëŠ” ì¿¼ë¦¬ í”„ë¦¬ë¡œë“œ
   */
  private async loadFrequentQueries(): Promise<void> {
    // ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒ¨í„´ë“¤ì„ ë¯¸ë¦¬ ìºì‹œ
    const frequentPatterns = [
      'ì„œë²„ ìƒíƒœ',
      'CPU ì‚¬ìš©ë¥ ',
      'ì—ëŸ¬ í•´ê²°',
      'ì„¤ì • ë°©ë²•',
    ];

    // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¡œë“œ (ë¸”ë¡œí‚¹í•˜ì§€ ì•ŠìŒ)
    setTimeout(() => {
      frequentPatterns.forEach(pattern => {
        this.warmupCache(pattern);
      });
    }, 5000);
  }

  /**
   * ğŸ”¥ ìºì‹œ ì›Œë°ì—…
   */
  private async warmupCache(query: string): Promise<void> {
    try {
      const cacheKey = this.getCacheKey(query, 'local');
      if (!this.memoryCache.has(cacheKey)) {
        // Local RAGë¡œ ë¯¸ë¦¬ ê²€ìƒ‰
        const result = await this.ragEngine.searchSimilar(query, {
          maxResults: 3,
          threshold: 0.5,
        });

        if (result.results.length > 0) {
          this.memoryCache.set(cacheKey, {
            response: result.results[0].content,
            engine: 'local-rag',
            confidence: 0.8,
            timestamp: Date.now(),
            ttl: this.DEFAULT_TTL * 2, // ë” ê¸´ TTL
          });
        }
      }
    } catch {
      // ì›Œë°ì—… ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
    }
  }

  /**
   * ğŸ” ê°œì„ ëœ ì¿¼ë¦¬ ì²˜ë¦¬
   */
  async query(request: {
    query: string;
    mode?: 'auto' | 'local' | 'google-ai';
    context?: AIQueryContext;
    options?: AIQueryOptions & {
      stream?: boolean;
      useCache?: boolean;
      preferredEngine?: 'local-rag' | 'google-ai';
    };
  }): Promise<AIEngineResponse> {
    const startTime = Date.now();

    // ì´ˆê¸°í™” ëŒ€ê¸° (í•„ìš”í•œ ê²½ìš°ë§Œ)
    if (this.initPromise && !this.isInitialized) {
      await Promise.race([
        this.initPromise,
        new Promise(resolve => setTimeout(resolve, 1000)), // ìµœëŒ€ 1ì´ˆ ëŒ€ê¸°
      ]);
    }

    const { query, mode = 'auto', context = {}, options = {} } = request;

    // ìºì‹œ í™•ì¸
    if (options.useCache !== false) {
      const cachedResponse = this.checkCache(query, mode);
      if (cachedResponse) {
        this.updateMetrics('cache', Date.now() - startTime);
        return cachedResponse;
      }
    }

    // ì¿¼ë¦¬ ë¶„ì„ (auto ëª¨ë“œ)
    let selectedEngine: 'local-rag' | 'google-ai';
    let analysis: ReturnType<typeof QueryComplexityAnalyzer.analyze> | null =
      null;

    if (mode === 'auto') {
      analysis = QueryComplexityAnalyzer.analyze(query);
      selectedEngine = options.preferredEngine || analysis.recommendedEngine;

      console.log(
        `ğŸ¤– ìë™ ì—”ì§„ ì„ íƒ: ${selectedEngine} (ì‹ ë¢°ë„: ${analysis.confidence})`
      );
    } else {
      selectedEngine = mode === 'local' ? 'local-rag' : 'google-ai';
    }

    // ë³‘ë ¬ ì²˜ë¦¬ ì¤€ë¹„
    const _tasks: Promise<any>[] = [];

    // MCP ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ë¹„ë¸”ë¡œí‚¹)
    let mcpContextPromise: Promise<MCPContext | null> = Promise.resolve(null);
    if (options?.includeMCPContext) {
      mcpContextPromise = this.contextLoader
        .queryMCPContextForRAG(query, {
          maxFiles: 5,
          includeSystemContext: true,
        })
        .catch(() => null);
    }

    // ì—”ì§„ë³„ ì²˜ë¦¬
    try {
      const response = await this.processWithEngine(
        selectedEngine,
        query,
        context,
        options,
        mcpContextPromise,
        analysis
      );

      // ìºì‹œ ì €ì¥
      if (response.success && options.useCache !== false) {
        this.saveToCache(query, mode, response);
      }

      // ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
      this.updateMetrics(selectedEngine, Date.now() - startTime);

      return response;
    } catch (error) {
      console.error(`âŒ ${selectedEngine} ì²˜ë¦¬ ì‹¤íŒ¨:`, error);

      // ìë™ í´ë°± (auto ëª¨ë“œì—ì„œë§Œ)
      if (mode === 'auto' && selectedEngine === 'google-ai') {
        console.log('ğŸ”„ Local RAGë¡œ ìë™ ì „í™˜...');
        this.metrics.autoSwitchCount++;

        return this.processWithEngine(
          'local-rag',
          query,
          context,
          options,
          mcpContextPromise,
          analysis
        );
      }

      throw error;
    }
  }

  /**
   * ğŸ¤– ì—”ì§„ë³„ ì²˜ë¦¬
   */
  private async processWithEngine(
    engine: 'local-rag' | 'google-ai',
    query: string,
    context: AIQueryContext,
    options: AIQueryOptions & {
      useCache?: boolean;
      preferredEngine?: 'local-rag' | 'google-ai';
    },
    mcpContextPromise: Promise<MCPContext | null>,
    _analysis: ReturnType<typeof QueryComplexityAnalyzer.analyze> | null
  ): Promise<any> {
    if (engine === 'local-rag') {
      return this.processLocalQuery(query, context, options, mcpContextPromise);
    } else {
      return this.processGoogleAIQuery(
        query,
        context,
        options,
        mcpContextPromise
      );
    }
  }

  /**
   * ğŸ  ê°œì„ ëœ Local RAG ì²˜ë¦¬
   */
  private async processLocalQuery(
    query: string,
    context: AIQueryContext,
    options: AIQueryOptions & {
      useCache?: boolean;
      preferredEngine?: 'local-rag' | 'google-ai';
    },
    mcpContextPromise: Promise<MCPContext | null>
  ): Promise<any> {
    const startTime = Date.now();

    // ë³‘ë ¬ ì‹¤í–‰
    const [ragResult, mcpContext] = await Promise.all([
      this.ragEngine.searchSimilar(query, {
        maxResults: 5,
        threshold: 0.5,
        category: options?.category as string | undefined,
      }),
      mcpContextPromise,
    ]);

    const response = this.generateLocalResponse(
      query,
      ragResult,
      mcpContext,
      context
    );

    return {
      success: true,
      response,
      engine: 'local-rag',
      confidence: this.calculateConfidence(ragResult),
      metadata: {
        ragResults: ragResult.totalResults,
        cached: ragResult.cached,
        mcpUsed: !!mcpContext,
      },
      processingTime: Date.now() - startTime,
    };
  }

  /**
   * ğŸŒ ê°œì„ ëœ Google AI ì²˜ë¦¬
   */
  private async processGoogleAIQuery(
    query: string,
    context: AIQueryContext,
    options: AIQueryOptions & {
      useCache?: boolean;
      preferredEngine?: 'local-rag' | 'google-ai';
    },
    mcpContextPromise: Promise<MCPContext | null>
  ): Promise<any> {
    const startTime = Date.now();

    if (!this.googleAIModel) {
      throw new Error('Google AIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }

    // MCP ì»¨í…ìŠ¤íŠ¸ ëŒ€ê¸°
    const mcpContext = await mcpContextPromise;

    // í”„ë¡¬í”„íŠ¸ ìƒì„±
    const prompt = this.buildGoogleAIPrompt(query, context, mcpContext);

    // ìƒì„± ì„¤ì •
    const generationConfig = {
      temperature: options?.temperature || 0.7,
      maxOutputTokens: options?.maxTokens || 1000,
      topK: 40,
      topP: 0.95,
    };

    // ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
    if (options.stream) {
      const result = await this.googleAIModel.generateContentStream({
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        generationConfig,
      });

      return {
        success: true,
        stream: result.stream,
        engine: 'google-ai',
        processingTime: Date.now() - startTime,
      };
    }

    // ì¼ë°˜ ìƒì„±
    const result = await this.googleAIModel.generateContent({
      contents: [{ role: 'user', parts: [{ text: prompt }] }],
      generationConfig,
    });

    const response = result.response;
    const text = response.text();

    return {
      success: true,
      response: text,
      engine: 'google-ai',
      confidence: 0.9,
      metadata: {
        model: 'gemini-pro',
        tokensUsed: response.usageMetadata?.totalTokenCount,
        mcpUsed: !!mcpContext,
      },
      processingTime: Date.now() - startTime,
    };
  }

  /**
   * ğŸ’¾ ìºì‹œ ê´€ë¦¬
   */
  private getCacheKey(query: string, mode: string): string {
    return `${mode}:${query.toLowerCase().trim()}`;
  }

  private checkCache(query: string, mode: string): AIEngineResponse | null {
    const cacheKey = this.getCacheKey(query, mode);
    const entry = this.memoryCache.get(cacheKey);

    if (entry && Date.now() - entry.timestamp < entry.ttl) {
      return {
        success: true,
        response: entry.response,
        engine: entry.engine,
        confidence: entry.confidence,
        metadata: { ...entry.metadata, cached: true },
        processingTime: 0,
      };
    }

    return null;
  }

  private saveToCache(
    query: string,
    mode: string,
    response: AIEngineResponse
  ): void {
    if (this.memoryCache.size >= this.MAX_CACHE_SIZE) {
      // LRU ì •ì±…: ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
      const oldestKey = Array.from(this.memoryCache.entries()).sort(
        (a, b) => a[1].timestamp - b[1].timestamp
      )[0][0];
      this.memoryCache.delete(oldestKey);
    }

    const cacheKey = this.getCacheKey(query, mode);
    this.memoryCache.set(cacheKey, {
      response: response.response,
      engine: response.engine,
      confidence: response.confidence,
      metadata: response.metadata,
      timestamp: Date.now(),
      ttl: this.DEFAULT_TTL,
    });
  }

  /**
   * ğŸ§¹ ìºì‹œ ìœ ì§€ë³´ìˆ˜
   */
  private startCacheMaintenance(): void {
    setInterval(() => {
      const now = Date.now();
      const keysToDelete: string[] = [];

      this.memoryCache.forEach((entry, key) => {
        if (now - entry.timestamp > entry.ttl) {
          keysToDelete.push(key);
        }
      });

      keysToDelete.forEach(key => this.memoryCache.delete(key));
    }, 60000); // 1ë¶„ë§ˆë‹¤
  }

  /**
   * ğŸ“Š ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
   */
  private updateMetrics(engine: string, responseTime: number): void {
    if (engine === 'cache') {
      this.metrics.cacheHitRate = this.metrics.cacheHitRate * 0.95 + 0.05; // ì´ë™ í‰ê· 
    } else {
      this.metrics.cacheHitRate *= 0.95; // ìºì‹œ ë¯¸ìŠ¤

      if (engine === 'local-rag') {
        this.metrics.engineUsage.local++;
      } else {
        this.metrics.engineUsage.googleAI++;
      }
    }

    // í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
    this.metrics.avgResponseTime =
      this.metrics.avgResponseTime * 0.9 + responseTime * 0.1;
  }

  /**
   * ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ
   */
  getPerformanceMetrics(): PerformanceMetrics {
    return { ...this.metrics };
  }

  /**
   * ğŸ”„ ì—”ì§„ ìƒíƒœ ì¡°íšŒ
   */
  async getEngineStatus(): Promise<{
    local: boolean;
    googleAI: boolean;
    mcp: boolean;
    cacheSize: number;
    metrics: PerformanceMetrics;
  }> {
    const [ragHealth, mcpStatus] = await Promise.all([
      this.ragEngine.healthCheck(),
      this.contextLoader.getIntegratedStatus(),
    ]);

    return {
      local: ragHealth.status === 'healthy',
      googleAI: !!this.googleAIModel,
      mcp: mcpStatus.mcpServer.status === 'online',
      cacheSize: this.memoryCache.size,
      metrics: this.getPerformanceMetrics(),
    };
  }

  // ê¸°ì¡´ ë©”ì„œë“œë“¤ ì¬ì‚¬ìš©...
  private generateLocalResponse(
    query: string,
    _ragResult: any, // RAGResult íƒ€ì…ì´ í•„ìš”í•¨
    _mcpContext: MCPContext | null,
    _context: AIQueryContext
  ): string {
    // TODO: ì‹¤ì œ êµ¬í˜„ í•„ìš”
    return `Based on the context: ${query}`;
  }

  private buildGoogleAIPrompt(
    query: string,
    _context: AIQueryContext,
    _mcpContext: MCPContext | null
  ): string {
    // TODO: ì‹¤ì œ êµ¬í˜„ í•„ìš”
    return query;
  }

  private calculateConfidence(_ragResult: any): number {
    // TODO: ì‹¤ì œ êµ¬í˜„ í•„ìš” (RAGResult íƒ€ì… ì •ì˜ í›„)
    return 0.5;
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let improvedEngineInstance: ImprovedQueryEngine | null = null;

export function getImprovedQueryEngine(): ImprovedQueryEngine {
  if (!improvedEngineInstance) {
    improvedEngineInstance = new ImprovedQueryEngine();
  }
  return improvedEngineInstance;
}
