/**
 * ğŸ¯ SimplifiedQueryEngine - ë‹¨ìˆœí™”ëœ AI ì¿¼ë¦¬ ì—”ì§„
 *
 * âœ… ë¡œì»¬ ëª¨ë“œ: Supabase RAG ì—”ì§„ ì‚¬ìš©
 * âœ… Google AI ëª¨ë“œ: Gemini API ì§ì ‘ í˜¸ì¶œ
 * âœ… MCPëŠ” ì»¨í…ìŠ¤íŠ¸ ë³´ì¡°ë¡œë§Œ ì‚¬ìš©
 * âœ… API ì‚¬ìš©ëŸ‰ ìµœì í™”
 * âœ… ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„ ë° ìë™ ì—”ì§„ ì„ íƒ
 * âœ… ì‘ë‹µ ì‹œê°„ 500ms ì´í•˜ ëª©í‘œ
 */

import type { SupabaseRAGEngine } from './supabase-rag-engine';
import { getSupabaseRAGEngine } from './supabase-rag-engine';
import { CloudContextLoader } from '@/services/mcp/CloudContextLoader';
import { MockContextLoader } from './MockContextLoader';
import { vmBackendConnector } from '@/services/vm/VMBackendConnector';
import { QueryComplexityAnalyzer } from './query-complexity-analyzer';
import type { ComplexityScore } from './query-complexity-analyzer';
import {
  createCacheKey,
  getTTL,
  validateDataSize,
} from '@/config/free-tier-cache-config';
import { 
  validateGoogleAIMCPConfig,
  getGCPVMMCPEnv 
} from '@/lib/env-safe';
import type {
  AIQueryContext,
  AIQueryOptions,
  MCPContext,
  RAGSearchResult,
  AIMetadata,
  ServerArray,
} from '@/types/ai-service-types';

export interface QueryRequest {
  query: string;
  mode?: 'local' | 'google-ai' | 'local-ai'; // 'auto' ì œê±°, 'local-ai' ì¶”ê°€
  context?: AIQueryContext;
  
  // ëª¨ë“œë³„ ê¸°ëŠ¥ ì œì–´ ì˜µì…˜ (UnifiedAIEngineRouterì—ì„œ ì„¤ì •)
  enableGoogleAI?: boolean;        // Google AI API í™œì„±í™”/ë¹„í™œì„±í™”
  enableAIAssistantMCP?: boolean;  // ë¡œì»¬ MCPë¥¼ í†µí•œ ì»¨í…ìŠ¤íŠ¸ ë¡œë”© í™œì„±í™”/ë¹„í™œì„±í™”
  enableKoreanNLP?: boolean;       // í•œêµ­ì–´ NLP í™œì„±í™”/ë¹„í™œì„±í™”
  enableVMBackend?: boolean;       // VM AI ë°±ì—”ë“œ í™œì„±í™”/ë¹„í™œì„±í™” (MCPì™€ ë¬´ê´€)
  
  options?: AIQueryOptions & {
    includeThinking?: boolean;
    includeMCPContext?: boolean;
    category?: string;
    cached?: boolean;
    timeoutMs?: number; // íƒ€ì„ì•„ì›ƒ ì„¤ì •
    commandContext?: {
      isCommandRequest?: boolean;
      categories?: string[];
      specificCommands?: string[];
      requestType?: 'command_inquiry' | 'command_usage' | 'command_request' | 'general';
    };
  };
}

export interface QueryResponse {
  success: boolean;
  response: string;
  engine: 'local-rag' | 'local-ai' | 'google-ai' | 'fallback';
  confidence: number;
  thinkingSteps: Array<{
    step: string;
    description?: string;
    status: 'pending' | 'completed' | 'failed';
    timestamp: number;
    duration?: number;
  }>;
  metadata?: AIMetadata & {
    complexity?: ComplexityScore;
    cacheHit?: boolean;
  };
  error?: string;
  processingTime: number;
}

export class SimplifiedQueryEngine {
  protected ragEngine: SupabaseRAGEngine;
  protected contextLoader: CloudContextLoader;
  protected mockContextLoader: MockContextLoader;
  protected isInitialized = false;
  private responseCache: Map<
    string,
    { response: QueryResponse; timestamp: number }
  > = new Map();
  private initPromise: Promise<void> | null = null;

  constructor() {
    this.ragEngine = getSupabaseRAGEngine();
    this.contextLoader = CloudContextLoader.getInstance();
    this.mockContextLoader = MockContextLoader.getInstance();

    // ìºì‹œ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬ (5ë¶„ë§ˆë‹¤)
    setInterval(() => this.cleanupCache(), 5 * 60 * 1000);
  }

  /**
   * ğŸš€ ì—”ì§„ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰)
   */
  async _initialize(): Promise<void> {
    if (this.isInitialized) return;

    // ì´ë¯¸ ì´ˆê¸°í™” ì§„í–‰ ì¤‘ì´ë©´ ê¸°ë‹¤ë¦¼
    if (this.initPromise) {
      return this.initPromise;
    }

    this.initPromise = this.performInitialization();

    try {
      await this.initPromise;
    } finally {
      this.initPromise = null;
    }
  }

  private async performInitialization(): Promise<void> {
    try {
      console.log('ğŸš€ SimplifiedQueryEngine ì´ˆê¸°í™” ì¤‘...');

      // RAG ì—”ì§„ ì´ˆê¸°í™” (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
      const initTimeout = new Promise<void>((_, reject) =>
        setTimeout(() => reject(new Error('ì´ˆê¸°í™” íƒ€ì„ì•„ì›ƒ')), 5000)
      );

      await Promise.race([this.ragEngine._initialize(), initTimeout]);

      this.isInitialized = true;
      console.log('âœ… SimplifiedQueryEngine ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (error) {
      console.error('âŒ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      // ì´ˆê¸°í™” ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
      this.isInitialized = true;
    }
  }

  /**
   * ğŸ” ì¿¼ë¦¬ ì²˜ë¦¬ (ìºì‹± ë° ìë™ ì—”ì§„ ì„ íƒ)
   */
  async query(request: QueryRequest): Promise<QueryResponse> {
    const startTime = Date.now();

    // ì´ˆê¸°í™” ë³‘ë ¬ ì‹¤í–‰
    const initPromise = this._initialize();

    const {
      query,
      mode = 'local', // ê¸°ë³¸ê°’: ë¡œì»¬ ëª¨ë“œ (ë” ì´ìƒ auto ì—†ìŒ)
      context = {},
      options = {},
      // ìƒˆë¡œìš´ ëª¨ë“œë³„ ê¸°ëŠ¥ ì œì–´ ì˜µì…˜
      enableGoogleAI = false,
      enableAIAssistantMCP = false,
      enableKoreanNLP = true,
      enableVMBackend = true,
    } = request;

    const thinkingSteps: QueryResponse['thinkingSteps'] = [];
    const timeoutMs = options.timeoutMs || 450; // ê¸°ë³¸ 450ms (ëª©í‘œ: 500ms ì´í•˜)

    // ìºì‹œ í™•ì¸
    const cacheKey = this.generateCacheKey(query, mode, context);
    const cachedResponse = this.getCachedResponse(cacheKey);
    if (cachedResponse && options.cached !== false) {
      const baseMetadata = cachedResponse.metadata || {};
      return {
        ...cachedResponse,
        metadata: {
          ...baseMetadata,
          cacheHit: true,
        } as AIMetadata & { cacheHit?: boolean },
        processingTime: Date.now() - startTime,
      };
    }

    // ì´ˆê¸°í™” ì™„ë£Œ ëŒ€ê¸°
    await initPromise;

    try {
      // ë¹ˆ ì¿¼ë¦¬ ì²´í¬
      if (!query || query.trim().length === 0) {
        return {
          success: true,
          response: 'ì§ˆì˜ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”',
          engine: 'local-rag',
          confidence: 0,
          thinkingSteps: [
            {
              step: 'ë¹ˆ ì¿¼ë¦¬ í™•ì¸',
              description: 'ì…ë ¥ëœ ì¿¼ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤',
              status: 'completed',
              timestamp: Date.now(),
            },
          ],
          processingTime: Date.now() - startTime,
        };
      }

      // ğŸ”¥ NEW: ëª…ë ¹ì–´ ì¿¼ë¦¬ ê°ì§€ ë° ì²˜ë¦¬
      const commandStepStart = Date.now();
      thinkingSteps.push({
        step: 'ëª…ë ¹ì–´ ê°ì§€',
        description: 'ëª…ë ¹ì–´ ê´€ë ¨ ì¿¼ë¦¬ì¸ì§€ í™•ì¸',
        status: 'pending',
        timestamp: commandStepStart,
      });

      // ëª…ë ¹ì–´ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€
      const isCommandQuery = this.detectCommandQuery(query, options.commandContext);
      
      if (isCommandQuery) {
        thinkingSteps[thinkingSteps.length - 1].status = 'completed';
        thinkingSteps[thinkingSteps.length - 1].description = 'ëª…ë ¹ì–´ ì¿¼ë¦¬ë¡œ ê°ì§€ë¨';
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - commandStepStart;

        // ëª…ë ¹ì–´ ì „ìš© ì²˜ë¦¬
        return await this.processCommandQuery(
          query,
          options.commandContext,
          thinkingSteps,
          startTime
        );
      } else {
        thinkingSteps[thinkingSteps.length - 1].status = 'completed';
        thinkingSteps[thinkingSteps.length - 1].description = 'ì¼ë°˜ ì¿¼ë¦¬ë¡œ íŒë‹¨';
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - commandStepStart;
      }

      // ëª¨ë“œë³„ ì²˜ë¦¬ ì „í™˜
      thinkingSteps.push({
        step: 'ëª¨ë“œ ì„ íƒ',
        description: `${mode} ëª¨ë“œ ì„ íƒë¨ (Google AI: ${enableGoogleAI}, AI MCP: ${enableAIAssistantMCP})`,
        status: 'completed',
        timestamp: Date.now(),
      });

      // 2ë‹¨ê³„: ë³‘ë ¬ ì²˜ë¦¬ ì¤€ë¹„
      const processingPromises: Promise<unknown>[] = [];
      let mcpContext: MCPContext | null = null;

      // MCP ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (AI ì–´ì‹œìŠ¤í„´íŠ¸ MCPê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
      if (options.includeMCPContext && enableAIAssistantMCP) {
        const mcpStepIndex = thinkingSteps.length;
        thinkingSteps.push({
          step: 'AI ì–´ì‹œìŠ¤í„´íŠ¸ MCP ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘',
          status: 'pending',
          timestamp: Date.now(),
        });

        processingPromises.push(
          this.contextLoader
            .queryMCPContextForRAG(query, {
              maxFiles: 3, // ì„±ëŠ¥ì„ ìœ„í•´ íŒŒì¼ ìˆ˜ ì œí•œ
              includeSystemContext: true,
            })
            .then(result => {
              mcpContext = result;
              thinkingSteps[mcpStepIndex].status = 'completed';
              thinkingSteps[mcpStepIndex].description =
                `${result?.files?.length || 0}ê°œ íŒŒì¼ ìˆ˜ì§‘`;
              thinkingSteps[mcpStepIndex].duration =
                Date.now() - thinkingSteps[mcpStepIndex].timestamp;
            })
            .catch(error => {
              console.warn('MCP ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨:', error);
              thinkingSteps[mcpStepIndex].status = 'failed';
              thinkingSteps[mcpStepIndex].duration =
                Date.now() - thinkingSteps[mcpStepIndex].timestamp;
            })
        );
      } else if (options.includeMCPContext && !enableAIAssistantMCP) {
        thinkingSteps.push({
          step: 'MCP ê±´ë„ˆë›°ê¸°',
          description: 'AI ì–´ì‹œìŠ¤í„´íŠ¸ MCP ë¹„í™œì„±í™”ë¨ (ë¡œì»¬ AI ëª¨ë“œ)',
          status: 'completed',
          timestamp: Date.now(),
        });
      }

      // ë³‘ë ¬ ì²˜ë¦¬ ëŒ€ê¸° (ìµœëŒ€ 100ms)
      if (processingPromises.length > 0) {
        await Promise.race([
          Promise.all(processingPromises),
          new Promise(resolve => setTimeout(resolve, 100)),
        ]);
      }

      // 3ë‹¨ê³„: íƒ€ì„ì•„ì›ƒì„ ê³ ë ¤í•œ ì¿¼ë¦¬ ì²˜ë¦¬
      const queryTimeout = new Promise<QueryResponse>((_, reject) =>
        setTimeout(() => reject(new Error('ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ')), timeoutMs)
      );

      let response: QueryResponse;

      try {
        if (mode === 'local-ai' || (mode === 'local' && !enableGoogleAI)) {
          // ë¡œì»¬ AI ëª¨ë“œ: Korean NLP + Supabase RAG + VM ë°±ì—”ë“œ (Google AI API ì œì™¸)
          response = await Promise.race([
            this.processLocalAIModeQuery(
              query,
              context,
              options,
              mcpContext,
              thinkingSteps,
              startTime,
              { enableKoreanNLP, enableVMBackend }
            ),
            queryTimeout,
          ]);
        } else {
          // êµ¬ê¸€ AI ëª¨ë“œ: ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
          response = await Promise.race([
            this.processGoogleAIModeQuery(
              query,
              context,
              options,
              mcpContext,
              thinkingSteps,
              startTime,
              { enableGoogleAI, enableAIAssistantMCP, enableKoreanNLP, enableVMBackend }
            ),
            queryTimeout,
          ]);
        }

        // ì„±ê³µ ì‘ë‹µ ìºì‹±
        if (response.success && response.processingTime < 500) {
          this.setCachedResponse(cacheKey, response);
        }

        return response;
      } catch (_timeoutError) {
        // íƒ€ì„ì•„ì›ƒ ì‹œ ë¹ ë¥¸ í´ë°±
        console.warn('ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ, í´ë°± ëª¨ë“œë¡œ ì „í™˜');

        if (mode === 'google-ai' || enableGoogleAI) {
          // Google AI íƒ€ì„ì•„ì›ƒ ì‹œ ë¡œì»¬ë¡œ í´ë°±
          return await this.processLocalAIModeQuery(
            query,
            context,
            options,
            null, // MCP ì»¨í…ìŠ¤íŠ¸ ìŠ¤í‚µ
            thinkingSteps,
            startTime,
            { enableKoreanNLP: true, enableVMBackend: true }
          );
        } else {
          // ë¡œì»¬ë„ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ì‘ë‹µ
          return this.generateFallbackResponse(query, thinkingSteps, startTime);
        }
      }
    } catch (error) {
      console.error('âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨:', error);

      return {
        success: false,
        response: 'ì£„ì†¡í•©ë‹ˆë‹¤. ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        engine: mode === 'local' || mode === 'local-ai' ? 'local-rag' : 'google-ai',
        confidence: 0,
        thinkingSteps,
        error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜',
        processingTime: Date.now() - startTime,
      };
    }
  }

  /**
   * ğŸ  ë¡œì»¬ RAG ì¿¼ë¦¬ ì²˜ë¦¬ (ìµœì í™”ë¨)
   */
  private async processLocalQuery(
    query: string,
    context: AIQueryContext | undefined,
    options: QueryRequest['options'],
    mcpContext: MCPContext | null,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number,
    complexity?: ComplexityScore
  ): Promise<QueryResponse> {
    // RAG ê²€ìƒ‰
    const ragStepStart = Date.now();
    thinkingSteps.push({
      step: 'RAG ê²€ìƒ‰',
      description: 'Supabase ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰',
      status: 'pending',
      timestamp: ragStepStart,
    });

    // ë³µì¡ë„ì— ë”°ë¼ ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì¡°ì •
    const maxResults = complexity && complexity.score < 30 ? 3 : 5;
    const threshold = complexity && complexity.score < 30 ? 0.6 : 0.5;

    const ragResult = await this.ragEngine.searchSimilar(query, {
      maxResults,
      threshold,
      category: options?.category,
      enableMCP: false, // MCPëŠ” ì´ë¯¸ ë³„ë„ë¡œ ì²˜ë¦¬
    });

    thinkingSteps[thinkingSteps.length - 1].status = 'completed';
    thinkingSteps[thinkingSteps.length - 1].description =
      `${ragResult.totalResults}ê°œ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬`;
    thinkingSteps[thinkingSteps.length - 1].duration =
      Date.now() - ragStepStart;

    // ì‘ë‹µ ìƒì„±
    const responseStepStart = Date.now();
    thinkingSteps.push({
      step: 'ì‘ë‹µ ìƒì„±',
      description: 'ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ ìƒì„±',
      status: 'pending',
      timestamp: responseStepStart,
    });

    const response = this.generateLocalResponse(
      query,
      ragResult,
      mcpContext,
      context
    );

    thinkingSteps[thinkingSteps.length - 1].status = 'completed';
    thinkingSteps[thinkingSteps.length - 1].duration =
      Date.now() - responseStepStart;

    return {
      success: true,
      response,
      engine: 'local-rag',
      confidence: this.calculateConfidence(ragResult),
      thinkingSteps,
      metadata: {
        ragResults: ragResult.totalResults,
        cached: ragResult.cached,
        mcpUsed: !!mcpContext,
        mockMode: !!this.mockContextLoader.getMockContext(),
        complexity,
      } as AIMetadata & { complexity?: ComplexityScore; cacheHit?: boolean; mockMode?: boolean },
      processingTime: Date.now() - startTime,
    };
  }

  /**
   * ë¡œì»¬ AI ëª¨ë“œ ì¿¼ë¦¬ ì²˜ë¦¬
   * - í•œêµ­ì–´ NLP ì²˜ë¦¬ (enableKoreanNLP=trueì¼ ë•Œ)
   * - Supabase RAG ê²€ìƒ‰
   * - VM ë°±ì—”ë“œ ì—°ë™ (enableVMBackend=trueì¼ ë•Œ) 
   * - Google AI API ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
   * - AI ì–´ì‹œìŠ¤í„´íŠ¸ MCP ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
   */
  private async processLocalAIModeQuery(
    query: string,
    context: AIQueryContext | undefined,
    options: QueryRequest['options'],
    mcpContext: MCPContext | null,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number,
    modeConfig: { enableKoreanNLP: boolean; enableVMBackend: boolean }
  ): Promise<QueryResponse> {
    const { enableKoreanNLP, enableVMBackend } = modeConfig;

    // 1ë‹¨ê³„: í•œêµ­ì–´ NLP ì²˜ë¦¬ (í™œì„±í™”ëœ ê²½ìš°)
    if (enableKoreanNLP) {
      const nlpStepStart = Date.now();
      thinkingSteps.push({
        step: 'í•œêµ­ì–´ NLP ì²˜ë¦¬',
        description: 'í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë° ì˜ë„ ë¶„ì„',
        status: 'pending',
        timestamp: nlpStepStart,
      });

      try {
        // í•œêµ­ì–´ ë¹„ìœ¨ í™•ì¸
        const koreanRatio = this.calculateKoreanRatio(query);
        
        if (koreanRatio > 0.3) {
          // í•œêµ­ì–´ê°€ 30% ì´ìƒì¸ ê²½ìš° NLP ì²˜ë¦¬
          // TODO: ì‹¤ì œ Korean NLP ì—”ì§„ í˜¸ì¶œ (GCP Functions)
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description = 
            `í•œêµ­ì–´ ë¹„ìœ¨ ${Math.round(koreanRatio * 100)}% - NLP ì²˜ë¦¬ ì™„ë£Œ`;
        } else {
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description = 
            `ì˜ì–´ ì¿¼ë¦¬ ê°ì§€ - NLP ê±´ë„ˆë›°ê¸°`;
        }
        
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - nlpStepStart;
      } catch (error) {
        console.warn('í•œêµ­ì–´ NLP ì²˜ë¦¬ ì‹¤íŒ¨:', error);
        thinkingSteps[thinkingSteps.length - 1].status = 'failed';
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - nlpStepStart;
      }
    }

    // 2ë‹¨ê³„: RAG ê²€ìƒ‰ (Supabase pgvector)
    const ragStepStart = Date.now();
    thinkingSteps.push({
      step: 'Supabase RAG ê²€ìƒ‰',
      description: 'pgvector ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰',
      status: 'pending',
      timestamp: ragStepStart,
    });

    const ragResult = await this.ragEngine.searchSimilar(query, {
      maxResults: 5, // ê³ ì •ê°’ (ë³µì¡ë„ ë¶„ì„ ì—†ìŒ)
      threshold: 0.5,
      category: options?.category,
      enableMCP: false, // AI ì–´ì‹œìŠ¤í„´íŠ¸ MCPëŠ” ë¡œì»¬ AI ëª¨ë“œì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    });

    thinkingSteps[thinkingSteps.length - 1].status = 'completed';
    thinkingSteps[thinkingSteps.length - 1].description =
      `${ragResult.totalResults}ê°œ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬`;
    thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - ragStepStart;

    // 3ë‹¨ê³„: VM ë°±ì—”ë“œ ì—°ë™ (í™œì„±í™”ëœ ê²½ìš°)
    let vmBackendResult = null;
    if (enableVMBackend) {
      const vmStepStart = Date.now();
      thinkingSteps.push({
        step: 'VM ë°±ì—”ë“œ ì—°ë™',
        description: 'GCP VMì˜ ê³ ê¸‰ AI ì„œë¹„ìŠ¤ ì—°ë™',
        status: 'pending',
        timestamp: vmStepStart,
      });

      try {
        // VM ë°±ì—”ë“œ ì‹¤ì œ ì—°ë™ êµ¬í˜„
        if (vmBackendConnector.isEnabled) {
          // ì„¸ì…˜ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
          const session = await vmBackendConnector.createSession('local-ai-user', {
            query,
            mode: 'local-ai',
            ragResults: ragResult.totalResults
          });
          
          if (session) {
            await vmBackendConnector.addMessage(session.id, {
              role: 'user',
              content: query,
              metadata: { ragResults: ragResult.totalResults, mode: 'local-ai' }
            });
            
            vmBackendResult = {
              sessionId: session.id,
              contextEnhanced: true
            };
          }
        }
        
        thinkingSteps[thinkingSteps.length - 1].status = 'completed';
        thinkingSteps[thinkingSteps.length - 1].description = 'VM ë°±ì—”ë“œ ì—°ë™ ì™„ë£Œ';
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - vmStepStart;
      } catch (error) {
        console.warn('VM ë°±ì—”ë“œ ì—°ë™ ì‹¤íŒ¨:', error);
        thinkingSteps[thinkingSteps.length - 1].status = 'failed';
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - vmStepStart;
      }
    }

    // 4ë‹¨ê³„: ì‘ë‹µ ìƒì„±
    const responseStepStart = Date.now();
    thinkingSteps.push({
      step: 'ë¡œì»¬ AI ì‘ë‹µ ìƒì„±',
      description: 'RAG ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ ìƒì„± (Google AI ì‚¬ìš© ì•ˆí•¨)',
      status: 'pending',
      timestamp: responseStepStart,
    });

    const response = this.generateLocalResponse(
      query,
      ragResult,
      mcpContext,
      context
    );

    thinkingSteps[thinkingSteps.length - 1].status = 'completed';
    thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - responseStepStart;

    return {
      success: true,
      response,
      engine: 'local-ai',
      confidence: this.calculateConfidence(ragResult),
      thinkingSteps,
      metadata: {
        ragResults: ragResult.totalResults,
        cached: ragResult.cached,
        mcpUsed: !!mcpContext,
        mockMode: !!this.mockContextLoader.getMockContext(),
        koreanNLPUsed: enableKoreanNLP,
        vmBackendUsed: enableVMBackend && !!vmBackendResult,
        mode: 'local-ai',
      } as AIMetadata & { koreanNLPUsed?: boolean; vmBackendUsed?: boolean; mockMode?: boolean },
      processingTime: Date.now() - startTime,
    };
  }

  /**
   * í•œêµ­ì–´ ë¹„ìœ¨ ê³„ì‚° (ë³µì¡ë„ ë¶„ì„ì—ì„œ ë¶„ë¦¬)
   */
  private calculateKoreanRatio(text: string): number {
    const koreanChars = text.match(/[ã„±-ã…|ã…-ã…£|ê°€-í£]/g) || [];
    return koreanChars.length / text.length;
  }

  /**
   * êµ¬ê¸€ AI ëª¨ë“œ ì¿¼ë¦¬ ì²˜ë¦¬
   * - Google AI API í™œì„±í™”
   * - AI ì–´ì‹œìŠ¤í„´íŠ¸ MCP í™œì„±í™” (CloudContextLoader)
   * - í•œêµ­ì–´ NLP ì²˜ë¦¬
   * - VM ë°±ì—”ë“œ ì—°ë™
   * - ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
   */
  private async processGoogleAIModeQuery(
    query: string,
    context: AIQueryContext | undefined,
    options: QueryRequest['options'],
    mcpContext: MCPContext | null,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number,
    modeConfig: { 
      enableGoogleAI: boolean; 
      enableAIAssistantMCP: boolean; 
      enableKoreanNLP: boolean; 
      enableVMBackend: boolean;
    }
  ): Promise<QueryResponse> {
    const { enableGoogleAI, enableAIAssistantMCP, enableKoreanNLP, enableVMBackend } = modeConfig;

    // 1ë‹¨ê³„: í•œêµ­ì–´ NLP ì²˜ë¦¬ (í™œì„±í™”ëœ ê²½ìš°)
    if (enableKoreanNLP) {
      const nlpStepStart = Date.now();
      thinkingSteps.push({
        step: 'í•œêµ­ì–´ NLP ì²˜ë¦¬',
        description: 'í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë° ì˜ë„ ë¶„ì„',
        status: 'pending',
        timestamp: nlpStepStart,
      });

      try {
        const koreanRatio = this.calculateKoreanRatio(query);
        
        if (koreanRatio > 0.3) {
          // TODO: ì‹¤ì œ Korean NLP ì—”ì§„ í˜¸ì¶œ
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description = 
            `í•œêµ­ì–´ ë¹„ìœ¨ ${Math.round(koreanRatio * 100)}% - NLP ì²˜ë¦¬ ì™„ë£Œ`;
        } else {
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description = 
            `ì˜ì–´ ì¿¼ë¦¬ ê°ì§€ - NLP ê±´ë„ˆë›°ê¸°`;
        }
        
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - nlpStepStart;
      } catch (error) {
        console.warn('í•œêµ­ì–´ NLP ì²˜ë¦¬ ì‹¤íŒ¨:', error);
        thinkingSteps[thinkingSteps.length - 1].status = 'failed';
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - nlpStepStart;
      }
    }

    // 2ë‹¨ê³„: Google AI API ì²˜ë¦¬ (í•µì‹¬ ê¸°ëŠ¥)
    const googleStepStart = Date.now();
    thinkingSteps.push({
      step: 'Google AI ì²˜ë¦¬',
      description: 'Gemini API í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„±',
      status: 'pending',
      timestamp: googleStepStart,
    });

    try {
      if (!enableGoogleAI) {
        throw new Error('Google AI APIê°€ ë¹„í™œì„±í™”ë¨');
      }

      // ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
      const prompt = this.buildGoogleAIPrompt(query, context, mcpContext);

      // Google AI API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), 400); // 400ms íƒ€ì„ì•„ì›ƒ

      const response = await fetch('/api/ai/google-ai/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          prompt,
          temperature: 0.7, // ê³ ì •ê°’ (ë³µì¡ë„ ë¶„ì„ ì—†ìŒ)
          maxTokens: 1000,  // ê³ ì •ê°’
        }),
        signal: controller.signal,
      });

      clearTimeout(timeout);

      if (!response.ok) {
        throw new Error(`Google AI API ì˜¤ë¥˜: ${response.statusText}`);
      }

      const data = await response.json();

      thinkingSteps[thinkingSteps.length - 1].status = 'completed';
      thinkingSteps[thinkingSteps.length - 1].description = 'Gemini API ì‘ë‹µ ìˆ˜ì‹ ';
      thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - googleStepStart;

      // 2.5ë‹¨ê³„: GCP VM MCP ì„œë²„ ì§ì ‘ í˜¸ì¶œ (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤ ì ìš©)
      let gcpMcpResult = null;
      const mcpConfig = validateGoogleAIMCPConfig();
      
      if (mcpConfig.isValid && mcpConfig.config.gcpVMMCP.integrationEnabled) {
        const mcpStepStart = Date.now();
        thinkingSteps.push({
          step: 'GCP VM MCP ìì—°ì–´ ì²˜ë¦¬',
          description: 'MCP ì„œë²„ë¡œ Google AI ê²°ê³¼ ë³´ê°• ì¤‘',
          status: 'pending',
          timestamp: mcpStepStart,
        });

        try {
          const { serverUrl, timeout } = mcpConfig.config.gcpVMMCP;
          
          // JSON-RPC í‘œì¤€ ì¤€ìˆ˜ (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤)
          const mcpRequest = {
            jsonrpc: '2.0',
            id: `mcp-${Date.now()}`,
            method: 'query',
            params: {
              query,
              mode: 'natural-language',
              context: {
                googleAIResponse: data.response || data.text,
                originalQuery: query,
                timestamp: new Date().toISOString(),
                mcpContext: mcpContext
              },
              options: {
                temperature: 0.7,
                maxTokens: 500,
                includeMetrics: true,
                source: 'google-ai-mode'
              }
            }
          };

          // íƒ€ì„ì•„ì›ƒ ì„¤ì • (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤)
          const controller = new AbortController();
          const mcpTimeout = setTimeout(() => {
            controller.abort();
            console.warn(`âš ï¸ GCP VM MCP íƒ€ì„ì•„ì›ƒ (${timeout}ms)`);
          }, timeout);

          // GCP VM MCP ì„œë²„ ì§ì ‘ í˜¸ì¶œ
          console.log(`ğŸŒ GCP VM MCP ì„œë²„ í˜¸ì¶œ: ${serverUrl}`);
          
          const mcpResponse = await fetch(`${serverUrl}/mcp/query`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'X-MCP-Type': 'google-ai',
              'X-Client': 'openmanager-vibe-v5-simplified-engine',
              'X-Request-ID': mcpRequest.id,
            },
            body: JSON.stringify(mcpRequest.params), // MCP ì„œë²„ê°€ paramsë§Œ ì²˜ë¦¬í•˜ëŠ” ê²½ìš°
            signal: controller.signal,
          });

          clearTimeout(mcpTimeout);

          if (!mcpResponse.ok) {
            throw new Error(`GCP VM MCP ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: ${mcpResponse.status} ${mcpResponse.statusText}`);
          }

          const mcpData = await mcpResponse.json();
          
          // ì‘ë‹µ ê²€ì¦ (JSON-RPC í‘œì¤€)
          if (mcpData.success !== undefined ? mcpData.success : true) {
            gcpMcpResult = {
              enhanced: mcpData.response || mcpData.result,
              processingTime: Date.now() - mcpStepStart,
              serverUsed: 'gcp-vm-mcp',
              metadata: mcpData.metadata || {
                mcpType: 'google-ai',
                aiMode: 'natural-language-processing'
              }
            };

            thinkingSteps[thinkingSteps.length - 1].status = 'completed';
            thinkingSteps[thinkingSteps.length - 1].description = 
              `MCP ìì—°ì–´ ì²˜ë¦¬ ì™„ë£Œ (${gcpMcpResult.processingTime}ms)`;
            
            console.log(`âœ… GCP VM MCP í˜¸ì¶œ ì„±ê³µ: ${gcpMcpResult.processingTime}ms`);
          } else {
            throw new Error(mcpData.error || 'MCP ì„œë²„ì—ì„œ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°˜í™˜');
          }

          thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - mcpStepStart;
          
        } catch (error) {
          // ìƒì„¸í•œ ì—ëŸ¬ í•¸ë“¤ë§ (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤)
          const errorMsg = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
          
          console.warn(`âš ï¸ GCP VM MCP í˜¸ì¶œ ì‹¤íŒ¨: ${errorMsg}`);
          
          thinkingSteps[thinkingSteps.length - 1].status = 'failed';
          thinkingSteps[thinkingSteps.length - 1].description = `MCP ì„œë²„ ì˜¤ë¥˜: ${errorMsg}`;
          thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - mcpStepStart;
          
          // MCP ì‹¤íŒ¨ëŠ” ì „ì²´ ì‘ë‹µì„ ë°©í•´í•˜ì§€ ì•ŠìŒ (í´ë°±)
          gcpMcpResult = {
            fallback: true,
            error: errorMsg,
            processingTime: Date.now() - mcpStepStart
          };
        }
      } else {
        // í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì • ì‹œ ë¡œê¹… (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤)
        if (!mcpConfig.isValid) {
          console.log(`ğŸ”§ GCP VM MCP ë¹„í™œì„±í™”: ${mcpConfig.errors.join(', ')}`);
        } else {
          console.log('ğŸ”§ GCP VM MCP í†µí•© ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤');
        }
      }

      // 3ë‹¨ê³„: VM ë°±ì—”ë“œ ì—°ë™ (í™œì„±í™”ëœ ê²½ìš°)
      let vmBackendResult = null;
      if (enableVMBackend) {
        const vmStepStart = Date.now();
        thinkingSteps.push({
          step: 'VM ë°±ì—”ë“œ ê³ ê¸‰ ì²˜ë¦¬',
          description: 'GCP VMì˜ DeepAnalyzer, StreamProcessor ì—°ë™',
          status: 'pending',
          timestamp: vmStepStart,
        });

        try {
          // VM ë°±ì—”ë“œ ê³ ê¸‰ ê¸°ëŠ¥ ì—°ë™ êµ¬í˜„
          if (vmBackendConnector.isEnabled) {
            try {
              // 1. ì„¸ì…˜ ìƒì„± ë° ë©”ì‹œì§€ ê¸°ë¡
              const session = await vmBackendConnector.createSession('google-ai-user', {
                query,
                mode: 'google-ai',
                googleAIResponse: data.response,
                mcpUsed: !!mcpContext && enableAIAssistantMCP
              });

              if (session) {
                await vmBackendConnector.addMessage(session.id, {
                  role: 'user',
                  content: query,
                  metadata: { mode: 'google-ai', mcpContext: !!mcpContext }
                });

                await vmBackendConnector.addMessage(session.id, {
                  role: 'assistant',
                  content: data.response || data.text,
                  metadata: { 
                    model: data.model,
                    tokensUsed: data.tokensUsed,
                    confidence: data.confidence
                  }
                });

                // 2. ì‹¬ì¸µ ë¶„ì„ ì‹œì‘ (ë¹„ë™ê¸°)
                const analysisJob = await vmBackendConnector.startDeepAnalysis(
                  'pattern',
                  query,
                  {
                    googleAIResponse: data.response,
                    sessionId: session.id,
                    mcpContext: mcpContext
                  }
                );

                // 3. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¤€ë¹„
                if (enableVMBackend) {
                  await vmBackendConnector.subscribeToSession(session.id);
                }

                vmBackendResult = {
                  sessionId: session.id,
                  analysisJobId: analysisJob?.id,
                  deepAnalysisStarted: !!analysisJob,
                  streamingEnabled: true
                };
              }
            } catch (vmError) {
              console.warn('VM ë°±ì—”ë“œ ê³ ê¸‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', vmError);
              // VM ë°±ì—”ë“œ ì˜¤ë¥˜ëŠ” ì „ì²´ ì‘ë‹µì„ ë°©í•´í•˜ì§€ ì•ŠìŒ
            }
          }
          
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description = 'VM ë°±ì—”ë“œ ê³ ê¸‰ ì²˜ë¦¬ ì™„ë£Œ';
          thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - vmStepStart;
        } catch (error) {
          console.warn('VM ë°±ì—”ë“œ ê³ ê¸‰ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
          thinkingSteps[thinkingSteps.length - 1].status = 'failed';
          thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - vmStepStart;
        }
      }

      // Google AI ì‘ë‹µê³¼ GCP VM MCP ê²°ê³¼ í†µí•©
      let finalResponse = data.response || data.text || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      let finalConfidence = data.confidence || 0.9;
      
      // GCP VM MCP ê²°ê³¼ê°€ ìˆê³  ì„±ê³µì ì´ë©´ ì‘ë‹µ í–¥ìƒ
      if (gcpMcpResult && !gcpMcpResult.fallback && gcpMcpResult.enhanced) {
        // MCPê°€ ì‘ë‹µì„ ë³´ê°•í•œ ê²½ìš°
        finalResponse = gcpMcpResult.enhanced;
        finalConfidence = Math.min(finalConfidence + 0.1, 1.0); // ì‹ ë¢°ë„ 10% í–¥ìƒ (ìµœëŒ€ 1.0)
        
        console.log(`âœ¨ GCP VM MCPë¡œ ì‘ë‹µ ë³´ê°• ì™„ë£Œ (ì‹ ë¢°ë„: ${finalConfidence})`);
      } else if (gcpMcpResult && gcpMcpResult.fallback) {
        console.log(`âš ï¸ GCP VM MCP í´ë°± ëª¨ë“œ: ${gcpMcpResult.error}`);
      }

      return {
        success: true,
        response: finalResponse,
        engine: 'google-ai',
        confidence: finalConfidence,
        thinkingSteps,
        metadata: {
          model: data.model || 'gemini-pro',
          tokensUsed: data.tokensUsed,
          mcpUsed: !!(mcpContext && enableAIAssistantMCP) || !!gcpMcpResult,
          aiAssistantMCPUsed: enableAIAssistantMCP,
          koreanNLPUsed: enableKoreanNLP,
          vmBackendUsed: enableVMBackend && !!vmBackendResult,
          gcpVMMCPUsed: !!gcpMcpResult && !gcpMcpResult.fallback, // ğŸ¯ GCP VM MCP ì‚¬ìš© ì—¬ë¶€
          gcpVMMCPResult: gcpMcpResult ? {
            serverUsed: gcpMcpResult.serverUsed,
            processingTime: gcpMcpResult.processingTime,
            fallback: gcpMcpResult.fallback,
            metadata: gcpMcpResult.metadata
          } : null,
          mockMode: !!this.mockContextLoader.getMockContext(),
          mode: 'google-ai',
        } as AIMetadata & { 
          aiAssistantMCPUsed?: boolean; 
          koreanNLPUsed?: boolean; 
          vmBackendUsed?: boolean; 
          gcpVMMCPUsed?: boolean;
          gcpVMMCPResult?: any;
          mockMode?: boolean;
        },
        processingTime: Date.now() - startTime,
      };
    } catch (error) {
      console.error('Google AI ì²˜ë¦¬ ì˜¤ë¥˜:', error);

      // í´ë°±: ë¡œì»¬ AI ëª¨ë“œë¡œ ì „í™˜
      thinkingSteps[thinkingSteps.length - 1].status = 'failed';
      thinkingSteps[thinkingSteps.length - 1].description = 'Google AI ì‹¤íŒ¨, ë¡œì»¬ AI ëª¨ë“œë¡œ ì „í™˜';
      thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - googleStepStart;

      return await this.processLocalAIModeQuery(
        query,
        context,
        options,
        mcpContext,
        thinkingSteps,
        startTime,
        { enableKoreanNLP: true, enableVMBackend: true }
      );
    }
  }

  /**
   * ğŸŒ Google AI ì¿¼ë¦¬ ì²˜ë¦¬ (ìµœì í™”ë¨)
   */
  private async processGoogleAIQuery(
    query: string,
    context: AIQueryContext | undefined,
    options: QueryRequest['options'],
    mcpContext: MCPContext | null,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number,
    complexity?: ComplexityScore
  ): Promise<QueryResponse> {
    const googleStepStart = Date.now();
    thinkingSteps.push({
      step: 'Google AI ì¤€ë¹„',
      description: 'Gemini API í˜¸ì¶œ ì¤€ë¹„',
      status: 'pending',
      timestamp: googleStepStart,
    });

    try {
      // ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
      const prompt = this.buildGoogleAIPrompt(query, context, mcpContext);

      // ë³µì¡ë„ì— ë”°ë¼ íŒŒë¼ë¯¸í„° ì¡°ì •
      const temperature = complexity && complexity.score > 70 ? 0.8 : 0.7;
      const maxTokens = complexity && complexity.score > 70 ? 1500 : 1000;

      // Google AI API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), 400); // 400ms íƒ€ì„ì•„ì›ƒ

      const response = await fetch('/api/ai/google-ai/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          prompt,
          temperature,
          maxTokens,
        }),
        signal: controller.signal,
      });

      clearTimeout(timeout);

      if (!response.ok) {
        throw new Error(`Google AI API ì˜¤ë¥˜: ${response.statusText}`);
      }

      const data = await response.json();

      thinkingSteps[thinkingSteps.length - 1].status = 'completed';
      thinkingSteps[thinkingSteps.length - 1].description =
        'Gemini API ì‘ë‹µ ìˆ˜ì‹ ';
      thinkingSteps[thinkingSteps.length - 1].duration =
        Date.now() - googleStepStart;

      return {
        success: true,
        response: data.response || data.text || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        engine: 'google-ai',
        confidence: data.confidence || 0.9,
        thinkingSteps,
        metadata: {
          model: data.model || 'gemini-pro',
          tokensUsed: data.tokensUsed,
          mcpUsed: !!mcpContext,
          mockMode: !!this.mockContextLoader.getMockContext(),
          complexity,
        } as AIMetadata & { complexity?: ComplexityScore; cacheHit?: boolean; mockMode?: boolean },
        processingTime: Date.now() - startTime,
      };
    } catch (error) {
      console.error('Google AI ì²˜ë¦¬ ì˜¤ë¥˜:', error);

      // í´ë°±: ë¡œì»¬ RAGë¡œ ì „í™˜
      thinkingSteps[thinkingSteps.length - 1].status = 'failed';
      thinkingSteps[thinkingSteps.length - 1].description =
        'Google AI ì‹¤íŒ¨, ë¡œì»¬ ëª¨ë“œë¡œ ì „í™˜';
      thinkingSteps[thinkingSteps.length - 1].duration =
        Date.now() - googleStepStart;

      return await this.processLocalQuery(
        query,
        context,
        options,
        mcpContext,
        thinkingSteps,
        startTime,
        complexity
      );
    }
  }

  /**
   * ğŸ“ ë¡œì»¬ ì‘ë‹µ ìƒì„±
   */
  protected generateLocalResponse(
    query: string,
    ragResult: { results: Array<{ id: string; content: string; similarity: number; metadata?: AIMetadata }> },
    mcpContext: MCPContext | null,
    userContext: AIQueryContext | undefined
  ): string {
    // Mock ëª¨ë“œ í™•ì¸ ë° ì²˜ë¦¬
    const mockContext = this.mockContextLoader.getMockContext();
    if (mockContext) {
      // Mock ì„œë²„ ê´€ë ¨ ì¿¼ë¦¬ ì²˜ë¦¬
      if (query.toLowerCase().includes('ì„œë²„')) {
        return this.generateMockServerResponse(query, mockContext);
      }
      
      // ìƒí™© ë¶„ì„ ì¿¼ë¦¬ - ë°ì´í„°ë§Œ ë³´ê³  AIê°€ ìŠ¤ìŠ¤ë¡œ íŒë‹¨
      if (query.toLowerCase().includes('ìƒí™©') || query.toLowerCase().includes('ë¶„ì„')) {
        return this.generateMockServerResponse(query, mockContext);
      }
    }

    // ì¼ë°˜ ì„œë²„ ê´€ë ¨ ì¿¼ë¦¬ ì²˜ë¦¬
    if (userContext?.servers && query.toLowerCase().includes('ì„œë²„')) {
      return this.generateServerResponse(query, userContext.servers);
    }

    if (ragResult.results.length === 0) {
      // Mock ëª¨ë“œì¼ ë•Œ ì¶”ê°€ ì•ˆë‚´
      if (mockContext) {
        return 'ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n' +
               'ğŸ­ í˜„ì¬ Mock ë°ì´í„° ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.\n' + 
               'ì„œë²„ ìƒíƒœ, ë©”íŠ¸ë¦­, ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”.';
      }
      return 'ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.';
    }

    let response = '';

    // RAG ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ
    const topResult = ragResult.results[0];
    response += topResult.content;

    // ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
    if (ragResult.results.length > 1) {
      response += '\n\nì¶”ê°€ ì •ë³´:\n';
      ragResult.results
        .slice(1, 3)
        .forEach((result, idx) => {
          response += `${idx + 1}. ${result.content.substring(0, 100)}...\n`;
        });
    }

    // MCP ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if (mcpContext && mcpContext.files.length > 0) {
      response += '\n\ní”„ë¡œì íŠ¸ íŒŒì¼ ì°¸ê³ :\n';
      mcpContext.files.slice(0, 2).forEach(file => {
        response += `- ${file.path}\n`;
      });
    }

    // Mock ëª¨ë“œ ì•ˆë‚´ ì¶”ê°€
    if (mockContext) {
      response += `\n\nğŸ­ Mock ë°ì´í„° ëª¨ë“œ (${mockContext.currentTime})`;
    }

    return response;
  }

  /**
   * ğŸ“Š ì„œë²„ ê´€ë ¨ ì‘ë‹µ ìƒì„±
   */
  private generateServerResponse(query: string, servers: ServerArray): string {
    const lowerQuery = query.toLowerCase();

    // CPU ì‚¬ìš©ë¥  ê´€ë ¨ ì¿¼ë¦¬
    if (lowerQuery.includes('cpu')) {
      const highCpuServers = servers.filter(s => s.cpu > 70);
      if (highCpuServers.length > 0) {
        return `CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ ì„œë²„:\n${highCpuServers
          .map(s => `- ${s.name}: ${s.cpu}%`)
          .join('\n')}`;
      }
      return 'CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤.';
    }

    // ì „ì²´ ì„œë²„ ìƒíƒœ ìš”ì•½
    if (lowerQuery.includes('ìƒíƒœ') || lowerQuery.includes('ìš”ì•½')) {
      const statusCount = {
        ì •ìƒ: servers.filter(
          s => s.status === 'healthy' || s.status === 'online'
        ).length,
        ì£¼ì˜: servers.filter(s => s.status === 'warning').length,
        ìœ„í—˜: servers.filter(
          s => s.status === 'critical' || s.status === 'offline'
        ).length,
      };

      return `ì „ì²´ ì„œë²„ ìƒíƒœ ìš”ì•½:\n- ì •ìƒ: ${statusCount.ì •ìƒ}ëŒ€\n- ì£¼ì˜: ${statusCount.ì£¼ì˜}ëŒ€\n- ìœ„í—˜: ${statusCount.ìœ„í—˜}ëŒ€\n\nì´ ${servers.length}ëŒ€ì˜ ì„œë²„ê°€ ëª¨ë‹ˆí„°ë§ë˜ê³  ìˆìŠµë‹ˆë‹¤.`;
    }

    return `${servers.length}ê°œì˜ ì„œë²„ê°€ ëª¨ë‹ˆí„°ë§ë˜ê³  ìˆìŠµë‹ˆë‹¤.`;
  }

  /**
   * ğŸ­ Mock ì„œë²„ ê´€ë ¨ ì‘ë‹µ ìƒì„± (ë°ì´í„° ê¸°ë°˜ ë¶„ì„ë§Œ)
   */
  private generateMockServerResponse(query: string, mockContext: any): string {
    const lowerQuery = query.toLowerCase();

    // ì „ì²´ ìƒíƒœ ìš”ì•½
    if (lowerQuery.includes('ìƒíƒœ') || lowerQuery.includes('ìš”ì•½')) {
      let analysis = `ğŸ­ ì„œë²„ ìƒíƒœ ë¶„ì„ (${mockContext.currentTime})\n\n` +
                    `ì „ì²´ ì„œë²„: ${mockContext.metrics.serverCount}ëŒ€\n` +
                    `- ìœ„í—˜: ${mockContext.metrics.criticalCount}ëŒ€\n` +
                    `- ê²½ê³ : ${mockContext.metrics.warningCount}ëŒ€\n` +
                    `- ì •ìƒ: ${mockContext.metrics.healthyCount}ëŒ€\n\n` +
                    `í‰ê·  ë©”íŠ¸ë¦­:\n` +
                    `- CPU: ${mockContext.metrics.avgCpu}%\n` +
                    `- Memory: ${mockContext.metrics.avgMemory}%\n` +
                    `- Disk: ${mockContext.metrics.avgDisk}%\n\n`;
      
      // ë°ì´í„° ê¸°ë°˜ ìƒí™© ë¶„ì„
      if (mockContext.metrics.criticalCount > mockContext.metrics.serverCount * 0.3) {
        analysis += `âš ï¸ ë¶„ì„: ì „ì²´ ì„œë²„ì˜ 30% ì´ìƒì´ ìœ„í—˜ ìƒíƒœì…ë‹ˆë‹¤. ëŒ€ê·œëª¨ ì¥ì• ê°€ ë°œìƒí–ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.`;
      } else if (mockContext.metrics.avgCpu > 80) {
        analysis += `ğŸ“Š ë¶„ì„: í‰ê·  CPU ì‚¬ìš©ë¥ ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. íŠ¸ë˜í”½ ê¸‰ì¦ì´ë‚˜ ì„±ëŠ¥ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`;
      } else if (mockContext.metrics.avgMemory > 85) {
        analysis += `ğŸ’¾ ë¶„ì„: ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ìœ„í—˜ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë‚˜ ê³¼ë¶€í•˜ ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`;
      } else {
        analysis += `âœ… ë¶„ì„: ì „ë°˜ì ìœ¼ë¡œ ì‹œìŠ¤í…œì´ ì•ˆì •ì ì¸ ìƒíƒœì…ë‹ˆë‹¤.`;
      }
      
      return analysis;
    }

    // CPU ê´€ë ¨ ì¿¼ë¦¬
    if (lowerQuery.includes('cpu')) {
      let cpuAnalysis = `ğŸ­ CPU ìƒíƒœ ë¶„ì„ (${mockContext.currentTime})\n\n` +
                       `í‰ê·  CPU ì‚¬ìš©ë¥ : ${mockContext.metrics.avgCpu}%\n`;
      
      if (mockContext.metrics.avgCpu > 70) {
        cpuAnalysis += `\nâš ï¸ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ì„±ëŠ¥ ì €í•˜ê°€ ì˜ˆìƒë©ë‹ˆë‹¤.`;
      } else if (mockContext.metrics.avgCpu < 30) {
        cpuAnalysis += `\nâœ… CPU ì‚¬ìš©ë¥ ì´ ë‚®ì•„ ì‹œìŠ¤í…œì´ ì—¬ìœ ë¡­ìŠµë‹ˆë‹¤.`;
      } else {
        cpuAnalysis += `\nğŸ“Š CPU ì‚¬ìš©ë¥ ì´ ì •ìƒ ë²”ìœ„ì…ë‹ˆë‹¤.`;
      }
      
      return cpuAnalysis;
    }

    // ìœ„í—˜/ë¬¸ì œ ì„œë²„
    if (lowerQuery.includes('ìœ„í—˜') || lowerQuery.includes('ë¬¸ì œ') || lowerQuery.includes('ì¥ì• ')) {
      if (mockContext.metrics.criticalCount > 0) {
        let problemAnalysis = `ğŸ­ ë¬¸ì œ ì„œë²„ ë¶„ì„ (${mockContext.currentTime})\n\n` +
                             `ìœ„í—˜ ì„œë²„: ${mockContext.metrics.criticalCount}ëŒ€\n` +
                             `ê²½ê³  ì„œë²„: ${mockContext.metrics.warningCount}ëŒ€\n\n`;
        
        // ë°ì´í„° íŒ¨í„´ìœ¼ë¡œ ë¬¸ì œ ì›ì¸ ì¶”ì¸¡
        if (mockContext.metrics.avgCpu > 80 && mockContext.metrics.criticalCount > 3) {
          problemAnalysis += `ğŸ’¡ ë¶„ì„: CPU ê³¼ë¶€í•˜ë¡œ ì¸í•œ ë‹¤ì¤‘ ì„œë²„ ì¥ì• ë¡œ ë³´ì…ë‹ˆë‹¤.`;
        } else if (mockContext.metrics.avgMemory > 85) {
          problemAnalysis += `ğŸ’¡ ë¶„ì„: ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì„œë²„ ë¬¸ì œë¡œ ì¶”ì •ë©ë‹ˆë‹¤.`;
        } else {
          problemAnalysis += `ğŸ’¡ ë¶„ì„: ê°œë³„ ì„œë²„ì˜ í•˜ë“œì›¨ì–´ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ë¬¸ì œì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.`;
        }
        
        return problemAnalysis;
      }
      return `ğŸ­ í˜„ì¬ ìœ„í—˜ ìƒíƒœì˜ ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤. (${mockContext.currentTime})`;
    }

    // ìƒí™© ë¶„ì„
    if (lowerQuery.includes('ìƒí™©') || lowerQuery.includes('ë¶„ì„')) {
      const criticalRatio = mockContext.metrics.criticalCount / mockContext.metrics.serverCount;
      const warningRatio = mockContext.metrics.warningCount / mockContext.metrics.serverCount;
      
      let situationAnalysis = `ğŸ­ í˜„ì¬ ìƒí™© ë¶„ì„ (${mockContext.currentTime})\n\n`;
      
      if (criticalRatio > 0.5) {
        situationAnalysis += `ğŸš¨ ì‹¬ê°: ì ˆë°˜ ì´ìƒì˜ ì„œë²„ê°€ ìœ„í—˜ ìƒíƒœì…ë‹ˆë‹¤. ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ ì¥ì• ê°€ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.\n`;
        situationAnalysis += `- í‰ê·  CPU: ${mockContext.metrics.avgCpu}%\n`;
        situationAnalysis += `- í‰ê·  Memory: ${mockContext.metrics.avgMemory}%\n`;
        situationAnalysis += `\nì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.`;
      } else if (criticalRatio > 0.2 || warningRatio > 0.4) {
        situationAnalysis += `âš ï¸ ì£¼ì˜: ë‹¤ìˆ˜ì˜ ì„œë²„ì—ì„œ ë¬¸ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n`;
        situationAnalysis += `- ìœ„í—˜: ${mockContext.metrics.criticalCount}ëŒ€ (${Math.round(criticalRatio * 100)}%)\n`;
        situationAnalysis += `- ê²½ê³ : ${mockContext.metrics.warningCount}ëŒ€ (${Math.round(warningRatio * 100)}%)\n`;
        situationAnalysis += `\nì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•´ì•¼ í•©ë‹ˆë‹¤.`;
      } else {
        situationAnalysis += `âœ… ì •ìƒ: ëŒ€ë¶€ë¶„ì˜ ì„œë²„ê°€ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n`;
        situationAnalysis += `- ì •ìƒ ì„œë²„: ${mockContext.metrics.healthyCount}ëŒ€\n`;
        situationAnalysis += `- í‰ê·  ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ ì´ ì ì • ìˆ˜ì¤€ì…ë‹ˆë‹¤.`;
      }
      
      return situationAnalysis;
    }

    // ê¸°ë³¸ ì‘ë‹µ
    return `ğŸ­ Mock ëª¨ë“œ (${mockContext.currentTime})\n\n` +
           mockContext.metrics.serverCount + 'ê°œì˜ ì„œë²„ê°€ ëª¨ë‹ˆí„°ë§ë˜ê³  ìˆìŠµë‹ˆë‹¤.';
  }

  /**
   * ğŸ—ï¸ Google AI í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  protected buildGoogleAIPrompt(
    query: string,
    context: AIQueryContext | undefined,
    mcpContext: MCPContext | null
  ): string {
    let prompt = `ì‚¬ìš©ì ì§ˆë¬¸: ${query}\n\n`;

    // Mock ëª¨ë“œ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    const mockContext = this.mockContextLoader.getMockContext();
    if (mockContext) {
      prompt += 'ğŸ­ Mock ë°ì´í„° ëª¨ë“œ:\n';
      prompt += this.mockContextLoader.generateContextString();
      prompt += '\n\n';
    }

    // ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    if (context && Object.keys(context).length > 0) {
      prompt += 'ì»¨í…ìŠ¤íŠ¸:\n';
      prompt += JSON.stringify(context, null, 2) + '\n\n';
    }

    // MCP ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    if (mcpContext && mcpContext.files.length > 0) {
      prompt += 'ê´€ë ¨ íŒŒì¼ ë‚´ìš©:\n';
      mcpContext.files.forEach(file => {
        prompt += `\níŒŒì¼: ${file.path}\n`;
        prompt += `${file.content.substring(0, 500)}...\n`;
      });
      prompt += '\n';
    }

    prompt += 'ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.';

    return prompt;
  }

  /**
   * ğŸ“Š ì‹ ë¢°ë„ ê³„ì‚°
   */
  protected calculateConfidence(ragResult: { results: Array<{ similarity: number }> }): number {
    if (ragResult.results.length === 0) return 0.1;

    // ìµœê³  ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„
    const topSimilarity = ragResult.results[0].similarity;
    const resultCount = ragResult.results.length;

    // ìœ ì‚¬ë„ì™€ ê²°ê³¼ ê°œìˆ˜ë¥¼ ì¢…í•©í•œ ì‹ ë¢°ë„
    const confidence =
      topSimilarity * 0.7 + Math.min(resultCount / 10, 1) * 0.3;

    return Math.min(confidence, 0.95);
  }

  /**
   * ğŸ”‘ ìºì‹œ í‚¤ ìƒì„±
   */
  private generateCacheKey(
    query: string,
    mode: string,
    context?: AIQueryContext
  ): string {
    const normalizedQuery = query.toLowerCase().trim();
    const contextKey = context?.servers ? 'with-servers' : 'no-context';
    return createCacheKey('ai', `${mode}:${normalizedQuery}:${contextKey}`);
  }

  /**
   * ğŸ“¦ ìºì‹œëœ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
   */
  private getCachedResponse(key: string): QueryResponse | null {
    const cached = this.responseCache.get(key);
    if (!cached) return null;

    const ttl = getTTL('aiResponse'); // 15ë¶„
    const age = Date.now() - cached.timestamp;

    if (age > ttl * 1000) {
      this.responseCache.delete(key);
      return null;
    }

    return cached.response;
  }

  /**
   * ğŸ’¾ ì‘ë‹µ ìºì‹±
   */
  private setCachedResponse(key: string, response: QueryResponse): void {
    // ìºì‹œ í¬ê¸° ì œí•œ ì²´í¬
    if (this.responseCache.size >= 100) {
      // ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì‚­ì œ
      const oldestKey = Array.from(this.responseCache.entries()).sort(
        (a, b) => a[1].timestamp - b[1].timestamp
      )[0][0];
      this.responseCache.delete(oldestKey);
    }

    // ë°ì´í„° í¬ê¸° ê²€ì¦
    if (validateDataSize(response, 'aiResponse')) {
      this.responseCache.set(key, {
        response,
        timestamp: Date.now(),
      });
    }
  }

  /**
   * ğŸ§¹ ìºì‹œ ì •ë¦¬
   */
  private cleanupCache(): void {
    const now = Date.now();
    const ttl = getTTL('aiResponse') * 1000;

    for (const [key, value] of this.responseCache.entries()) {
      if (now - value.timestamp > ttl) {
        this.responseCache.delete(key);
      }
    }
  }

  /**
   * ğŸš¨ í´ë°± ì‘ë‹µ ìƒì„±
   */
  private generateFallbackResponse(
    query: string,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number
  ): QueryResponse {
    thinkingSteps.push({
      step: 'í´ë°± ëª¨ë“œ',
      description: 'ëª¨ë“  ì—”ì§„ ì‹¤íŒ¨, ê¸°ë³¸ ì‘ë‹µ ìƒì„±',
      status: 'completed',
      timestamp: Date.now(),
    });

    return {
      success: true,
      response:
        'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.',
      engine: 'fallback',
      confidence: 0.1,
      thinkingSteps,
      processingTime: Date.now() - startTime,
    };
  }

  /**
   * ğŸ” ëª…ë ¹ì–´ ì¿¼ë¦¬ ê°ì§€
   */
  private detectCommandQuery(
    query: string, 
    commandContext?: any
  ): boolean {
    // 1. commandContextê°€ ëª…ì‹œì ìœ¼ë¡œ ì œê³µëœ ê²½ìš°
    if (commandContext?.isCommandRequest) {
      return true;
    }

    // 2. ëª…ë ¹ì–´ ê´€ë ¨ í‚¤ì›Œë“œ íŒ¨í„´ ê°ì§€
    const commandKeywords = [
      // í•œêµ­ì–´ íŒ¨í„´
      /ëª…ë ¹ì–´?\s*(ì–´ë–»?ê²Œ|ì–´ë–¤|ë¬´ì—‡|ë­|ì¶”ì²œ|ì•Œë ¤)/i,
      /ì–´ë–¤?\s*ëª…ë ¹ì–´?/i,
      /(ì‹¤í–‰|ì‚¬ìš©|ì…ë ¥)í•´ì•¼?\s*í• ?\s*ëª…ë ¹ì–´?/i,
      /(ì„œë²„|ì‹œìŠ¤í…œ)\s*(ê´€ë¦¬|ëª¨ë‹ˆí„°ë§|ì ê²€|í™•ì¸)\s*ëª…ë ¹ì–´?/i,
      /ë¦¬ëˆ…ìŠ¤|ìœˆë„ìš°|ë„ì»¤|ì¿ ë²„ë„¤í‹°ìŠ¤.*ëª…ë ¹ì–´?/i,
      
      // ì˜ì–´ íŒ¨í„´
      /what\s+(command|cmd)/i,
      /how\s+to\s+(run|execute|use)/i,
      /(server|system)\s+(command|cmd)/i,
      /(linux|windows|docker|k8s|kubectl)\s+(command|cmd)/i,
      
      // êµ¬ì²´ì  ëª…ë ¹ì–´ ì–¸ê¸‰
      /\b(top|htop|ps|grep|find|df|free|netstat|systemctl|docker|kubectl)\b/i,
    ];

    // 3. í‚¤ì›Œë“œ ë§¤ì¹­
    const hasKeyword = commandKeywords.some(pattern => pattern.test(query));
    if (hasKeyword) {
      return true;
    }

    // 4. ì„œë²„ ID + ëª…ë ¹ì–´ íŒ¨í„´ ê°ì§€
    const serverCommandPattern = /(web-prd|app-prd|db-main|db-repl|file-nas|backup).*ëª…ë ¹ì–´?/i;
    if (serverCommandPattern.test(query)) {
      return true;
    }

    return false;
  }

  /**
   * ğŸ› ï¸ ëª…ë ¹ì–´ ì¿¼ë¦¬ ì „ìš© ì²˜ë¦¬
   */
  private async processCommandQuery(
    query: string,
    commandContext: any,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number
  ): Promise<QueryResponse> {
    const commandStepStart = Date.now();
    
    // ëª…ë ¹ì–´ ë¶„ì„ ë‹¨ê³„ ì¶”ê°€
    thinkingSteps.push({
      step: 'ëª…ë ¹ì–´ ë¶„ì„',
      description: 'ëª…ë ¹ì–´ ìš”ì²­ ì„¸ë¶€ ë¶„ì„ ì¤‘',
      status: 'pending',
      timestamp: commandStepStart,
    });

    try {
      // UnifiedAIEngineRouter ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ë™ì  importë¡œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€)
      const { getUnifiedAIRouter } = await import('./UnifiedAIEngineRouter');
      const aiRouter = getUnifiedAIRouter();

      // ëª…ë ¹ì–´ ì¶”ì²œ ì‹œìŠ¤í…œ ì‚¬ìš©
      const recommendationResult = await aiRouter.getCommandRecommendations(query, {
        maxRecommendations: 5,
        includeAnalysis: true,
      });

      thinkingSteps[thinkingSteps.length - 1].status = 'completed';
      thinkingSteps[thinkingSteps.length - 1].description = 
        `${recommendationResult.recommendations.length}ê°œ ëª…ë ¹ì–´ ì¶”ì²œ ìƒì„±`;
      thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - commandStepStart;

      // ì‘ë‹µ ìƒì„±
      const responseStepStart = Date.now();
      thinkingSteps.push({
        step: 'ëª…ë ¹ì–´ ì‘ë‹µ ìƒì„±',
        description: 'ëª…ë ¹ì–´ ì¶”ì²œ ì‘ë‹µ í¬ë§·íŒ…',
        status: 'pending',
        timestamp: responseStepStart,
      });

      // ì‹ ë¢°ë„ ê³„ì‚° (ëª…ë ¹ì–´ ê°ì§€ ì •í™•ë„ ê¸°ë°˜)
      const confidence = Math.min(
        recommendationResult.analysis.confidence + 0.2, // ëª…ë ¹ì–´ ì‹œìŠ¤í…œ ë³´ë„ˆìŠ¤
        0.95
      );

      thinkingSteps[thinkingSteps.length - 1].status = 'completed';
      thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - responseStepStart;

      return {
        success: true,
        response: recommendationResult.formattedResponse,
        engine: 'local-rag', // ëª…ë ¹ì–´ëŠ” ë¡œì»¬ ì²˜ë¦¬
        confidence,
        thinkingSteps,
        metadata: {
          commandMode: true,
          recommendationCount: recommendationResult.recommendations.length,
          analysisResult: recommendationResult.analysis,
          requestType: commandContext?.requestType || 'command_request',
        } as AIMetadata & { 
          commandMode?: boolean;
          recommendationCount?: number;
          analysisResult?: any;
          requestType?: string;
        },
        processingTime: Date.now() - startTime,
      };

    } catch (error) {
      console.error('âŒ ëª…ë ¹ì–´ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      
      thinkingSteps[thinkingSteps.length - 1].status = 'failed';
      thinkingSteps[thinkingSteps.length - 1].description = 'ëª…ë ¹ì–´ ë¶„ì„ ì‹¤íŒ¨';
      thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - commandStepStart;

      // í´ë°±: ê¸°ë³¸ ëª…ë ¹ì–´ ì•ˆë‚´
      const fallbackResponse = this.generateCommandFallbackResponse(query);
      
      return {
        success: true,
        response: fallbackResponse,
        engine: 'fallback',
        confidence: 0.3,
        thinkingSteps,
        metadata: {
          commandMode: true,
          fallback: true,
        } as AIMetadata & { 
          commandMode?: boolean;
          fallback?: boolean;
        },
        processingTime: Date.now() - startTime,
      };
    }
  }

  /**
   * ğŸš¨ ëª…ë ¹ì–´ í´ë°± ì‘ë‹µ ìƒì„±
   */
  private generateCommandFallbackResponse(query: string): string {
    const lowerQuery = query.toLowerCase();
    
    // ì„œë²„ ìœ í˜•ë³„ ê¸°ë³¸ ëª…ë ¹ì–´ ì œì•ˆ
    if (lowerQuery.includes('linux') || lowerQuery.includes('ubuntu')) {
      return `Linux ì‹œìŠ¤í…œ ê´€ë¦¬ ê¸°ë³¸ ëª…ë ¹ì–´:\n\n` +
             `ğŸ“Š ëª¨ë‹ˆí„°ë§:\n` +
             `â€¢ top - ì‹¤ì‹œê°„ í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§\n` +
             `â€¢ htop - í–¥ìƒëœ í”„ë¡œì„¸ìŠ¤ ë·°ì–´\n` +
             `â€¢ free -h - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n` +
             `â€¢ df -h - ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n\n` +
             `ğŸ” ê²€ìƒ‰ ë° ê´€ë¦¬:\n` +
             `â€¢ ps aux | grep [í”„ë¡œì„¸ìŠ¤ëª…] - í”„ë¡œì„¸ìŠ¤ ê²€ìƒ‰\n` +
             `â€¢ systemctl status [ì„œë¹„ìŠ¤ëª…] - ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸\n` +
             `â€¢ netstat -tuln - ë„¤íŠ¸ì›Œí¬ í¬íŠ¸ í™•ì¸\n\n` +
             `ìì„¸í•œ ëª…ë ¹ì–´ëŠ” "web-prd-01 ëª…ë ¹ì–´" ê°™ì´ ì„œë²„ë¥¼ ì§€ì •í•´ì„œ ë¬¼ì–´ë³´ì„¸ìš”.`;
    }

    if (lowerQuery.includes('windows')) {
      return `Windows ì‹œìŠ¤í…œ ê´€ë¦¬ ê¸°ë³¸ ëª…ë ¹ì–´:\n\n` +
             `ğŸ“Š ëª¨ë‹ˆí„°ë§ (PowerShell):\n` +
             `â€¢ Get-Process | Sort-Object CPU -Descending - í”„ë¡œì„¸ìŠ¤ ì •ë ¬\n` +
             `â€¢ Get-Counter "\\Processor(_Total)\\% Processor Time" - CPU ì‚¬ìš©ë¥ \n` +
             `â€¢ Get-WmiObject Win32_LogicalDisk - ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰\n\n` +
             `ğŸ” ë„¤íŠ¸ì›Œí¬ ë° ì„œë¹„ìŠ¤:\n` +
             `â€¢ netstat -an | findstr LISTENING - ì—´ë¦° í¬íŠ¸ í™•ì¸\n` +
             `â€¢ Get-Service | Where-Object {$_.Status -eq "Running"} - ì‹¤í–‰ ì¤‘ì¸ ì„œë¹„ìŠ¤\n\n` +
             `ìì„¸í•œ ëª…ë ¹ì–´ëŠ” "file-nas-01 ëª…ë ¹ì–´"ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”.`;
    }

    // ì¼ë°˜ì ì¸ ëª…ë ¹ì–´ ì§ˆë¬¸
    return `ì„œë²„ ê´€ë¦¬ ëª…ë ¹ì–´ë¥¼ ì°¾ê³  ê³„ì‹œëŠ”êµ°ìš”! ğŸ› ï¸\n\n` +
           `ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì²´ì ìœ¼ë¡œ ë¬¼ì–´ë³´ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n` +
           `ğŸ“‹ ì˜ˆì‹œ:\n` +
           `â€¢ "web-prd-01 ì„œë²„ ëª…ë ¹ì–´" - Nginx ì›¹ì„œë²„ ê´€ë¦¬ ëª…ë ¹ì–´\n` +
           `â€¢ "db-main-01 PostgreSQL ëª…ë ¹ì–´" - ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ ëª…ë ¹ì–´\n` +
           `â€¢ "app-prd-01 Java ëª…ë ¹ì–´" - Tomcat ì• í”Œë¦¬ì¼€ì´ì…˜ ì„œë²„ ëª…ë ¹ì–´\n` +
           `â€¢ "Docker ì»¨í…Œì´ë„ˆ ëª…ë ¹ì–´" - ì»¨í…Œì´ë„ˆ ê´€ë¦¬ ëª…ë ¹ì–´\n\n` +
           `ğŸ’¡ í˜„ì¬ ê´€ë¦¬ ì¤‘ì¸ ì„œë²„: web-prd-01, web-prd-02, app-prd-01, app-prd-02, ` +
           `db-main-01, db-repl-01, file-nas-01, backup-01`;
  }

  /**
   * ğŸ¥ í—¬ìŠ¤ì²´í¬
   */
  async healthCheck(): Promise<{
    status: string;
    engines: {
      localRAG: boolean;
      googleAI: boolean;
      mcp: boolean;
    };
  }> {
    const ragHealth = await this.ragEngine.healthCheck();
    const mcpStatus = await this.contextLoader.getIntegratedStatus();

    return {
      status: ragHealth.status === 'healthy' ? 'healthy' : 'degraded',
      engines: {
        localRAG: ragHealth.vectorDB,
        googleAI: true, // API ì—”ë“œí¬ì¸íŠ¸ ì¡´ì¬ ì—¬ë¶€ë¡œ íŒë‹¨
        mcp: mcpStatus.mcpServer.status === 'online',
      },
    };
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let engineInstance: SimplifiedQueryEngine | null = null;

export function getSimplifiedQueryEngine(): SimplifiedQueryEngine {
  if (!engineInstance) {
    engineInstance = new SimplifiedQueryEngine();
  }
  return engineInstance;
}
