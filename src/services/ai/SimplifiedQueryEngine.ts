/**
 * ğŸ¯ SimplifiedQueryEngine - ë‹¨ìˆœí™”ëœ AI ì¿¼ë¦¬ ì—”ì§„
 *
 * âœ… ë¡œì»¬ ëª¨ë“œ: Supabase RAG ì—”ì§„ ì‚¬ìš©
 * âœ… Google AI ëª¨ë“œ: Gemini API ì§ì ‘ í˜¸ì¶œ
 * âœ… MCPëŠ” ì»¨í…ìŠ¤íŠ¸ ë³´ì¡°ë¡œë§Œ ì‚¬ìš©
 * âœ… API ì‚¬ìš©ëŸ‰ ìµœì í™”
 * âœ… ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„ ë° ìë™ ì—”ì§„ ì„ íƒ
 * âœ… ì‘ë‹µ ì‹œê°„ 500ms ì´í•˜ ëª©í‘œ
 */

import type { SupabaseRAGEngine } from './supabase-rag-engine';
import { getSupabaseRAGEngine } from './supabase-rag-engine';
import { CloudContextLoader } from '@/services/mcp/CloudContextLoader';
import { QueryComplexityAnalyzer } from './query-complexity-analyzer';
import type { ComplexityScore } from './query-complexity-analyzer';
import {
  createCacheKey,
  getTTL,
  validateDataSize,
} from '@/config/free-tier-cache-config';
import type {
  AIQueryContext,
  AIQueryOptions,
  MCPContext,
  RAGSearchResult,
  AIMetadata,
  ServerArray,
} from '@/types/ai-service-types';

export interface QueryRequest {
  query: string;
  mode?: 'local' | 'google-ai' | 'auto'; // auto ëª¨ë“œ ì¶”ê°€
  context?: AIQueryContext;
  options?: AIQueryOptions & {
    includeThinking?: boolean;
    includeMCPContext?: boolean;
    category?: string;
    cached?: boolean;
    timeoutMs?: number; // íƒ€ì„ì•„ì›ƒ ì„¤ì •
  };
}

export interface QueryResponse {
  success: boolean;
  response: string;
  engine: 'local-rag' | 'google-ai' | 'fallback';
  confidence: number;
  thinkingSteps: Array<{
    step: string;
    description?: string;
    status: 'pending' | 'completed' | 'failed';
    timestamp: number;
    duration?: number;
  }>;
  metadata?: AIMetadata & {
    complexity?: ComplexityScore;
    cacheHit?: boolean;
  };
  error?: string;
  processingTime: number;
}

export class SimplifiedQueryEngine {
  protected ragEngine: SupabaseRAGEngine;
  protected contextLoader: CloudContextLoader;
  protected isInitialized = false;
  private responseCache: Map<
    string,
    { response: QueryResponse; timestamp: number }
  > = new Map();
  private initPromise: Promise<void> | null = null;

  constructor() {
    this.ragEngine = getSupabaseRAGEngine();
    this.contextLoader = CloudContextLoader.getInstance();

    // ìºì‹œ ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬ (5ë¶„ë§ˆë‹¤)
    setInterval(() => this.cleanupCache(), 5 * 60 * 1000);
  }

  /**
   * ğŸš€ ì—”ì§„ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰)
   */
  async initialize(): Promise<void> {
    if (this.isInitialized) return;

    // ì´ë¯¸ ì´ˆê¸°í™” ì§„í–‰ ì¤‘ì´ë©´ ê¸°ë‹¤ë¦¼
    if (this.initPromise) {
      return this.initPromise;
    }

    this.initPromise = this.performInitialization();

    try {
      await this.initPromise;
    } finally {
      this.initPromise = null;
    }
  }

  private async performInitialization(): Promise<void> {
    try {
      console.log('ğŸš€ SimplifiedQueryEngine ì´ˆê¸°í™” ì¤‘...');

      // RAG ì—”ì§„ ì´ˆê¸°í™” (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
      const initTimeout = new Promise<void>((_, reject) =>
        setTimeout(() => reject(new Error('ì´ˆê¸°í™” íƒ€ì„ì•„ì›ƒ')), 5000)
      );

      await Promise.race([this.ragEngine.initialize(), initTimeout]);

      this.isInitialized = true;
      console.log('âœ… SimplifiedQueryEngine ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (error) {
      console.error('âŒ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      // ì´ˆê¸°í™” ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
      this.isInitialized = true;
    }
  }

  /**
   * ğŸ” ì¿¼ë¦¬ ì²˜ë¦¬ (ìºì‹± ë° ìë™ ì—”ì§„ ì„ íƒ)
   */
  async query(request: QueryRequest): Promise<QueryResponse> {
    const startTime = Date.now();

    // ì´ˆê¸°í™” ë³‘ë ¬ ì‹¤í–‰
    const initPromise = this.initialize();

    const {
      query,
      mode = 'auto', // ê¸°ë³¸ê°’: ìë™ ì„ íƒ
      context = {},
      options = {},
    } = request;

    const thinkingSteps: QueryResponse['thinkingSteps'] = [];
    const timeoutMs = options.timeoutMs || 450; // ê¸°ë³¸ 450ms (ëª©í‘œ: 500ms ì´í•˜)

    // ìºì‹œ í™•ì¸
    const cacheKey = this.generateCacheKey(query, mode, context);
    const cachedResponse = this.getCachedResponse(cacheKey);
    if (cachedResponse && options.cached !== false) {
      const baseMetadata = cachedResponse.metadata || {};
      return {
        ...cachedResponse,
        metadata: {
          ...baseMetadata,
          cacheHit: true,
        } as AIMetadata & { complexity?: ComplexityScore; cacheHit?: boolean },
        processingTime: Date.now() - startTime,
      };
    }

    // ì´ˆê¸°í™” ì™„ë£Œ ëŒ€ê¸°
    await initPromise;

    try {
      // ë¹ˆ ì¿¼ë¦¬ ì²´í¬
      if (!query || query.trim().length === 0) {
        return {
          success: true,
          response: 'ì§ˆì˜ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”',
          engine: 'local-rag',
          confidence: 0,
          thinkingSteps: [
            {
              step: 'ë¹ˆ ì¿¼ë¦¬ í™•ì¸',
              description: 'ì…ë ¥ëœ ì¿¼ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤',
              status: 'completed',
              timestamp: Date.now(),
            },
          ],
          processingTime: Date.now() - startTime,
        };
      }

      // 1ë‹¨ê³„: ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„ (ìë™ ëª¨ë“œì¼ ë•Œ)
      const complexityStartTime = Date.now();
      let complexity: ComplexityScore | undefined;
      let selectedMode = mode;

      if (mode === 'auto') {
        complexity = QueryComplexityAnalyzer.analyze(query, {
          hasServerData: !!context.servers,
          previousQueries: context.previousQueries,
        });

        selectedMode =
          complexity.recommendation === 'hybrid'
            ? 'local'
            : complexity.recommendation;

        thinkingSteps.push({
          step: 'ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„',
          description: `ë³µì¡ë„: ${complexity.score}/100, ì¶”ì²œ: ${complexity.recommendation}`,
          status: 'completed',
          timestamp: Date.now(),
          duration: Date.now() - complexityStartTime,
        });
      } else {
        thinkingSteps.push({
          step: 'ì¿¼ë¦¬ ë¶„ì„',
          description: `ëª¨ë“œ: ${mode}, ì¿¼ë¦¬ ê¸¸ì´: ${query.length}ì`,
          status: 'completed',
          timestamp: Date.now(),
        });
      }

      // 2ë‹¨ê³„: ë³‘ë ¬ ì²˜ë¦¬ ì¤€ë¹„
      const processingPromises: Promise<any>[] = [];
      let mcpContext: MCPContext | null = null;

      // MCP ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ë¹„ë™ê¸°)
      if (options.includeMCPContext && selectedMode === 'google-ai') {
        const mcpStepIndex = thinkingSteps.length;
        thinkingSteps.push({
          step: 'MCP ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘',
          status: 'pending',
          timestamp: Date.now(),
        });

        processingPromises.push(
          this.contextLoader
            .queryMCPContextForRAG(query, {
              maxFiles: 3, // ì„±ëŠ¥ì„ ìœ„í•´ íŒŒì¼ ìˆ˜ ì œí•œ
              includeSystemContext: true,
            })
            .then(result => {
              mcpContext = result;
              thinkingSteps[mcpStepIndex].status = 'completed';
              thinkingSteps[mcpStepIndex].description =
                `${result?.files?.length || 0}ê°œ íŒŒì¼ ìˆ˜ì§‘`;
              thinkingSteps[mcpStepIndex].duration =
                Date.now() - thinkingSteps[mcpStepIndex].timestamp;
            })
            .catch(error => {
              console.warn('MCP ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨:', error);
              thinkingSteps[mcpStepIndex].status = 'failed';
              thinkingSteps[mcpStepIndex].duration =
                Date.now() - thinkingSteps[mcpStepIndex].timestamp;
            })
        );
      }

      // ë³‘ë ¬ ì²˜ë¦¬ ëŒ€ê¸° (ìµœëŒ€ 100ms)
      if (processingPromises.length > 0) {
        await Promise.race([
          Promise.all(processingPromises),
          new Promise(resolve => setTimeout(resolve, 100)),
        ]);
      }

      // 3ë‹¨ê³„: íƒ€ì„ì•„ì›ƒì„ ê³ ë ¤í•œ ì¿¼ë¦¬ ì²˜ë¦¬
      const queryTimeout = new Promise<QueryResponse>((_, reject) =>
        setTimeout(() => reject(new Error('ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ')), timeoutMs)
      );

      let response: QueryResponse;

      try {
        if (selectedMode === 'local') {
          response = await Promise.race([
            this.processLocalQuery(
              query,
              context,
              options,
              mcpContext,
              thinkingSteps,
              startTime,
              complexity
            ),
            queryTimeout,
          ]);
        } else {
          response = await Promise.race([
            this.processGoogleAIQuery(
              query,
              context,
              options,
              mcpContext,
              thinkingSteps,
              startTime,
              complexity
            ),
            queryTimeout,
          ]);
        }

        // ì„±ê³µ ì‘ë‹µ ìºì‹±
        if (response.success && response.processingTime < 500) {
          this.setCachedResponse(cacheKey, response);
        }

        return response;
      } catch (_timeoutError) {
        // íƒ€ì„ì•„ì›ƒ ì‹œ ë¹ ë¥¸ í´ë°±
        console.warn('ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ, í´ë°± ëª¨ë“œë¡œ ì „í™˜');

        if (selectedMode === 'google-ai') {
          // Google AI íƒ€ì„ì•„ì›ƒ ì‹œ ë¡œì»¬ë¡œ í´ë°±
          return await this.processLocalQuery(
            query,
            context,
            options,
            null, // MCP ì»¨í…ìŠ¤íŠ¸ ìŠ¤í‚µ
            thinkingSteps,
            startTime,
            complexity
          );
        } else {
          // ë¡œì»¬ë„ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ì‘ë‹µ
          return this.generateFallbackResponse(query, thinkingSteps, startTime);
        }
      }
    } catch (error) {
      console.error('âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨:', error);

      return {
        success: false,
        response: 'ì£„ì†¡í•©ë‹ˆë‹¤. ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        engine: mode === 'local' ? 'local-rag' : 'google-ai',
        confidence: 0,
        thinkingSteps,
        error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜',
        processingTime: Date.now() - startTime,
      };
    }
  }

  /**
   * ğŸ  ë¡œì»¬ RAG ì¿¼ë¦¬ ì²˜ë¦¬ (ìµœì í™”ë¨)
   */
  private async processLocalQuery(
    query: string,
    context: AIQueryContext | undefined,
    options: QueryRequest['options'],
    mcpContext: MCPContext | null,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number,
    complexity?: ComplexityScore
  ): Promise<QueryResponse> {
    // RAG ê²€ìƒ‰
    const ragStepStart = Date.now();
    thinkingSteps.push({
      step: 'RAG ê²€ìƒ‰',
      description: 'Supabase ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰',
      status: 'pending',
      timestamp: ragStepStart,
    });

    // ë³µì¡ë„ì— ë”°ë¼ ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì¡°ì •
    const maxResults = complexity && complexity.score < 30 ? 3 : 5;
    const threshold = complexity && complexity.score < 30 ? 0.6 : 0.5;

    const ragResult = await this.ragEngine.searchSimilar(query, {
      maxResults,
      threshold,
      category: options?.category,
      enableMCP: false, // MCPëŠ” ì´ë¯¸ ë³„ë„ë¡œ ì²˜ë¦¬
    });

    thinkingSteps[thinkingSteps.length - 1].status = 'completed';
    thinkingSteps[thinkingSteps.length - 1].description =
      `${ragResult.totalResults}ê°œ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬`;
    thinkingSteps[thinkingSteps.length - 1].duration =
      Date.now() - ragStepStart;

    // ì‘ë‹µ ìƒì„±
    const responseStepStart = Date.now();
    thinkingSteps.push({
      step: 'ì‘ë‹µ ìƒì„±',
      description: 'ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ ìƒì„±',
      status: 'pending',
      timestamp: responseStepStart,
    });

    const response = this.generateLocalResponse(
      query,
      ragResult,
      mcpContext,
      context
    );

    thinkingSteps[thinkingSteps.length - 1].status = 'completed';
    thinkingSteps[thinkingSteps.length - 1].duration =
      Date.now() - responseStepStart;

    return {
      success: true,
      response,
      engine: 'local-rag',
      confidence: this.calculateConfidence(ragResult),
      thinkingSteps,
      metadata: {
        ragResults: ragResult.totalResults,
        cached: ragResult.cached,
        mcpUsed: !!mcpContext,
        complexity,
      } as AIMetadata & { complexity?: ComplexityScore; cacheHit?: boolean },
      processingTime: Date.now() - startTime,
    };
  }

  /**
   * ğŸŒ Google AI ì¿¼ë¦¬ ì²˜ë¦¬ (ìµœì í™”ë¨)
   */
  private async processGoogleAIQuery(
    query: string,
    context: AIQueryContext | undefined,
    options: QueryRequest['options'],
    mcpContext: MCPContext | null,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number,
    complexity?: ComplexityScore
  ): Promise<QueryResponse> {
    const googleStepStart = Date.now();
    thinkingSteps.push({
      step: 'Google AI ì¤€ë¹„',
      description: 'Gemini API í˜¸ì¶œ ì¤€ë¹„',
      status: 'pending',
      timestamp: googleStepStart,
    });

    try {
      // ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
      const prompt = this.buildGoogleAIPrompt(query, context, mcpContext);

      // ë³µì¡ë„ì— ë”°ë¼ íŒŒë¼ë¯¸í„° ì¡°ì •
      const temperature = complexity && complexity.score > 70 ? 0.8 : 0.7;
      const maxTokens = complexity && complexity.score > 70 ? 1500 : 1000;

      // Google AI API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), 400); // 400ms íƒ€ì„ì•„ì›ƒ

      const response = await fetch('/api/ai/google-ai/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          prompt,
          temperature,
          maxTokens,
        }),
        signal: controller.signal,
      });

      clearTimeout(timeout);

      if (!response.ok) {
        throw new Error(`Google AI API ì˜¤ë¥˜: ${response.statusText}`);
      }

      const data = await response.json();

      thinkingSteps[thinkingSteps.length - 1].status = 'completed';
      thinkingSteps[thinkingSteps.length - 1].description =
        'Gemini API ì‘ë‹µ ìˆ˜ì‹ ';
      thinkingSteps[thinkingSteps.length - 1].duration =
        Date.now() - googleStepStart;

      return {
        success: true,
        response: data.response || data.text || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        engine: 'google-ai',
        confidence: data.confidence || 0.9,
        thinkingSteps,
        metadata: {
          model: data.model || 'gemini-pro',
          tokensUsed: data.tokensUsed,
          mcpUsed: !!mcpContext,
          complexity,
        } as AIMetadata & { complexity?: ComplexityScore; cacheHit?: boolean },
        processingTime: Date.now() - startTime,
      };
    } catch (error) {
      console.error('Google AI ì²˜ë¦¬ ì˜¤ë¥˜:', error);

      // í´ë°±: ë¡œì»¬ RAGë¡œ ì „í™˜
      thinkingSteps[thinkingSteps.length - 1].status = 'failed';
      thinkingSteps[thinkingSteps.length - 1].description =
        'Google AI ì‹¤íŒ¨, ë¡œì»¬ ëª¨ë“œë¡œ ì „í™˜';
      thinkingSteps[thinkingSteps.length - 1].duration =
        Date.now() - googleStepStart;

      return await this.processLocalQuery(
        query,
        context,
        options,
        mcpContext,
        thinkingSteps,
        startTime,
        complexity
      );
    }
  }

  /**
   * ğŸ“ ë¡œì»¬ ì‘ë‹µ ìƒì„±
   */
  protected generateLocalResponse(
    query: string,
    ragResult: any, // RAGSearchResult from supabase-rag-engine
    mcpContext: MCPContext | null,
    userContext: AIQueryContext | undefined
  ): string {
    // ì„œë²„ ê´€ë ¨ ì¿¼ë¦¬ ì²˜ë¦¬
    if (userContext?.servers && query.toLowerCase().includes('ì„œë²„')) {
      return this.generateServerResponse(query, userContext.servers);
    }

    if (ragResult.results.length === 0) {
      return 'ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.';
    }

    let response = '';

    // RAG ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ
    const topResult = ragResult.results[0];
    response += topResult.content;

    // ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
    if (ragResult.results.length > 1) {
      response += '\n\nì¶”ê°€ ì •ë³´:\n';
      ragResult.results
        .slice(1, 3)
        .forEach((result: RAGSearchResult, idx: number) => {
          response += `${idx + 1}. ${result.content.substring(0, 100)}...\n`;
        });
    }

    // MCP ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if (mcpContext && mcpContext.files.length > 0) {
      response += '\n\ní”„ë¡œì íŠ¸ íŒŒì¼ ì°¸ê³ :\n';
      mcpContext.files.slice(0, 2).forEach(file => {
        response += `- ${file.path}\n`;
      });
    }

    return response;
  }

  /**
   * ğŸ“Š ì„œë²„ ê´€ë ¨ ì‘ë‹µ ìƒì„±
   */
  private generateServerResponse(query: string, servers: ServerArray): string {
    const lowerQuery = query.toLowerCase();

    // CPU ì‚¬ìš©ë¥  ê´€ë ¨ ì¿¼ë¦¬
    if (lowerQuery.includes('cpu')) {
      const highCpuServers = servers.filter(s => s.cpu > 70);
      if (highCpuServers.length > 0) {
        return `CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ ì„œë²„:\n${highCpuServers
          .map(s => `- ${s.name}: ${s.cpu}%`)
          .join('\n')}`;
      }
      return 'CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤.';
    }

    // ì „ì²´ ì„œë²„ ìƒíƒœ ìš”ì•½
    if (lowerQuery.includes('ìƒíƒœ') || lowerQuery.includes('ìš”ì•½')) {
      const statusCount = {
        ì •ìƒ: servers.filter(
          s => s.status === 'healthy' || s.status === 'online'
        ).length,
        ì£¼ì˜: servers.filter(s => s.status === 'warning').length,
        ìœ„í—˜: servers.filter(
          s => s.status === 'critical' || s.status === 'offline'
        ).length,
      };

      return `ì „ì²´ ì„œë²„ ìƒíƒœ ìš”ì•½:\n- ì •ìƒ: ${statusCount.ì •ìƒ}ëŒ€\n- ì£¼ì˜: ${statusCount.ì£¼ì˜}ëŒ€\n- ìœ„í—˜: ${statusCount.ìœ„í—˜}ëŒ€\n\nì´ ${servers.length}ëŒ€ì˜ ì„œë²„ê°€ ëª¨ë‹ˆí„°ë§ë˜ê³  ìˆìŠµë‹ˆë‹¤.`;
    }

    return `${servers.length}ê°œì˜ ì„œë²„ê°€ ëª¨ë‹ˆí„°ë§ë˜ê³  ìˆìŠµë‹ˆë‹¤.`;
  }

  /**
   * ğŸ—ï¸ Google AI í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  protected buildGoogleAIPrompt(
    query: string,
    context: AIQueryContext | undefined,
    mcpContext: MCPContext | null
  ): string {
    let prompt = `ì‚¬ìš©ì ì§ˆë¬¸: ${query}\n\n`;

    // ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    if (context && Object.keys(context).length > 0) {
      prompt += 'ì»¨í…ìŠ¤íŠ¸:\n';
      prompt += JSON.stringify(context, null, 2) + '\n\n';
    }

    // MCP ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    if (mcpContext && mcpContext.files.length > 0) {
      prompt += 'ê´€ë ¨ íŒŒì¼ ë‚´ìš©:\n';
      mcpContext.files.forEach(file => {
        prompt += `\níŒŒì¼: ${file.path}\n`;
        prompt += `${file.content.substring(0, 500)}...\n`;
      });
      prompt += '\n';
    }

    prompt += 'ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.';

    return prompt;
  }

  /**
   * ğŸ“Š ì‹ ë¢°ë„ ê³„ì‚°
   */
  protected calculateConfidence(ragResult: any): number {
    // RAGSearchResult from supabase-rag-engine
    if (ragResult.results.length === 0) return 0.1;

    // ìµœê³  ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„
    const topSimilarity = ragResult.results[0].similarity || 0;
    const resultCount = ragResult.results.length;

    // ìœ ì‚¬ë„ì™€ ê²°ê³¼ ê°œìˆ˜ë¥¼ ì¢…í•©í•œ ì‹ ë¢°ë„
    const confidence =
      topSimilarity * 0.7 + Math.min(resultCount / 10, 1) * 0.3;

    return Math.min(confidence, 0.95);
  }

  /**
   * ğŸ”‘ ìºì‹œ í‚¤ ìƒì„±
   */
  private generateCacheKey(
    query: string,
    mode: string,
    context?: AIQueryContext
  ): string {
    const normalizedQuery = query.toLowerCase().trim();
    const contextKey = context?.servers ? 'with-servers' : 'no-context';
    return createCacheKey('ai', `${mode}:${normalizedQuery}:${contextKey}`);
  }

  /**
   * ğŸ“¦ ìºì‹œëœ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
   */
  private getCachedResponse(key: string): QueryResponse | null {
    const cached = this.responseCache.get(key);
    if (!cached) return null;

    const ttl = getTTL('aiResponse'); // 15ë¶„
    const age = Date.now() - cached.timestamp;

    if (age > ttl * 1000) {
      this.responseCache.delete(key);
      return null;
    }

    return cached.response;
  }

  /**
   * ğŸ’¾ ì‘ë‹µ ìºì‹±
   */
  private setCachedResponse(key: string, response: QueryResponse): void {
    // ìºì‹œ í¬ê¸° ì œí•œ ì²´í¬
    if (this.responseCache.size >= 100) {
      // ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì‚­ì œ
      const oldestKey = Array.from(this.responseCache.entries()).sort(
        (a, b) => a[1].timestamp - b[1].timestamp
      )[0][0];
      this.responseCache.delete(oldestKey);
    }

    // ë°ì´í„° í¬ê¸° ê²€ì¦
    if (validateDataSize(response, 'aiResponse')) {
      this.responseCache.set(key, {
        response,
        timestamp: Date.now(),
      });
    }
  }

  /**
   * ğŸ§¹ ìºì‹œ ì •ë¦¬
   */
  private cleanupCache(): void {
    const now = Date.now();
    const ttl = getTTL('aiResponse') * 1000;

    for (const [key, value] of this.responseCache.entries()) {
      if (now - value.timestamp > ttl) {
        this.responseCache.delete(key);
      }
    }
  }

  /**
   * ğŸš¨ í´ë°± ì‘ë‹µ ìƒì„±
   */
  private generateFallbackResponse(
    query: string,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number
  ): QueryResponse {
    thinkingSteps.push({
      step: 'í´ë°± ëª¨ë“œ',
      description: 'ëª¨ë“  ì—”ì§„ ì‹¤íŒ¨, ê¸°ë³¸ ì‘ë‹µ ìƒì„±',
      status: 'completed',
      timestamp: Date.now(),
    });

    return {
      success: true,
      response:
        'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.',
      engine: 'fallback',
      confidence: 0.1,
      thinkingSteps,
      processingTime: Date.now() - startTime,
    };
  }

  /**
   * ğŸ¥ í—¬ìŠ¤ì²´í¬
   */
  async healthCheck(): Promise<{
    status: string;
    engines: {
      localRAG: boolean;
      googleAI: boolean;
      mcp: boolean;
    };
  }> {
    const ragHealth = await this.ragEngine.healthCheck();
    const mcpStatus = await this.contextLoader.getIntegratedStatus();

    return {
      status: ragHealth.status === 'healthy' ? 'healthy' : 'degraded',
      engines: {
        localRAG: ragHealth.vectorDB,
        googleAI: true, // API ì—”ë“œí¬ì¸íŠ¸ ì¡´ì¬ ì—¬ë¶€ë¡œ íŒë‹¨
        mcp: mcpStatus.mcpServer.status === 'online',
      },
    };
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let engineInstance: SimplifiedQueryEngine | null = null;

export function getSimplifiedQueryEngine(): SimplifiedQueryEngine {
  if (!engineInstance) {
    engineInstance = new SimplifiedQueryEngine();
  }
  return engineInstance;
}
