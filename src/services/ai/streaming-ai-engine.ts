/**
 * ğŸš€ Streaming AI Engine - 152ms ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ì´ˆê³ ì† AI ì—”ì§„
 *
 * í•µì‹¬ ìµœì í™” ì „ëµ:
 * 1. Edge Runtime ì™„ì „ í™œìš©
 * 2. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„
 * 3. ì˜ˆì¸¡ì  ìºì‹±
 * 4. ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
 * 5. ë©”ëª¨ë¦¬ ê¸°ë°˜ ì´ˆê³ ì† ì•¡ì„¸ìŠ¤
 *
 * ì„±ëŠ¥ ëª©í‘œ: 280ms â†’ 152ms (45% ê°œì„ )
 */

import { unifiedCache, CacheNamespace } from '@/lib/unified-cache';
import { getQueryCacheManager } from './query-cache-manager';
import { aiLogger } from '@/lib/logger';
import type { QueryRequest, QueryResponse } from './SimplifiedQueryEngine';

// Node.js Runtime ì‚¬ìš© (ì•ˆì •ì„± ìš°ì„ )
// Edge Runtime ì œê±°: Vercel ê²½ê³  í•´ê²° ë° ì•ˆì •ì„± í™•ë³´

interface StreamingConfig {
  enableStreaming: boolean;
  enablePredictiveCaching: boolean;
  enableParallelProcessing: boolean;
  maxConcurrency: number;
  targetResponseTime: number; // 152ms ëª©í‘œ
  streamingChunkSize: number;
  predictiveCacheSize: number;
}

interface StreamingMetrics {
  responseTime: number;
  cacheHitRate: number;
  streamingEfficiency: number;
  parallelEfficiency: number;
  predictiveAccuracy: number;
  memoryUsage: number;
}

interface PredictivePattern {
  pattern: string;
  frequency: number;
  avgResponseTime: number;
  nextLikelyQueries: string[];
  preloadPriority: number;
}

export class StreamingAIEngine {
  private config: StreamingConfig;
  private metrics: StreamingMetrics;
  private predictivePatterns = new Map<string, PredictivePattern>();
  private activeStreams = new Map<string, ReadableStream>();
  private preloadedResponses = new Map<string, QueryResponse>();

  constructor(config?: Partial<StreamingConfig>) {
    this.config = {
      enableStreaming: true,
      enablePredictiveCaching: true,
      enableParallelProcessing: true,
      maxConcurrency: 5,
      targetResponseTime: 152, // 152ms ëª©í‘œ
      streamingChunkSize: 1024,
      predictiveCacheSize: 50,
      ...config,
    };

    this.metrics = {
      responseTime: 0,
      cacheHitRate: 0,
      streamingEfficiency: 0,
      parallelEfficiency: 0,
      predictiveAccuracy: 0,
      memoryUsage: 0,
    };

    // ì˜ˆì¸¡ì  íŒ¨í„´ í•™ìŠµ ì‹œì‘
    this.initializePredictivePatterns();
  }

  /**
   * ğŸš€ ì´ˆê³ ì† ìŠ¤íŠ¸ë¦¬ë° ì¿¼ë¦¬ ì²˜ë¦¬
   */
  async query(request: QueryRequest): Promise<QueryResponse> {
    const startTime = performance.now();
    const streamId = this.generateStreamId(request);

    try {
      // 1. ì¦‰ì‹œ ìºì‹œ í™•ì¸ (< 1ms)
      const cached = await this.getInstantCache(request);
      if (cached) {
        this.updateMetrics('cache_hit', performance.now() - startTime);
        return cached;
      }

      // 2. ì˜ˆì¸¡ì  ì‘ë‹µ í™•ì¸ (< 5ms)
      const predicted = this.getPredictiveResponse(request);
      if (predicted) {
        this.updateMetrics('predictive_hit', performance.now() - startTime);
        return predicted;
      }

      // 3. ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹œì‘
      if (this.config.enableStreaming) {
        return await this.processStreamingQuery(request, streamId, startTime);
      }

      // 4. ë³‘ë ¬ ì²˜ë¦¬ í´ë°±
      return await this.processParallelQuery(request, startTime);
    } catch (error) {
      aiLogger.error('StreamingAIEngine ì˜¤ë¥˜', error);
      return this.createFallbackResponse(request, startTime);
    }
  }

  /**
   * âš¡ ì¦‰ì‹œ ìºì‹œ í™•ì¸ (< 1ms)
   */
  private async getInstantCache(
    request: QueryRequest
  ): Promise<QueryResponse | null> {
    try {
      // ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ì¦‰ì‹œ í™•ì¸
      const cacheKey = this.generateCacheKey(request);
      const cached = await unifiedCache.get<QueryResponse>(
        cacheKey,
        CacheNamespace.AI_RESPONSE
      );

      if (
        cached &&
        Date.now() -
          (typeof cached.metadata?.timestamp === 'number'
            ? cached.metadata.timestamp
            : cached.metadata?.timestamp instanceof Date
              ? cached.metadata.timestamp.getTime()
              : 0) <
          300000
      ) {
        // 5ë¶„ TTL
        return {
          ...cached,
          metadata: {
            ...cached.metadata,
            cached: true,
            cacheType: 'instant',
            processingTime: 1, // < 1ms
          },
        };
      }
    } catch (error) {
      aiLogger.warn('ì¦‰ì‹œ ìºì‹œ í™•ì¸ ì‹¤íŒ¨', error);
    }

    return null;
  }

  /**
   * ğŸ”® ì˜ˆì¸¡ì  ì‘ë‹µ (< 5ms)
   */
  private getPredictiveResponse(request: QueryRequest): QueryResponse | null {
    if (!this.config.enablePredictiveCaching) return null;

    try {
      const pattern = this.extractPattern(request.query);
      const preloaded = this.preloadedResponses.get(pattern);

      if (preloaded) {
        // ì‘ë‹µì„ í˜„ì¬ ì¿¼ë¦¬ì— ë§ê²Œ ì¡°ì •
        return {
          ...preloaded,
          response: this.adaptResponseToQuery(
            preloaded.response,
            request.query
          ),
          metadata: {
            ...preloaded.metadata,
            predictive: true,
            processingTime: 5,
          },
        };
      }
    } catch (error) {
      aiLogger.warn('ì˜ˆì¸¡ì  ì‘ë‹µ ì‹¤íŒ¨', error);
    }

    return null;
  }

  /**
   * ğŸŒŠ ìŠ¤íŠ¸ë¦¬ë° ì¿¼ë¦¬ ì²˜ë¦¬
   */
  private async processStreamingQuery(
    request: QueryRequest,
    streamId: string,
    startTime: number
  ): Promise<QueryResponse> {
    try {
      // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
      const stream = new ReadableStream({
        start: (controller) => {
          this.activeStreams.set(streamId, stream);

          // ë¹ ë¥¸ ì´ˆê¸° ì‘ë‹µ (50ms ì´ë‚´)
          setTimeout(() => {
            const initialChunk = this.generateInitialResponse(request);
            controller.enqueue(
              new TextEncoder().encode(JSON.stringify(initialChunk))
            );
          }, 20);

          // ë³‘ë ¬ë¡œ ì™„ì „í•œ ì‘ë‹µ ì²˜ë¦¬
          void this.processCompleteResponse(request, controller, startTime);
        },
      });

      // ìŠ¤íŠ¸ë¦¼ì—ì„œ ìµœì¢… ì‘ë‹µ ëŒ€ê¸°
      return await this.collectStreamResponse(stream, startTime);
    } catch (error) {
      aiLogger.error('ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹¤íŒ¨', error);
      return this.processParallelQuery(request, startTime);
    }
  }

  /**
   * ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬ (í´ë°± ë˜ëŠ” ë©”ì¸ ëª¨ë“œ)
   */
  private async processParallelQuery(
    request: QueryRequest,
    startTime: number
  ): Promise<QueryResponse> {
    const tasks: Promise<QueryResponse | null>[] = [];

    // 1. Supabase RAG ê²€ìƒ‰ (ë³‘ë ¬)
    tasks.push(this.processRAGQuery(request));

    // 2. íŒ¨í„´ ë§¤ì¹­ ì‘ë‹µ (ë³‘ë ¬)
    tasks.push(this.processPatternQuery(request));

    // 3. ê¸°ë³¸ ì‘ë‹µ ìƒì„± (ë³‘ë ¬)
    if (tasks.length < this.config.maxConcurrency) {
      tasks.push(this.processBasicQuery(request));
    }

    try {
      // Race ë°©ì‹ìœ¼ë¡œ ì²« ë²ˆì§¸ ì„±ê³µ ì‘ë‹µ ì‚¬ìš©
      const results = await Promise.allSettled(tasks);

      for (const result of results) {
        if (result.status === 'fulfilled' && result.value) {
          const response = result.value;
          response.processingTime = performance.now() - startTime;

          // ë¹„ë™ê¸°ë¡œ ìºì‹œ ë° íŒ¨í„´ í•™ìŠµ
          void this.learnAndCache(request, response);

          return response;
        }
      }

      // ëª¨ë“  ì‘ì—… ì‹¤íŒ¨ ì‹œ í´ë°±
      return this.createFallbackResponse(request, startTime);
    } catch (error) {
      aiLogger.error('ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨', error);
      return this.createFallbackResponse(request, startTime);
    }
  }

  /**
   * ğŸ§  RAG ì¿¼ë¦¬ ì²˜ë¦¬
   */
  private async processRAGQuery(
    request: QueryRequest
  ): Promise<QueryResponse | null> {
    try {
      const cacheManager = getQueryCacheManager();

      // íŒ¨í„´ ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
      const patternResponse = await cacheManager.getFromPatternCache(
        request.query
      );
      if (patternResponse) {
        return {
          ...patternResponse,
          metadata: {
            ...patternResponse.metadata,
            source: 'rag_pattern_cache',
          },
        };
      }

      // ì‹¤ì œ RAG ê²€ìƒ‰ì€ ì‹œê°„ì´ ê±¸ë¦¬ë¯€ë¡œ ìŠ¤í‚µí•˜ê³  íŒ¨í„´ ê¸°ë°˜ ì‘ë‹µ ì‚¬ìš©
      return null;
    } catch (error) {
      aiLogger.warn('RAG ì²˜ë¦¬ ì‹¤íŒ¨', error);
      return null;
    }
  }

  /**
   * ğŸ¯ íŒ¨í„´ ë§¤ì¹­ ì¿¼ë¦¬ ì²˜ë¦¬
   */
  private async processPatternQuery(
    request: QueryRequest
  ): Promise<QueryResponse | null> {
    try {
      const pattern = this.extractPattern(request.query);
      const knownPattern = this.predictivePatterns.get(pattern);

      if (knownPattern && knownPattern.frequency > 5) {
        return {
          success: true,
          response: this.generatePatternBasedResponse(
            request.query,
            knownPattern
          ),
          engine: 'pattern-matched' as const,
          confidence: Math.min(0.8, knownPattern.frequency / 100),
          thinkingSteps: [
            {
              step: 'íŒ¨í„´ ë§¤ì¹­',
              description: `ì´ì „ ${knownPattern.frequency}íšŒ íŒ¨í„´ê³¼ ë§¤ì¹­`,
              status: 'completed',
              timestamp: Date.now(),
            },
          ],
          metadata: {
            pattern,
            frequency: knownPattern.frequency,
            source: 'pattern_matching',
          },
          processingTime: 15, // ë§¤ìš° ë¹ ë¥¸ íŒ¨í„´ ë§¤ì¹­
        };
      }

      return null;
    } catch (error) {
      aiLogger.warn('íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨', error);
      return null;
    }
  }

  /**
   * ğŸ“ ê¸°ë³¸ ì¿¼ë¦¬ ì²˜ë¦¬
   */
  private async processBasicQuery(
    request: QueryRequest
  ): Promise<QueryResponse | null> {
    // ë§¤ìš° ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ
    const keywords = this.extractKeywords(request.query);
    const response = this.generateKeywordBasedResponse(keywords, request.query);

    return {
      success: true,
      response,
      engine: 'basic-keyword' as const,
      confidence: 0.6,
      thinkingSteps: [
        {
          step: 'í‚¤ì›Œë“œ ë¶„ì„',
          description: `${keywords.length}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ`,
          status: 'completed',
          timestamp: Date.now(),
        },
      ],
      metadata: {
        keywords,
        source: 'basic_query',
      },
      processingTime: 10, // ë§¤ìš° ë¹ ë¥¸ ê¸°ë³¸ ì²˜ë¦¬
    };
  }

  /**
   * ğŸ¯ ì´ˆê¸° ì‘ë‹µ ìƒì„± (20ms ì´ë‚´)
   */
  private generateInitialResponse(
    _request: QueryRequest
  ): Partial<QueryResponse> {
    return {
      success: true,
      response: 'ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...',
      engine: 'streaming-initial' as const,
      confidence: 0.1,
      metadata: {
        streaming: true,
        initial: true,
      },
    };
  }

  /**
   * ğŸ“Š ì™„ì „í•œ ì‘ë‹µ ì²˜ë¦¬ (ë¹„ë™ê¸°)
   */
  private async processCompleteResponse(
    request: QueryRequest,
    controller: ReadableStreamDefaultController,
    startTime: number
  ): Promise<void> {
    try {
      // ë³‘ë ¬ë¡œ ì™„ì „í•œ ì‘ë‹µ ìƒì„±
      const response = await this.processParallelQuery(request, startTime);

      // ìŠ¤íŠ¸ë¦¼ì— ìµœì¢… ì‘ë‹µ ì „ì†¡
      controller.enqueue(new TextEncoder().encode(JSON.stringify(response)));
      controller.close();
    } catch (error) {
      controller.error(error);
    }
  }

  /**
   * ğŸŒŠ ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ìˆ˜ì§‘
   */
  private async collectStreamResponse(
    stream: ReadableStream,
    startTime: number
  ): Promise<QueryResponse> {
    try {
      const reader = stream.getReader();
      let finalResponse: QueryResponse | null = null;

      // íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ì‘ë‹µ ìˆ˜ì§‘
      const timeout = new Promise<QueryResponse>((_, reject) =>
        setTimeout(
          () => reject(new Error('Stream timeout')),
          this.config.targetResponseTime
        )
      );

      const streamProcessing = (async (): Promise<QueryResponse> => {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          try {
            const chunk = new TextDecoder().decode(value);
            const parsed = JSON.parse(chunk);

            if (parsed.success && parsed.response) {
              finalResponse = parsed;
            }
          } catch {
            // íŒŒì‹± ì—ëŸ¬ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì†
          }
        }

        return (
          finalResponse ||
          this.createFallbackResponse({} as QueryRequest, startTime)
        );
      })();

      return await Promise.race([streamProcessing, timeout]);
    } catch (error) {
      aiLogger.error('ìŠ¤íŠ¸ë¦¼ ìˆ˜ì§‘ ì‹¤íŒ¨', error);
      return this.createFallbackResponse({} as QueryRequest, startTime);
    }
  }

  /**
   * ğŸ§  íŒ¨í„´ í•™ìŠµ ë° ìºì‹± (ë¹„ë™ê¸°)
   */
  private async learnAndCache(
    request: QueryRequest,
    response: QueryResponse
  ): Promise<void> {
    try {
      // íŒ¨í„´ í•™ìŠµ
      const pattern = this.extractPattern(request.query);
      const existing = this.predictivePatterns.get(pattern);

      if (existing) {
        existing.frequency++;
        existing.avgResponseTime =
          (existing.avgResponseTime + response.processingTime) / 2;
      } else {
        this.predictivePatterns.set(pattern, {
          pattern,
          frequency: 1,
          avgResponseTime: response.processingTime,
          nextLikelyQueries: [],
          preloadPriority: 1,
        });
      }

      // ì‘ë‹µ ìºì‹±
      const cacheKey = this.generateCacheKey(request);
      await unifiedCache.set(cacheKey, response, {
        ttlSeconds: 300,
        namespace: CacheNamespace.AI_RESPONSE,
        pattern,
        metadata: { responseTime: response.processingTime },
      });

      // ì˜ˆì¸¡ì  ì‘ë‹µ ì‚¬ì „ ë¡œë”©
      if (response.processingTime < this.config.targetResponseTime) {
        this.preloadedResponses.set(pattern, response);
      }
    } catch (error) {
      aiLogger.warn('íŒ¨í„´ í•™ìŠµ ì‹¤íŒ¨', error);
    }
  }

  /**
   * ğŸ”‘ ìºì‹œ í‚¤ ìƒì„±
   */
  private generateCacheKey(request: QueryRequest): string {
    const normalized = request.query.toLowerCase().trim();
    return `streaming:${this.hashString(normalized)}`;
  }

  /**
   * ğŸ¯ íŒ¨í„´ ì¶”ì¶œ
   */
  private extractPattern(query: string): string {
    return query
      .toLowerCase()
      .replace(/\d+/g, '{number}')
      .replace(/\b(ì„œë²„|cpu|ë©”ëª¨ë¦¬|ë””ìŠ¤í¬|ë„¤íŠ¸ì›Œí¬)\s*\S*/g, '$1 {value}')
      .trim();
  }

  /**
   * ğŸ”¤ í‚¤ì›Œë“œ ì¶”ì¶œ
   */
  private extractKeywords(query: string): string[] {
    const stopWords = new Set([
      'ì€',
      'ëŠ”',
      'ì´',
      'ê°€',
      'ì„',
      'ë¥¼',
      'ì˜',
      'ì—',
      'ì—ì„œ',
      'ìœ¼ë¡œ',
      'ë¡œ',
    ]);
    return query
      .split(/\s+/)
      .filter((word) => word.length > 1 && !stopWords.has(word))
      .slice(0, 5);
  }

  /**
   * ğŸ“ íŒ¨í„´ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
   */
  private generatePatternBasedResponse(
    query: string,
    pattern: PredictivePattern
  ): string {
    const templates = [
      `${query}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.`,
      `ìš”ì²­í•˜ì‹  ${query} ê´€ë ¨ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.`,
      `${query}ì— ëŒ€í•´ ${pattern.frequency}íšŒì˜ ì´ì „ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤.`,
    ];

    const randomIndex = Math.floor(Math.random() * templates.length);
    return (
      templates[randomIndex] ??
      templates[0] ??
      `${query}ì— ëŒ€í•œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.`
    );
  }

  /**
   * ğŸ”¤ í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
   */
  private generateKeywordBasedResponse(
    keywords: string[],
    query: string
  ): string {
    if (keywords.length === 0) {
      return 'ì§ˆë¬¸ì— ëŒ€í•œ ê¸°ë³¸ ì •ë³´ë¥¼ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.';
    }

    const primaryKeyword = keywords[0];
    return `${primaryKeyword}ì— ëŒ€í•œ ì •ë³´: ${query}ì™€ ê´€ë ¨ëœ ìƒì„¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.`;
  }

  /**
   * ğŸ†˜ í´ë°± ì‘ë‹µ ìƒì„±
   */
  private createFallbackResponse(
    request: QueryRequest,
    startTime: number
  ): QueryResponse {
    return {
      success: true,
      response:
        'í˜„ì¬ ì‹œìŠ¤í…œì´ ìµœì í™” ëª¨ë“œë¡œ ë™ì‘ì¤‘ì…ë‹ˆë‹¤. ê¸°ë³¸ ì •ë³´ë¥¼ ì œê³µí•´ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
      engine: 'streaming-fallback' as const,
      confidence: 0.3,
      thinkingSteps: [
        {
          step: 'í´ë°± ëª¨ë“œ',
          description: 'ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•œ í´ë°± ì²˜ë¦¬',
          status: 'completed',
          timestamp: Date.now(),
        },
      ],
      metadata: {
        fallback: true,
        targetTime: this.config.targetResponseTime,
      },
      processingTime: performance.now() - startTime,
    };
  }

  /**
   * ğŸ”§ ì‘ë‹µì„ ì¿¼ë¦¬ì— ë§ê²Œ ì¡°ì •
   */
  private adaptResponseToQuery(baseResponse: string, query: string): string {
    // ê°„ë‹¨í•œ í…œí”Œë¦¿ ì¹˜í™˜
    return baseResponse.replace(/\{query\}/g, query);
  }

  /**
   * #ï¸âƒ£ ë¬¸ìì—´ í•´ì‹œ
   */
  private hashString(str: string): string {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = (hash << 5) - hash + char;
      hash = hash & hash;
    }
    return Math.abs(hash).toString(36);
  }

  /**
   * ğŸ”„ ìŠ¤íŠ¸ë¦¼ ID ìƒì„±
   */
  private generateStreamId(request: QueryRequest): string {
    return `stream_${Date.now()}_${this.hashString(request.query)}`;
  }

  /**
   * ğŸ“Š ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
   */
  private updateMetrics(
    type: 'cache_hit' | 'predictive_hit' | 'streaming' | 'parallel',
    responseTime: number
  ): void {
    this.metrics.responseTime = (this.metrics.responseTime + responseTime) / 2;

    if (type === 'cache_hit' || type === 'predictive_hit') {
      this.metrics.cacheHitRate = Math.min(
        this.metrics.cacheHitRate + 0.1,
        1.0
      );
    }

    if (responseTime < this.config.targetResponseTime) {
      this.metrics.streamingEfficiency = Math.min(
        this.metrics.streamingEfficiency + 0.05,
        1.0
      );
    }
  }

  /**
   * ğŸ¯ ì˜ˆì¸¡ì  íŒ¨í„´ ì´ˆê¸°í™”
   */
  private initializePredictivePatterns(): void {
    // ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒ¨í„´ë“¤ ì‚¬ì „ ë¡œë”©
    const commonPatterns = [
      'cpu ì‚¬ìš©ë¥ ',
      'ë©”ëª¨ë¦¬ ìƒíƒœ',
      'ë””ìŠ¤í¬ ìš©ëŸ‰',
      'ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½',
      'ì„œë²„ ìƒíƒœ',
      'ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§',
    ];

    commonPatterns.forEach((pattern) => {
      this.predictivePatterns.set(pattern, {
        pattern,
        frequency: 10,
        avgResponseTime: 100,
        nextLikelyQueries: [],
        preloadPriority: 5,
      });
    });
  }

  /**
   * ğŸ“Š ì„±ëŠ¥ í†µê³„ ì¡°íšŒ
   */
  getPerformanceStats(): StreamingMetrics & {
    targetAchievementRate: number;
    patternsLearned: number;
    preloadedResponses: number;
  } {
    const targetAchievementRate =
      this.metrics.responseTime <= this.config.targetResponseTime
        ? 1.0
        : this.config.targetResponseTime / this.metrics.responseTime;

    return {
      ...this.metrics,
      targetAchievementRate,
      patternsLearned: this.predictivePatterns.size,
      preloadedResponses: this.preloadedResponses.size,
    };
  }

  /**
   * ğŸ§¹ ìºì‹œ ë° íŒ¨í„´ ì •ë¦¬
   */
  cleanup(): void {
    // í™œì„± ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
    this.activeStreams.clear();

    // ì˜¤ë˜ëœ ì˜ˆì¸¡ì  ì‘ë‹µ ì •ë¦¬
    const cutoff = Date.now() - 600000; // 10ë¶„
    for (const [key, response] of this.preloadedResponses.entries()) {
      const timestamp =
        typeof response.metadata?.timestamp === 'number'
          ? response.metadata.timestamp
          : response.metadata?.timestamp instanceof Date
            ? response.metadata.timestamp.getTime()
            : 0;
      if (timestamp < cutoff) {
        this.preloadedResponses.delete(key);
      }
    }
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let streamingEngineInstance: StreamingAIEngine | null = null;

export function getStreamingAIEngine(
  config?: Partial<StreamingConfig>
): StreamingAIEngine {
  if (!streamingEngineInstance) {
    streamingEngineInstance = new StreamingAIEngine(config);

    // 10ë¶„ë§ˆë‹¤ ì •ë¦¬
    setInterval(() => streamingEngineInstance?.cleanup(), 10 * 60 * 1000);
  }

  return streamingEngineInstance;
}
