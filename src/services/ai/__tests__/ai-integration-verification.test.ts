/**
 * ðŸ§ª AI ì‹œìŠ¤í…œ í†µí•© ê²€ì¦ í…ŒìŠ¤íŠ¸
 * 
 * í•µì‹¬ ê²€ì¦ í•­ëª©:
 * - ë¡œì»¬ AI vs í´ë¼ìš°ë“œ AI ëª¨ë“œ ë¹„êµ
 * - GCP Cloud Functions í†µí•©
 * - AI ì–´ì‹œìŠ¤í„´íŠ¸ ê¸°ëŠ¥ ì „ì²´ ì›Œí¬í”Œë¡œìš°
 * - ì‹¤ì œ ì‚¬ìš©ìž ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
 */

import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
import {
  SimplifiedQueryEngine,
  getSimplifiedQueryEngine,
} from '../SimplifiedQueryEngine';
import type { QueryRequest, QueryResponse } from '../SimplifiedQueryEngine.types';
import type { AIQueryContext } from '@/types/ai-service-types';
import { getGCPFunctionsClient, analyzeKoreanNLP } from '@/lib/gcp/gcp-functions-client';

// Mock GCP Functions for testing
vi.mock('@/lib/gcp/gcp-functions-client', () => ({
  getGCPFunctionsClient: vi.fn(() => ({
    callFunction: vi.fn().mockResolvedValue({
      success: true,
      data: {
        intent: 'server_monitoring',
        confidence: 0.85,
        analysis: {
          intent: 'server_status_check',
          sentiment: 'neutral',
          keywords: ['ì„œë²„', 'ìƒíƒœ', 'í™•ì¸'],
          topics: ['monitoring', 'system'],
          summary: 'ì„œë²„ ìƒíƒœ í™•ì¸ ìš”ì²­'
        }
      }
    })
  })),
  analyzeKoreanNLP: vi.fn().mockResolvedValue({
    success: true,
    data: {
      intent: 'server_monitoring',
      entities: [
        { type: 'service', value: 'ì„œë²„', confidence: 0.9 }
      ],
      semantic_analysis: {
        main_topic: 'Server Monitoring',
        urgency_level: 'medium',
        technical_complexity: 0.7
      }
    }
  })
}));

// Mock other dependencies
vi.mock('../supabase-rag-engine', () => ({
  getSupabaseRAGEngine: vi.fn(() => ({
    searchSimilar: vi.fn().mockResolvedValue({
      results: [
        {
          content: 'ì„œë²„ ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ: CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ ì‚¬ìš©ë¥  í™•ì¸',
          similarity: 0.87,
          metadata: { category: 'monitoring', source: 'knowledge_base' }
        }
      ],
      totalResults: 1,
      cached: false
    }),
    _initialize: vi.fn().mockResolvedValue(undefined),
    healthCheck: vi.fn().mockResolvedValue({ status: 'healthy', vectorDB: true })
  }))
}));

vi.mock('@/services/mcp/CloudContextLoader', () => ({
  CloudContextLoader: {
    getInstance: vi.fn(() => ({
      queryMCPContextForRAG: vi.fn().mockResolvedValue({
        files: [
          { path: '/monitoring/server-status.md', content: 'ì„œë²„ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë¬¸ì„œ' }
        ],
        systemContext: { activeServers: 15 }
      }),
      getIntegratedStatus: vi.fn().mockResolvedValue({
        mcpServer: { status: 'online' }
      })
    }))
  }
}));

vi.mock('../embedding-service', () => ({
  embeddingService: {
    createEmbedding: vi.fn().mockImplementation(async (text: string) => {
      const hash = text.split('').reduce((a, b) => { a = ((a << 5) - a) + b.charCodeAt(0); return a & a }, 0);
      const embedding = Array.from({ length: 384 }, (_, i) => Math.sin(hash + i) * 0.1);
      const magnitude = Math.sqrt(embedding.reduce((sum, val) => sum + val * val, 0));
      return magnitude > 0 ? embedding.map(v => v / magnitude) : embedding;
    }),
    clearCache: vi.fn(),
    getCacheStats: vi.fn(() => ({ size: 0, maxSize: 1000, hitRate: 0, hits: 0, misses: 0 }))
  }
}));

// Mock other required modules
vi.mock('../query-complexity-analyzer', () => ({
  QueryComplexityAnalyzer: {
    analyze: vi.fn(() => ({
      score: 50,
      recommendation: 'local',
      confidence: 0.8,
      factors: { length: 15, keywords: 2, patterns: 1, context: 1, language: 0 }
    }))
  }
}));

vi.mock('@/config/free-tier-cache-config', () => ({
  createCacheKey: vi.fn((prefix, key) => `${prefix}:${key}`),
  getTTL: vi.fn(() => 900),
  validateDataSize: vi.fn(() => true)
}));

vi.mock('@/lib/env-safe', () => ({
  validateGoogleAIMCPConfig: vi.fn(() => ({
    isValid: true,
    errors: [],
    warnings: [],
    config: {
      googleAI: {
        isValid: true,
        apiKey: 'test-api-key',
        modelName: 'gemini-pro',
        maxTokens: 2000,
        temperature: 0.7
      }
    }
  }))
}));

// Mock fetch for Google AI API
global.fetch = vi.fn();

const TEST_TIMEOUT = 15000; // 15 seconds

describe('AI System Integration Verification', () => {
  let engine: SimplifiedQueryEngine;

  // Test environment variables
  const originalEnv = {
    USE_LOCAL_EMBEDDINGS: process.env.USE_LOCAL_EMBEDDINGS,
    GOOGLE_AI_ENABLED: process.env.GOOGLE_AI_ENABLED,
    GOOGLE_AI_API_KEY: process.env.GOOGLE_AI_API_KEY,
    NEXT_PUBLIC_GCP_FUNCTIONS_URL: process.env.NEXT_PUBLIC_GCP_FUNCTIONS_URL,
  };

  beforeEach(() => {
    vi.clearAllMocks();
    engine = new SimplifiedQueryEngine();
  });

  afterEach(() => {
    // Restore original environment variables
    Object.keys(originalEnv).forEach(key => {
      if (originalEnv[key as keyof typeof originalEnv] !== undefined) {
        process.env[key] = originalEnv[key as keyof typeof originalEnv];
      } else {
        delete process.env[key];
      }
    });
  });

  describe('Local AI Mode Integration', () => {
    beforeEach(() => {
      process.env.USE_LOCAL_EMBEDDINGS = 'true';
      delete process.env.GOOGLE_AI_API_KEY;
    });

    it(
      'should handle complete local AI workflow',
      async () => {
        const request: QueryRequest = {
          query: 'í˜„ìž¬ ì„œë²„ë“¤ì˜ CPU ì‚¬ìš©ë¥ ì´ ë†’ì€ì§€ í™•ì¸í•´ì£¼ì„¸ìš”',
          mode: 'local-ai',
          context: {
            servers: [
              { id: 'srv-001', name: 'web-server-1', status: 'healthy', cpu: 85, memory: 60 },
              { id: 'srv-002', name: 'db-server-1', status: 'warning', cpu: 92, memory: 78 }
            ]
          }
        };

        const response = await engine.query(request);

        expect(response.success).toBe(true);
        expect(response.engine).toBe('local-ai');
        expect(response.response).toContain('ì„œë²„');
        expect(response.confidence).toBeGreaterThan(0);
        expect(response.processingTime).toBeGreaterThan(0);
        
        // Should not call Google AI API in local mode
        expect(global.fetch).not.toHaveBeenCalled();
        
        // Should have thinking steps for local processing
        const steps = response.thinkingSteps.map(s => s.step);
        expect(steps).toContain('ëª¨ë“œ ì„ íƒ');
        expect(steps.some(s => s.includes('ë¡œì»¬') || s.includes('AI'))).toBe(true);
      },
      TEST_TIMEOUT
    );

    it(
      'should integrate with GCP Cloud Functions for Korean NLP',
      async () => {
        const response = await engine.query({
          query: 'ì„œë²„ ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œë¥¼ ìž‘ì„±í•´ì£¼ì„¸ìš”',
          mode: 'local-ai',
          options: { enableKoreanNLP: true }
        });

        expect(response.success).toBe(true);
        expect(response.engine).toBe('local-ai');
        
        // Should include NLP processing step
        const nlpStep = response.thinkingSteps.find(step => 
          step.step.includes('NLP') || step.step.includes('ì˜ë„')
        );
        expect(nlpStep).toBeDefined();
        
        // Should not call Google AI API
        expect(global.fetch).not.toHaveBeenCalled();
      },
      TEST_TIMEOUT
    );
  });

  describe('Cloud AI Mode Integration', () => {
    beforeEach(() => {
      process.env.USE_LOCAL_EMBEDDINGS = 'false';
      process.env.GOOGLE_AI_ENABLED = 'true';
      process.env.GOOGLE_AI_API_KEY = 'test-api-key';

      // Mock Google AI API response
      vi.mocked(global.fetch).mockResolvedValue({
        ok: true,
        json: async () => ({
          response: 'Google AIê°€ ìƒì„±í•œ ì„œë²„ ë¶„ì„ ì‘ë‹µìž…ë‹ˆë‹¤.',
          confidence: 0.92,
          model: 'gemini-pro',
          tokensUsed: 150
        })
      } as Response);
    });

    it(
      'should handle complete Google AI workflow',
      async () => {
        const request: QueryRequest = {
          query: 'ë³µìž¡í•œ ì„œë²„ ì„±ëŠ¥ ìµœì í™” ì „ëžµì„ ì œì•ˆí•´ì£¼ì„¸ìš”',
          mode: 'google-ai',
          enableGoogleAI: true,
          options: {
            includeMCPContext: true,
            enableKoreanNLP: true
          }
        };

        const response = await engine.query(request);

        expect(response.success).toBe(true);
        expect(response.engine).toBe('google-ai');
        expect(response.response).toContain('Google AIê°€ ìƒì„±í•œ');
        expect(response.confidence).toBeGreaterThan(0.9);
        expect(response.metadata?.model).toBe('gemini-pro');
        
        // Should call Google AI API
        expect(global.fetch).toHaveBeenCalledWith(
          '/api/ai/google-ai/generate',
          expect.objectContaining({
            method: 'POST',
            headers: expect.objectContaining({
              'Content-Type': 'application/json'
            })
          })
        );
      },
      TEST_TIMEOUT
    );

    it(
      'should fallback to local AI when Google AI fails',
      async () => {
        // Mock Google AI API failure
        vi.mocked(global.fetch).mockRejectedValue(new Error('Google AI API unavailable'));

        const response = await engine.query({
          query: 'Google AI ì‹¤íŒ¨ ì‹œ fallback í…ŒìŠ¤íŠ¸',
          mode: 'google-ai',
          enableGoogleAI: true
        });

        expect(response.success).toBe(true);
        expect(response.engine).toBe('local-ai'); // Should fallback to local-ai
        
        // Should have attempted Google AI first, then fallen back
        expect(global.fetch).toHaveBeenCalled();
      },
      TEST_TIMEOUT
    );
  });

  describe('Auto Mode Intelligence', () => {
    it(
      'should intelligently select local AI for simple queries',
      async () => {
        const response = await engine.query({
          query: 'ì„œë²„ ìƒíƒœ',
          mode: 'auto'
        });

        expect(response.success).toBe(true);
        expect(['local-ai', 'local-rag']).toContain(response.engine);
        expect(global.fetch).not.toHaveBeenCalled();
      },
      TEST_TIMEOUT
    );

    it(
      'should handle complex server analysis scenarios',
      async () => {
        const complexContext: AIQueryContext = {
          servers: Array.from({ length: 10 }, (_, i) => ({
            id: `srv-${i.toString().padStart(3, '0')}`,
            name: `server-${i + 1}`,
            status: Math.random() > 0.7 ? 'warning' : 'healthy',
            cpu: Math.floor(Math.random() * 100),
            memory: Math.floor(Math.random() * 100),
            disk: Math.floor(Math.random() * 100),
            network: Math.floor(Math.random() * 100)
          })),
          previousQueries: [
            'ì„œë²„ ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„',
            'ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ìµœì í™”',
            'ë„¤íŠ¸ì›Œí¬ ë³‘ëª© í˜„ìƒ í•´ê²°'
          ]
        };

        const response = await engine.query({
          query: 'ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆì˜ ì„œë²„ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–¥í›„ 1ì£¼ì¼ê°„ì˜ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ì˜ˆì¸¡ê³¼ ìµœì í™” ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”',
          mode: 'auto',
          context: complexContext,
          options: {
            includeMCPContext: true,
            enableKoreanNLP: true
          }
        });

        expect(response.success).toBe(true);
        expect(response.confidence).toBeGreaterThan(0.5);
        expect(response.processingTime).toBeLessThan(10000); // Should complete within 10s
        
        // Should analyze all provided servers
        const serverMentions = complexContext.servers!.filter(server => 
          response.response.includes(server.name) || response.response.includes(server.id)
        );
        
        // Should provide meaningful analysis
        expect(response.response.length).toBeGreaterThan(100);
        expect(response.thinkingSteps.length).toBeGreaterThan(3);
      },
      TEST_TIMEOUT
    );
  });

  describe('Error Handling & Resilience', () => {
    it(
      'should gracefully handle RAG engine failures',
      async () => {
        // Mock RAG engine failure
        const mockRAGEngine = vi.mocked(await import('../supabase-rag-engine'));
        mockRAGEngine.getSupabaseRAGEngine = vi.fn(() => ({
          searchSimilar: vi.fn().mockRejectedValue(new Error('Database connection failed')),
          _initialize: vi.fn().mockResolvedValue(undefined),
          healthCheck: vi.fn().mockResolvedValue({ status: 'unhealthy', vectorDB: false })
        }));

        const response = await engine.query({
          query: 'RAG ì—”ì§„ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬',
          mode: 'local-ai'
        });

        // Should handle the error gracefully
        expect(response.success).toBe(false);
        expect(response.error).toContain('Database connection failed');
        expect(response.engine).toBe('local-ai');
      },
      TEST_TIMEOUT
    );

    it(
      'should maintain performance under load',
      async () => {
        const queries = Array.from({ length: 5 }, (_, i) => 
          engine.query({
            query: `ë™ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ${i + 1}`,
            mode: 'local-ai'
          })
        );

        const startTime = Date.now();
        const responses = await Promise.all(queries);
        const totalTime = Date.now() - startTime;

        // All queries should succeed
        expect(responses.every(r => r.success)).toBe(true);
        
        // Should complete within reasonable time (parallel processing)
        expect(totalTime).toBeLessThan(5000); // 5 seconds for 5 queries
        
        // Each query should be processed efficiently
        responses.forEach(response => {
          expect(response.processingTime).toBeLessThan(2000);
          expect(response.confidence).toBeGreaterThan(0);
        });
      },
      TEST_TIMEOUT
    );
  });

  describe('System Health & Monitoring', () => {
    it(
      'should provide comprehensive health check',
      async () => {
        const health = await engine.healthCheck();

        expect(health.status).toMatch(/healthy|degraded/);
        expect(typeof health.engines.localRAG).toBe('boolean');
        expect(typeof health.engines.googleAI).toBe('boolean');
        expect(typeof health.engines.mcp).toBe('boolean');
        
        // Should include performance metrics
        expect(health.performance).toBeDefined();
        expect(health.timestamp).toBeDefined();
      },
      TEST_TIMEOUT
    );

    it(
      'should track and report performance metrics',
      async () => {
        const response = await engine.query({
          query: 'ì„±ëŠ¥ ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸',
          mode: 'local-ai'
        });

        expect(response.metadata).toBeDefined();
        expect(response.metadata!.ragResults).toBeGreaterThanOrEqual(0);
        expect(typeof response.metadata!.cached).toBe('boolean');
        expect(response.processingTime).toBeGreaterThan(0);
        
        // Should include thinking steps with timing
        const stepsWithTiming = response.thinkingSteps.filter(s => s.duration && s.duration > 0);
        expect(stepsWithTiming.length).toBeGreaterThan(0);
      },
      TEST_TIMEOUT
    );
  });
});