/**
 * ğŸ”„ OpenManager v5 ë°ì´í„° í”Œë¡œìš° ë§¤ë‹ˆì €
 * 
 * ë°ì´í„° ìƒì„±ê¸° â†’ ì„œë²„ ëª¨ë‹ˆí„°ë§ â†’ AI ì—ì´ì „íŠ¸ ê°„ì˜
 * ì²´ê³„ì ì¸ ë°ì´í„° íë¦„ ê´€ë¦¬ ë° ìµœì í™”
 */

import { EnhancedServerMetrics } from '../simulationEngine';
import { simulationEngine } from '../simulationEngine';
import { PythonWarmupService } from './PythonWarmupService';
import { autoScalingEngine } from './AutoScalingEngine';

export interface DataFlowMetrics {
  serverCount: number;
  dataGeneration: {
    lastUpdate: Date;
    updateInterval: number;
    generatedMetrics: number;
    realisticPatterns: boolean;
  };
  aiProcessing: {
    lastAnalysis: Date;
    aiResponses: number;
    pythonEngineActive: boolean;
    predictionAccuracy: number;
  };
  autoScaling: {
    lastDecision: Date;
    scalingActions: number;
    currentPolicy: any;
    targetServers: number;
  };
  performance: {
    dataLatency: number;
    aiLatency: number;
    uiRenderTime: number;
    memoryUsage: number;
  };
}

export class DataFlowManager {
  private static instance: DataFlowManager;
  private isRunning: boolean = false;
  private dataFlowMetrics: DataFlowMetrics;
  private pythonWarmup: PythonWarmupService;
  private lastServerData: EnhancedServerMetrics[] = [];
  
  // ë°ì´í„° í”Œë¡œìš° íƒ€ì´ë° ìµœì í™”
  private readonly FLOW_INTERVALS = {
    DATA_GENERATION: 5000,    // 5ì´ˆë§ˆë‹¤ ë°ì´í„° ìƒì„±
    AI_ANALYSIS: 10000,       // 10ì´ˆë§ˆë‹¤ AI ë¶„ì„
    AUTO_SCALING: 30000,      // 30ì´ˆë§ˆë‹¤ ìŠ¤ì¼€ì¼ë§ ê²€í† 
    UI_UPDATE: 3000,          // 3ì´ˆë§ˆë‹¤ UI ì—…ë°ì´íŠ¸
    PERFORMANCE_CHECK: 15000  // 15ì´ˆë§ˆë‹¤ ì„±ëŠ¥ ì²´í¬
  };

  private constructor() {
    this.pythonWarmup = PythonWarmupService.getInstance();
    this.dataFlowMetrics = this.initializeMetrics();
  }

  static getInstance(): DataFlowManager {
    if (!this.instance) {
      this.instance = new DataFlowManager();
    }
    return this.instance;
  }

  private initializeMetrics(): DataFlowMetrics {
    return {
      serverCount: 0,
      dataGeneration: {
        lastUpdate: new Date(),
        updateInterval: this.FLOW_INTERVALS.DATA_GENERATION,
        generatedMetrics: 0,
        realisticPatterns: true
      },
      aiProcessing: {
        lastAnalysis: new Date(),
        aiResponses: 0,
        pythonEngineActive: false,
        predictionAccuracy: 0
      },
      autoScaling: {
        lastDecision: new Date(),
        scalingActions: 0,
        currentPolicy: null,
        targetServers: 8
      },
      performance: {
        dataLatency: 0,
        aiLatency: 0,
        uiRenderTime: 0,
        memoryUsage: 0
      }
    };
  }

  /**
   * ğŸš€ ë°ì´í„° í”Œë¡œìš° ì‹œì‘
   */
  async startDataFlow(): Promise<void> {
    if (this.isRunning) {
      console.log('âš ï¸ ë°ì´í„° í”Œë¡œìš°ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤');
      return;
    }

    console.log('ğŸš€ ë°ì´í„° í”Œë¡œìš° ë§¤ë‹ˆì € ì‹œì‘...');
    this.isRunning = true;

    try {
      // Python AI ì—”ì§„ ì›œì—…
      const pythonStatus = await this.pythonWarmup.checkPythonStatus();
      this.dataFlowMetrics.aiProcessing.pythonEngineActive = pythonStatus.isWarm;
      
      // ë°ì´í„° í”Œë¡œìš° íƒ€ì´ë¨¸ ì‹œì‘
      this.startDataGenerationFlow();
      this.startAIAnalysisFlow();
      this.startAutoScalingFlow();
      this.startPerformanceMonitoring();

      console.log('âœ… ë°ì´í„° í”Œë¡œìš° ë§¤ë‹ˆì € ì‹œì‘ ì™„ë£Œ');
      
    } catch (error) {
      console.error('âŒ ë°ì´í„° í”Œë¡œìš° ì‹œì‘ ì‹¤íŒ¨:', error);
      this.isRunning = false;
      throw error;
    }
  }

  /**
   * ğŸ“Š ë°ì´í„° ìƒì„± í”Œë¡œìš°
   */
  private startDataGenerationFlow(): void {
    setInterval(async () => {
      if (!this.isRunning) return;

      const startTime = Date.now();
      
      try {
        // ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„ì—ì„œ ì„œë²„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        const servers = simulationEngine.getServers();
        
        // ë°ì´í„° í”Œë¡œìš° ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        this.dataFlowMetrics.serverCount = servers.length;
        this.dataFlowMetrics.dataGeneration.lastUpdate = new Date();
        this.dataFlowMetrics.dataGeneration.generatedMetrics++;
        this.dataFlowMetrics.performance.dataLatency = Date.now() - startTime;
        
        // ìµœì‹  ë°ì´í„° ìºì‹œ
        this.lastServerData = servers;
        
        console.log(`ğŸ“Š ë°ì´í„° ìƒì„± ì™„ë£Œ: ${servers.length}ê°œ ì„œë²„, ${Date.now() - startTime}ms`);
        
      } catch (error) {
        console.error('âŒ ë°ì´í„° ìƒì„± í”Œë¡œìš° ì˜¤ë¥˜:', error);
      }
    }, this.FLOW_INTERVALS.DATA_GENERATION);
  }

  /**
   * ğŸ¤– AI ë¶„ì„ í”Œë¡œìš°
   */
  private startAIAnalysisFlow(): void {
    setInterval(async () => {
      if (!this.isRunning || this.lastServerData.length === 0) return;

      const startTime = Date.now();
      
      try {
        // Python AI ì—”ì§„ ìƒíƒœ í™•ì¸
        const pythonStatus = await this.pythonWarmup.checkPythonStatus();
        this.dataFlowMetrics.aiProcessing.pythonEngineActive = pythonStatus.isWarm;
        
        // AI ë¶„ì„ ì‹¤í–‰ (Python ìš°ì„ , TypeScript í´ë°±)
        let analysisResult = null;
        
        if (pythonStatus.isWarm) {
          // Python AI ì—”ì§„ ì‚¬ìš©
          try {
            const response = await fetch('/api/ai/mcp', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                action: 'analyze',
                servers: this.lastServerData.slice(0, 10) // ì„±ëŠ¥ì„ ìœ„í•´ ìµœëŒ€ 10ê°œ ì„œë²„ë§Œ ë¶„ì„
              })
            });
            
            if (response.ok) {
              analysisResult = await response.json();
            }
          } catch (pythonError) {
            console.warn('âš ï¸ Python AI ë¶„ì„ ì‹¤íŒ¨, TypeScript í´ë°±:', pythonError);
          }
        }
        
        // TypeScript í´ë°± ë¶„ì„ (ê°„ë‹¨í•œ ë©”íŠ¸ë¦­ ê³„ì‚°)
        if (!analysisResult) {
          analysisResult = this.performBasicAnalysis(this.lastServerData);
        }
        
        // AI ë¶„ì„ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        this.dataFlowMetrics.aiProcessing.lastAnalysis = new Date();
        this.dataFlowMetrics.aiProcessing.aiResponses++;
        this.dataFlowMetrics.performance.aiLatency = Date.now() - startTime;
        
        console.log(`ğŸ¤– AI ë¶„ì„ ì™„ë£Œ: ${this.dataFlowMetrics.aiProcessing.pythonEngineActive ? 'Python' : 'TypeScript'} ì—”ì§„, ${Date.now() - startTime}ms`);
        
      } catch (error) {
        console.error('âŒ AI ë¶„ì„ í”Œë¡œìš° ì˜¤ë¥˜:', error);
      }
    }, this.FLOW_INTERVALS.AI_ANALYSIS);
  }

  /**
   * âš–ï¸ ìë™ ìŠ¤ì¼€ì¼ë§ í”Œë¡œìš°
   */
  private startAutoScalingFlow(): void {
    setInterval(async () => {
      if (!this.isRunning || this.lastServerData.length === 0) return;

      try {
        // ìë™ ìŠ¤ì¼€ì¼ë§ ì˜ì‚¬ê²°ì •
        const scalingDecision = await autoScalingEngine.makeScalingDecision(this.lastServerData);
        
        // ìŠ¤ì¼€ì¼ë§ ì‹œë®¬ë ˆì´ì…˜ ë¡œê·¸
        if (scalingDecision.action !== 'maintain') {
          console.log(`âš–ï¸ ìŠ¤ì¼€ì¼ë§ ì‹œë®¬ë ˆì´ì…˜: ${scalingDecision.action} (${scalingDecision.currentServers} â†’ ${scalingDecision.targetServers})`);
          this.dataFlowMetrics.autoScaling.scalingActions++;
        }
        
        // ìŠ¤ì¼€ì¼ë§ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        this.dataFlowMetrics.autoScaling.lastDecision = new Date();
        this.dataFlowMetrics.autoScaling.currentPolicy = autoScalingEngine.getCurrentConfig();
        this.dataFlowMetrics.autoScaling.targetServers = scalingDecision.targetServers;
        
        console.log(`âš–ï¸ ìŠ¤ì¼€ì¼ë§ ê²€í†  ì™„ë£Œ: ${scalingDecision.action}, íƒ€ê²Ÿ: ${scalingDecision.targetServers}ê°œ`);
        
      } catch (error) {
        console.error('âŒ ìë™ ìŠ¤ì¼€ì¼ë§ í”Œë¡œìš° ì˜¤ë¥˜:', error);
      }
    }, this.FLOW_INTERVALS.AUTO_SCALING);
  }

  /**
   * ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
   */
  private startPerformanceMonitoring(): void {
    setInterval(() => {
      if (!this.isRunning) return;

      try {
        // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
        const estimatedMemory = process.memoryUsage ? process.memoryUsage().heapUsed / 1024 / 1024 : 0;
        this.dataFlowMetrics.performance.memoryUsage = estimatedMemory;
        
        // UI ë Œë”ë§ ì‹œê°„ ì¶”ì • (í‰ê·  ì‘ë‹µ ì‹œê°„ ê¸°ë°˜)
        const avgLatency = (this.dataFlowMetrics.performance.dataLatency + this.dataFlowMetrics.performance.aiLatency) / 2;
        this.dataFlowMetrics.performance.uiRenderTime = avgLatency;
        
        // ì„±ëŠ¥ ê²½ê³  ì²´í¬
        if (avgLatency > 5000) { // 5ì´ˆ ì´ìƒ
          console.warn('âš ï¸ ë°ì´í„° í”Œë¡œìš° ì§€ì—° ê°ì§€:', avgLatency, 'ms');
        }
        
        if (estimatedMemory > 512) { // 512MB ì´ìƒ
          console.warn('âš ï¸ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì§€:', estimatedMemory.toFixed(1), 'MB');
        }
        
      } catch (error) {
        console.error('âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜:', error);
      }
    }, this.FLOW_INTERVALS.PERFORMANCE_CHECK);
  }

  /**
   * ğŸ“Š ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰ (TypeScript í´ë°±)
   */
  private performBasicAnalysis(servers: EnhancedServerMetrics[]): any {
    const totalServers = servers.length;
    const avgCpu = servers.reduce((sum, s) => sum + s.cpu_usage, 0) / totalServers;
    const avgMemory = servers.reduce((sum, s) => sum + s.memory_usage, 0) / totalServers;
    const criticalServers = servers.filter(s => s.status === 'critical').length;
    
    return {
      analysis: 'basic_metrics',
      server_count: totalServers,
      avg_cpu: avgCpu.toFixed(1),
      avg_memory: avgMemory.toFixed(1),
      critical_servers: criticalServers,
      health_score: ((totalServers - criticalServers) / totalServers * 100).toFixed(1),
      timestamp: new Date().toISOString()
    };
  }

  /**
   * ğŸ›‘ ë°ì´í„° í”Œë¡œìš° ì¤‘ì§€
   */
  stopDataFlow(): void {
    console.log('ğŸ›‘ ë°ì´í„° í”Œë¡œìš° ë§¤ë‹ˆì € ì¤‘ì§€...');
    this.isRunning = false;
  }

  /**
   * ğŸ“Š í˜„ì¬ ë°ì´í„° í”Œë¡œìš° ë©”íŠ¸ë¦­ ë°˜í™˜
   */
  getMetrics(): DataFlowMetrics {
    return { ...this.dataFlowMetrics };
  }

  /**
   * ğŸ” ë°ì´í„° í”Œë¡œìš° ìƒíƒœ í™•ì¸
   */
  getStatus(): {
    isRunning: boolean;
    serverCount: number;
    lastUpdate: Date;
    aiEngineActive: boolean;
    scalingActive: boolean;
  } {
    return {
      isRunning: this.isRunning,
      serverCount: this.dataFlowMetrics.serverCount,
      lastUpdate: this.dataFlowMetrics.dataGeneration.lastUpdate,
      aiEngineActive: this.dataFlowMetrics.aiProcessing.pythonEngineActive,
      scalingActive: this.dataFlowMetrics.autoScaling.scalingActions > 0
    };
  }

  /**
   * ğŸ¯ ìµœì‹  ì„œë²„ ë°ì´í„° ë°˜í™˜
   */
  getLatestServerData(): EnhancedServerMetrics[] {
    return [...this.lastServerData];
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë‚´ë³´ë‚´ê¸°
export const dataFlowManager = DataFlowManager.getInstance(); 