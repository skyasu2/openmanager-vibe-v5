/**
 * ğŸ§  TensorFlow.js AI ì—”ì§„ v3.0
 * 
 * âœ… Vercel ì„œë²„ë¦¬ìŠ¤ ì™„ì „ í˜¸í™˜
 * âœ… ë¸Œë¼ìš°ì € + Node.js ì§€ì›  
 * âœ… ì¥ì•  ì˜ˆì¸¡ ì‹ ê²½ë§
 * âœ… ì´ìƒ íƒì§€ ì˜¤í† ì¸ì½”ë”
 * âœ… ì‹œê³„ì—´ LSTM ëª¨ë¸
 * âœ… ì™„ì „ ë¡œì»¬ AI (ì™¸ë¶€ API ì—†ìŒ)
 */

import * as tf from '@tensorflow/tfjs';

interface PredictionResult {
  prediction: number[];
  confidence: number;
  model_info: string;
  processing_time: number;
}

interface AnomalyResult {
  is_anomaly: boolean;
  anomaly_score: number;
  threshold: number;
  model_info: string;
}

interface AIAnalysisResult {
  failure_predictions: Record<string, PredictionResult>;
  anomaly_detections: Record<string, AnomalyResult>;
  trend_predictions: Record<string, number[]>;
  ai_insights: string[];
  processing_stats: {
    total_time: number;
    models_used: string[];
    metrics_analyzed: number;
  };
}

export class TensorFlowAIEngine {
  private models: Map<string, tf.LayersModel> = new Map();
  private initialized = false;
  private modelSpecs: Map<string, any> = new Map();

  constructor() {
    this.initializeModelSpecs();
  }

  private initializeModelSpecs(): void {
    // ğŸ¯ ì¥ì•  ì˜ˆì¸¡ ëª¨ë¸ ìŠ¤í™
    this.modelSpecs.set('failure_prediction', {
      input_shape: [10],
      layers: [
        { type: 'dense', units: 64, activation: 'relu' },
        { type: 'dropout', rate: 0.2 },
        { type: 'dense', units: 32, activation: 'relu' },
        { type: 'dropout', rate: 0.2 },
        { type: 'dense', units: 16, activation: 'relu' },
        { type: 'dense', units: 1, activation: 'sigmoid' }
      ],
      optimizer: 'adam',
      loss: 'binaryCrossentropy',
      description: 'ì¥ì•  í™•ë¥  ì˜ˆì¸¡ ì‹ ê²½ë§'
    });

    // ğŸ” ì´ìƒ íƒì§€ ëª¨ë¸ ìŠ¤í™ (ì˜¤í† ì¸ì½”ë”)
    this.modelSpecs.set('anomaly_detection', {
      input_shape: [20],
      encoder_layers: [
        { type: 'dense', units: 16, activation: 'relu' },
        { type: 'dense', units: 8, activation: 'relu' },
        { type: 'dense', units: 4, activation: 'relu' }
      ],
      decoder_layers: [
        { type: 'dense', units: 8, activation: 'relu' },
        { type: 'dense', units: 16, activation: 'relu' },
        { type: 'dense', units: 20, activation: 'linear' }
      ],
      optimizer: 'adam',
      loss: 'meanSquaredError',
      description: 'ì˜¤í† ì¸ì½”ë” ê¸°ë°˜ ì´ìƒ íƒì§€'
    });

    // ğŸ“ˆ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸ ìŠ¤í™ (LSTM)
    this.modelSpecs.set('timeseries', {
      input_shape: [10, 1],
      layers: [
        { type: 'lstm', units: 50, return_sequences: true },
        { type: 'dropout', rate: 0.2 },
        { type: 'lstm', units: 50, return_sequences: false },
        { type: 'dropout', rate: 0.2 },
        { type: 'dense', units: 25 },
        { type: 'dense', units: 1 }
      ],
      optimizer: 'adam',
      loss: 'meanSquaredError',
      description: 'LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡'
    });
  }

  async initialize(): Promise<void> {
    if (this.initialized) return;

    console.log('ğŸ§  TensorFlow.js AI ì—”ì§„ ì´ˆê¸°í™” ì¤‘...');
    
    try {
      // TensorFlow.js ë°±ì—”ë“œ ì„¤ì •
      await this.setupTensorFlowBackend();
      
      // ëª¨ë¸ë“¤ ì´ˆê¸°í™”
      await this.initializeAllModels();
      
      this.initialized = true;
      console.log('âœ… TensorFlow.js AI ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ');
      console.log(`ğŸ”§ ë°±ì—”ë“œ: ${tf.getBackend()}`);
      console.log(`ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©: ${JSON.stringify(tf.memory())}`);
      
    } catch (error: any) {
      console.error('âŒ TensorFlow.js ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  private async setupTensorFlowBackend(): Promise<void> {
    try {
      // Vercel í™˜ê²½ì—ì„œ ìµœì  ë°±ì—”ë“œ ì„¤ì •
      if (typeof window !== 'undefined') {
        // ë¸Œë¼ìš°ì € í™˜ê²½
        await tf.setBackend('webgl');
        console.log('ğŸŒ ë¸Œë¼ìš°ì € WebGL ë°±ì—”ë“œ ì„¤ì •');
      } else {
        // Node.js í™˜ê²½ (Vercel ì„œë²„ë¦¬ìŠ¤)
        await tf.setBackend('cpu');
        console.log('ğŸ–¥ï¸ Node.js CPU ë°±ì—”ë“œ ì„¤ì •');
      }
      
      await tf.ready();
      console.log(`âœ… TensorFlow.js ë°±ì—”ë“œ ì¤€ë¹„: ${tf.getBackend()}`);
      
    } catch (error: any) {
      console.warn('âš ï¸ ë°±ì—”ë“œ ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©:', error);
    }
  }

  private async initializeAllModels(): Promise<void> {
    const modelPromises = [
      this.initializeFailurePredictionModel(),
      this.initializeAnomalyDetectionModel(),
      this.initializeTimeSeriesModel()
    ];

    await Promise.all(modelPromises);
    console.log(`ğŸ“Š ${this.models.size}ê°œ AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ`);
  }

  private async initializeFailurePredictionModel(): Promise<void> {
    const spec = this.modelSpecs.get('failure_prediction')!;
    
    const model = tf.sequential({
      layers: [
        tf.layers.dense({ 
          inputShape: spec.input_shape, 
          units: 64, 
          activation: 'relu',
          name: 'failure_hidden1'
        }),
        tf.layers.dropout({ rate: 0.2 }),
        tf.layers.dense({ 
          units: 32, 
          activation: 'relu',
          name: 'failure_hidden2'
        }),
        tf.layers.dropout({ rate: 0.2 }),
        tf.layers.dense({ 
          units: 16, 
          activation: 'relu',
          name: 'failure_hidden3'
        }),
        tf.layers.dense({ 
          units: 1, 
          activation: 'sigmoid',
          name: 'failure_output'
        })
      ]
    });

    model.compile({
      optimizer: tf.train.adam(0.001),
      loss: 'binaryCrossentropy',
      metrics: ['accuracy']
    });

    this.models.set('failure_prediction', model);
    console.log('ğŸ¯ ì¥ì•  ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ');
  }

  private async initializeAnomalyDetectionModel(): Promise<void> {
    // ì˜¤í† ì¸ì½”ë” ì¸ì½”ë”
    const encoder = tf.sequential({
      layers: [
        tf.layers.dense({ 
          inputShape: [20], 
          units: 16, 
          activation: 'relu',
          name: 'encoder_1'
        }),
        tf.layers.dense({ 
          units: 8, 
          activation: 'relu',
          name: 'encoder_2'
        }),
        tf.layers.dense({ 
          units: 4, 
          activation: 'relu',
          name: 'bottleneck'
        })
      ]
    });

    // ì˜¤í† ì¸ì½”ë” ë””ì½”ë”
    const decoder = tf.sequential({
      layers: [
        tf.layers.dense({ 
          inputShape: [4], 
          units: 8, 
          activation: 'relu',
          name: 'decoder_1'
        }),
        tf.layers.dense({ 
          units: 16, 
          activation: 'relu',
          name: 'decoder_2'
        }),
        tf.layers.dense({ 
          units: 20, 
          activation: 'linear',
          name: 'decoder_output'
        })
      ]
    });

    // ì „ì²´ ì˜¤í† ì¸ì½”ë”
    const autoencoder = tf.sequential();
    autoencoder.add(encoder);
    autoencoder.add(decoder);

    autoencoder.compile({
      optimizer: 'adam',
      loss: 'meanSquaredError'
    });

    this.models.set('anomaly_detection', autoencoder);
    console.log('ğŸ” ì´ìƒ íƒì§€ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ');
  }

  private async initializeTimeSeriesModel(): Promise<void> {
    const model = tf.sequential({
      layers: [
        tf.layers.lstm({ 
          units: 50, 
          returnSequences: true, 
          inputShape: [10, 1],
          name: 'lstm_1'
        }),
        tf.layers.dropout({ rate: 0.2 }),
        tf.layers.lstm({ 
          units: 50, 
          returnSequences: false,
          name: 'lstm_2'
        }),
        tf.layers.dropout({ rate: 0.2 }),
        tf.layers.dense({ 
          units: 25,
          name: 'dense_1'
        }),
        tf.layers.dense({ 
          units: 1,
          name: 'output'
        })
      ]
    });

    model.compile({
      optimizer: 'adam',
      loss: 'meanSquaredError',
      metrics: ['mae']
    });

    this.models.set('timeseries', model);
    console.log('ğŸ“ˆ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ');
  }

  async predictFailure(metrics: number[]): Promise<PredictionResult> {
    await this.initialize();
    
    const startTime = Date.now();
    const model = this.models.get('failure_prediction');
    if (!model) throw new Error('ì¥ì•  ì˜ˆì¸¡ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ');

    // ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
    const processedMetrics = this.preprocessMetrics(metrics, 10);
    const inputTensor = tf.tensor2d([processedMetrics]);

    try {
      const prediction = model.predict(inputTensor) as tf.Tensor;
      const predictionArray = await prediction.data();
      
      const processingTime = Date.now() - startTime;
      
      return {
        prediction: Array.from(predictionArray),
        confidence: predictionArray[0] > 0.5 ? predictionArray[0] : 1 - predictionArray[0],
        model_info: 'TensorFlow.js ì‹ ê²½ë§ (4ì¸µ, ReLU+Sigmoid)',
        processing_time: processingTime
      };
    } finally {
      inputTensor.dispose();
    }
  }

  async detectAnomalies(timeSeries: number[]): Promise<AnomalyResult> {
    await this.initialize();
    
    const model = this.models.get('anomaly_detection');
    if (!model) throw new Error('ì´ìƒ íƒì§€ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ');

    // ë°ì´í„° ì „ì²˜ë¦¬
    const processedData = this.preprocessMetrics(timeSeries, 20);
    const inputTensor = tf.tensor2d([processedData]);

    try {
      const reconstruction = model.predict(inputTensor) as tf.Tensor;
      const reconstructionData = await reconstruction.data();
      
      // ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚° (MSE)
      const originalData = await inputTensor.data();
      const mse = this.calculateMSE(Array.from(originalData), Array.from(reconstructionData));
      
      // ë™ì  ì„ê³„ê°’ (ë°ì´í„°ì˜ í‘œì¤€í¸ì°¨ ê¸°ë°˜)
      const threshold = this.calculateDynamicThreshold(processedData);
      const isAnomaly = mse > threshold;
      
      return {
        is_anomaly: isAnomaly,
        anomaly_score: mse,
        threshold: threshold,
        model_info: 'TensorFlow.js ì˜¤í† ì¸ì½”ë” (20â†’4â†’20)'
      };
    } finally {
      inputTensor.dispose();
    }
  }

  async predictTimeSeries(historicalData: number[], steps: number = 5): Promise<number[]> {
    await this.initialize();
    
    const model = this.models.get('timeseries');
    if (!model) throw new Error('ì‹œê³„ì—´ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ');

    // ì‹œê³„ì—´ ë°ì´í„° ì „ì²˜ë¦¬
    const sequences = this.createSequences(historicalData, 10);
    if (sequences.length === 0) return [];

    const lastSequence = sequences[sequences.length - 1];
    const currentSequence = [...lastSequence];

    try {
      const predictions = [];

      for (let i = 0; i < steps; i++) {
        const sequenceTensor = tf.tensor3d([currentSequence]);
        const prediction = model.predict(sequenceTensor) as tf.Tensor;
        const predictionValue = (await prediction.data())[0];
        
        predictions.push(predictionValue);
        
        // ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸
        currentSequence.shift();
        currentSequence.push([predictionValue]);
        
        sequenceTensor.dispose();
        prediction.dispose();
      }

      return predictions;
    } catch (error: any) {
      console.error('ì‹œê³„ì—´ ì˜ˆì¸¡ ì‹¤íŒ¨:', error);
      return [];
    }
  }

  async analyzeMetricsWithAI(metrics: Record<string, number[]>): Promise<AIAnalysisResult> {
    await this.initialize();

    const startTime = Date.now();
    const analysis: AIAnalysisResult = {
      failure_predictions: {},
      anomaly_detections: {},
      trend_predictions: {},
      ai_insights: [],
      processing_stats: {
        total_time: 0,
        models_used: [],
        metrics_analyzed: Object.keys(metrics).length
      }
    };

    for (const [metricName, values] of Object.entries(metrics)) {
      try {
        // ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ í™•ì¸
        if (!Array.isArray(values) || values.length < 5) {
          console.warn(`${metricName}: ë°ì´í„° ë¶€ì¡± (${values.length}ê°œ)`);
          continue;
        }

        // 1. ì¥ì•  ì˜ˆì¸¡
        const failurePred = await this.predictFailure(values.slice(-10));
        analysis.failure_predictions[metricName] = failurePred;
        analysis.processing_stats.models_used.push('failure_prediction');

        // 2. ì´ìƒ íƒì§€
        const anomalyDet = await this.detectAnomalies(values);
        analysis.anomaly_detections[metricName] = anomalyDet;
        analysis.processing_stats.models_used.push('anomaly_detection');

        // 3. ì‹œê³„ì—´ ì˜ˆì¸¡
        if (values.length >= 10) {
          const trendPred = await this.predictTimeSeries(values, 5);
          analysis.trend_predictions[metricName] = trendPred;
          analysis.processing_stats.models_used.push('timeseries');
        }

        // 4. AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
        this.generateInsights(metricName, failurePred, anomalyDet, analysis.ai_insights);

      } catch (error: any) {
        console.error(`${metricName} ë¶„ì„ ì‹¤íŒ¨:`, error);
        analysis.ai_insights.push(`âš ï¸ ${metricName}: ë¶„ì„ ì˜¤ë¥˜ (${error.message})`);
      }
    }

    analysis.processing_stats.total_time = Date.now() - startTime;
    analysis.processing_stats.models_used = [...new Set(analysis.processing_stats.models_used)];

    console.log(`ğŸ§  AI ë¶„ì„ ì™„ë£Œ: ${analysis.processing_stats.total_time}ms`);
    return analysis;
  }

  private generateInsights(
    metricName: string, 
    failurePred: PredictionResult, 
    anomalyDet: AnomalyResult, 
    insights: string[]
  ): void {
    // ì¥ì•  ì˜ˆì¸¡ ì¸ì‚¬ì´íŠ¸
    if (failurePred.prediction[0] > 0.7) {
      insights.push(
        `ğŸš¨ ${metricName}: ë†’ì€ ì¥ì•  ìœ„í—˜ ê°ì§€ (${(failurePred.prediction[0] * 100).toFixed(1)}%)`
      );
    } else if (failurePred.prediction[0] > 0.4) {
      insights.push(
        `âš ï¸ ${metricName}: ì¤‘ê°„ ìˆ˜ì¤€ ìœ„í—˜ (${(failurePred.prediction[0] * 100).toFixed(1)}%)`
      );
    }

    // ì´ìƒ íƒì§€ ì¸ì‚¬ì´íŠ¸
    if (anomalyDet.is_anomaly) {
      const severity = anomalyDet.anomaly_score > anomalyDet.threshold * 2 ? 'ì‹¬ê°' : 'ê²½ë¯¸';
      insights.push(
        `ğŸ” ${metricName}: ${severity}í•œ ì´ìƒê°’ íƒì§€ (ì ìˆ˜: ${anomalyDet.anomaly_score.toFixed(3)})`
      );
    }

    // ì‹ ë¢°ë„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
    if (failurePred.confidence < 0.6) {
      insights.push(
        `ğŸ“Š ${metricName}: ì˜ˆì¸¡ ì‹ ë¢°ë„ ë‚®ìŒ (${(failurePred.confidence * 100).toFixed(1)}%) - ì¶”ê°€ ë°ì´í„° í•„ìš”`
      );
    }
  }

  private preprocessMetrics(metrics: number[], targetLength: number): number[] {
    if (!Array.isArray(metrics) || metrics.length === 0) {
      return new Array(targetLength).fill(0);
    }

    // ì •ê·œí™” (0-1 ë²”ìœ„)
    const min = Math.min(...metrics);
    const max = Math.max(...metrics);
    const range = max - min || 1;
    
    const normalized = metrics.map(val => (val - min) / range);

    // ê¸¸ì´ ì¡°ì •
    if (normalized.length === targetLength) return normalized;
    
    if (normalized.length > targetLength) {
      // ìµœê·¼ ë°ì´í„°ë§Œ ì‚¬ìš©
      return normalized.slice(-targetLength);
    } else {
      // í‰ê· ê°’ìœ¼ë¡œ íŒ¨ë”©
      const mean = normalized.reduce((sum, val) => sum + val, 0) / normalized.length;
      const padded = [...normalized];
      while (padded.length < targetLength) {
        padded.unshift(mean);
      }
      return padded;
    }
  }

  private createSequences(data: number[], sequenceLength: number): number[][][] {
    if (data.length < sequenceLength) return [];
    
    const sequences = [];
    for (let i = 0; i <= data.length - sequenceLength; i++) {
      const sequence = data.slice(i, i + sequenceLength).map(val => [val]);
      sequences.push(sequence);
    }
    return sequences;
  }

  private calculateMSE(original: number[], reconstructed: number[]): number {
    if (original.length !== reconstructed.length) return Infinity;
    
    const mse = original.reduce((sum, val, i) => {
      const error = val - reconstructed[i];
      return sum + error * error;
    }, 0) / original.length;
    
    return mse;
  }

  private calculateDynamicThreshold(data: number[]): number {
    // í‘œì¤€í¸ì°¨ ê¸°ë°˜ ë™ì  ì„ê³„ê°’
    const mean = data.reduce((sum, val) => sum + val, 0) / data.length;
    const variance = data.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / data.length;
    const stdDev = Math.sqrt(variance);
    
    // 2-sigma ê·œì¹™ ì ìš©
    return Math.max(0.01, stdDev * 2);
  }

  async getModelInfo(): Promise<any> {
    return {
      framework: 'TensorFlow.js',
      version: tf.version_core,
      backend: tf.getBackend(),
      models: Array.from(this.models.keys()),
      memory_usage: tf.memory(),
      initialized: this.initialized,
      model_specs: Object.fromEntries(this.modelSpecs),
      supported_features: [
        'ì¥ì•  ì˜ˆì¸¡',
        'ì´ìƒ íƒì§€',
        'ì‹œê³„ì—´ ì˜ˆì¸¡',
        'ì‹¤ì‹œê°„ ë¶„ì„',
        'Vercel ì„œë²„ë¦¬ìŠ¤ í˜¸í™˜'
      ]
    };
  }

  dispose(): void {
    console.log('ğŸ—‘ï¸ TensorFlow.js ëª¨ë¸ ì •ë¦¬ ì¤‘...');
    
    this.models.forEach((model, name) => {
      try {
        model.dispose();
        console.log(`âœ… ${name} ëª¨ë¸ ì •ë¦¬ ì™„ë£Œ`);
      } catch (error: any) {
        console.error(`âŒ ${name} ëª¨ë¸ ì •ë¦¬ ì‹¤íŒ¨:`, error);
      }
    });
    
    this.models.clear();
    this.initialized = false;
    
    console.log(`ğŸ“Š ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ: ${JSON.stringify(tf.memory())}`);
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const tensorFlowAIEngine = new TensorFlowAIEngine(); 