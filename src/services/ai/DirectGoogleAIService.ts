/**
 * ğŸ¯ DirectGoogleAIService - ì§ì ‘ Google AI SDK í†µí•© ì„œë¹„ìŠ¤
 *
 * ğŸ”§ ì•„í‚¤í…ì²˜ ê°œì„ :
 * - API Wrapper Anti-Pattern ì œê±°
 * - ì¤‘ê°„ ë ˆì´ì–´ ì—†ëŠ” ì§ì ‘ SDK í˜¸ì¶œ
 * - ë‹¨ìˆœí™”ëœ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
 * - Promise.race ê¸°ë°˜ ì•ˆì „í•œ íƒ€ì„ì•„ì›ƒ
 *
 * ğŸ“Š ì„±ëŠ¥ ê°œì„ :
 * - ë„¤íŠ¸ì›Œí¬ ë¼ìš´ë“œíŠ¸ë¦½ ì œê±° (~500ms ì ˆì•½)
 * - JSON ì§ë ¬í™”/ì—­ì§ë ¬í™” ì˜¤ë²„í—¤ë“œ ì œê±° (~200ms ì ˆì•½)
 * - íƒ€ì„ì•„ì›ƒ ì¤‘ì²© ë¬¸ì œ í•´ê²°
 *
 * @author Gemini Architecture Specialist
 * @version 1.0.0
 */

import type { GoogleGenerativeAI, GenerativeModel } from '@google/generative-ai';
import { getGoogleAIClient } from '@/lib/ai/google-ai-client';
import { getEnvironmentTimeouts } from '@/utils/timeout-config';
import debug from '@/utils/debug';
import { getGoogleAIKey, getGoogleAISecondaryKey } from '@/lib/google-ai-manager';

export interface DirectGoogleAIOptions {
  model: string;
  temperature: number;
  maxTokens: number;
  timeout?: number;
}

export interface DirectGoogleAIResponse {
  success: boolean;
  content: string;
  model: string;
  usage?: {
    promptTokens?: number;
    completionTokens?: number;
    totalTokens?: number;
  };
  responseTime: number;
  error?: string;
}

/**
 * ğŸš€ Direct Google AI Service
 *
 * Clean Architecture ì›ì¹™ì„ ë”°ë¥´ëŠ” ì§ì ‘ SDK í†µí•©:
 * - ì™¸ë¶€ ì˜ì¡´ì„±ì„ ëª…í™•íˆ ë¶„ë¦¬
 * - ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì¤€ìˆ˜
 * - íƒ€ì„ì•„ì›ƒê³¼ ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ì„œë¹„ìŠ¤ ë ˆë²¨ì—ì„œ ê´€ë¦¬
 */
export class DirectGoogleAIService {
  private genAI: GoogleGenerativeAI | null = null;
  private modelCache = new Map<string, GenerativeModel>();

  constructor() {
    // ì´ˆê¸°í™”ëŠ” lazy loadingìœ¼ë¡œ ì²˜ë¦¬
  }

  /**
   * ğŸ”§ Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (Lazy Loading + ì•ˆì „ ê²€ì¦)
   */
  private initializeClient(): GoogleGenerativeAI {
    if (this.genAI) {
      return this.genAI;
    }

    try {
      const primaryKey = getGoogleAIKey();
      const secondaryKey = getGoogleAISecondaryKey();
      let apiKeyToUse: string | null = null;

      if (primaryKey) {
        apiKeyToUse = primaryKey;
      } else if (secondaryKey) {
        apiKeyToUse = secondaryKey;
      }

      if (!apiKeyToUse) {
        throw new Error('Google AI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }

      this.genAI = getGoogleAIClient(apiKeyToUse);

      // ğŸ” SDK ê°ì²´ ì•ˆì „ì„± ê²€ì¦
      if (!this.genAI || typeof this.genAI !== 'object') {
        throw new Error('getGoogleAIClient()ê°€ ìœ íš¨í•œ ê°ì²´ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      }

      if (typeof this.genAI.getGenerativeModel !== 'function') {
        debug.error('âŒ SDK ê²€ì¦ ì‹¤íŒ¨', {
          genAI: this.genAI,
          type: typeof this.genAI,
          constructor: this.genAI.constructor?.name,
          hasGetGenerativeModel: 'getGenerativeModel' in this.genAI,
          methods: Object.getOwnPropertyNames(this.genAI)
        });
        throw new Error('Google AI SDKì˜ getGenerativeModel ë©”ì„œë“œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      }

      debug.log('âœ… DirectGoogleAIService: Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ');
      return this.genAI;
    } catch (error) {
      debug.error('âŒ DirectGoogleAIService: í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨', error);
      throw new Error(`Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: ${error}`);
    }
  }

  /**
   * ğŸš€ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ìºì‹± ì ìš©)
   */
  private async getModel(modelName: string, temperature: number, maxTokens: number): Promise<GenerativeModel> {
    const cacheKey = `${modelName}-${temperature}-${maxTokens}`;

    const cachedModel = this.modelCache.get(cacheKey);
    if (cachedModel) {
      return cachedModel;
    }

    const genAI = this.initializeClient();

    const model = genAI.getGenerativeModel({
      model: modelName,
      generationConfig: {
        temperature,
        maxOutputTokens: maxTokens,
      },
    });

    this.modelCache.set(cacheKey, model);
    return model;
  }

  /**
   * â±ï¸ íƒ€ì„ì•„ì›ƒ Promise ìƒì„±
   */
  private createTimeoutPromise(timeoutMs: number): Promise<never> {
    return new Promise((_, reject) => {
      setTimeout(() => {
        reject(new Error(`Google AI ì§ì ‘ í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (${timeoutMs}ms)`));
      }, timeoutMs);
    });
  }

  /**
   * ğŸ¯ ì½˜í…ì¸  ìƒì„± (ë©”ì¸ ë©”ì„œë“œ)
   *
   * ì•„í‚¤í…ì²˜ ê°œì„ ì :
   * 1. ì§ì ‘ SDK í˜¸ì¶œ - ì¤‘ê°„ ë ˆì´ì–´ ì—†ìŒ
   * 2. Promise.race ê¸°ë°˜ íƒ€ì„ì•„ì›ƒ - AbortController ë³µì¡ì„± ì œê±°
   * 3. ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ë³´ì¡´
   * 4. ì„±ëŠ¥ ë©”íŠ¸ë¦­ í¬í•¨
   */
  async generateContent(
    prompt: string,
    options: DirectGoogleAIOptions
  ): Promise<DirectGoogleAIResponse> {
    const startTime = Date.now();

    // íƒ€ì„ì•„ì›ƒ ì„¤ì • (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” 5ì´ˆ - ë¬´ë£Œ í‹°ì–´ ìµœì í™”)
    const timeouts = getEnvironmentTimeouts();
    const timeoutMs = options.timeout || timeouts.GOOGLE_AI; // ğŸ¯ ë„‰ë„‰í•œ íƒ€ì„ì•„ì›ƒ: timeout-config.ts ì„¤ì • ì‚¬ìš© (8ì´ˆ)

    debug.log('ğŸš€ DirectGoogleAIService: ì½˜í…ì¸  ìƒì„± ì‹œì‘', {
      model: options.model,
      temperature: options.temperature,
      maxTokens: options.maxTokens,
      timeout: timeoutMs,
      promptLength: prompt.length
    });

    try {
      // ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
      const model = await this.getModel(options.model, options.temperature, options.maxTokens);

      // Promise.raceë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
      const generationPromise = model.generateContent(prompt);
      const timeoutPromise = this.createTimeoutPromise(timeoutMs);

      const result = await Promise.race([
        generationPromise,
        timeoutPromise
      ]);

      const responseTime = Date.now() - startTime;
      const content = result.response.text();

      debug.log('âœ… DirectGoogleAIService: ì„±ê³µ', {
        responseTime,
        contentLength: content.length,
        model: options.model
      });

      return {
        success: true,
        content,
        model: options.model,
        responseTime,
        usage: {
          // Google AI SDKëŠ” usage ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šì§€ë§Œ êµ¬ì¡° ìœ ì§€
          promptTokens: Math.ceil(prompt.length / 4), // ëŒ€ëµì  ê³„ì‚°
          completionTokens: Math.ceil(content.length / 4),
          totalTokens: Math.ceil((prompt.length + content.length) / 4)
        }
      };

    } catch (error) {
      const responseTime = Date.now() - startTime;
      const errorMessage = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';

      debug.error('âŒ DirectGoogleAIService: ì‹¤íŒ¨', {
        error: errorMessage,
        responseTime,
        model: options.model,
        timeout: timeoutMs
      });

      return {
        success: false,
        content: '',
        model: options.model,
        responseTime,
        error: errorMessage
      };
    }
  }

  /**
   * ğŸ” í—¬ìŠ¤ ì²´í¬ (ì—°ê²° í…ŒìŠ¤íŠ¸)
   */
  async healthCheck(): Promise<boolean> {
    try {
      const testResponse = await this.generateContent(
        'Hello',
        {
          model: 'gemini-2.0-flash-exp',
          temperature: 0.1,
          maxTokens: 10,
          timeout: 2000 // 2ì´ˆ íƒ€ì„ì•„ì›ƒ
        }
      );

      return testResponse.success;
    } catch (error) {
      debug.error('âŒ DirectGoogleAIService: í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨', error);
      return false;
    }
  }

  /**
   * ğŸ§¹ ìºì‹œ ì •ë¦¬
   */
  clearCache(): void {
    this.modelCache.clear();
    debug.log('ğŸ§¹ DirectGoogleAIService: ëª¨ë¸ ìºì‹œ ì •ë¦¬ ì™„ë£Œ');
  }

  /**
   * ğŸ“Š ìºì‹œ ìƒíƒœ ì¡°íšŒ
   */
  getCacheStats(): { size: number; keys: string[] } {
    return {
      size: this.modelCache.size,
      keys: Array.from(this.modelCache.keys())
    };
  }
}

/**
 * ğŸ­ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
 */
let directGoogleAIServiceInstance: DirectGoogleAIService | null = null;

export function getDirectGoogleAIService(): DirectGoogleAIService {
  if (!directGoogleAIServiceInstance) {
    directGoogleAIServiceInstance = new DirectGoogleAIService();
  }
  return directGoogleAIServiceInstance;
}

/**
 * ğŸ”„ ì¸ìŠ¤í„´ìŠ¤ ì¬ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©)
 */
export function resetDirectGoogleAIService(): void {
  directGoogleAIServiceInstance = null;
}
