// MCP (Model Context Protocol) ê¸°ë°˜ AI ë¼ìš°í„°
export interface MCPTask {
  id: string;
  type: 'timeseries' | 'nlp' | 'anomaly' | 'complex_ml';
  priority: 'high' | 'medium' | 'low';
  data: any;
  context: MCPContext;
  timeout?: number;
}

export interface MCPContext {
  serverMetrics?: ServerMetrics[];
  logEntries?: LogEntry[];
  timeRange?: { start: Date; end: Date };
  userQuery?: string;
  previousResults?: any[];
  sessionId?: string;
}

export interface MCPResponse {
  success: boolean;
  results: MCPTaskResult[];
  summary: string;
  confidence: number;
  processingTime: number;
  enginesUsed: string[];
  recommendations: string[];
  metadata: {
    tasksExecuted: number;
    successRate: number;
    fallbacksUsed: number;
    pythonWarmupTriggered: boolean;
  };
}

export interface MCPTaskResult {
  taskId: string;
  type: string;
  success: boolean;
  result?: any;
  error?: string;
  executionTime: number;
  engine: string;
  confidence?: number;
  warning?: string;
}

export interface Intent {
  primary: string;
  confidence: number;
  needsTimeSeries: boolean;
  needsNLP: boolean;
  needsAnomalyDetection: boolean;
  needsComplexML: boolean;
  entities: string[];
  urgency: 'low' | 'medium' | 'high' | 'critical';
}

export interface ServerMetrics {
  timestamp: string;
  cpu: number;
  memory: number;
  disk: number;
  networkIn: number;
  networkOut: number;
  responseTime?: number;
  activeConnections?: number;
}

export interface LogEntry {
  timestamp: string;
  level: 'INFO' | 'WARN' | 'ERROR' | 'DEBUG';
  message: string;
  source: string;
  details?: any;
}

export class MCPAIRouter {
  private intentClassifier: any; // UnifiedIntentClassifier ë˜ëŠ” fallback
  private taskOrchestrator: TaskOrchestrator;
  private responseMerger: ResponseMerger;
  private sessionManager: SessionManager;
  private pythonServiceWarmedUp: boolean = false;
  private warmupPromise: Promise<void> | null = null;
  
  constructor() {
    this.initializeIntentClassifier();
    this.taskOrchestrator = new TaskOrchestrator();
    this.responseMerger = new ResponseMerger();
    this.sessionManager = new SessionManager();
    
    console.log('ğŸ”§ MCP AI Router ì´ˆê¸°í™” (ì˜¨ë””ë§¨ë“œ ì›œì—… ëª¨ë“œ)');
  }

  /**
   * ğŸ¯ í†µí•© Intent Classifier ì´ˆê¸°í™” (Jules ë¶„ì„ ê¸°ë°˜)
   */
  private async initializeIntentClassifier(): Promise<void> {
    try {
      // ê¸°ì¡´ IntentClassifier ì‚¬ìš©
      const { IntentClassifier } = await import('./IntentClassifier');
      this.intentClassifier = new IntentClassifier();
      console.log('ğŸ¯ Intent Classifier ë¡œë“œ ì™„ë£Œ');
    } catch (error) {
      console.warn('âš ï¸ IntentClassifier ë¡œë“œ ì‹¤íŒ¨:', error);
      // ê¸°ë³¸ fallback
      this.intentClassifier = {
        classify: async (query: string) => ({
          primary: 'general_inquiry',
          confidence: 0.5,
          needsTimeSeries: false,
          needsNLP: false,
          needsAnomalyDetection: false,
          needsComplexML: false,
          entities: [],
          urgency: 'medium'
        })
      };
    }
  }

  /**
   * ğŸ¯ ë©”ì¸ ì²˜ë¦¬ íë¦„
   */
  async processQuery(query: string, context: MCPContext): Promise<MCPResponse> {
    const startTime = Date.now();
    const sessionId = context.sessionId || this.generateSessionId();
    
    try {
      // 1. ì„¸ì…˜ ê´€ë¦¬ ë° ì»¨í…ìŠ¤íŠ¸ ê°œì„ 
      const enrichedContext = await this.sessionManager.enrichContext(sessionId, context);
      
      // 2. ì˜ë„ ë¶„ì„ ë° ì‘ì—… ë¶„í•´ (í†µí•© ë¶„ë¥˜ê¸° ì‚¬ìš©)
      const intent = await this.classifyIntent(query);
      const tasks = await this.decomposeTasks(intent, enrichedContext);
      
      // 3. ì‘ì—… ìš°ì„ ìˆœìœ„ ì •ë ¬
      const prioritizedTasks = this.prioritizeTasks(tasks, intent.urgency);
      
      // ğŸ”¥ ì˜¨ë””ë§¨ë“œ ì›œì—…: Python ì‘ì—…ì´ ìˆì„ ë•Œë§Œ ì›œì—…
      const hasPythonTasks = prioritizedTasks.some(task => task.type === 'complex_ml');
      if (hasPythonTasks) {
        console.log('ğŸ Python ì‘ì—… ê°ì§€ - ì˜¨ë””ë§¨ë“œ ì›œì—… ì‹œì‘');
        await this.ensurePythonServiceReady();
      }
      
      // 4. ë³‘ë ¬ ì²˜ë¦¬ (JavaScript + Python)
      const results = await this.taskOrchestrator.executeParallel(prioritizedTasks);
      
      // 5. ê²°ê³¼ í†µí•© ë° ì‘ë‹µ ìƒì„±
      const response = await this.responseMerger.mergeResults(results, intent, enrichedContext);
      
      // 6. ì„¸ì…˜ ì—…ë°ì´íŠ¸
      await this.sessionManager.updateSession(sessionId, { query, intent, results, response });
      
      return {
        ...response,
        processingTime: Date.now() - startTime,
        metadata: {
          tasksExecuted: results.length,
          successRate: results.filter(r => r.success).length / results.length,
          fallbacksUsed: results.filter(r => r.warning?.includes('fallback')).length,
          pythonWarmupTriggered: hasPythonTasks
        }
      };
      
    } catch (error) {
      console.error('MCP Router ì²˜ë¦¬ ì˜¤ë¥˜:', error);
      return this.createErrorResponse(error, Date.now() - startTime);
    }
  }

  /**
   * ğŸ¯ í†µí•© ì˜ë„ ë¶„ë¥˜ (ìƒˆë¡œìš´ ë¶„ë¥˜ê¸° í˜¸í™˜)
   */
  private async classifyIntent(query: string): Promise<Intent> {
    try {
      const result = await this.intentClassifier.classify(query);
      
      // UnifiedIntentClassifier ê²°ê³¼ë¥¼ ê¸°ì¡´ Intent íƒ€ì…ìœ¼ë¡œ ë³€í™˜
      if (result.intent && result.confidence !== undefined) {
        return {
          primary: result.intent,
          confidence: result.confidence,
          needsTimeSeries: result.needsTimeSeries || false,
          needsNLP: result.needsNLP || false,
          needsAnomalyDetection: result.needsAnomalyDetection || false,
          needsComplexML: result.needsComplexML || false,
          entities: result.entities || [],
          urgency: result.urgency || 'medium'
        };
      }
      
      // ê¸°ì¡´ IntentClassifier ê²°ê³¼ëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜
      return result;
    } catch (error) {
      console.warn('âš ï¸ ì˜ë„ ë¶„ë¥˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©:', error);
      return {
        primary: 'general_inquiry',
        confidence: 0.5,
        needsTimeSeries: false,
        needsNLP: false,
        needsAnomalyDetection: false,
        needsComplexML: false,
        entities: [],
        urgency: 'medium'
      };
    }
  }

  /**
   * ğŸ”§ ì˜ë„ ê¸°ë°˜ ì‘ì—… ë¶„í•´
   */
  private async decomposeTasks(intent: Intent, context: MCPContext): Promise<MCPTask[]> {
    const tasks: MCPTask[] = [];
    const baseId = Date.now();

    // ğŸ”¥ ì‹œê³„ì—´ ì˜ˆì¸¡ ì‘ì—… (TensorFlow.js)
    if (intent.needsTimeSeries && context.serverMetrics) {
      tasks.push({
        id: `timeseries_${baseId}`,
        type: 'timeseries',
        priority: intent.urgency === 'critical' ? 'high' : 'medium',
        data: {
          metrics: context.serverMetrics,
          predictionHours: this.getPredictionHours(intent),
          features: ['cpu', 'memory', 'disk', 'networkIn', 'networkOut']
        },
        context,
        timeout: 15000
      });
    }

    // ğŸ“ í…ìŠ¤íŠ¸ ë¶„ì„ ì‘ì—… (Transformers.js)
    if (intent.needsNLP) {
      tasks.push({
        id: `nlp_${baseId + 1}`,
        type: 'nlp',
        priority: 'medium',
        data: {
          text: context.userQuery,
          logs: context.logEntries,
          analysisType: this.getNLPAnalysisType(intent)
        },
        context,
        timeout: 10000
      });
    }

    // âš¡ ì´ìƒ íƒì§€ ì‘ì—… (ONNX.js)
    if (intent.needsAnomalyDetection && context.serverMetrics) {
      tasks.push({
        id: `anomaly_${baseId + 2}`,
        type: 'anomaly',
        priority: intent.urgency === 'critical' ? 'high' : 'medium',
        data: {
          metrics: context.serverMetrics,
          sensitivity: this.getAnomalySensitivity(intent),
          lookbackHours: 24
        },
        context,
        timeout: 8000
      });
    }

    // ğŸ ë³µì¡í•œ ML ì‘ì—… (External Python)
    if (intent.needsComplexML) {
      tasks.push({
        id: `complex_ml_${baseId + 3}`,
        type: 'complex_ml',
        priority: 'low', // ì™¸ë¶€ ì„œë¹„ìŠ¤ë¼ ìš°ì„ ìˆœìœ„ ë‚®ìŒ
        data: {
          query: context.userQuery,
          metrics: context.serverMetrics,
          logs: context.logEntries,
          analysisType: 'advanced_pattern_detection'
        },
        context,
        timeout: 20000
      });
    }

    return tasks;
  }

  /**
   * ğŸ“Š ì‘ì—… ìš°ì„ ìˆœìœ„ ì •ë ¬
   */
  private prioritizeTasks(tasks: MCPTask[], urgency: string): MCPTask[] {
    const priorityOrder = { high: 3, medium: 2, low: 1 };
    
    return tasks.sort((a, b) => {
      // ê¸´ê¸‰ë„ê°€ ë†’ìœ¼ë©´ ìš°ì„ ìˆœìœ„ ì¡°ì •
      if (urgency === 'critical') {
        if (a.type === 'anomaly' || a.type === 'timeseries') a.priority = 'high';
      }
      
      return priorityOrder[b.priority] - priorityOrder[a.priority];
    });
  }

  /**
   * ğŸ†” ì„¸ì…˜ ID ìƒì„±
   */
  private generateSessionId(): string {
    return `mcp_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  /**
   * âŒ ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±
   */
  private createErrorResponse(error: any, processingTime: number): MCPResponse {
    return {
      success: false,
      results: [],
      summary: `AI ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`,
      confidence: 0,
      processingTime,
      enginesUsed: [],
      recommendations: ['ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”', 'ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”'],
      metadata: {
        tasksExecuted: 0,
        successRate: 0,
        fallbacksUsed: 0,
        pythonWarmupTriggered: false
      }
    };
  }

  /**
   * ğŸ“ˆ ì˜ˆì¸¡ ì‹œê°„ ê²°ì •
   */
  private getPredictionHours(intent: Intent): number {
    if (intent.urgency === 'critical') return 1;
    if (intent.urgency === 'high') return 6;
    return 24;
  }

  /**
   * ğŸ” NLP ë¶„ì„ íƒ€ì… ê²°ì •
   */
  private getNLPAnalysisType(intent: Intent): string {
    const primary = intent.primary.toLowerCase();
    if (primary.includes('log')) return 'log_analysis';
    if (primary.includes('error')) return 'error_classification';
    if (primary.includes('performance')) return 'performance_analysis';
    return 'general_analysis';
  }

  /**
   * ğŸ¯ ì´ìƒ íƒì§€ ë¯¼ê°ë„ ì„¤ì •
   */
  private getAnomalySensitivity(intent: Intent): number {
    switch (intent.urgency) {
      case 'critical': return 0.8;
      case 'high': return 0.85;
      case 'medium': return 0.9;
      default: return 0.95;
    }
  }

  /**
   * ğŸš€ Python ì„œë¹„ìŠ¤ ì›œì—… í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (ì˜¨ë””ë§¨ë“œ)
   */
  private async startWarmupProcess(): Promise<void> {
    if (this.pythonServiceWarmedUp) {
      console.log('âœ… Python ì„œë¹„ìŠ¤ ì´ë¯¸ ì›œì—…ë¨ - ê±´ë„ˆë›°ê¸°');
      return;
    }
    
    if (this.warmupPromise) {
      console.log('ğŸ”„ Python ì›œì—… ì§„í–‰ ì¤‘ - ëŒ€ê¸°');
      return this.warmupPromise;
    }
    
    console.log('ğŸš€ ì˜¨ë””ë§¨ë“œ Python ì›œì—… ì‹œì‘');
    this.warmupPromise = this.warmupPythonService();
    return this.warmupPromise;
  }

  /**
   * ğŸ”¥ Python ì„œë¹„ìŠ¤ ì›œì—… (ì ë“  ì„œë²„ ê¹¨ìš°ê¸°) - ìµœì í™”ëœ ì˜¨ë””ë§¨ë“œ ë²„ì „
   */
  private async warmupPythonService(): Promise<void> {
    if (this.pythonServiceWarmedUp) return;
    
    const pythonServiceUrl = process.env.FASTAPI_BASE_URL || 'https://openmanager-ai-engine.onrender.com';
    const startTime = Date.now();
    
    try {
      console.log('ğŸ”¥ Python ì„œë¹„ìŠ¤ ì›œì—… ì‹œì‘ (ì˜¨ë””ë§¨ë“œ)...', pythonServiceUrl);
      
      // í—¬ìŠ¤ì²´í¬ë¡œ ì„œë²„ ê¹¨ìš°ê¸° (íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•)
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 20000); // 20ì´ˆë¡œ ë‹¨ì¶•
      
      const response = await fetch(`${pythonServiceUrl}/health`, {
        method: 'GET',
        signal: controller.signal,
        headers: {
          'User-Agent': 'OpenManager-OnDemand-Warmup'
        }
      });
      
      clearTimeout(timeoutId);
      
      if (response.ok) {
        const data = await response.json();
        const warmupTime = Date.now() - startTime;
        
        console.log(`âœ… ì˜¨ë””ë§¨ë“œ Python ì›œì—… ì™„ë£Œ! (${warmupTime}ms)`, data);
        this.pythonServiceWarmedUp = true;
        
        // ğŸ“Š ì›œì—… ì„±ê³µ ê¸°ë¡ (ì•ˆì „í•œ í˜¸ì¶œ)
        try {
          if (typeof monitoringService !== 'undefined' && monitoringService.recordWarmupAttempt) {
            monitoringService.recordWarmupAttempt(true, warmupTime);
          }
        } catch (monitoringError) {
          console.warn('âš ï¸ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ê¸°ë¡ ì‹¤íŒ¨ (ë¬´ì‹œ):', monitoringError);
        }
        
        // ğŸ¯ ì˜¨ë””ë§¨ë“œ ëª¨ë“œ: ê¸°ë³¸ ì›œì—…ë§Œ ì™„ë£Œ
        console.log('ğŸ¯ ì˜¨ë””ë§¨ë“œ ëª¨ë“œ: ê¸°ë³¸ ì›œì—…ë§Œ ì™„ë£Œ');
      } else {
        throw new Error(`ì›œì—… í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: ${response.status}`);
      }
    } catch (error: any) {
      const warmupTime = Date.now() - startTime;
      console.warn('âš ï¸ ì˜¨ë””ë§¨ë“œ Python ì›œì—… ì‹¤íŒ¨:', error.message);
      
      // ğŸ“Š ì›œì—… ì‹¤íŒ¨ ê¸°ë¡ (ì•ˆì „í•œ í˜¸ì¶œ)
      try {
        if (typeof monitoringService !== 'undefined' && monitoringService.recordWarmupAttempt) {
          monitoringService.recordWarmupAttempt(false, warmupTime, error.message);
        }
      } catch (monitoringError) {
        console.warn('âš ï¸ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ê¸°ë¡ ì‹¤íŒ¨ (ë¬´ì‹œ):', monitoringError);
      }
      
      // ì˜¨ë””ë§¨ë“œ ëª¨ë“œì—ì„œëŠ” ì›œì—… ì‹¤íŒ¨ ì‹œ Python ì‘ì—… ê±´ë„ˆë›°ê¸°
      console.log('ğŸ”„ Python ì‘ì—… ê±´ë„ˆë›°ê³  JavaScript ì—”ì§„ìœ¼ë¡œ ì²˜ë¦¬');
    } finally {
      this.warmupPromise = null; // í”„ë¡œë¯¸ìŠ¤ ë¦¬ì…‹
    }
  }

  /**
   * ğŸ”„ Python ì„œë¹„ìŠ¤ ì¤€ë¹„ ìƒíƒœ ë³´ì¥ (ì˜¨ë””ë§¨ë“œ)
   */
  private async ensurePythonServiceReady(): Promise<void> {
    if (!this.pythonServiceWarmedUp) {
      await this.startWarmupProcess();
    }
  }

  /**
   * ğŸ”§ ì—”ì§„ ìƒíƒœ í™•ì¸ (ì˜¨ë””ë§¨ë“œ ìƒíƒœ í¬í•¨)
   */
  async getEngineStatus(): Promise<any> {
    return {
      tensorflow: await this.taskOrchestrator.checkTensorFlowStatus(),
      transformers: await this.taskOrchestrator.checkTransformersStatus(),
      onnx: await this.taskOrchestrator.checkONNXStatus(),
      python: await this.taskOrchestrator.checkPythonStatus(),
      pythonWarmedUp: this.pythonServiceWarmedUp,
      warmupMode: 'on-demand', // ì˜¨ë””ë§¨ë“œ ëª¨ë“œ í‘œì‹œ
      allReady: true
    };
  }

  /**
   * ğŸ§ª ì›œì—…ìš© ê°„ë‹¨í•œ ë¶„ì„ ìˆ˜í–‰ (ìˆ˜ë™ ì›œì—… ì „ìš©)
   */
  private async performWarmupAnalysis(): Promise<void> {
    try {
      const pythonServiceUrl = process.env.FASTAPI_BASE_URL || 'https://openmanager-ai-engine.onrender.com';
      
      const response = await fetch(`${pythonServiceUrl}/analyze`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query: 'manual warmup test',
          metrics: [{
            timestamp: new Date().toISOString(),
            cpu: 50, memory: 60, disk: 70,
            networkIn: 1000, networkOut: 2000
          }]
        }),
        signal: AbortSignal.timeout(15000)
      });
      
      if (response.ok) {
        console.log('ğŸ¯ Python ì„œë¹„ìŠ¤ ì™„ì „ ì›œì—… ì™„ë£Œ (ìˆ˜ë™ íŠ¸ë¦¬ê±°)');
      }
    } catch (error) {
      console.warn('âš ï¸ ì™„ì „ ì›œì—… ë¶„ì„ ì‹¤íŒ¨ (ì •ìƒ):', error);
    }
  }

  /**
   * ğŸ”„ ìˆ˜ë™ ì›œì—… íŠ¸ë¦¬ê±° (ê´€ë¦¬ììš©)
   */
  async triggerManualWarmup(): Promise<boolean> {
    try {
      console.log('ğŸ”§ ìˆ˜ë™ ì›œì—… íŠ¸ë¦¬ê±° ì‹œì‘');
      await this.startWarmupProcess();
      
      // ìˆ˜ë™ ì›œì—…ì—ì„œëŠ” ì™„ì „ ì›œì—… ìˆ˜í–‰
      if (this.pythonServiceWarmedUp) {
        await this.performWarmupAnalysis();
        console.log('âœ… ìˆ˜ë™ ì›œì—… ì™„ë£Œ (ì™„ì „ ì›œì—…)');
        return true;
      }
      
      return false;
    } catch (error) {
      console.error('âŒ ìˆ˜ë™ ì›œì—… ì‹¤íŒ¨:', error);
      return false;
    }
  }
}

// Import ì„ ì–¸ë“¤
import { IntentClassifier } from './IntentClassifier';
import { TaskOrchestrator } from './TaskOrchestrator';
import { ResponseMerger } from './ResponseMerger';
import { SessionManager } from './SessionManager';
import { monitoringService } from './MonitoringService'; 