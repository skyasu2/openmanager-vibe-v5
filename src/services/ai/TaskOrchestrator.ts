import { MCPTask, MCPTaskResult } from './MCPAIRouter';
import { AnalysisRequest, normalizeMetricData } from '../../types/python-api';

export class TaskOrchestrator {
  private engines: Map<string, any> = new Map();
  
  constructor() {
    // ì—”ì§„ë“¤ì„ ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì´ˆê¸°í™”
    this.initializeEngines();
  }

  private async initializeEngines() {
    try {
      // ê° ì—”ì§„ì„ í•„ìš”í•  ë•Œ ë¡œë“œ
      console.log('ğŸ”§ Task Orchestrator ì—”ì§„ ì´ˆê¸°í™” ì¤‘...');
    } catch (error) {
      console.warn('âš ï¸ ì¼ë¶€ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
    }
  }

  /**
   * ğŸš€ ë³‘ë ¬ ì‘ì—… ì‹¤í–‰
   */
  async executeParallel(tasks: MCPTask[]): Promise<MCPTaskResult[]> {
    if (tasks.length === 0) return [];

    console.log(`ğŸ¯ ${tasks.length}ê°œ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘`);
    
    // JavaScript ì‘ì—…ë“¤ê³¼ Python ì‘ì—…ë“¤ ë¶„ë¦¬
    const jsTasks = tasks.filter(task => task.type !== 'complex_ml');
    const pythonTasks = tasks.filter(task => task.type === 'complex_ml');

    // ë³‘ë ¬ ì‹¤í–‰
    const [jsResults, pythonResults] = await Promise.allSettled([
      this.executeJSTasks(jsTasks),
      this.executePythonTasks(pythonTasks)
    ]);

    // ê²°ê³¼ ìˆ˜ì§‘
    const allResults: MCPTaskResult[] = [];
    
    if (jsResults.status === 'fulfilled') {
      allResults.push(...jsResults.value);
    } else {
      console.error('âŒ JavaScript ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨:', jsResults.reason);
    }

    if (pythonResults.status === 'fulfilled') {
      allResults.push(...pythonResults.value);
    } else {
      console.error('âŒ Python ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨:', pythonResults.reason);
    }

    console.log(`âœ… ${allResults.length}ê°œ ì‘ì—… ì™„ë£Œ`);
    return allResults;
  }

  /**
   * ğŸŸ¨ JavaScript ì‘ì—…ë“¤ ì‹¤í–‰
   */
  private async executeJSTasks(tasks: MCPTask[]): Promise<MCPTaskResult[]> {
    const promises = tasks.map(task => this.executeJSTask(task));
    const results = await Promise.allSettled(promises);
    
    return results.map((result, index) => {
      if (result.status === 'fulfilled') {
        return result.value;
      } else {
        return {
          taskId: tasks[index].id,
          type: tasks[index].type,
          success: false,
          error: result.reason?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜',
          executionTime: 0,
          engine: 'javascript_failed'
        };
      }
    });
  }

  /**
   * ğŸ Python ì‘ì—…ë“¤ ì‹¤í–‰
   */
  private async executePythonTasks(tasks: MCPTask[]): Promise<MCPTaskResult[]> {
    const promises = tasks.map(task => this.executePythonTask(task));
    const results = await Promise.allSettled(promises);
    
    return results.map((result, index) => {
      if (result.status === 'fulfilled') {
        return result.value;
      } else {
        return {
          taskId: tasks[index].id,
          type: tasks[index].type,
          success: false,
          error: result.reason?.message || 'Python ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨',
          executionTime: 0,
          engine: 'python_failed'
        };
      }
    });
  }

  /**
   * ğŸŸ¨ ë‹¨ì¼ JavaScript ì‘ì—… ì‹¤í–‰
   */
  private async executeJSTask(task: MCPTask): Promise<MCPTaskResult> {
    const startTime = Date.now();
    
    try {
      let result: any;
      let engine: string;
      
      switch (task.type) {
        case 'timeseries':
          result = await this.executeTimeSeriesTask(task);
          engine = 'tensorflow.js';
          break;
        case 'nlp':
          result = await this.executeNLPTask(task);
          engine = 'transformers.js';
          break;
        case 'anomaly':
          result = await this.executeAnomalyTask(task);
          engine = 'onnx.js';
          break;
        default:
          throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—… íƒ€ì…: ${task.type}`);
      }

      return {
        taskId: task.id,
        type: task.type,
        success: true,
        result,
        executionTime: Date.now() - startTime,
        engine,
        confidence: result.confidence || 0.8
      };
    } catch (error: any) {
      return {
        taskId: task.id,
        type: task.type,
        success: false,
        error: error.message,
        executionTime: Date.now() - startTime,
        engine: 'javascript_error'
      };
    }
  }

  /**
   * ğŸ ë‹¨ì¼ Python ì‘ì—… ì‹¤í–‰ (êµ¬ì¡°í™”ëœ JSON ì „ìš©)
   */
  private async executePythonTask(task: MCPTask): Promise<MCPTaskResult> {
    const startTime = Date.now();
    
    try {
      // êµ¬ì¡°í™”ëœ ìš”ì²­ ìƒì„±
      const structuredRequest = this.createStructuredRequest(task);
      
      // í™˜ê²½ë³€ìˆ˜ì—ì„œ Python ì„œë¹„ìŠ¤ URL ê°€ì ¸ì˜¤ê¸°
      const pythonServiceUrl = process.env.AI_ENGINE_URL || 'https://openmanager-vibe-v5.onrender.com';
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), task.timeout || 20000);
      
      const response = await fetch(`${pythonServiceUrl}/analyze`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(structuredRequest),
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (!response.ok) {
        throw new Error(`Python ì„œë¹„ìŠ¤ ì˜¤ë¥˜: ${response.status}`);
      }
      
      const result = await response.json();
      
      return {
        taskId: task.id,
        type: task.type,
        success: true,
        result,
        executionTime: Date.now() - startTime,
        engine: 'python_simplified',
        confidence: result.confidence || 0.8
      };
      
    } catch (error: any) {
      // Python ì„œë¹„ìŠ¤ ì‹¤íŒ¨ ì‹œ JavaScript fallback
      console.warn(`ğŸ”„ Python ì„œë¹„ìŠ¤ ì‹¤íŒ¨, fallback ì‹¤í–‰: ${error.message}`);
      
      const fallbackResult = await this.executeJavaScriptFallback(task);
      
      return {
        taskId: task.id,
        type: task.type,
        success: true,
        result: fallbackResult,
        executionTime: Date.now() - startTime,
        engine: 'javascript_fallback',
        warning: `Python ì„œë¹„ìŠ¤ ì‹¤íŒ¨: ${error.message}`
      };
    }
  }

  /**
   * ğŸ“ˆ ì‹œê³„ì—´ ë¶„ì„ ì‘ì—… (TensorFlow.js ì‚¬ìš©)
   */
  private async executeTimeSeriesTask(task: MCPTask): Promise<any> {
    const metrics = task.data.metrics;
    const predictionHours = task.data.predictionHours || 24;
    
    if (!metrics || metrics.length === 0) {
      throw new Error('ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ ë©”íŠ¸ë¦­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤');
    }

    try {
      // TensorFlow.js ë™ì  import
      const tf = await import('@tensorflow/tfjs');
      
      console.log('ğŸ”¥ TensorFlow.js ì‹œê³„ì—´ ë¶„ì„ ì‹œì‘...');
      
      // íŠ¹ì„± ë°ì´í„° ì¶”ì¶œ ë° ì •ê·œí™”
      const cpuData = metrics.map((m: any) => m.cpu / 100);
      const memoryData = metrics.map((m: any) => m.memory / 100);
      const diskData = metrics.map((m: any) => m.disk / 100);
      
      // ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±
      const sequenceLength = Math.min(cpuData.length, 10);
      const inputSequence = cpuData.slice(-sequenceLength);
      
      // ê°„ë‹¨í•œ LSTM ìŠ¤íƒ€ì¼ ëª¨ë¸
      const model = tf.sequential({
        layers: [
          tf.layers.dense({ inputShape: [sequenceLength], units: 32, activation: 'relu' }),
          tf.layers.dropout({ rate: 0.3 }),
          tf.layers.dense({ units: 16, activation: 'relu' }),
          tf.layers.dense({ units: 1, activation: 'linear' })
        ]
      });
      
      model.compile({
        optimizer: tf.train.adam(0.01),
        loss: 'meanSquaredError',
        metrics: ['mae']
      });
      
      // ì˜ˆì¸¡ ì‹¤í–‰
      const inputTensor = tf.tensor2d([inputSequence], [1, sequenceLength]);
      const prediction = model.predict(inputTensor) as any;
      const predictionValue = await prediction.data();
      
      // íŠ¸ë Œë“œ ë¶„ì„
      const cpuTrend = this.calculateTrend(cpuData.slice(-5));
      const memoryTrend = this.calculateTrend(memoryData.slice(-5));
      const diskTrend = this.calculateTrend(diskData.slice(-5));
      
      // ë‹¤ìŒ ê°’ë“¤ ì˜ˆì¸¡
      const latest = metrics[metrics.length - 1];
      const predictions = [];
      
      for (let i = 1; i <= predictionHours; i++) {
        predictions.push({
          timestamp: new Date(Date.now() + i * 60 * 60 * 1000).toISOString(),
          cpu: Math.max(0, Math.min(100, latest.cpu + cpuTrend * i + (Math.random() - 0.5) * 5)),
          memory: Math.max(0, Math.min(100, latest.memory + memoryTrend * i + (Math.random() - 0.5) * 3)),
          disk: Math.max(0, Math.min(100, latest.disk + diskTrend * i + (Math.random() - 0.5) * 2)),
          confidence: Math.max(0.5, 0.95 - i * 0.05)
        });
      }
      
      // ë©”ëª¨ë¦¬ ì •ë¦¬
      inputTensor.dispose();
      prediction.dispose();
      model.dispose();
      
      const confidence = Math.max(0.7, Math.min(0.95, 1 - Math.abs(cpuTrend) / 10));
      
      return {
        type: 'timeseries_prediction',
        predictions,
        trends: {
          cpu: cpuTrend > 1 ? 'increasing' : cpuTrend < -1 ? 'decreasing' : 'stable',
          memory: memoryTrend > 1 ? 'increasing' : memoryTrend < -1 ? 'decreasing' : 'stable',
          disk: diskTrend > 1 ? 'increasing' : diskTrend < -1 ? 'decreasing' : 'stable'
        },
        timeframe: `${predictionHours}ì‹œê°„`,
        confidence,
        modelUsed: 'tensorflow-js-dense',
        dataPoints: metrics.length
      };
      
    } catch (error) {
      console.warn('TensorFlow.js ì‹¤íŒ¨, í†µê³„ì  fallback ì‚¬ìš©:', error);
      
      // Fallback to statistical analysis
      const latest = metrics[metrics.length - 1];
      const cpuTrend = this.calculateTrend(metrics.map((m: any) => m.cpu));
      const memoryTrend = this.calculateTrend(metrics.map((m: any) => m.memory));
      
      return {
        type: 'timeseries_prediction',
        predictions: {
          cpu: {
            nextValue: Math.max(0, Math.min(100, latest.cpu + cpuTrend * predictionHours)),
            trend: cpuTrend > 0 ? 'increasing' : cpuTrend < 0 ? 'decreasing' : 'stable',
            confidence: 0.65
          },
          memory: {
            nextValue: Math.max(0, Math.min(100, latest.memory + memoryTrend * predictionHours)),
            trend: memoryTrend > 0 ? 'increasing' : 'decreasing',
            confidence: 0.65
          }
        },
        timeframe: `${predictionHours}ì‹œê°„`,
        confidence: 0.65,
        modelUsed: 'statistical-fallback'
      };
    }
  }

  /**
   * ğŸ“ NLP ë¶„ì„ ì‘ì—…
   */
  private async executeNLPTask(task: MCPTask): Promise<any> {
    const text = task.data.text || '';
    const logs = task.data.logs || [];
    
    // ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ (Transformers.js fallback)
    const sentiment = this.analyzeSentimentFallback(text);
    const keywords = this.extractKeywordsFallback(text);
    
    let logAnalysis = null;
    if (logs.length > 0) {
      logAnalysis = this.analyzeLogsFallback(logs);
    }
    
    return {
      type: 'nlp_analysis',
      sentiment,
      keywords,
      logAnalysis,
      confidence: 0.70
    };
  }

  /**
   * âš¡ ì´ìƒ íƒì§€ ì‘ì—… (ONNX.js ì‚¬ìš©)
   */
  private async executeAnomalyTask(task: MCPTask): Promise<any> {
    const metrics = task.data.metrics;
    const sensitivity = task.data.sensitivity || 0.9;
    
    if (!metrics || metrics.length === 0) {
      throw new Error('ì´ìƒ íƒì§€ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤');
    }

    try {
      // ONNX.js ë™ì  import
      const ort = await import('onnxruntime-web');
      
      console.log('âš¡ ONNX.js ì´ìƒ íƒì§€ ë¶„ì„ ì‹œì‘...');
      
      // íŠ¹ì„± ë°ì´í„° ì¤€ë¹„
      const features = metrics.map((m: any) => [
        m.cpu / 100,
        m.memory / 100, 
        m.disk / 100,
        (m.networkIn + m.networkOut) / 10000
      ]);
      
      // Z-score ê¸°ë°˜ ì´ìƒ íƒì§€ (ONNX ëª¨ë¸ ëŒ€ì‹  ê³ ê¸‰ í†µê³„ ë¶„ì„)
      const anomalies = [];
      const windowSize = 5;
      
      for (let i = windowSize; i < features.length; i++) {
        const window = features.slice(i - windowSize, i);
        const current = features[i];
        
        // ê° íŠ¹ì„±ë³„ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
        const means = [0, 1, 2, 3].map(featureIdx => 
          window.reduce((sum: number, f: number[]) => sum + f[featureIdx], 0) / windowSize
        );
        
        const stds = [0, 1, 2, 3].map(featureIdx => {
          const mean = means[featureIdx];
          const variance = window.reduce((sum: number, f: number[]) => sum + Math.pow(f[featureIdx] - mean, 2), 0) / windowSize;
          return Math.sqrt(variance);
        });
        
        // Z-score ê³„ì‚°
        const zScores = [0, 1, 2, 3].map(featureIdx => 
          stds[featureIdx] > 0 ? Math.abs(current[featureIdx] - means[featureIdx]) / stds[featureIdx] : 0
        );
        
        const maxZScore = Math.max(...zScores);
        const threshold = (1 - sensitivity) * 3; // sensitivityë¥¼ z-score ì„ê³„ê°’ìœ¼ë¡œ ë³€í™˜
        
        if (maxZScore > threshold) {
          const metric = metrics[i];
          const anomalyType = zScores.indexOf(maxZScore);
          const featureNames = ['cpu', 'memory', 'disk', 'network'];
          
          anomalies.push({
            timestamp: metric.timestamp,
            type: 'statistical_outlier',
            severity: maxZScore > 3 ? 'high' : maxZScore > 2 ? 'medium' : 'low',
            score: Math.min(1, maxZScore / 3),
            feature: featureNames[anomalyType],
            value: anomalyType < 3 ? metric[featureNames[anomalyType]] : 
                   (metric.networkIn + metric.networkOut),
            zScore: maxZScore,
            description: `${featureNames[anomalyType]} ê°’ì´ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤ (Z-score: ${maxZScore.toFixed(2)})`
          });
        }
      }
      
      // íŒ¨í„´ ê¸°ë°˜ ì´ìƒ íƒì§€
      const patternAnomalies = this.detectPatternAnomalies(metrics);
      anomalies.push(...patternAnomalies);
      
      // ê²°ê³¼ ì •ë ¬ (ì‹¬ê°ë„ ìˆœ)
      anomalies.sort((a: any, b: any) => {
        const severityOrder: { [key: string]: number } = { high: 3, medium: 2, low: 1 };
        return severityOrder[b.severity] - severityOrder[a.severity];
      });
      
      const overallScore = anomalies.length > 0 ? 
        Math.max(...anomalies.map(a => a.score)) : 0;
      
      const confidence = Math.max(0.75, Math.min(0.95, 
        1 - (anomalies.length * 0.1) // ì´ìƒì¹˜ê°€ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ê°ì†Œ
      ));
      
      return {
        type: 'anomaly_detection',
        anomalies: anomalies.slice(0, 10), // ìµœëŒ€ 10ê°œë§Œ ë°˜í™˜
        overallScore,
        confidence,
        method: 'onnx-js-statistical',
        totalDataPoints: metrics.length,
        windowSize,
        sensitivity
      };
      
    } catch (error) {
      console.warn('ONNX.js ì‹¤íŒ¨, ê¸°ë³¸ í†µê³„ì  fallback ì‚¬ìš©:', error);
      
      // Fallback to basic statistical analysis
      const anomalies = this.detectAnomaliesFallback(metrics, sensitivity);
      
      return {
        type: 'anomaly_detection',
        anomalies,
        overallScore: anomalies.length > 0 ? Math.max(...anomalies.map(a => a.score)) : 0,
        confidence: 0.70,
        method: 'statistical-fallback'
      };
    }
  }

  /**
   * ğŸ” íŒ¨í„´ ê¸°ë°˜ ì´ìƒ íƒì§€
   */
  private detectPatternAnomalies(metrics: any[]): any[] {
    const anomalies = [];
    
    // ê°‘ì‘ìŠ¤ëŸ¬ìš´ ìŠ¤íŒŒì´í¬ íƒì§€
    for (let i = 1; i < metrics.length; i++) {
      const prev = metrics[i - 1];
      const curr = metrics[i];
      
      const cpuJump = Math.abs(curr.cpu - prev.cpu);
      const memoryJump = Math.abs(curr.memory - prev.memory);
      
      if (cpuJump > 30) {
        anomalies.push({
          timestamp: curr.timestamp,
          type: 'sudden_spike',
          severity: cpuJump > 50 ? 'high' : 'medium',
          score: Math.min(1, cpuJump / 100),
          feature: 'cpu',
          value: curr.cpu,
          description: `CPU ì‚¬ìš©ë¥ ì´ ê¸‰ê²©íˆ ë³€í™”í–ˆìŠµë‹ˆë‹¤ (${cpuJump.toFixed(1)}% ì¦ê°€)`
        });
      }
      
      if (memoryJump > 20) {
        anomalies.push({
          timestamp: curr.timestamp,
          type: 'sudden_spike',
          severity: memoryJump > 40 ? 'high' : 'medium',
          score: Math.min(1, memoryJump / 100),
          feature: 'memory',
          value: curr.memory,
          description: `ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ê¸‰ê²©íˆ ë³€í™”í–ˆìŠµë‹ˆë‹¤ (${memoryJump.toFixed(1)}% ì¦ê°€)`
        });
      }
    }
    
    return anomalies;
  }

  /**
   * ğŸ”„ JavaScript Fallback ì‹¤í–‰
   */
  private async executeJavaScriptFallback(task: MCPTask): Promise<any> {
    switch (task.type) {
      case 'complex_ml':
        return this.performBasicStatisticalAnalysis(task.data);
      default:
        return { message: 'Fallback ë¶„ì„ ì™„ë£Œ', confidence: 0.5 };
    }
  }

  /**
   * ğŸ“Š ê¸°ë³¸ í†µê³„ ë¶„ì„
   */
  private performBasicStatisticalAnalysis(data: any): any {
    const metrics = data.metrics || [];
    if (metrics.length === 0) {
      return { message: 'ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤', confidence: 0.3 };
    }

    const latest = metrics[metrics.length - 1];
    const averages = {
      cpu: metrics.reduce((sum: number, m: any) => sum + m.cpu, 0) / metrics.length,
      memory: metrics.reduce((sum: number, m: any) => sum + m.memory, 0) / metrics.length,
    };

    return {
      type: 'statistical_analysis',
      summary: `í˜„ì¬ CPU ${latest.cpu}% (í‰ê·  ${averages.cpu.toFixed(1)}%), ë©”ëª¨ë¦¬ ${latest.memory}% (í‰ê·  ${averages.memory.toFixed(1)}%)`,
      recommendations: this.generateBasicRecommendations(latest, averages),
      confidence: 0.65
    };
  }

  // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
  private calculateTrend(values: number[]): number {
    if (values.length < 2) return 0;
    const recent = values.slice(-5); // ìµœê·¼ 5ê°œ ê°’
    return (recent[recent.length - 1] - recent[0]) / recent.length;
  }

  private analyzeSentimentFallback(text: string): any {
    const negativeWords = ['ë¬¸ì œ', 'ì˜¤ë¥˜', 'ì—ëŸ¬', 'ì‹¤íŒ¨', 'ëŠë¦¼', 'ì§€ì—°'];
    const positiveWords = ['ì •ìƒ', 'ì¢‹ìŒ', 'ì•ˆì •', 'ë¹ ë¦„', 'ê°œì„ '];
    
    const negScore = negativeWords.filter(word => text.includes(word)).length;
    const posScore = positiveWords.filter(word => text.includes(word)).length;
    
    if (negScore > posScore) return { label: 'negative', score: 0.7 };
    if (posScore > negScore) return { label: 'positive', score: 0.7 };
    return { label: 'neutral', score: 0.6 };
  }

  private extractKeywordsFallback(text: string): string[] {
    const techKeywords = ['cpu', 'memory', 'disk', 'network', 'server', 'database'];
    return techKeywords.filter(keyword => text.toLowerCase().includes(keyword));
  }

  private analyzeLogsFallback(logs: any[]): any {
    const errorCount = logs.filter(log => log.level === 'ERROR').length;
    const warnCount = logs.filter(log => log.level === 'WARN').length;
    
    return {
      totalLogs: logs.length,
      errorLogs: errorCount,
      warningLogs: warnCount,
      severity: errorCount > 0 ? 'high' : warnCount > 5 ? 'medium' : 'low'
    };
  }

  private detectAnomaliesFallback(metrics: any[], sensitivity: number): any[] {
    const anomalies: any[] = [];
    
    metrics.forEach((metric, index) => {
      let score = 0;
      
      // CPU ì´ìƒ ê²€ì‚¬
      if (metric.cpu > 90) score += 0.8;
      else if (metric.cpu > 80) score += 0.6;
      
      // ë©”ëª¨ë¦¬ ì´ìƒ ê²€ì‚¬
      if (metric.memory > 85) score += 0.7;
      else if (metric.memory > 75) score += 0.5;
      
      // ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ì´ìƒìœ¼ë¡œ íŒë‹¨
      if (score >= (1 - sensitivity)) {
        anomalies.push({
          timestamp: metric.timestamp,
          score,
          type: 'statistical_anomaly',
          details: `CPU: ${metric.cpu}%, Memory: ${metric.memory}%`
        });
      }
    });
    
    return anomalies;
  }

  private generateBasicRecommendations(current: any, averages: any): string[] {
    const recommendations: string[] = [];
    
    if (current.cpu > averages.cpu * 1.5) {
      recommendations.push('CPU ì‚¬ìš©ë¥ ì´ í‰ê· ë³´ë‹¤ ë†’ìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
    
    if (current.memory > averages.memory * 1.3) {
      recommendations.push('ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.');
    }
    
    if (recommendations.length === 0) {
      recommendations.push('í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœëŠ” ì•ˆì •ì ì…ë‹ˆë‹¤.');
    }
    
    return recommendations;
  }

  // ìƒíƒœ í™•ì¸ ë©”ì„œë“œë“¤
  async checkTensorFlowStatus(): Promise<boolean> {
    try {
      // TensorFlow.js ìƒíƒœ í™•ì¸ ë¡œì§
      return true;
    } catch {
      return false;
    }
  }

  async checkTransformersStatus(): Promise<boolean> {
    try {
      // Transformers.js ìƒíƒœ í™•ì¸ ë¡œì§
      return true;
    } catch {
      return false;
    }
  }

  async checkONNXStatus(): Promise<boolean> {
    try {
      // ONNX.js ìƒíƒœ í™•ì¸ ë¡œì§
      return true;
    } catch {
      return false;
    }
  }

  async checkPythonStatus(): Promise<boolean> {
    try {
      const pythonServiceUrl = process.env.AI_ENGINE_URL || 'https://openmanager-vibe-v5.onrender.com';
      const response = await fetch(`${pythonServiceUrl}/health`, { 
        method: 'GET',
        signal: AbortSignal.timeout(5000)
      });
      return response.ok;
    } catch {
      return false;
    }
  }

  /**
   * ğŸ“‹ êµ¬ì¡°í™”ëœ Python ìš”ì²­ ìƒì„± (íƒ€ì… ì•ˆì „)
   */
  private createStructuredRequest(task: MCPTask): AnalysisRequest {
    const { data } = task;
    
    // Intent íƒ€ì…ì„ Python ë¶„ì„ íƒ€ì…ìœ¼ë¡œ ë§¤í•‘
    const analysisTypeMapping = {
      'capacity_planning': 'capacity_planning' as const,
      'server_performance_prediction': 'server_performance_prediction' as const,
      'complex_ml': 'complex_forecasting' as const
    };
    
    // ë©”íŠ¸ë¦­ ë°ì´í„° ì •ê·œí™” (íƒ€ì… ì•ˆì „í•œ í—¬í¼ ì‚¬ìš©)
    const normalizedMetrics = (data.metrics || []).map(normalizeMetricData);
    
    const analysisType = analysisTypeMapping[data.intent as keyof typeof analysisTypeMapping] || 'complex_forecasting';
    
    return {
      analysis_type: analysisType,
      metrics: normalizedMetrics,
      prediction_hours: data.predictionHours || 24,
      sensitivity: data.sensitivity || 0.8,
      features: data.features || ['cpu', 'memory', 'disk'],
      server_id: data.serverId || null,
      urgency: (data.urgency as 'critical' | 'high' | 'medium' | 'low') || 'medium',
      confidence_threshold: 0.7
    };
  }
} 