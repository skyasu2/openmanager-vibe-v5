import { MCPTask, MCPTaskResult } from './MCPAIRouter';
import { AnalysisRequest, normalizeMetricData } from '../../types/python-api';
import { 
  LightweightAnomalyDetector, 
  createLightweightAnomalyDetector,
  MetricData 
} from './lightweight-anomaly-detector';
import { 
  enhancedDataGenerator,
  ScenarioType 
} from '../../utils/enhanced-data-generator';

export class TaskOrchestrator {
  private engines: Map<string, any> = new Map();
  private anomalyDetector: LightweightAnomalyDetector;
  
  constructor() {
    // ì—”ì§„ë“¤ì„ ì§€ì—° ë¡œë”©ìœ¼ë¡œ ì´ˆê¸°í™”
    this.initializeEngines();
    
    // ê²½ëŸ‰í™”ëœ ì´ìƒ íƒì§€ê¸° ì´ˆê¸°í™”
    this.anomalyDetector = createLightweightAnomalyDetector({
      threshold: 2.0,
      windowSize: 15,
      sensitivity: 0.85,
      methods: ['zscore', 'iqr', 'trend', 'threshold']
    });
  }

  private async initializeEngines() {
    try {
      // ê° ì—”ì§„ì„ í•„ìš”í•  ë•Œ ë¡œë“œ
      console.log('ğŸ”§ Task Orchestrator ì—”ì§„ ì´ˆê¸°í™” ì¤‘...');
    } catch (error) {
      console.warn('âš ï¸ ì¼ë¶€ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
    }
  }

  /**
   * ğŸš€ ë³‘ë ¬ ì‘ì—… ì‹¤í–‰
   */
  async executeParallel(tasks: MCPTask[]): Promise<MCPTaskResult[]> {
    if (tasks.length === 0) return [];

    console.log(`ğŸ¯ ${tasks.length}ê°œ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘`);
    
    // JavaScript ì‘ì—…ë“¤ê³¼ Python ì‘ì—…ë“¤ ë¶„ë¦¬
    const jsTasks = tasks.filter(task => task.type !== 'complex_ml');
    const pythonTasks = tasks.filter(task => task.type === 'complex_ml');

    // ë³‘ë ¬ ì‹¤í–‰
    const [jsResults, pythonResults] = await Promise.allSettled([
      this.executeJSTasks(jsTasks),
      this.executePythonTasks(pythonTasks)
    ]);

    // ê²°ê³¼ ìˆ˜ì§‘
    const allResults: MCPTaskResult[] = [];
    
    if (jsResults.status === 'fulfilled') {
      allResults.push(...jsResults.value);
    } else {
      console.error('âŒ JavaScript ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨:', jsResults.reason);
    }

    if (pythonResults.status === 'fulfilled') {
      allResults.push(...pythonResults.value);
    } else {
      console.error('âŒ Python ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨:', pythonResults.reason);
    }

    console.log(`âœ… ${allResults.length}ê°œ ì‘ì—… ì™„ë£Œ`);
    return allResults;
  }

  /**
   * ğŸŸ¨ JavaScript ì‘ì—…ë“¤ ì‹¤í–‰
   */
  private async executeJSTasks(tasks: MCPTask[]): Promise<MCPTaskResult[]> {
    const promises = tasks.map(task => this.executeJSTask(task));
    const results = await Promise.allSettled(promises);
    
    return results.map((result, index) => {
      if (result.status === 'fulfilled') {
        return result.value;
      } else {
        return {
          taskId: tasks[index].id,
          type: tasks[index].type,
          success: false,
          error: result.reason?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜',
          executionTime: 0,
          engine: 'javascript_failed'
        };
      }
    });
  }

  /**
   * ğŸ Python ì‘ì—…ë“¤ ì‹¤í–‰
   */
  private async executePythonTasks(tasks: MCPTask[]): Promise<MCPTaskResult[]> {
    const promises = tasks.map(task => this.executePythonTask(task));
    const results = await Promise.allSettled(promises);
    
    return results.map((result, index) => {
      if (result.status === 'fulfilled') {
        return result.value;
      } else {
        return {
          taskId: tasks[index].id,
          type: tasks[index].type,
          success: false,
          error: result.reason?.message || 'Python ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨',
          executionTime: 0,
          engine: 'python_failed'
        };
      }
    });
  }

  /**
   * ğŸŸ¨ ë‹¨ì¼ JavaScript ì‘ì—… ì‹¤í–‰
   */
  private async executeJSTask(task: MCPTask): Promise<MCPTaskResult> {
    const startTime = Date.now();
    
    try {
      let result: any;
      let engine: string;
      
      switch (task.type) {
        case 'timeseries':
          result = await this.executeTimeSeriesTask(task);
          engine = 'tensorflow.js';
          break;
        case 'nlp':
          result = await this.executeNLPTask(task);
          engine = 'transformers.js';
          break;
        case 'anomaly':
          result = await this.executeAnomalyTask(task);
          engine = 'onnx.js';
          break;
        default:
          throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—… íƒ€ì…: ${task.type}`);
      }

      return {
        taskId: task.id,
        type: task.type,
        success: true,
        result,
        executionTime: Date.now() - startTime,
        engine,
        confidence: result.confidence || 0.8
      };
    } catch (error: any) {
      return {
        taskId: task.id,
        type: task.type,
        success: false,
        error: error.message,
        executionTime: Date.now() - startTime,
        engine: 'javascript_error'
      };
    }
  }

  /**
   * ğŸ ë‹¨ì¼ Python ì‘ì—… ì‹¤í–‰ (êµ¬ì¡°í™”ëœ JSON ì „ìš©)
   */
  private async executePythonTask(task: MCPTask): Promise<MCPTaskResult> {
    const startTime = Date.now();
    
    try {
      // êµ¬ì¡°í™”ëœ ìš”ì²­ ìƒì„±
      const structuredRequest = this.createStructuredRequest(task);
      
      // í™˜ê²½ë³€ìˆ˜ì—ì„œ Python ì„œë¹„ìŠ¤ URL ê°€ì ¸ì˜¤ê¸°
      const pythonServiceUrl = process.env.AI_ENGINE_URL || 'https://openmanager-vibe-v5.onrender.com';
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), task.timeout || 20000);
      
      const response = await fetch(`${pythonServiceUrl}/analyze`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(structuredRequest),
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      
      if (!response.ok) {
        throw new Error(`Python ì„œë¹„ìŠ¤ ì˜¤ë¥˜: ${response.status}`);
      }
      
      const result = await response.json();
      
      return {
        taskId: task.id,
        type: task.type,
        success: true,
        result,
        executionTime: Date.now() - startTime,
        engine: 'python_simplified',
        confidence: result.confidence || 0.8
      };
      
    } catch (error: any) {
      // Python ì„œë¹„ìŠ¤ ì‹¤íŒ¨ ì‹œ JavaScript fallback
      console.warn(`ğŸ”„ Python ì„œë¹„ìŠ¤ ì‹¤íŒ¨, fallback ì‹¤í–‰: ${error.message}`);
      
      const fallbackResult = await this.executeJavaScriptFallback(task);
      
      return {
        taskId: task.id,
        type: task.type,
        success: true,
        result: fallbackResult,
        executionTime: Date.now() - startTime,
        engine: 'javascript_fallback',
        warning: `Python ì„œë¹„ìŠ¤ ì‹¤íŒ¨: ${error.message}`
      };
    }
  }

  /**
   * ğŸ“ˆ ì‹œê³„ì—´ ë¶„ì„ ì‘ì—… (TensorFlow.js ì‚¬ìš©)
   */
  private async executeTimeSeriesTask(task: MCPTask): Promise<any> {
    const metrics = task.data.metrics;
    const predictionHours = task.data.predictionHours || 24;
    
    if (!metrics || metrics.length === 0) {
      throw new Error('ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ ë©”íŠ¸ë¦­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤');
    }

    try {
      // TensorFlow.js ë™ì  import
      const tf = await import('@tensorflow/tfjs');
      
      console.log('ğŸ”¥ TensorFlow.js ì‹œê³„ì—´ ë¶„ì„ ì‹œì‘...');
      
      // íŠ¹ì„± ë°ì´í„° ì¶”ì¶œ ë° ì •ê·œí™”
      const cpuData = metrics.map((m: any) => m.cpu / 100);
      const memoryData = metrics.map((m: any) => m.memory / 100);
      const diskData = metrics.map((m: any) => m.disk / 100);
      
      // ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±
      const sequenceLength = Math.min(cpuData.length, 10);
      const inputSequence = cpuData.slice(-sequenceLength);
      
      // ê°„ë‹¨í•œ LSTM ìŠ¤íƒ€ì¼ ëª¨ë¸
      const model = tf.sequential({
        layers: [
          tf.layers.dense({ inputShape: [sequenceLength], units: 32, activation: 'relu' }),
          tf.layers.dropout({ rate: 0.3 }),
          tf.layers.dense({ units: 16, activation: 'relu' }),
          tf.layers.dense({ units: 1, activation: 'linear' })
        ]
      });
      
      model.compile({
        optimizer: tf.train.adam(0.01),
        loss: 'meanSquaredError',
        metrics: ['mae']
      });
      
      // ì˜ˆì¸¡ ì‹¤í–‰
      const inputTensor = tf.tensor2d([inputSequence], [1, sequenceLength]);
      const prediction = model.predict(inputTensor) as any;
      const predictionValue = await prediction.data();
      
      // íŠ¸ë Œë“œ ë¶„ì„
      const cpuTrend = this.calculateTrend(cpuData.slice(-5));
      const memoryTrend = this.calculateTrend(memoryData.slice(-5));
      const diskTrend = this.calculateTrend(diskData.slice(-5));
      
      // ë‹¤ìŒ ê°’ë“¤ ì˜ˆì¸¡
      const latest = metrics[metrics.length - 1];
      const predictions = [];
      
      for (let i = 1; i <= predictionHours; i++) {
        predictions.push({
          timestamp: new Date(Date.now() + i * 60 * 60 * 1000).toISOString(),
          cpu: Math.max(0, Math.min(100, latest.cpu + cpuTrend * i + (Math.random() - 0.5) * 5)),
          memory: Math.max(0, Math.min(100, latest.memory + memoryTrend * i + (Math.random() - 0.5) * 3)),
          disk: Math.max(0, Math.min(100, latest.disk + diskTrend * i + (Math.random() - 0.5) * 2)),
          confidence: Math.max(0.5, 0.95 - i * 0.05)
        });
      }
      
      // ë©”ëª¨ë¦¬ ì •ë¦¬
      inputTensor.dispose();
      prediction.dispose();
      model.dispose();
      
      const confidence = Math.max(0.7, Math.min(0.95, 1 - Math.abs(cpuTrend) / 10));
      
      return {
        type: 'timeseries_prediction',
        predictions,
        trends: {
          cpu: cpuTrend > 1 ? 'increasing' : cpuTrend < -1 ? 'decreasing' : 'stable',
          memory: memoryTrend > 1 ? 'increasing' : memoryTrend < -1 ? 'decreasing' : 'stable',
          disk: diskTrend > 1 ? 'increasing' : diskTrend < -1 ? 'decreasing' : 'stable'
        },
        timeframe: `${predictionHours}ì‹œê°„`,
        confidence,
        modelUsed: 'tensorflow-js-dense',
        dataPoints: metrics.length
      };
      
    } catch (error) {
      console.warn('TensorFlow.js ì‹¤íŒ¨, í†µê³„ì  fallback ì‚¬ìš©:', error);
      
      // Fallback to statistical analysis
      const latest = metrics[metrics.length - 1];
      const cpuTrend = this.calculateTrend(metrics.map((m: any) => m.cpu));
      const memoryTrend = this.calculateTrend(metrics.map((m: any) => m.memory));
      
      return {
        type: 'timeseries_prediction',
        predictions: {
          cpu: {
            nextValue: Math.max(0, Math.min(100, latest.cpu + cpuTrend * predictionHours)),
            trend: cpuTrend > 0 ? 'increasing' : cpuTrend < 0 ? 'decreasing' : 'stable',
            confidence: 0.65
          },
          memory: {
            nextValue: Math.max(0, Math.min(100, latest.memory + memoryTrend * predictionHours)),
            trend: memoryTrend > 0 ? 'increasing' : 'decreasing',
            confidence: 0.65
          }
        },
        timeframe: `${predictionHours}ì‹œê°„`,
        confidence: 0.65,
        modelUsed: 'statistical-fallback'
      };
    }
  }

  /**
   * ğŸ“ NLP ë¶„ì„ ì‘ì—…
   */
  private async executeNLPTask(task: MCPTask): Promise<any> {
    const text = task.data.text || '';
    const logs = task.data.logs || [];
    
    // ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ (Transformers.js fallback)
    const sentiment = this.analyzeSentimentFallback(text);
    const keywords = this.extractKeywordsFallback(text);
    
    let logAnalysis = null;
    if (logs.length > 0) {
      logAnalysis = this.analyzeLogsFallback(logs);
    }
    
    return {
      type: 'nlp_analysis',
      sentiment,
      keywords,
      logAnalysis,
      confidence: 0.70
    };
  }

  /**
   * âš¡ ì´ìƒ íƒì§€ ì‘ì—… (Enhanced ë²„ì „)
   */
  private async executeAnomalyTask(task: MCPTask): Promise<any> {
    const metrics = task.data.metrics;
    const sensitivity = task.data.sensitivity || 0.85;
    
    if (!metrics || metrics.length === 0) {
      throw new Error('ì´ìƒ íƒì§€ë¥¼ ìœ„í•œ ë©”íŠ¸ë¦­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤');
    }

    console.log('âš¡ Enhanced ì´ìƒ íƒì§€ ë¶„ì„ ì‹œì‘...');
    
    // ë©”íŠ¸ë¦­ ë°ì´í„° ë³€í™˜
    const formattedMetrics: MetricData[] = metrics.map((m: any) => ({
      timestamp: m.timestamp || new Date().toISOString(),
      cpu: m.cpu,
      memory: m.memory,
      disk: m.disk,
      networkIn: m.networkIn,
      networkOut: m.networkOut,
      responseTime: m.responseTime
    }));
    
    // ê²½ëŸ‰í™”ëœ ì´ìƒ íƒì§€ ì‹¤í–‰
    const result = await this.anomalyDetector.detectAnomalies(
      formattedMetrics,
      ['cpu', 'memory', 'disk'],
      {
        windowSize: Math.min(20, Math.floor(metrics.length / 3)),
        sensitivity
      }
    );
    
    // ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ë³€í™˜
    return {
      type: 'enhanced_anomaly_detection',
      anomalies: result.anomalies.map(anomaly => ({
        timestamp: anomaly.timestamp,
        type: anomaly.type,
        severity: anomaly.severity,
        score: anomaly.score,
        feature: anomaly.feature,
        value: anomaly.value,
        zScore: anomaly.zScore,
        description: anomaly.description
      })),
      overallScore: result.overallScore,
      confidence: result.confidence,
      method: 'lightweight-statistics',
      processingTime: result.processingTime,
      recommendations: result.recommendations
    };
  }

  /**
   * ğŸ”„ JavaScript Fallback ì‹¤í–‰
   */
  private async executeJavaScriptFallback(task: MCPTask): Promise<any> {
    switch (task.type) {
      case 'complex_ml':
        return this.performBasicStatisticalAnalysis(task.data);
      default:
        return { message: 'Fallback ë¶„ì„ ì™„ë£Œ', confidence: 0.5 };
    }
  }

  /**
   * ğŸ“Š ê¸°ë³¸ í†µê³„ ë¶„ì„
   */
  private performBasicStatisticalAnalysis(data: any): any {
    const metrics = data.metrics || [];
    if (metrics.length === 0) {
      return { message: 'ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤', confidence: 0.3 };
    }

    const latest = metrics[metrics.length - 1];
    const averages = {
      cpu: metrics.reduce((sum: number, m: any) => sum + m.cpu, 0) / metrics.length,
      memory: metrics.reduce((sum: number, m: any) => sum + m.memory, 0) / metrics.length,
    };

    return {
      type: 'statistical_analysis',
      summary: `í˜„ì¬ CPU ${latest.cpu}% (í‰ê·  ${averages.cpu.toFixed(1)}%), ë©”ëª¨ë¦¬ ${latest.memory}% (í‰ê·  ${averages.memory.toFixed(1)}%)`,
      recommendations: this.generateBasicRecommendations(latest, averages),
      confidence: 0.65
    };
  }

  // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
  private calculateTrend(values: number[]): number {
    if (values.length < 2) return 0;
    const recent = values.slice(-5); // ìµœê·¼ 5ê°œ ê°’
    return (recent[recent.length - 1] - recent[0]) / recent.length;
  }

  private analyzeSentimentFallback(text: string): any {
    const negativeWords = ['ë¬¸ì œ', 'ì˜¤ë¥˜', 'ì—ëŸ¬', 'ì‹¤íŒ¨', 'ëŠë¦¼', 'ì§€ì—°'];
    const positiveWords = ['ì •ìƒ', 'ì¢‹ìŒ', 'ì•ˆì •', 'ë¹ ë¦„', 'ê°œì„ '];
    
    const negScore = negativeWords.filter(word => text.includes(word)).length;
    const posScore = positiveWords.filter(word => text.includes(word)).length;
    
    if (negScore > posScore) return { label: 'negative', score: 0.7 };
    if (posScore > negScore) return { label: 'positive', score: 0.7 };
    return { label: 'neutral', score: 0.6 };
  }

  private extractKeywordsFallback(text: string): string[] {
    const techKeywords = ['cpu', 'memory', 'disk', 'network', 'server', 'database'];
    return techKeywords.filter(keyword => text.toLowerCase().includes(keyword));
  }

  private analyzeLogsFallback(logs: any[]): any {
    const errorCount = logs.filter(log => log.level === 'ERROR').length;
    const warnCount = logs.filter(log => log.level === 'WARN').length;
    
    return {
      totalLogs: logs.length,
      errorLogs: errorCount,
      warningLogs: warnCount,
      severity: errorCount > 0 ? 'high' : warnCount > 5 ? 'medium' : 'low'
    };
  }

  private generateBasicRecommendations(current: any, averages: any): string[] {
    const recommendations: string[] = [];
    
    if (current.cpu > averages.cpu * 1.5) {
      recommendations.push('CPU ì‚¬ìš©ë¥ ì´ í‰ê· ë³´ë‹¤ ë†’ìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
    
    if (current.memory > averages.memory * 1.3) {
      recommendations.push('ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.');
    }
    
    if (recommendations.length === 0) {
      recommendations.push('í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœëŠ” ì•ˆì •ì ì…ë‹ˆë‹¤.');
    }
    
    return recommendations;
  }

  // ìƒíƒœ í™•ì¸ ë©”ì„œë“œë“¤
  async checkTensorFlowStatus(): Promise<boolean> {
    try {
      // TensorFlow.js ìƒíƒœ í™•ì¸ ë¡œì§
      return true;
    } catch {
      return false;
    }
  }

  async checkTransformersStatus(): Promise<boolean> {
    try {
      // Transformers.js ìƒíƒœ í™•ì¸ ë¡œì§
      return true;
    } catch {
      return false;
    }
  }

  async checkONNXStatus(): Promise<boolean> {
    try {
      // ONNX.js ìƒíƒœ í™•ì¸ ë¡œì§
      return true;
    } catch {
      return false;
    }
  }

  async checkPythonStatus(): Promise<boolean> {
    try {
      const pythonServiceUrl = process.env.AI_ENGINE_URL || 'https://openmanager-vibe-v5.onrender.com';
      const response = await fetch(`${pythonServiceUrl}/health`, { 
        method: 'GET',
        signal: AbortSignal.timeout(5000)
      });
      return response.ok;
    } catch {
      return false;
    }
  }

  /**
   * ğŸ“‹ êµ¬ì¡°í™”ëœ Python ìš”ì²­ ìƒì„± (íƒ€ì… ì•ˆì „)
   */
  private createStructuredRequest(task: MCPTask): AnalysisRequest {
    const { data } = task;
    
    // Intent íƒ€ì…ì„ Python ë¶„ì„ íƒ€ì…ìœ¼ë¡œ ë§¤í•‘
    const analysisTypeMapping = {
      'capacity_planning': 'capacity_planning' as const,
      'server_performance_prediction': 'server_performance_prediction' as const,
      'complex_ml': 'complex_forecasting' as const
    };
    
    // ë©”íŠ¸ë¦­ ë°ì´í„° ì •ê·œí™” (íƒ€ì… ì•ˆì „í•œ í—¬í¼ ì‚¬ìš©)
    const normalizedMetrics = (data.metrics || []).map(normalizeMetricData);
    
    const analysisType = analysisTypeMapping[data.intent as keyof typeof analysisTypeMapping] || 'complex_forecasting';
    
    return {
      analysis_type: analysisType,
      metrics: normalizedMetrics,
      prediction_hours: data.predictionHours || 24,
      sensitivity: data.sensitivity || 0.8,
      features: data.features || ['cpu', 'memory', 'disk'],
      server_id: data.serverId || null,
      urgency: (data.urgency as 'critical' | 'high' | 'medium' | 'low') || 'medium',
      confidence_threshold: 0.7
    };
  }
} 