/**
 * ğŸ” OpenManager Vibe v5 - AI ì—”ì§„ ë¡œê¹… ì‹œìŠ¤í…œ ê³ ë„í™”
 *
 * ê³ ê¸‰ AI ë¡œê¹… ì‹œìŠ¤í…œ:
 * - Winston + Pino í•˜ì´ë¸Œë¦¬ë“œ ë¡œê¹…
 * - AI ì‚¬ê³  ê³¼ì • ì¶”ì 
 * - ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
 * - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
 * - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë²„í¼ë§
 */

import winston from 'winston';
import pino from 'pino';
import chalk from 'chalk';

export enum LogLevel {
  ERROR = 'error',
  WARN = 'warn',
  INFO = 'info',
  DEBUG = 'debug',
  VERBOSE = 'verbose',
  AI_THINKING = 'ai_thinking',
  AI_ANALYSIS = 'ai_analysis',
  AI_PERFORMANCE = 'ai_performance',
}

export enum LogCategory {
  AI_ENGINE = 'ai_engine',
  MCP = 'mcp',
  RAG = 'rag',
  GOOGLE_AI = 'google_ai',
  PREDICTION = 'prediction',
  ANOMALY = 'anomaly',
  HYBRID = 'hybrid',
  FALLBACK = 'fallback',
  PERFORMANCE = 'performance',
  SYSTEM = 'system',
}

export interface AILogEntry {
  id: string;
  timestamp: string;
  level: LogLevel;
  category: LogCategory;
  engine: string;
  message: string;
  data?: any;
  metadata?: {
    query?: string;
    userId?: string;
    sessionId?: string;
    requestId?: string;
    duration?: number;
    memoryUsage?: any;
    cpuUsage?: any;
    thinkingSteps?: number;
    conclusionCount?: number;
    errorType?: string;
    hasStack?: boolean;
    contextKeys?: string[];
    suggestions?: string[];
    analysisType?: string;
    confidence?: number;
    resultKeys?: string[];
    operation?: string;
    [key: string]: any; // í™•ì¥ ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„°
  };
  thinking?: {
    steps: any[];
    reasoning: string;
    conclusions: string[];
    confidence?: number;
    alternatives?: string[];
  };
  performance?: {
    responseTime: number;
    memoryDelta: number;
    cpuLoad: number;
    cacheHit?: boolean;
    apiCalls?: number;
  };
  context?: any;
  tags?: string[];
  correlationId?: string;
}

export interface LogFilters {
  level?: LogLevel[];
  category?: LogCategory[];
  engine?: string[];
  since?: string;
  until?: string;
  limit?: number;
  search?: string;
  hasError?: boolean;
  hasThinking?: boolean;
  minConfidence?: number;
}

export class AILogger {
  private static instance: AILogger;
  private winstonLogger: winston.Logger;
  private pinoLogger: any;
  private logBuffer: AILogEntry[] = [];
  private readonly bufferSize = 1000;
  private logCounter = 0;
  private performanceMetrics = new Map<string, any>();
  private isProduction = process.env.NODE_ENV === 'production';
  private subscribers = new Set<(log: AILogEntry) => void>();

  private constructor() {
    this.initializeWinston();
    this.initializePino();
    this.startPerformanceMonitoring();
  }

  public static getInstance(): AILogger {
    if (!AILogger.instance) {
      AILogger.instance = new AILogger();
    }
    return AILogger.instance;
  }

  private initializeWinston(): void {
    const transports: winston.transport[] = [];

    // ê°œë°œ í™˜ê²½: ì»¬ëŸ¬í’€í•œ ì½˜ì†” ì¶œë ¥
    if (!this.isProduction) {
      transports.push(
        new winston.transports.Console({
          format: winston.format.combine(
            winston.format.colorize(),
            winston.format.timestamp(),
            winston.format.printf(({ timestamp, level, message, ...meta }) => {
              const metaStr = Object.keys(meta).length
                ? JSON.stringify(meta, null, 2)
                : '';
              return `${chalk.gray(timestamp)} ${level}: ${message} ${chalk.dim(metaStr)}`;
            })
          ),
        })
      );
    }

    // í”„ë¡œë•ì…˜ í™˜ê²½: íŒŒì¼ ë¡œê¹…
    if (this.isProduction) {
      transports.push(
        new winston.transports.File({
          filename: 'logs/ai-error.log',
          level: 'error',
        }),
        new winston.transports.File({
          filename: 'logs/ai-combined.log',
        })
      );
    }

    this.winstonLogger = winston.createLogger({
      level: this.isProduction ? 'info' : 'debug',
      format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.errors({ stack: true }),
        winston.format.json()
      ),
      transports,
    });
  }

  private mapToWinstonLevel(level: LogLevel): string {
    switch (level) {
      case LogLevel.ERROR:
        return 'error';
      case LogLevel.WARN:
        return 'warn';
      case LogLevel.INFO:
        return 'info';
      case LogLevel.DEBUG:
        return 'debug';
      case LogLevel.VERBOSE:
        return 'verbose';
      case LogLevel.AI_THINKING:
        return 'debug';
      case LogLevel.AI_ANALYSIS:
        return 'info';
      case LogLevel.AI_PERFORMANCE:
        return 'debug';
      default:
        return 'info';
    }
  }

  private mapToPinoLevel(level: LogLevel): string {
    switch (level) {
      case LogLevel.ERROR:
        return 'error';
      case LogLevel.WARN:
        return 'warn';
      case LogLevel.INFO:
        return 'info';
      case LogLevel.DEBUG:
        return 'debug';
      case LogLevel.VERBOSE:
        return 'trace';
      case LogLevel.AI_THINKING:
        return 'debug';
      case LogLevel.AI_ANALYSIS:
        return 'info';
      case LogLevel.AI_PERFORMANCE:
        return 'debug';
      default:
        return 'info';
    }
  }

  private initializePino(): void {
    const pinoConfig: any = {
      level: this.isProduction ? 'info' : 'debug',
      timestamp: pino.stdTimeFunctions.isoTime,
      formatters: {
        level: (label: string) => ({ level: label }),
      },
    };

    // ê°œë°œ í™˜ê²½: pretty print
    if (!this.isProduction) {
      pinoConfig.transport = {
        target: 'pino-pretty',
        options: {
          colorize: true,
          translateTime: 'yyyy-mm-dd HH:MM:ss',
          ignore: 'pid,hostname',
        },
      };
    }

    this.pinoLogger = pino(pinoConfig);
  }

  private startPerformanceMonitoring(): void {
    // 5ì´ˆë§ˆë‹¤ ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    setInterval(() => {
      const memUsage = process.memoryUsage();
      const cpuUsage = process.cpuUsage();

      this.performanceMetrics.set('memory', {
        rss: memUsage.rss,
        heapUsed: memUsage.heapUsed,
        heapTotal: memUsage.heapTotal,
        external: memUsage.external,
        timestamp: new Date().toISOString(),
      });

      this.performanceMetrics.set('cpu', {
        user: cpuUsage.user,
        system: cpuUsage.system,
        timestamp: new Date().toISOString(),
      });
    }, 5000);
  }

  /**
   * ğŸ¤– AI ì—”ì§„ ë¡œê·¸ ê¸°ë¡ (ë©”ì¸ ë©”ì„œë“œ)
   */
  public async logAI(entry: Partial<AILogEntry>): Promise<void> {
    const logEntry: AILogEntry = {
      id: `ai-log-${++this.logCounter}-${Date.now()}`,
      timestamp: new Date().toISOString(),
      level: entry.level || LogLevel.INFO,
      category: entry.category || LogCategory.AI_ENGINE,
      engine: entry.engine || 'unknown',
      message: entry.message || '',
      data: entry.data,
      metadata: {
        ...entry.metadata,
        memoryUsage: process.memoryUsage(),
        cpuUsage: process.cpuUsage(),
      },
      thinking: entry.thinking,
      performance: entry.performance,
      context: entry.context,
      tags: entry.tags || [],
      correlationId: entry.correlationId,
    };

    // ë²„í¼ì— ì¶”ê°€
    this.addToBuffer(logEntry);

    // Winston ë¡œê¹… (ë ˆë²¨ ë§¤í•‘)
    const winstonLevel = this.mapToWinstonLevel(logEntry.level);
    this.winstonLogger[winstonLevel](logEntry.message, logEntry);

    // Pino ë¡œê¹… (ë” ë¹ ë¥¸ ì„±ëŠ¥)
    const pinoLevel = this.mapToPinoLevel(logEntry.level);
    this.pinoLogger[pinoLevel](logEntry);

    // ì‹¤ì‹œê°„ êµ¬ë…ìë“¤ì—ê²Œ ì•Œë¦¼
    this.notifySubscribers(logEntry);

    // ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    this.updatePerformanceMetrics(logEntry);
  }

  /**
   * ğŸ§  AI ì‚¬ê³  ê³¼ì • ë¡œê¹…
   */
  public async logThinking(
    engine: string,
    category: LogCategory,
    query: string,
    steps: any[],
    reasoning: string,
    conclusions: string[],
    confidence?: number,
    alternatives?: string[]
  ): Promise<void> {
    await this.logAI({
      level: LogLevel.AI_THINKING,
      category,
      engine,
      message: `ğŸ§  AI ì‚¬ê³  ê³¼ì •: ${query.slice(0, 100)}${query.length > 100 ? '...' : ''}`,
      thinking: {
        steps,
        reasoning,
        conclusions,
        confidence: confidence || 0.8,
        alternatives: alternatives || [],
      },
      metadata: {
        query,
        thinkingSteps: steps.length,
        conclusionCount: conclusions.length,
      },
      tags: ['thinking', 'reasoning', 'analysis'],
    });
  }

  /**
   * âš¡ AI ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…
   */
  public async logPerformance(
    engine: string,
    category: LogCategory,
    operation: string,
    responseTime: number,
    metadata?: any
  ): Promise<void> {
    const memAfter = process.memoryUsage();

    await this.logAI({
      level: LogLevel.AI_PERFORMANCE,
      category,
      engine,
      message: `âš¡ ì„±ëŠ¥: ${operation} - ${responseTime}ms`,
      performance: {
        responseTime,
        memoryDelta: memAfter.heapUsed,
        cpuLoad: process.cpuUsage().user,
        cacheHit: metadata?.cacheHit || false,
        apiCalls: metadata?.apiCalls || 0,
      },
      metadata: {
        ...metadata,
        operation,
        timestamp: new Date().toISOString(),
      },
      tags: ['performance', 'metrics', operation],
    });
  }

  /**
   * âŒ AI ì—”ì§„ ì˜¤ë¥˜ ë¡œê¹…
   */
  public async logError(
    engine: string,
    category: LogCategory,
    error: Error | string,
    context?: any,
    correlationId?: string
  ): Promise<void> {
    const errorMessage = error instanceof Error ? error.message : error;
    const errorStack = error instanceof Error ? error.stack : undefined;

    await this.logAI({
      level: LogLevel.ERROR,
      category,
      engine,
      message: `âŒ AI ì—”ì§„ ì˜¤ë¥˜: ${errorMessage}`,
      data: {
        error: errorMessage,
        stack: errorStack,
        context,
        timestamp: new Date().toISOString(),
      },
      metadata: {
        errorType:
          error instanceof Error ? error.constructor.name : 'StringError',
        hasStack: !!errorStack,
        contextKeys: context ? Object.keys(context) : [],
      },
      correlationId,
      tags: ['error', 'exception', category],
    });
  }

  /**
   * âš ï¸ AI ì—”ì§„ ê²½ê³  ë¡œê¹…
   */
  public async logWarning(
    engine: string,
    category: LogCategory,
    message: string,
    data?: any,
    suggestions?: string[]
  ): Promise<void> {
    await this.logAI({
      level: LogLevel.WARN,
      category,
      engine,
      message: `âš ï¸ ${message}`,
      data,
      metadata: {
        suggestions: suggestions || [],
        timestamp: new Date().toISOString(),
      },
      tags: ['warning', 'attention', category],
    });
  }

  /**
   * ğŸ“Š AI ë¶„ì„ ê²°ê³¼ ë¡œê¹…
   */
  public async logAnalysis(
    engine: string,
    category: LogCategory,
    analysisType: string,
    results: any,
    confidence: number,
    metadata?: any
  ): Promise<void> {
    await this.logAI({
      level: LogLevel.AI_ANALYSIS,
      category,
      engine,
      message: `ğŸ“Š AI ë¶„ì„: ${analysisType} (ì‹ ë¢°ë„: ${Math.round(confidence * 100)}%)`,
      data: results,
      thinking: {
        steps: [],
        reasoning: `${analysisType} ë¶„ì„ ì™„ë£Œ`,
        conclusions: [`ë¶„ì„ ê²°ê³¼ ${Object.keys(results).length}ê°œ í•­ëª© ë„ì¶œ`],
        confidence,
      },
      metadata: {
        ...metadata,
        analysisType,
        confidence,
        resultKeys: Object.keys(results),
        timestamp: new Date().toISOString(),
      },
      tags: ['analysis', analysisType, 'results'],
    });
  }

  // === ë²„í¼ ë° ê²€ìƒ‰ ë©”ì„œë“œë“¤ ===

  private addToBuffer(entry: AILogEntry): void {
    this.logBuffer.push(entry);
    if (this.logBuffer.length > this.bufferSize) {
      this.logBuffer = this.logBuffer.slice(-this.bufferSize);
    }
  }

  private notifySubscribers(entry: AILogEntry): void {
    this.subscribers.forEach(callback => {
      try {
        callback(entry);
      } catch (error) {
        console.error('êµ¬ë…ì ì•Œë¦¼ ì˜¤ë¥˜:', error);
      }
    });
  }

  private updatePerformanceMetrics(entry: AILogEntry): void {
    const engineKey = `${entry.engine}-${entry.category}`;

    if (!this.performanceMetrics.has(engineKey)) {
      this.performanceMetrics.set(engineKey, {
        totalLogs: 0,
        errorCount: 0,
        avgResponseTime: 0,
        lastActivity: null,
      });
    }

    const metrics = this.performanceMetrics.get(engineKey);
    metrics.totalLogs++;
    metrics.lastActivity = entry.timestamp;

    if (entry.level === LogLevel.ERROR) {
      metrics.errorCount++;
    }

    if (entry.performance?.responseTime) {
      metrics.avgResponseTime =
        (metrics.avgResponseTime + entry.performance.responseTime) / 2;
    }
  }

  // === ë¡œê·¸ ì¡°íšŒ ë° í•„í„°ë§ ë©”ì„œë“œë“¤ ===

  public getRecentLogs(limit: number = 100): AILogEntry[] {
    return this.logBuffer.slice(-limit);
  }

  public getLogsByEngine(engine: string, limit: number = 50): AILogEntry[] {
    return this.logBuffer.filter(log => log.engine === engine).slice(-limit);
  }

  public getLogsByCategory(
    category: LogCategory,
    limit: number = 50
  ): AILogEntry[] {
    return this.logBuffer
      .filter(log => log.category === category)
      .slice(-limit);
  }

  public getErrorLogs(limit: number = 50): AILogEntry[] {
    return this.logBuffer
      .filter(log => log.level === LogLevel.ERROR)
      .slice(-limit);
  }

  public getThinkingLogs(limit: number = 20): AILogEntry[] {
    return this.logBuffer
      .filter(log => log.level === LogLevel.AI_THINKING)
      .slice(-limit);
  }

  public getAnalysisLogs(limit: number = 30): AILogEntry[] {
    return this.logBuffer
      .filter(log => log.level === LogLevel.AI_ANALYSIS)
      .slice(-limit);
  }

  public getPerformanceLogs(limit: number = 50): AILogEntry[] {
    return this.logBuffer
      .filter(log => log.level === LogLevel.AI_PERFORMANCE)
      .slice(-limit);
  }

  public getPerformanceMetrics(): Map<string, any> {
    return new Map(this.performanceMetrics);
  }

  public searchLogs(query: string, filters?: LogFilters): AILogEntry[] {
    let filteredLogs = [...this.logBuffer];

    // í…ìŠ¤íŠ¸ ê²€ìƒ‰
    if (query) {
      const searchTerm = query.toLowerCase();
      filteredLogs = filteredLogs.filter(
        log =>
          log.message.toLowerCase().includes(searchTerm) ||
          log.engine.toLowerCase().includes(searchTerm) ||
          (log.thinking?.reasoning || '').toLowerCase().includes(searchTerm) ||
          JSON.stringify(log.data || {})
            .toLowerCase()
            .includes(searchTerm)
      );
    }

    // í•„í„° ì ìš©
    if (filters) {
      if (filters.level?.length) {
        filteredLogs = filteredLogs.filter(log =>
          filters.level!.includes(log.level)
        );
      }

      if (filters.category?.length) {
        filteredLogs = filteredLogs.filter(log =>
          filters.category!.includes(log.category)
        );
      }

      if (filters.engine?.length) {
        filteredLogs = filteredLogs.filter(log =>
          filters.engine!.includes(log.engine)
        );
      }

      if (filters.since) {
        const sinceDate = new Date(filters.since);
        filteredLogs = filteredLogs.filter(
          log => new Date(log.timestamp) >= sinceDate
        );
      }

      if (filters.until) {
        const untilDate = new Date(filters.until);
        filteredLogs = filteredLogs.filter(
          log => new Date(log.timestamp) <= untilDate
        );
      }

      if (filters.hasError) {
        filteredLogs = filteredLogs.filter(log => log.level === LogLevel.ERROR);
      }

      if (filters.hasThinking) {
        filteredLogs = filteredLogs.filter(
          log => log.thinking && log.thinking.steps.length > 0
        );
      }

      if (filters.minConfidence !== undefined) {
        filteredLogs = filteredLogs.filter(
          log =>
            log.thinking?.confidence !== undefined &&
            log.thinking.confidence >= filters.minConfidence!
        );
      }
    }

    // ì œí•œ ì ìš©
    const limit = filters?.limit || 100;
    return filteredLogs.slice(-limit);
  }

  // === ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì§€ì› ===

  public subscribe(callback: (log: AILogEntry) => void): () => void {
    this.subscribers.add(callback);
    return () => this.subscribers.delete(callback);
  }

  public getLogStats(): any {
    const stats = {
      totalLogs: this.logBuffer.length,
      byLevel: {} as Record<string, number>,
      byCategory: {} as Record<string, number>,
      byEngine: {} as Record<string, number>,
      recentErrors: this.getErrorLogs(10).length,
      avgResponseTime: 0,
      memoryUsage: process.memoryUsage(),
      uptime: process.uptime(),
    };

    // í†µê³„ ê³„ì‚°
    this.logBuffer.forEach(log => {
      stats.byLevel[log.level] = (stats.byLevel[log.level] || 0) + 1;
      stats.byCategory[log.category] =
        (stats.byCategory[log.category] || 0) + 1;
      stats.byEngine[log.engine] = (stats.byEngine[log.engine] || 0) + 1;
    });

    return stats;
  }

  // === ì •ë¦¬ ë©”ì„œë“œë“¤ ===

  public clearLogs(): void {
    this.logBuffer = [];
    this.logCounter = 0;
  }

  public async flushLogs(): Promise<void> {
    // í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ë¡œê·¸ë¥¼ íŒŒì¼ì´ë‚˜ ì™¸ë¶€ ì„œë¹„ìŠ¤ë¡œ í”ŒëŸ¬ì‹œ
    if (this.isProduction && this.logBuffer.length > 0) {
      try {
        // ì—¬ê¸°ì„œ ì™¸ë¶€ ë¡œê·¸ ì„œë¹„ìŠ¤ë¡œ ì „ì†¡í•  ìˆ˜ ìˆìŒ
        // ì˜ˆ: Elasticsearch, CloudWatch, etc.
        console.log(`ğŸ”„ ${this.logBuffer.length}ê°œ ë¡œê·¸ í”ŒëŸ¬ì‹œ ì™„ë£Œ`);
      } catch (error) {
        console.error('ë¡œê·¸ í”ŒëŸ¬ì‹œ ì˜¤ë¥˜:', error);
      }
    }
  }

  public async shutdown(): Promise<void> {
    await this.flushLogs();
    this.subscribers.clear();
    this.performanceMetrics.clear();
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë‚´ë³´ë‚´ê¸°
export const aiLogger = AILogger.getInstance();
