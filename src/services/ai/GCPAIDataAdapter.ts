/**
 * ğŸ¤– GCP AI ë°ì´í„° ì–´ëŒ‘í„°
 * 
 * GCP ì‹¤ì‹œê°„ ì„œë²„ ë°ì´í„°ë¥¼ AI ì—”ì§„ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
 * ê¸°ì¡´ AIAnalysisDataset ì¸í„°í˜ì´ìŠ¤ì™€ ì™„ë²½í•œ í˜¸í™˜ì„± ë³´ì¥
 */

import { AIAnalysisDataset, ServerMetadata, TimeSeriesMetrics } from '@/types/ai-agent-input-schema';
import { GCPDataResponse } from '@/types/gcp-data-generator';

interface GCPAIAdapterOptions {
    sessionId?: string;
    enableAnomalyDetection?: boolean;
    includeHistoricalData?: boolean;
    dataRetentionHours?: number;
    aiOptimization?: boolean;
}

interface ProcessedAIData {
    dataset: AIAnalysisDataset;
    metadata: {
        source: 'GCP' | 'Local' | 'Hybrid';
        processingTime: number;
        dataQuality: number;
        confidence: number;
        totalMetrics: number;
        anomaliesDetected: number;
    };
    insights: {
        summary: string;
        recommendations: string[];
        criticalAlerts: string[];
        patterns: string[];
    };
}

export class GCPAIDataAdapter {
    private cache: Map<string, any> = new Map();
    private lastUpdate: number = 0;
    private cacheTimeout: number = 30000; // 30ì´ˆ
    private sessionId: string | null = null;

    constructor(private options: GCPAIAdapterOptions = {}) {
        this.sessionId = options.sessionId || null;
    }

    /**
     * ğŸ¯ GCP ë°ì´í„°ë¥¼ AI ë¶„ì„ìš© ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜ (ë©”ì¸ ë©”ì„œë“œ)
     */
    async getAIAnalysisDataset(sessionId?: string): Promise<ProcessedAIData> {
        const startTime = Date.now();
        const targetSessionId = sessionId || this.sessionId;

        try {
            console.log('ğŸ¤– GCP â†’ AI ë°ì´í„° ë³€í™˜ ì‹œì‘...');

            // 1. GCP ë°ì´í„° ì¡°íšŒ
            const gcpData = await this.fetchGCPData(targetSessionId || undefined);

            if (!gcpData.success) {
                console.warn('âš ï¸ GCP ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨, ë¡œì»¬ ë°ì´í„°ë¡œ í´ë°±');
                return await this.generateLocalFallbackData();
            }

            // 2. AI ë¶„ì„ìš© ë°ì´í„°ì…‹ ë³€í™˜
            const dataset = await this.transformToAIDataset(gcpData.data!);

            // 3. AI ìµœì í™” ì²˜ë¦¬
            if (this.options.aiOptimization) {
                await this.optimizeForAI(dataset);
            }

            // 4. ì´ìƒ íƒì§€ (ì˜µì…˜)
            let anomaliesDetected = 0;
            if (this.options.enableAnomalyDetection) {
                anomaliesDetected = await this.detectAnomalies(dataset);
            }

            // 5. ì¸ì‚¬ì´íŠ¸ ìƒì„±
            const insights = this.generateInsights(dataset);

            // 6. ë°ì´í„° í’ˆì§ˆ í‰ê°€
            const dataQuality = this.assessDataQuality(dataset);

            const processingTime = Date.now() - startTime;

            const result: ProcessedAIData = {
                dataset,
                metadata: {
                    source: 'GCP',
                    processingTime,
                    dataQuality,
                    confidence: this.calculateConfidence(dataset),
                    totalMetrics: dataset.metrics.length,
                    anomaliesDetected
                },
                insights
            };

            console.log(`âœ… GCP â†’ AI ë³€í™˜ ì™„ë£Œ: ${dataset.metrics.length}ê°œ ë©”íŠ¸ë¦­, ${processingTime}ms`);
            return result;

        } catch (error) {
            console.error('âŒ GCP â†’ AI ë³€í™˜ ì‹¤íŒ¨:', error);

            // í´ë°±ìœ¼ë¡œ ë¡œì»¬ ë°ì´í„° ì‚¬ìš©
            console.log('ğŸ”„ ë¡œì»¬ ë°ì´í„°ë¡œ í´ë°±...');
            return await this.generateLocalFallbackData();
        }
    }

    /**
     * ğŸ“Š GCP ë°ì´í„° ì¡°íšŒ
     */
    private async fetchGCPData(sessionId?: string): Promise<GCPDataResponse> {
        if (!sessionId) {
            throw new Error('GCP ì„¸ì…˜ IDê°€ í•„ìš”í•©ë‹ˆë‹¤');
        }

        const cacheKey = `gcp-data-${sessionId}`;
        const now = Date.now();

        // ìºì‹œ í™•ì¸
        if (this.cache.has(cacheKey) && (now - this.lastUpdate) < this.cacheTimeout) {
            console.log('ğŸ“¦ GCP ë°ì´í„° ìºì‹œ ì‚¬ìš©');
            return this.cache.get(cacheKey);
        }

        try {
            const response = await fetch(`/api/gcp/server-data?sessionId=${sessionId}&limit=50`);
            const data = await response.json();

            if (data.success) {
                this.cache.set(cacheKey, data);
                this.lastUpdate = now;
            }

            return data;
        } catch (error) {
            console.error('GCP ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨:', error);
            return {
                success: false,
                error: error instanceof Error ? error.message : 'GCP ì—°ê²° ì‹¤íŒ¨'
            };
        }
    }

    /**
     * ğŸ”„ GCP ë°ì´í„°ë¥¼ AIAnalysisDatasetìœ¼ë¡œ ë³€í™˜
     */
    private async transformToAIDataset(gcpData: any): Promise<AIAnalysisDataset> {
        const metrics = gcpData.metrics as TimeSeriesMetrics[];
        const sessionInfo = gcpData.sessionInfo;

        // ì„œë²„ ë©”íƒ€ë°ì´í„° ìƒì„±
        const servers = this.extractServerMetadata(metrics);

        // ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        const timestamps = metrics.map(m => m.timestamp.getTime());
        const timeRange = {
            start: new Date(Math.min(...timestamps)),
            end: new Date(Math.max(...timestamps))
        };

        // ë¡œê·¸ ë° íŠ¸ë ˆì´ìŠ¤ ë°ì´í„° ìƒì„± (GCP ë©”íŠ¸ë¦­ ê¸°ë°˜)
        const logs = this.generateLogsFromMetrics(metrics);
        const traces = this.generateTracesFromMetrics(metrics);

        // íŒ¨í„´ ë¶„ì„
        const patterns = await this.analyzePatterns(metrics);

        const dataset: AIAnalysisDataset = {
            metadata: {
                generationTime: new Date(),
                timeRange,
                serverCount: servers.length,
                dataPoints: metrics.length,
                version: '2.0-gcp'
            },
            servers,
            metrics,
            logs,
            traces,
            patterns
        };

        return dataset;
    }

    /**
     * ğŸ–¥ï¸ ë©”íŠ¸ë¦­ì—ì„œ ì„œë²„ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
     */
    private extractServerMetadata(metrics: TimeSeriesMetrics[]): ServerMetadata[] {
        const serverMap = new Map<string, ServerMetadata>();

        metrics.forEach(metric => {
            if (!serverMap.has(metric.serverId)) {
                const server: ServerMetadata = {
                    id: metric.serverId,
                    name: this.getServerName(metric.serverId),
                    serverType: this.getServerType(metric.serverId),
                    location: {
                        region: 'local',
                        zone: 'local-a',
                        datacenter: 'Local',
                        cloud: 'On-Premise'
                    },
                    os: {
                        type: 'Linux',
                        distribution: 'Ubuntu',
                        version: '22.04',
                        architecture: 'x64'
                    },
                    usageProfile: {
                        type: 'Web',
                        tier: 'Production',
                        criticality: 'High',
                        scalingType: 'Auto'
                    },
                    resources: this.estimateServerResources(metric),
                    tags: {
                        environment: 'development',
                        type: 'fallback'
                    },
                    created: new Date(Date.now() - Math.random() * 86400000),
                    lastUpdate: metric.timestamp,
                    processes: []
                };
                serverMap.set(metric.serverId, server);
            }
        });

        return Array.from(serverMap.values());
    }

    /**
     * ğŸ“ ë©”íŠ¸ë¦­ì—ì„œ ë¡œê·¸ ë°ì´í„° ìƒì„±
     */
    private generateLogsFromMetrics(metrics: TimeSeriesMetrics[]): any[] {
        const logs: any[] = [];

        metrics.forEach(metric => {
            // ì—ëŸ¬ ë¡œê·¸ ìƒì„±
            if (metric.application.requests.errors > 0) {
                logs.push({
                    timestamp: metric.timestamp,
                    serverId: metric.serverId,
                    level: 'ERROR',
                    message: `HTTP errors detected: ${metric.application.requests.errors} out of ${metric.application.requests.total} requests`,
                    source: 'application',
                    metadata: {
                        errorRate: metric.application.requests.errors / metric.application.requests.total,
                        latencyP99: metric.application.requests.latency.p99
                    }
                });
            }

            // ì„±ëŠ¥ ê²½ê³  ë¡œê·¸
            if (metric.system.cpu.usage > 80) {
                logs.push({
                    timestamp: metric.timestamp,
                    serverId: metric.serverId,
                    level: 'WARN',
                    message: `High CPU usage detected: ${metric.system.cpu.usage.toFixed(1)}%`,
                    source: 'system',
                    metadata: {
                        cpuUsage: metric.system.cpu.usage,
                        load1: metric.system.cpu.load1
                    }
                });
            }

            // ë©”ëª¨ë¦¬ ê²½ê³  ë¡œê·¸
            const memoryUsage = metric.system.memory.used / (metric.system.memory.used + metric.system.memory.available) * 100;
            if (memoryUsage > 85) {
                logs.push({
                    timestamp: metric.timestamp,
                    serverId: metric.serverId,
                    level: 'WARN',
                    message: `High memory usage detected: ${memoryUsage.toFixed(1)}%`,
                    source: 'system',
                    metadata: {
                        memoryUsage,
                        availableMemory: metric.system.memory.available
                    }
                });
            }
        });

        return logs;
    }

    /**
     * ğŸ”— ë©”íŠ¸ë¦­ì—ì„œ íŠ¸ë ˆì´ìŠ¤ ë°ì´í„° ìƒì„±
     */
    private generateTracesFromMetrics(metrics: TimeSeriesMetrics[]): any[] {
        const traces: any[] = [];

        metrics.forEach(metric => {
            // ìš”ì²­ íŠ¸ë ˆì´ìŠ¤ ìƒì„±
            if (metric.application.requests.total > 0) {
                traces.push({
                    traceId: `trace-${metric.serverId}-${metric.timestamp.getTime()}`,
                    spanId: `span-${metric.serverId}`,
                    timestamp: metric.timestamp,
                    serverId: metric.serverId,
                    operation: 'http_request',
                    duration: metric.application.requests.latency.p50,
                    status: metric.application.requests.errors > 0 ? 'error' : 'success',
                    metadata: {
                        totalRequests: metric.application.requests.total,
                        successRate: metric.application.requests.success / metric.application.requests.total,
                        latency: metric.application.requests.latency
                    }
                });
            }

            // ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ë ˆì´ìŠ¤ ìƒì„±
            if (metric.application.database.queries.total > 0) {
                traces.push({
                    traceId: `db-trace-${metric.serverId}-${metric.timestamp.getTime()}`,
                    spanId: `db-span-${metric.serverId}`,
                    timestamp: metric.timestamp,
                    serverId: metric.serverId,
                    operation: 'database_query',
                    duration: metric.application.database.queries.slow > 0 ? 1000 : 100,
                    status: metric.application.database.deadlocks > 0 ? 'error' : 'success',
                    metadata: {
                        totalQueries: metric.application.database.queries.total,
                        slowQueries: metric.application.database.queries.slow,
                        connections: metric.application.database.connections
                    }
                });
            }
        });

        return traces;
    }

    /**
     * ğŸ“ˆ íŒ¨í„´ ë¶„ì„
     */
    private async analyzePatterns(metrics: TimeSeriesMetrics[]): Promise<any> {
        const anomalies: any[] = [];
        const correlations: any[] = [];
        const trends: any[] = [];

        // ì´ìƒ íŒ¨í„´ íƒì§€
        metrics.forEach(metric => {
            const cpuUsage = metric.system.cpu.usage;
            const memoryUsage = metric.system.memory.used / (metric.system.memory.used + metric.system.memory.available) * 100;
            const errorRate = metric.application.requests.total > 0
                ? metric.application.requests.errors / metric.application.requests.total
                : 0;

            // CPU ì´ìƒ
            if (cpuUsage > 90) {
                anomalies.push({
                    type: 'cpu_spike',
                    serverId: metric.serverId,
                    timestamp: metric.timestamp,
                    severity: 'critical',
                    value: cpuUsage,
                    threshold: 90,
                    confidence: 0.95
                });
            }

            // ë©”ëª¨ë¦¬ ì´ìƒ
            if (memoryUsage > 95) {
                anomalies.push({
                    type: 'memory_exhaustion',
                    serverId: metric.serverId,
                    timestamp: metric.timestamp,
                    severity: 'critical',
                    value: memoryUsage,
                    threshold: 95,
                    confidence: 0.9
                });
            }

            // ì—ëŸ¬ìœ¨ ì´ìƒ
            if (errorRate > 0.05) {
                anomalies.push({
                    type: 'high_error_rate',
                    serverId: metric.serverId,
                    timestamp: metric.timestamp,
                    severity: errorRate > 0.1 ? 'critical' : 'warning',
                    value: errorRate,
                    threshold: 0.05,
                    confidence: 0.85
                });
            }
        });

        // ìƒê´€ê´€ê³„ ë¶„ì„ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
        const serverGroups = this.groupMetricsByServer(metrics);
        Object.entries(serverGroups).forEach(([serverId, serverMetrics]) => {
            if (serverMetrics.length > 1) {
                const avgCpu = serverMetrics.reduce((sum, m) => sum + m.system.cpu.usage, 0) / serverMetrics.length;
                const avgErrors = serverMetrics.reduce((sum, m) => sum + m.application.requests.errors, 0) / serverMetrics.length;

                if (avgCpu > 70 && avgErrors > 10) {
                    correlations.push({
                        type: 'cpu_error_correlation',
                        serverId,
                        description: 'High CPU usage correlates with increased errors',
                        strength: 0.8,
                        confidence: 0.75
                    });
                }
            }
        });

        // íŠ¸ë Œë“œ ë¶„ì„
        Object.entries(serverGroups).forEach(([serverId, serverMetrics]) => {
            if (serverMetrics.length >= 3) {
                const sortedMetrics = serverMetrics.sort((a, b) => a.timestamp.getTime() - b.timestamp.getTime());
                const cpuTrend = this.calculateTrend(sortedMetrics.map(m => m.system.cpu.usage));

                if (Math.abs(cpuTrend) > 0.1) {
                    trends.push({
                        type: 'cpu_usage_trend',
                        serverId,
                        direction: cpuTrend > 0 ? 'increasing' : 'decreasing',
                        slope: cpuTrend,
                        confidence: 0.7
                    });
                }
            }
        });

        return {
            anomalies,
            correlations,
            trends
        };
    }

    /**
     * ğŸ§  AI ìµœì í™” ì²˜ë¦¬
     */
    private async optimizeForAI(dataset: AIAnalysisDataset): Promise<void> {
        // ë©”íŠ¸ë¦­ ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼)
        dataset.metrics.forEach(metric => {
            (metric as any).normalized = {
                cpu: metric.system.cpu.usage / 100,
                memory: metric.system.memory.used / (metric.system.memory.used + metric.system.memory.available),
                disk: metric.system.disk.utilization / 100,
                errorRate: metric.application.requests.total > 0
                    ? metric.application.requests.errors / metric.application.requests.total
                    : 0
            };
        });

        // AI ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if (this.options.aiOptimization) {
            (dataset.metadata as any).aiContext = {
                optimization: true,
                modelVersion: '2.0',
                features: ['anomaly_detection', 'pattern_analysis'],
                confidence: this.calculateConfidence(dataset)
            };
        }
    }

    /**
     * ğŸ’¡ ì¸ì‚¬ì´íŠ¸ ìƒì„±
     */
    private generateInsights(dataset: AIAnalysisDataset): any {
        const metrics = dataset.metrics;
        const serverCount = dataset.servers.length;

        // ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ë¶„ì„
        const avgCpu = metrics.reduce((sum, m) => sum + m.system.cpu.usage, 0) / metrics.length;
        const avgMemory = metrics.reduce((sum, m) => {
            return sum + (m.system.memory.used / (m.system.memory.used + m.system.memory.available) * 100);
        }, 0) / metrics.length;

        const totalErrors = metrics.reduce((sum, m) => sum + m.application.requests.errors, 0);
        const totalRequests = metrics.reduce((sum, m) => sum + m.application.requests.total, 0);
        const errorRate = totalRequests > 0 ? totalErrors / totalRequests : 0;

        // ì‹¬ê°ë„ ë¶„ë¥˜
        const criticalServers = metrics.filter(m =>
            m.system.cpu.usage > 90 ||
            (m.system.memory.used / (m.system.memory.used + m.system.memory.available)) > 0.95
        ).length;

        const warningServers = metrics.filter(m =>
            m.system.cpu.usage > 80 ||
            (m.system.memory.used / (m.system.memory.used + m.system.memory.available)) > 0.85
        ).length;

        return {
            summary: `${serverCount}ê°œ ì„œë²„ ëª¨ë‹ˆí„°ë§ ì¤‘. í‰ê·  CPU: ${avgCpu.toFixed(1)}%, ë©”ëª¨ë¦¬: ${avgMemory.toFixed(1)}%, ì „ì²´ ì—ëŸ¬ìœ¨: ${(errorRate * 100).toFixed(2)}%`,

            recommendations: [
                avgCpu > 80 ? 'ğŸš¨ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ìŠ¤ì¼€ì¼ë§ì„ ê³ ë ¤í•˜ì„¸ìš”.' : null,
                avgMemory > 85 ? 'ğŸš¨ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.' : null,
                errorRate > 0.05 ? 'ğŸš¨ ì—ëŸ¬ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.' : null,
                criticalServers > 0 ? `ğŸ”¥ ${criticalServers}ê°œ ì„œë²„ê°€ ì„ê³„ ìƒíƒœì…ë‹ˆë‹¤.` : null,
                'ğŸ“Š GCP ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¶„ì„ì…ë‹ˆë‹¤.'
            ].filter(Boolean),

            criticalAlerts: [
                criticalServers > 0 ? `${criticalServers}ê°œ ì„œë²„ ì„ê³„ ìƒíƒœ` : null,
                errorRate > 0.1 ? 'ë†’ì€ ì—ëŸ¬ìœ¨ ê°ì§€' : null,
                dataset.patterns?.anomalies && dataset.patterns.anomalies.length > 5 ? 'ë‹¤ìˆ˜ ì´ìƒ íŒ¨í„´ ê°ì§€' : null ||
                    'ì •ìƒ ìš´ì˜ ìƒíƒœ'
            ].filter(Boolean),

            patterns: [
                `${dataset.patterns?.anomalies?.length || 0}ê°œ ì´ìƒ íŒ¨í„´ ê°ì§€`,
                `${dataset.patterns?.correlations?.length || 0}ê°œ ìƒê´€ê´€ê³„ ë°œê²¬`,
                `${dataset.patterns?.trends?.length || 0}ê°œ íŠ¸ë Œë“œ ë¶„ì„`
            ]
        };
    }

    // ===== í—¬í¼ ë©”ì„œë“œë“¤ =====

    private async generateLocalFallbackData(): Promise<ProcessedAIData> {
        console.log('ğŸ”„ ë¡œì»¬ í´ë°± ë°ì´í„° ìƒì„±...');

        // ê¸°ë³¸ í´ë°± ë°ì´í„°ì…‹ ìƒì„±
        const fallbackDataset: AIAnalysisDataset = {
            metadata: {
                generationTime: new Date(),
                timeRange: {
                    start: new Date(Date.now() - 3600000),
                    end: new Date()
                },
                serverCount: 3,
                dataPoints: 30,
                version: '2.0-fallback'
            },
            servers: [
                {
                    id: 'fallback-web-01',
                    name: 'Fallback Web Server',
                    serverType: 'nginx',
                    location: {
                        region: 'local',
                        zone: 'local-a',
                        datacenter: 'Local',
                        cloud: 'On-Premise'
                    },
                    os: {
                        type: 'Linux',
                        distribution: 'Ubuntu',
                        version: '22.04',
                        architecture: 'x64'
                    },
                    usageProfile: {
                        type: 'Web',
                        tier: 'Production',
                        criticality: 'High',
                        scalingType: 'Auto'
                    },
                    resources: this.estimateServerResources({
                        system: {
                            cpu: {
                                usage: 80,
                                load1: 0.5
                            },
                            memory: {
                                used: 4294967296,
                                available: 4294967296
                            },
                            disk: {
                                utilization: 0.5
                            }
                        },
                        application: {
                            requests: {
                                errors: 0,
                                total: 100,
                                success: 100
                            },
                            database: {
                                queries: {
                                    total: 0,
                                    slow: 0,
                                    deadlocks: 0
                                },
                                connections: 0
                            }
                        }
                    }),
                    tags: {
                        environment: 'development',
                        type: 'fallback'
                    },
                    created: new Date(Date.now() - Math.random() * 86400000),
                    lastUpdate: new Date(),
                    processes: []
                }
            ],
            metrics: [],
            logs: [],
            traces: [],
            patterns: {
                anomalies: [],
                correlations: [],
                trends: []
            }
        };

        return {
            dataset: fallbackDataset,
            metadata: {
                source: 'Local',
                processingTime: 10,
                dataQuality: 0.5,
                confidence: 0.3,
                totalMetrics: 0,
                anomaliesDetected: 0
            },
            insights: {
                summary: 'ë¡œì»¬ í´ë°± ë°ì´í„°ë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.',
                recommendations: ['GCP ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.'],
                criticalAlerts: ['GCP ë°ì´í„° ì†ŒìŠ¤ ì—°ê²° ì‹¤íŒ¨'],
                patterns: ['í´ë°± ëª¨ë“œ í™œì„±í™”']
            }
        };
    }

    private groupMetricsByServer(metrics: TimeSeriesMetrics[]): Record<string, TimeSeriesMetrics[]> {
        return metrics.reduce((groups, metric) => {
            if (!groups[metric.serverId]) {
                groups[metric.serverId] = [];
            }
            groups[metric.serverId].push(metric);
            return groups;
        }, {} as Record<string, TimeSeriesMetrics[]>);
    }

    private calculateTrend(values: number[]): number {
        if (values.length < 2) return 0;

        const n = values.length;
        const sumX = (n * (n - 1)) / 2;
        const sumY = values.reduce((sum, val) => sum + val, 0);
        const sumXY = values.reduce((sum, val, i) => sum + (i * val), 0);
        const sumXX = (n * (n - 1) * (2 * n - 1)) / 6;

        return (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);
    }

    private calculateConfidence(dataset: AIAnalysisDataset): number {
        const factors = [
            dataset.metrics.length > 10 ? 0.3 : 0.1,
            dataset.servers.length > 5 ? 0.2 : 0.1,
            dataset.patterns.anomalies.length > 0 ? 0.2 : 0.1,
            dataset.logs.length > 0 ? 0.15 : 0.05,
            dataset.traces.length > 0 ? 0.15 : 0.05
        ];

        return Math.min(1.0, factors.reduce((sum, factor) => sum + factor, 0));
    }

    private assessDataQuality(dataset: AIAnalysisDataset): number {
        let score = 0;

        // ë©”íŠ¸ë¦­ ì™„ì„±ë„
        if (dataset.metrics.length > 0) score += 0.3;

        // ì„œë²„ ë©”íƒ€ë°ì´í„° ì™„ì„±ë„
        if (dataset.servers.length > 0) score += 0.2;

        // íŒ¨í„´ ë¶„ì„ ì™„ì„±ë„
        if (dataset.patterns.anomalies.length > 0) score += 0.2;

        // ë¡œê·¸ ë°ì´í„° ì™„ì„±ë„
        if (dataset.logs.length > 0) score += 0.15;

        // íŠ¸ë ˆì´ìŠ¤ ë°ì´í„° ì™„ì„±ë„
        if (dataset.traces.length > 0) score += 0.15;

        return Math.min(1.0, score);
    }

    private generateAIRecommendations(dataset: AIAnalysisDataset): string[] {
        const recommendations = [];

        if (dataset.patterns.anomalies.length > 5) {
            recommendations.push('ë‹¤ìˆ˜ì˜ ì´ìƒ íŒ¨í„´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.');
        }

        if (dataset.metrics.length < 10) {
            recommendations.push('ë” ë§ì€ ë°ì´í„° í¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§ ì£¼ê¸°ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”.');
        }

        recommendations.push('GCP ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ í™œìš©í•œ AI ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.');

        return recommendations;
    }

    private async detectAnomalies(dataset: AIAnalysisDataset): Promise<number> {
        // ê¸°ì¡´ íŒ¨í„´ì—ì„œ ì´ìƒ ê°œìˆ˜ ë°˜í™˜
        return dataset.patterns.anomalies.length;
    }

    // ì„œë²„ ì •ë³´ ì¶”ì¶œ í—¬í¼ë“¤
    private getServerName(serverId: string): string {
        const nameMap: Record<string, string> = {
            'srv-web-01': 'Web Server 01',
            'srv-web-02': 'Web Server 02',
            'srv-web-03': 'Load Balancer',
            'srv-app-01': 'API Server 01',
            'srv-app-02': 'API Server 02',
            'srv-db-01': 'Primary Database',
            'srv-db-02': 'Replica Database',
            'srv-cache-01': 'Redis Cache',
            'srv-search-01': 'Elasticsearch',
            'srv-queue-01': 'Message Queue'
        };
        return nameMap[serverId] || serverId;
    }

    private getServerType(serverId: string): 'Host' | 'Cloud' | 'Container' | 'VM' | 'Edge' {
        if (serverId.includes('web') || serverId.includes('app')) {
            return 'Container';
        } else if (serverId.includes('db') || serverId.includes('cache')) {
            return 'VM';
        } else if (serverId.includes('edge')) {
            return 'Edge';
        } else if (serverId.includes('cloud')) {
            return 'Cloud';
        }
        return 'Host';
    }

    private calculateServerStatus(metric: TimeSeriesMetrics): string {
        const cpuUsage = metric.system.cpu.usage;
        const memoryUsage = metric.system.memory.used / (metric.system.memory.used + metric.system.memory.available) * 100;

        if (cpuUsage > 90 || memoryUsage > 95) return 'critical';
        if (cpuUsage > 80 || memoryUsage > 85) return 'warning';
        return 'healthy';
    }

    private generateServerTags(serverId: string): string[] {
        const tags = ['gcp', 'production'];

        if (serverId.includes('web')) tags.push('web-server');
        if (serverId.includes('app')) tags.push('application');
        if (serverId.includes('db')) tags.push('database');
        if (serverId.includes('cache')) tags.push('cache');

        return tags;
    }

    private estimateServerResources(metric: TimeSeriesMetrics): any {
        return {
            cpu: this.estimateCpuSpecs(metric),
            memory: this.estimateMemorySpecs(metric),
            disk: this.estimateDiskSpecs(metric),
            network: this.estimateNetworkSpecs(metric)
        };
    }

    private estimateCpuSpecs(metric: TimeSeriesMetrics): any {
        return {
            cores: Math.ceil(metric.system.cpu.load1),
            model: 'GCP Virtual CPU'
        };
    }

    private estimateMemorySpecs(metric: TimeSeriesMetrics): any {
        return {
            total: metric.system.memory.used + metric.system.memory.available,
            type: 'Virtual'
        };
    }

    private estimateDiskSpecs(metric: TimeSeriesMetrics): any {
        return {
            total: 100 * 1024 * 1024 * 1024, // 100GB ê°€ì •
            type: 'SSD'
        };
    }

    private estimateNetworkSpecs(metric: TimeSeriesMetrics): any {
        return {
            bandwidth: 1000,
            type: '1G'
        };
    }

    // ===== ê³µê°œ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ =====

    setSessionId(sessionId: string): void {
        this.sessionId = sessionId;
    }

    clearCache(): void {
        this.cache.clear();
        this.lastUpdate = 0;
    }

    getLastUpdate(): Date | null {
        return this.lastUpdate > 0 ? new Date(this.lastUpdate) : null;
    }
} 