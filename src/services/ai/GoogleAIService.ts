/**
 * ğŸ¤– Google AI Service v2025.7
 * Edge Runtime ì™„ì „ í˜¸í™˜ ë²„ì „
 *
 * ğŸ“‹ 2025ë…„ 7ì›” ìµœì‹  ëª¨ë¸ ì§€ì›:
 * - Gemini 2.0 Flash (ê¸°ë³¸, ì¶”ì²œ): 15 RPM, 1M TPM, 1500 RPD
 * - Gemini 2.5 Flash Preview: 10 RPM, 250K TPM, 500 RPD
 * - Gemini 2.5 Pro Experimental: 5 RPM, 250K TPM, 25 RPD
 * - Gemini 2.0 Flash-Lite: 30 RPM, 1M TPM, 1500 RPD
 */

import { getVercelConfig } from '@/config/vercel-edge-config';
import { edgeRuntimeService } from '@/lib/edge-runtime-utils';
import { AIRequest, AIResponse } from '@/types/ai-types';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { supabaseAILogger } from './logging/SupabaseAILogger';

// Edge Runtime ì„¤ì •
const vercelConfig = getVercelConfig();
const logger = edgeRuntimeService.logger;
const cache = edgeRuntimeService.cache;
const performance = edgeRuntimeService.performance;

// ğŸš€ ì‹ ê·œ: ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ëª¨ë¸ ë§¤í•‘ (Free Tier ì „ìš©)
const MODEL_MAPPING = {
  simple: 'gemini-2.0-flash-lite', // ë¹„ìš© ìµœì í™”
  normal: 'gemini-2.0-flash', // í‘œì¤€
  complex: 'gemini-2.5-pro', // ğŸš€ ë³µì¡í•œ ì¿¼ë¦¬ë„ ì•ˆì •ì ì¸ ë¬´ë£Œ í‹°ì–´ ëª¨ë¸ë¡œ ì²˜ë¦¬
} as const;

type QueryComplexity = keyof typeof MODEL_MAPPING;

interface GoogleAIConfig {
  apiKey: string;
  model:
  | 'gemini-2.0-flash'
  | 'gemini-2.5-flash'
  | 'gemini-2.5-pro'
  | 'gemini-2.0-flash-lite';
  enabled: boolean;
  rateLimits: {
    rpm: number;
    daily: number;
    tpm: number; // Token Per Minute ì¶”ê°€
  };
}

export interface GoogleAIResponse {
  success: boolean;
  content: string;
  model: string;
  tokensUsed?: number;
  cached?: boolean;
  processingTime: number;
  confidence: number;
  rateLimitInfo?: {
    remaining: number;
    resetTime: number;
    model: string;
  };
  error?: {
    code: string;
    message: string;
    details: string;
    timestamp: string;
    retryable: boolean;
  };
}

interface ServerMetrics {
  name: string;
  cpu_usage: number;
  memory_usage: number;
  disk_usage: number;
  response_time: number;
  status: string;
  timestamp: string;
}

/**
 * ğŸš« ì„œë²„ë¦¬ìŠ¤ í˜¸í™˜: ìš”ì²­ë³„ Google AI ì„œë¹„ìŠ¤
 * ì „ì—­ ìƒíƒœ ì—†ì´ ê° ìš”ì²­ë§ˆë‹¤ ìƒˆë¡œìš´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
 */
export class RequestScopedGoogleAIService {
  private genAI: GoogleGenerativeAI | null = null;
  private model: any = null;
  private initialized = false;
  private requestCount = 0;
  private lastError: string | null = null;

  constructor() {
    logger.info('ğŸš« ì„œë²„ë¦¬ìŠ¤ í˜¸í™˜: ìš”ì²­ë³„ Google AI Service ì´ˆê¸°í™”');
  }

  /**
   * ğŸ”§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ìš”ì²­ë³„)
   */
  async initialize(): Promise<void> {
    const timer = performance.startTimer('google-ai-initialization');

    try {
      // Vercel í™˜ê²½ì—ì„œ Google AI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
      if (!vercelConfig.enableGoogleAI) {
        throw new Error('Google AIëŠ” Pro í”Œëœì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤');
      }

      // ğŸ”‘ í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
      const apiKey = process.env.GOOGLE_AI_API_KEY;
      if (!apiKey) {
        throw new Error('Google AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
      }

      this.genAI = new GoogleGenerativeAI(apiKey);
      this.model = this.genAI.getGenerativeModel({
        model: process.env.GOOGLE_AI_MODEL || 'gemini-2.0-flash',
      });

      this.initialized = true;
      this.lastError = null;

      const duration = timer();
      logger.info(`âœ… ìš”ì²­ë³„ Google AI Service ì´ˆê¸°í™” ì™„ë£Œ: ${duration.toFixed(2)}ms`);
    } catch (error) {
      const duration = timer();
      this.lastError = error instanceof Error ? error.message : 'Unknown error';
      logger.error(
        `âŒ ìš”ì²­ë³„ Google AI Service ì´ˆê¸°í™” ì‹¤íŒ¨: ${duration.toFixed(2)}ms`,
        error
      );
      throw error;
    }
  }

  /**
   * ğŸš€ ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
   */
  private analyzeQueryComplexity(query: string): QueryComplexity {
    const length = query.length;
    const hasCode = query.includes('```');
    const hasKeywords =
      /(SELECT|UPDATE|DELETE|FROM|WHERE|function|class|interface|type)/i.test(
        query
      );

    if (hasCode || (length > 500 && hasKeywords)) {
      return 'complex';
    } else if (length > 150 || hasKeywords) {
      return 'normal';
    } else {
      return 'simple';
    }
  }

  /**
   * ğŸ¯ AI ì¿¼ë¦¬ ì²˜ë¦¬ (ìì—°ì–´ ì§ˆì˜ ì „ìš©)
   */
  async processQuery(request: AIRequest): Promise<AIResponse> {
    const requestId = `google_${++this.requestCount}_${Date.now()}`;
    const timer = performance.startTimer('google-ai-query');
    const sessionId = request.sessionId || requestId;

    logger.info(`ğŸ”„ ìš”ì²­ë³„ Google AI ì¿¼ë¦¬ ì²˜ë¦¬: ${requestId}`, {
      query: request.query?.substring(0, 100),
      mode: request.mode,
    });

    try {
      if (!this.initialized || !this.model || !this.genAI) {
        await this.initialize();
      }

      // ìì—°ì–´ ì§ˆì˜ í™•ì¸
      if (!this.isNaturalLanguageQuery(request.query || '')) {
        throw new Error('Google AIëŠ” ìì—°ì–´ ì§ˆì˜ì—ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤');
      }

      // ìºì‹œ í™•ì¸
      const cacheKey = `google_ai_${this.generateQueryHash(request.query || '')}`;
      const cached = cache.get(cacheKey);
      if (cached) {
        logger.info(`ğŸ“‹ Google AI ìºì‹œ ì‘ë‹µ: ${requestId}`);

        // ğŸ—„ï¸ ìºì‹œ ì‘ë‹µë„ ë¡œê·¸ì— ì €ì¥
        await this.logAIQuery(sessionId, request.query || '', cached.response, 'google-ai-cached', cached.processingTime || 0, cached.confidence || 0);

        return cached;
      }

      // Google AI ìš”ì²­
      const googleTimer = performance.startTimer('google-ai-api-call');

      const result: any = await Promise.race([
        this.model.generateContent(this.buildPrompt(request)),
        new Promise((_, reject) =>
          setTimeout(
            () => reject(new Error('Google AI API timeout')),
            vercelConfig.maxExecutionTime - 2000
          )
        ),
      ]);

      const googleDuration = googleTimer();

      if (!result.response) {
        throw new Error('Google AIì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤');
      }

      const text = result.response.text();
      const confidence = this.calculateConfidence(text, request.query || '');

      const response: AIResponse = {
        success: true,
        response: text,
        confidence,
        mode: request.mode || 'GOOGLE_ONLY',
        enginePath: ['google-ai-service'],
        processingTime: googleDuration,
        fallbacksUsed: 0,
        metadata: {
          mainEngine: 'Google AI (ìš”ì²­ë³„)',
          supportEngines: ['Google AI (Gemini)'],
          ragUsed: false,
          googleAIUsed: true,
          mcpContextUsed: false,
          subEnginesUsed: [],
          cacheUsed: false,
          requestId,
        },
      };

      // ìºì‹œì— ì €ì¥
      cache.set(cacheKey, response, 300000); // 5ë¶„ ìºì‹œ

      // ğŸ—„ï¸ AI ì§ˆì˜ ë¡œê·¸ ì €ì¥ (Supabase)
      await this.logAIQuery(sessionId, request.query || '', text, 'google-ai', googleDuration, confidence, request.context);

      const totalDuration = timer();
      logger.info(`âœ… ìš”ì²­ë³„ Google AI ì‘ë‹µ ì™„ë£Œ: ${totalDuration.toFixed(2)}ms`);

      return response;
    } catch (error) {
      const duration = timer();
      logger.error(`âŒ ìš”ì²­ë³„ Google AI ì²˜ë¦¬ ì‹¤íŒ¨: ${duration.toFixed(2)}ms`, error);

      // ğŸ—„ï¸ ì˜¤ë¥˜ë„ ë¡œê·¸ì— ì €ì¥
      await this.logAIQuery(sessionId, request.query || '', `ì˜¤ë¥˜: ${error instanceof Error ? error.message : 'Unknown error'}`, 'google-ai-error', duration, 0);

      return {
        success: false,
        response: 'ì£„ì†¡í•©ë‹ˆë‹¤. Google AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        confidence: 0,
        mode: request.mode || 'GOOGLE_ONLY',
        enginePath: ['google-ai-service'],
        processingTime: duration,
        fallbacksUsed: 0,
        metadata: {
          mainEngine: 'Google AI (ìš”ì²­ë³„)',
          supportEngines: [],
          ragUsed: false,
          googleAIUsed: false,
          mcpContextUsed: false,
          subEnginesUsed: [],
          cacheUsed: false,
          error: error instanceof Error ? error.message : 'Unknown error',
        },
      };
    }
  }

  private isNaturalLanguageQuery(query: string): boolean {
    // ìì—°ì–´ ì§ˆì˜ íŒ¨í„´ ê²€ì‚¬
    const naturalLanguagePatterns = [
      /^(ì–´ë–»ê²Œ|ì™œ|ë¬´ì—‡|ì–¸ì œ|ì–´ë””ì„œ|ëˆ„ê°€)/,
      /\?$/,
      /(ì„¤ëª…|ì•Œë ¤|ë„ì›€|ë°©ë²•|ì´ìœ )/,
      /(ì„œë²„|ì‹œìŠ¤í…œ|ëª¨ë‹ˆí„°ë§|ë¶„ì„)/,
    ];

    return naturalLanguagePatterns.some(pattern => pattern.test(query));
  }

  private buildPrompt(request: AIRequest): string {
    return `
ì‚¬ìš©ì ì§ˆë¬¸: ${request.query}

ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”:
1. í•œêµ­ì–´ë¡œ ë‹µë³€
2. ì„œë²„ ëª¨ë‹ˆí„°ë§ ë° ì‹œìŠ¤í…œ ê´€ë¦¬ ê´€ì ì—ì„œ ë‹µë³€
3. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
4. í•„ìš”ì‹œ ë‹¨ê³„ë³„ ì„¤ëª… í¬í•¨
`;
  }

  private calculateConfidence(response: string, query: string): number {
    if (response.length < 50) return 0.3;
    if (response.includes('ì£„ì†¡í•©ë‹ˆë‹¤')) return 0.4;
    if (response.includes('í™•ì‹¤í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤')) return 0.5;
    return 0.8;
  }

  private generateQueryHash(query: string): string {
    return Buffer.from(query).toString('base64').substring(0, 16);
  }

  /**
   * ğŸš« í—¬ìŠ¤ì²´í¬ ë¹„í™œì„±í™”
   */
  async healthCheck(): Promise<boolean> {
    console.warn('âš ï¸ Google AI í—¬ìŠ¤ì²´í¬ ë¬´ì‹œë¨ - ì„œë²„ë¦¬ìŠ¤ì—ì„œëŠ” ìš”ì²­ë³„ ì²˜ë¦¬');
    return true;
  }

  /**
   * ğŸš« ìƒíƒœ ì¡°íšŒ ë¹„í™œì„±í™”
   */
  getStatus() {
    console.warn('âš ï¸ Google AI ìƒíƒœ ì¡°íšŒ ë¬´ì‹œë¨ - ì„œë²„ë¦¬ìŠ¤ í™˜ê²½');
    return {
      initialized: this.initialized,
      available: false,
      mode: 'serverless',
      requestCount: this.requestCount,
      lastError: this.lastError,
    };
  }

  /**
   * ğŸš« ê°€ìš©ì„± í™•ì¸ ë¹„í™œì„±í™”
   */
  isAvailable(): boolean {
    console.warn('âš ï¸ Google AI ê°€ìš©ì„± í™•ì¸ ë¬´ì‹œë¨ - ì„œë²„ë¦¬ìŠ¤ í™˜ê²½');
    return false;
  }

  /**
   * ğŸš« ì¤€ë¹„ ìƒíƒœ í™•ì¸ ë¹„í™œì„±í™”
   */
  isReady(): boolean {
    console.warn('âš ï¸ Google AI ì¤€ë¹„ ìƒíƒœ í™•ì¸ ë¬´ì‹œë¨ - ì„œë²„ë¦¬ìŠ¤ í™˜ê²½');
    return this.initialized;
  }

  /**
   * ğŸš« ì—°ê²° í…ŒìŠ¤íŠ¸ ë¹„í™œì„±í™”
   */
  async testConnection(): Promise<{
    success: boolean;
    message: string;
    latency?: number;
  }> {
    console.warn('âš ï¸ Google AI ì—°ê²° í…ŒìŠ¤íŠ¸ ë¬´ì‹œë¨ - ì„œë²„ë¦¬ìŠ¤ í™˜ê²½');
    return {
      success: false,
      message: 'ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì—ì„œëŠ” ì—°ê²° í…ŒìŠ¤íŠ¸ê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.',
    };
  }

  /**
   * ğŸš« ì •ë¦¬ ë¹„í™œì„±í™”
   */
  cleanup(): void {
    console.warn('âš ï¸ Google AI ì •ë¦¬ ë¬´ì‹œë¨ - ì„œë²„ë¦¬ìŠ¤ì—ì„œëŠ” ìë™ ì •ë¦¬');
  }

  /**
   * ğŸ—„ï¸ AI ì§ˆì˜ ë¡œê·¸ ì €ì¥ (Supabase)
   */
  private async logAIQuery(
    sessionId: string,
    query: string,
    response: string,
    engine: string,
    processingTime: number,
    confidence: number,
    context?: any
  ): Promise<void> {
    try {
      // ì˜ë„ ë¶„ë¥˜
      const intent = this.classifyIntent(query);
      const category = this.classifyCategory(query);

      await supabaseAILogger.logQuery({
        session_id: sessionId,
        query: query.substring(0, 1000), // ê¸´ ì§ˆì˜ ì œí•œ
        response: response.substring(0, 2000), // ê¸´ ì‘ë‹µ ì œí•œ
        engine_used: engine,
        mode: 'GOOGLE_ONLY',
        confidence: confidence,
        processing_time: Math.round(processingTime),
        user_intent: intent,
        category: category,
        language: 'ko',
        token_count: this.estimateTokenCount(query + response),
        cost_estimate: this.estimateCost(query + response)
      });
    } catch (error) {
      logger.warn('âš ï¸ AI ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰):', error);
    }
  }

  /**
   * ğŸ¯ ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜
   */
  private classifyIntent(query: string): string {
    const intentPatterns = {
      'monitoring': ['ìƒíƒœ', 'ëª¨ë‹ˆí„°ë§', 'í™•ì¸', 'í˜„í™©'],
      'analysis': ['ë¶„ì„', 'ì›ì¸', 'ì´ìœ ', 'ì™œ'],
      'prediction': ['ì˜ˆì¸¡', 'ì˜ˆìƒ', 'ë¯¸ë˜', 'ì•ìœ¼ë¡œ'],
      'optimization': ['ìµœì í™”', 'ê°œì„ ', 'í–¥ìƒ', 'íš¨ìœ¨'],
      'troubleshooting': ['ë¬¸ì œ', 'ì˜¤ë¥˜', 'ì¥ì• ', 'í•´ê²°']
    };

    for (const [intent, patterns] of Object.entries(intentPatterns)) {
      if (patterns.some(pattern => query.includes(pattern))) {
        return intent;
      }
    }

    return 'general';
  }

  /**
   * ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
   */
  private classifyCategory(query: string): string {
    const categoryPatterns = {
      'server': ['ì„œë²„', 'ì„œë²„', 'ì¸ìŠ¤í„´ìŠ¤'],
      'database': ['ë°ì´í„°ë² ì´ìŠ¤', 'DB', 'ì¿¼ë¦¬'],
      'network': ['ë„¤íŠ¸ì›Œí¬', 'í†µì‹ ', 'ì—°ê²°'],
      'performance': ['ì„±ëŠ¥', 'ì†ë„', 'ì‘ë‹µì‹œê°„'],
      'security': ['ë³´ì•ˆ', 'ì¸ì¦', 'ê¶Œí•œ'],
      'logs': ['ë¡œê·¸', 'ê¸°ë¡', 'ì´ë²¤íŠ¸']
    };

    for (const [category, patterns] of Object.entries(categoryPatterns)) {
      if (patterns.some(pattern => query.includes(pattern))) {
        return category;
      }
    }

    return 'general';
  }

  /**
   * ğŸ”¢ í† í° ìˆ˜ ì¶”ì •
   */
  private estimateTokenCount(text: string): number {
    // í•œê¸€ ê¸°ì¤€ ëŒ€ëµì ì¸ í† í° ìˆ˜ ê³„ì‚°
    return Math.ceil(text.length / 3);
  }

  /**
   * ğŸ’° ë¹„ìš© ì¶”ì •
   */
  private estimateCost(text: string): number {
    const tokenCount = this.estimateTokenCount(text);
    // Google AI ê°€ê²© ê¸°ì¤€ (ëŒ€ëµì )
    const costPerToken = 0.00001; // $0.00001 per token
    return tokenCount * costPerToken;
  }
}

/**
 * ğŸ”§ ì„œë²„ë¦¬ìŠ¤ í˜¸í™˜ íŒ©í† ë¦¬ í•¨ìˆ˜
 */
export function createGoogleAIService(): RequestScopedGoogleAIService {
  return new RequestScopedGoogleAIService();
}

/**
 * ğŸš« ë ˆê±°ì‹œ í˜¸í™˜ì„± (ì‚¬ìš© ê¸ˆì§€)
 * @deprecated ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì—ì„œëŠ” createGoogleAIService() ì‚¬ìš©
 */
export const GoogleAIService = {
  getInstance: () => {
    console.warn('âš ï¸ GoogleAIService.getInstance()ëŠ” ì„œë²„ë¦¬ìŠ¤ì—ì„œ ì‚¬ìš© ê¸ˆì§€.');
    console.warn('ğŸ”§ ëŒ€ì‹  createGoogleAIService()ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.');
    return new RequestScopedGoogleAIService();
  }
};
