/**
 * ğŸ¤– Google AI Service v2025.7
 * Edge Runtime ì™„ì „ í˜¸í™˜ ë²„ì „
 *
 * ğŸ“‹ 2025ë…„ 7ì›” ìµœì‹  ëª¨ë¸ ì§€ì›:
 * - Gemini 2.0 Flash (ê¸°ë³¸, ì¶”ì²œ): 15 RPM, 1M TPM, 1500 RPD
 * - Gemini 2.5 Flash Preview: 10 RPM, 250K TPM, 500 RPD
 * - Gemini 2.5 Pro Experimental: 5 RPM, 250K TPM, 25 RPD
 * - Gemini 2.0 Flash-Lite: 30 RPM, 1M TPM, 1500 RPD
 */

import { getVercelConfig } from '@/config/vercel-edge-config';
import { edgeRuntimeService } from '@/lib/edge-runtime-utils';
import { AIRequest, AIResponse } from '@/types/ai-types';
import { GoogleGenerativeAI } from '@google/generative-ai';

// Edge Runtime ì„¤ì •
const vercelConfig = getVercelConfig();
const logger = edgeRuntimeService.logger;
const cache = edgeRuntimeService.cache;
const performance = edgeRuntimeService.performance;

// ğŸš€ ì‹ ê·œ: ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¥¸ ëª¨ë¸ ë§¤í•‘ (Free Tier ì „ìš©)
const MODEL_MAPPING = {
  simple: 'gemini-2.0-flash-lite', // ë¹„ìš© ìµœì í™”
  normal: 'gemini-2.0-flash', // í‘œì¤€
  complex: 'gemini-2.0-flash', // ğŸš€ ë³µì¡í•œ ì¿¼ë¦¬ë„ ì•ˆì •ì ì¸ ë¬´ë£Œ í‹°ì–´ ëª¨ë¸ë¡œ ì²˜ë¦¬
};

type QueryComplexity = keyof typeof MODEL_MAPPING;

interface GoogleAIConfig {
  apiKey: string;
  model:
    | 'gemini-2.0-flash'
    | 'gemini-2.5-flash'
    | 'gemini-2.5-pro'
    | 'gemini-2.0-flash-lite';
  enabled: boolean;
  rateLimits: {
    rpm: number;
    daily: number;
    tpm: number; // Token Per Minute ì¶”ê°€
  };
}

export interface GoogleAIResponse {
  success: boolean;
  content: string;
  model: string;
  tokensUsed?: number;
  cached?: boolean;
  processingTime: number;
  confidence: number;
  rateLimitInfo?: {
    remaining: number;
    resetTime: number;
    model: string;
  };
  error?: {
    code: string;
    message: string;
    details: string;
    timestamp: string;
    retryable: boolean;
  };
}

interface ServerMetrics {
  name: string;
  cpu_usage: number;
  memory_usage: number;
  disk_usage: number;
  response_time: number;
  status: string;
  timestamp: string;
}

/**
 * ğŸ¤– Google AI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
 * GOOGLE_ONLY ëª¨ë“œ ì „ìš©, ìì—°ì–´ ì§ˆì˜ ì²˜ë¦¬
 */
export class GoogleAIService {
  private static instance: GoogleAIService | null = null;
  private genAI: GoogleGenerativeAI | null = null;
  private model: any = null;
  private initialized = false;
  private requestCount = 0;
  private lastError: string | null = null;

  constructor() {
    logger.info('ğŸ¤– Google AI Service ì´ˆê¸°í™” ì‹œì‘ - Edge Runtime ëª¨ë“œ');
  }

  /**
   * ğŸ¯ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
   */
  public static getInstance(): GoogleAIService {
    if (!GoogleAIService.instance) {
      GoogleAIService.instance = new GoogleAIService();
    }
    return GoogleAIService.instance;
  }

  /**
   * ğŸ”§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
   */
  async initialize(): Promise<void> {
    const timer = performance.startTimer('google-ai-initialization');

    try {
      // Vercel í™˜ê²½ì—ì„œ Google AI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
      if (!vercelConfig.enableGoogleAI) {
        throw new Error('Google AIëŠ” Pro í”Œëœì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤');
      }

      const apiKey = process.env.GOOGLE_AI_API_KEY;
      if (!apiKey) {
        throw new Error('GOOGLE_AI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
      }

      this.genAI = new GoogleGenerativeAI(apiKey);
      this.model = this.genAI.getGenerativeModel({
        model: process.env.GOOGLE_AI_MODEL || 'gemini-2.0-flash',
      });

      this.initialized = true;
      this.lastError = null;

      const duration = timer();
      logger.info(`âœ… Google AI Service ì´ˆê¸°í™” ì™„ë£Œ: ${duration.toFixed(2)}ms`);
    } catch (error) {
      const duration = timer();
      this.lastError = error instanceof Error ? error.message : 'Unknown error';
      logger.error(
        `âŒ Google AI Service ì´ˆê¸°í™” ì‹¤íŒ¨: ${duration.toFixed(2)}ms`,
        error
      );
      throw error;
    }
  }

  /**
   * ğŸš€ ì‹ ê·œ: ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
   * @param query - ì‚¬ìš©ì ì¿¼ë¦¬
   * @returns 'simple' | 'normal' | 'complex'
   */
  private analyzeQueryComplexity(query: string): QueryComplexity {
    const length = query.length;
    const hasCode = query.includes('```');
    const hasKeywords =
      /(SELECT|UPDATE|DELETE|FROM|WHERE|function|class|interface|type)/i.test(
        query
      );

    if (hasCode || (length > 500 && hasKeywords)) {
      return 'complex';
    } else if (length > 150 || hasKeywords) {
      return 'normal';
    } else {
      return 'simple';
    }
  }

  /**
   * ğŸ¯ AI ì¿¼ë¦¬ ì²˜ë¦¬ (ìì—°ì–´ ì§ˆì˜ ì „ìš©)
   */
  async processQuery(request: AIRequest): Promise<AIResponse> {
    const requestId = `google_${++this.requestCount}_${Date.now()}`;
    const timer = performance.startTimer('google-ai-query');

    logger.info(`ğŸ”„ Google AI ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘: ${requestId}`, {
      query: request.query?.substring(0, 100),
      mode: request.mode,
    });

    try {
      if (!this.initialized || !this.model || !this.genAI) {
        throw new Error('Google AI Serviceê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
      }

      // ğŸš€ í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ Feature Flag ì ìš©
      const useDynamicRouting =
        process.env.USE_DYNAMIC_AI_MODEL_ROUTING === 'true';
      let modelToUse;
      let modelName;

      if (useDynamicRouting) {
        // ë™ì  ë¼ìš°íŒ… í™œì„±í™” ì‹œ
        const complexity = this.analyzeQueryComplexity(request.query || '');
        modelName = MODEL_MAPPING[complexity];
        modelToUse = this.genAI.getGenerativeModel({ model: modelName });
        logger.info(
          `ğŸ§  [FLAG ON] ë™ì  ëª¨ë¸ ì„ íƒ: ${complexity} â†’ ${modelName}`,
          { requestId }
        );
      } else {
        // ë™ì  ë¼ìš°íŒ… ë¹„í™œì„±í™” ì‹œ (ê¸°ì¡´ ë°©ì‹)
        modelName = process.env.GOOGLE_AI_MODEL || 'gemini-2.0-flash';
        modelToUse = this.model;
        logger.info(`ğŸ§  [FLAG OFF] ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: ${modelName}`, {
          requestId,
        });
      }

      // ìì—°ì–´ ì§ˆì˜ í™•ì¸
      if (!this.isNaturalLanguageQuery(request.query || '')) {
        throw new Error('Google AIëŠ” ìì—°ì–´ ì§ˆì˜ì—ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤');
      }

      // ìºì‹œ í™•ì¸
      const cacheKey = `google_ai_${this.generateQueryHash(request.query || '')}`;
      const cached = cache.get(cacheKey);
      if (cached) {
        logger.info(`ğŸ“‹ Google AI ìºì‹œ ì‘ë‹µ: ${requestId}`);
        return cached;
      }

      // ğŸ”’ í• ë‹¹ëŸ‰ ê´€ë¦¬ìì—ì„œ API í˜¸ì¶œ ê¶Œí•œ í™•ì¸
      const { GoogleAIQuotaManager } = await import(
        './engines/GoogleAIQuotaManager'
      );
      const quotaManager = new GoogleAIQuotaManager();

      const permission = await quotaManager.canPerformAPICall();
      if (!permission.allowed) {
        throw new Error(`API í˜¸ì¶œ ì œí•œ: ${permission.reason}`);
      }

      // Google AI ìš”ì²­
      const googleTimer = performance.startTimer('google-ai-api-call');

      const result: any = await Promise.race([
        modelToUse.generateContent(this.buildPrompt(request)), // ğŸš€ ì„ íƒëœ ëª¨ë¸ ì‚¬ìš©
        new Promise((_, reject) =>
          setTimeout(
            () => reject(new Error('Google AI API timeout')),
            vercelConfig.maxExecutionTime - 2000
          )
        ),
      ]);

      const googleDuration = googleTimer();

      if (!result.response) {
        await quotaManager.recordAPIFailure(); // ğŸš€ ì‹¤íŒ¨ ê¸°ë¡
        throw new Error('Google AIì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤');
      }

      const text = result.response.text();
      const confidence = this.calculateConfidence(text, request.query || '');

      // ğŸš€ ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚° ë° ê¸°ë¡
      const estimatedTokens = this.estimateTokenUsage(
        request.query || '',
        text
      );
      await quotaManager.recordAPIUsage(estimatedTokens);

      const response: AIResponse = {
        success: true,
        response: text,
        confidence,
        mode: request.mode || 'GOOGLE_ONLY',
        enginePath: ['google-ai-service'],
        processingTime: googleDuration,
        fallbacksUsed: 0,
        metadata: {
          mainEngine: `Google AI (${modelName})`, // ğŸš€ ì‚¬ìš©ëœ ëª¨ë¸ ì´ë¦„ ëª…ì‹œ
          supportEngines: ['Google AI (Gemini)'],
          ragUsed: false,
          googleAIUsed: true,
          mcpContextUsed: false,
          subEnginesUsed: [],
          cacheUsed: false,
          processingTime: googleDuration,
          enginePath: ['google-ai-service'],
        },
      };

      // ì„±ê³µí•œ ì‘ë‹µ ìºì‹œ ì €ì¥
      cache.set(cacheKey, response, vercelConfig.cacheTTL);

      const duration = timer();
      logger.info(
        `âœ… Google AI ì¿¼ë¦¬ ì™„ë£Œ: ${requestId} (${duration.toFixed(2)}ms)`
      );

      return response;
    } catch (error) {
      const duration = timer();
      this.lastError = error instanceof Error ? error.message : 'Unknown error';

      // ğŸš€ API ì‹¤íŒ¨ ê¸°ë¡ (í• ë‹¹ëŸ‰ ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ëœ ê²½ìš°ë§Œ)
      try {
        const { GoogleAIQuotaManager } = await import(
          './engines/GoogleAIQuotaManager'
        );
        const quotaManager = new GoogleAIQuotaManager();
        await quotaManager.recordAPIFailure();
      } catch (quotaError) {
        logger.warn('í• ë‹¹ëŸ‰ ê´€ë¦¬ì ì‹¤íŒ¨ ê¸°ë¡ ì¤‘ ì˜¤ë¥˜:', quotaError);
      }

      logger.error(
        `âŒ Google AI ì¿¼ë¦¬ ì‹¤íŒ¨: ${requestId} (${duration.toFixed(2)}ms)`,
        error
      );

      return {
        success: false,
        response: '',
        confidence: 0,
        mode: request.mode || 'GOOGLE_ONLY',
        enginePath: ['google-ai-error'],
        processingTime: duration,
        fallbacksUsed: 0,
        error: this.lastError,
        metadata: {
          mainEngine: 'Google AI (Error)',
          supportEngines: [],
          ragUsed: false,
          googleAIUsed: false,
          mcpContextUsed: false,
          subEnginesUsed: [],
          error: this.lastError,
        },
      };
    }
  }

  /**
   * ğŸ” ìì—°ì–´ ì§ˆì˜ íŒë³„
   */
  private isNaturalLanguageQuery(query: string): boolean {
    // í•œêµ­ì–´ ìì—°ì–´ íŒ¨í„´
    const koreanNaturalPatterns = [
      /^(ì–´ë–»ê²Œ|ì™œ|ë¬´ì—‡|ì–¸ì œ|ì–´ë””ì„œ|ëˆ„ê°€|ë¬´ì—‡ì„|ì–´ë–¤|ì–´ëŠ)/,
      /\?$/,
      /(ì„¤ëª…|ë¶„ì„|ìš”ì•½|ì •ë¦¬|ì•Œë ¤|ì¶”ì²œ|ë¹„êµ|ì°¨ì´|ë°©ë²•)/,
      /(í•  ìˆ˜ ìˆë‚˜ìš”|ê°€ëŠ¥í•œê°€ìš”|í•´ì£¼ì„¸ìš”|ë„ì™€ì£¼ì„¸ìš”)/,
      /(ë¬¸ì œ|í•´ê²°|ê°œì„ |ìµœì í™”|ì„±ëŠ¥|ìƒíƒœ)/,
    ];

    // ì˜ì–´ ìì—°ì–´ íŒ¨í„´
    const englishNaturalPatterns = [
      /^(how|why|what|when|where|who|which|can you|could you)/i,
      /\?$/,
      /(explain|analyze|summarize|tell me|recommend|compare|difference)/i,
      /(help|assist|show|provide|give)/i,
    ];

    const text = query.trim();
    return (
      koreanNaturalPatterns.some(pattern => pattern.test(text)) ||
      englishNaturalPatterns.some(pattern => pattern.test(text))
    );
  }

  /**
   * ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  private buildPrompt(request: AIRequest): string {
    const basePrompt = `
ë‹¹ì‹ ì€ ì„œë²„ ì‹œìŠ¤í…œ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: ${request.query}

ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”:
1. ê¸°ìˆ ì ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ ì œê³µ
2. ì‹¤ë¬´ì— ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ ì œì‹œ
3. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
4. í•„ìš”ì‹œ ë‹¨ê³„ë³„ ê°€ì´ë“œ ì œê³µ
5. ì£¼ì˜ì‚¬í•­ì´ë‚˜ ì œí•œì‚¬í•­ë„ í•¨ê»˜ ì•ˆë‚´

ë‹µë³€:`;

    return basePrompt.trim();
  }

  /**
   * ğŸ“Š ì‹ ë¢°ë„ ê³„ì‚°
   */
  private calculateConfidence(response: string, query: string): number {
    let confidence = 0.7; // Google AI ê¸°ë³¸ ì‹ ë¢°ë„

    // ì‘ë‹µ ê¸¸ì´ í‰ê°€
    if (response.length > 50) confidence += 0.1;
    if (response.length > 200) confidence += 0.1;

    // ì „ë¬¸ ìš©ì–´ í¬í•¨ ì—¬ë¶€
    const technicalTerms = [
      'CPU',
      'ë©”ëª¨ë¦¬',
      'ë””ìŠ¤í¬',
      'ë„¤íŠ¸ì›Œí¬',
      'ì„œë²„',
      'ë°ì´í„°ë² ì´ìŠ¤',
      'API',
      'ë¡œë“œë°¸ëŸ°ì„œ',
      'ìºì‹œ',
      'ëª¨ë‹ˆí„°ë§',
      'ë¡œê·¸',
      'ë°±ì—…',
    ];

    const termsFound = technicalTerms.filter(term =>
      response.toLowerCase().includes(term.toLowerCase())
    ).length;

    confidence += Math.min(termsFound * 0.02, 0.1);

    // êµ¬ì²´ì ì¸ í•´ê²°ì±… ì œì‹œ ì—¬ë¶€
    const solutionPatterns = [
      /ë‹¨ê³„/,
      /ë°©ë²•/,
      /í•´ê²°/,
      /ì„¤ì¹˜/,
      /ì„¤ì •/,
      /êµ¬ì„±/,
      /ìµœì í™”/,
    ];

    const solutionsFound = solutionPatterns.filter(pattern =>
      pattern.test(response)
    ).length;

    confidence += Math.min(solutionsFound * 0.03, 0.1);

    return Math.min(confidence, 0.95);
  }

  /**
   * ğŸš€ í† í° ì‚¬ìš©ëŸ‰ ì •í™•í•œ ì¶”ì • (2025.7.3 ê°œì„ )
   * Google AI Gemini í† í° ê³„ì‚° ìµœì í™”:
   * - í•œêµ­ì–´: í‰ê·  3.5ê¸€ì = 1í† í° (ê¸°ì¡´ 4ê¸€ìë³´ë‹¤ ì •í™•)
   * - ì˜ì–´: í‰ê·  4.2ê¸€ì = 1í† í° (ê³µë°± ë° êµ¬ë‘ì  ê³ ë ¤)
   * - ì½”ë“œ: í‰ê·  2.8ê¸€ì = 1í† í° (í‚¤ì›Œë“œ ë°€ë„ ë†’ìŒ)
   */
  private estimateTokenUsage(inputText: string, outputText: string): number {
    const combinedText = inputText + outputText;

    // ğŸ” í…ìŠ¤íŠ¸ íƒ€ì… ë¶„ì„
    const hasKorean = /[ã„±-ã…|ã…-ã…£|ê°€-í£]/.test(combinedText);
    const hasCode =
      /[{}();=><\/]/.test(combinedText) || /```/.test(combinedText);
    const hasEnglish = /[a-zA-Z]/.test(combinedText);

    // ğŸ¯ ì–¸ì–´ë³„ í† í° ë¹„ìœ¨ ê³„ì‚°
    let inputCharPerToken = 4; // ê¸°ë³¸ê°’
    let outputCharPerToken = 4;

    if (hasCode) {
      inputCharPerToken = 2.8;
      outputCharPerToken = 2.8;
    } else if (hasKorean) {
      inputCharPerToken = 3.5;
      outputCharPerToken = 3.5;
    } else if (hasEnglish) {
      inputCharPerToken = 4.2;
      outputCharPerToken = 4.2;
    }

    // ğŸ“Š í† í° ê³„ì‚° (ì†Œìˆ˜ì  ë°˜ì˜¬ë¦¼ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ)
    const inputTokens = Math.ceil(inputText.length / inputCharPerToken);
    const outputTokens = Math.ceil(outputText.length / outputCharPerToken);

    // ğŸš€ Google AI APIëŠ” ì…ë ¥+ì¶œë ¥ í† í° ëª¨ë‘ ì¹´ìš´íŠ¸
    const totalTokens = inputTokens + outputTokens;

    // ğŸ“ ìƒì„¸ ë¡œê¹… (ë””ë²„ê¹…ìš©)
    const textType = hasCode ? 'code' : hasKorean ? 'korean' : 'english';
    logger.info(
      `ğŸ”¢ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì • (${textType}): ì…ë ¥(${inputTokens}) + ì¶œë ¥(${outputTokens}) = ${totalTokens}`
    );

    return totalTokens;
  }

  /**
   * ğŸ”‘ ì¿¼ë¦¬ í•´ì‹œ ìƒì„±
   */
  private generateQueryHash(query: string): string {
    let hash = 0;
    for (let i = 0; i < query.length; i++) {
      const char = query.charCodeAt(i);
      hash = (hash << 5) - hash + char;
      hash = hash & hash; // 32bit integer ë³€í™˜
    }
    return Math.abs(hash).toString(36);
  }

  /**
   * ğŸ¯ ì‘ë‹µ ìƒì„± (UnifiedAIEngine í˜¸í™˜)
   */
  async generateResponse(prompt: string): Promise<GoogleAIResponse> {
    try {
      const request: AIRequest = {
        query: prompt,
        mode: 'GOOGLE_ONLY',
      };

      const response = await this.processQuery(request);

      return {
        success: response.success,
        content: response.response || '',
        model: process.env.GOOGLE_AI_MODEL || 'gemini-2.0-flash',
        tokensUsed: 0,
        cached: false,
        processingTime: response.processingTime || 0,
        confidence: response.confidence || 0.7,
        error: response.error
          ? {
              code: 'GOOGLE_AI_ERROR',
              message: response.error,
              details: response.error,
              timestamp: new Date().toISOString(),
              retryable: false,
            }
          : undefined,
      };
    } catch (error: any) {
      logger.error('âŒ Google AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error);

      return {
        success: false,
        content: '',
        model: process.env.GOOGLE_AI_MODEL || 'gemini-2.0-flash',
        tokensUsed: 0,
        cached: false,
        processingTime: 0,
        confidence: 0,
        error: {
          code: 'GOOGLE_AI_ERROR',
          message: error.message || 'Google AI API ì‹¤íŒ¨',
          details: error.stack || error.toString(),
          timestamp: new Date().toISOString(),
          retryable: false,
        },
      };
    }
  }

  /**
   * ğŸ¯ ì„œë²„ ë©”íŠ¸ë¦­ ë¶„ì„ (ê¸°ì¡´ í˜¸í™˜ì„±)
   */
  async analyzeServerMetrics(metrics: ServerMetrics[]): Promise<string> {
    const prompt = `
ì„œë²„ ëª¨ë‹ˆí„°ë§ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

${metrics
  .map(
    server => `
ì„œë²„: ${server.name}
CPU: ${server.cpu_usage}%
ë©”ëª¨ë¦¬: ${server.memory_usage}%
ë””ìŠ¤í¬: ${server.disk_usage}%
ì‘ë‹µì‹œê°„: ${server.response_time}ms
ìƒíƒœ: ${server.status}
`
  )
  .join('\n')}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½
2. ì£¼ì˜ê°€ í•„ìš”í•œ ì„œë²„ ì‹ë³„
3. ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­
4. ì˜ˆìƒë˜ëŠ” ë¬¸ì œì ê³¼ ëŒ€ì‘ë°©ì•ˆ

ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        `;

    const response = await this.generateResponse(prompt);
    return response.content;
  }

  /**
   * ğŸ¥ í—¬ìŠ¤ì²´í¬
   */
  async healthCheck(): Promise<boolean> {
    try {
      if (!this.initialized || !this.model) {
        return false;
      }

      // ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
      const testResult = await Promise.race([
        this.model.generateContent('ì•ˆë…•í•˜ì„¸ìš”'),
        new Promise((_, reject) =>
          setTimeout(() => reject(new Error('Health check timeout')), 5000)
        ),
      ]);

      return !!testResult.response;
    } catch (error) {
      logger.warn('Google AI í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨:', error);
      return false;
    }
  }

  /**
   * ğŸ“Š ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ
   */
  getStatus() {
    return {
      initialized: this.initialized,
      requestCount: this.requestCount,
      lastError: this.lastError,
      model: process.env.GOOGLE_AI_MODEL || 'gemini-2.0-flash',
      enabledInPlan: vercelConfig.enableGoogleAI,
      vercelPlan: vercelConfig.environment.isPro ? 'pro' : 'hobby',
      timestamp: new Date().toISOString(),
    };
  }

  /**
   * âœ… ê°€ìš©ì„± í™•ì¸
   */
  isAvailable(): boolean {
    return this.initialized && vercelConfig.enableGoogleAI;
  }

  /**
   * âœ… ì¤€ë¹„ ìƒíƒœ í™•ì¸
   */
  isReady(): boolean {
    return this.isAvailable();
  }

  /**
   * ğŸ”— ì—°ê²° í…ŒìŠ¤íŠ¸
   */
  async testConnection(): Promise<{
    success: boolean;
    message: string;
    latency?: number;
  }> {
    try {
      const isHealthy = await this.healthCheck();
      return {
        success: isHealthy,
        message: isHealthy ? 'Google AI ì—°ê²° ì„±ê³µ' : 'Google AI ì—°ê²° ì‹¤íŒ¨',
        latency: isHealthy ? 100 : 0,
      };
    } catch (error) {
      return {
        success: false,
        message: `Google AI ì—°ê²° ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'Unknown error'}`,
        latency: 0,
      };
    }
  }

  /**
   * ğŸ§¹ ì •ë¦¬ ì‘ì—…
   */
  cleanup(): void {
    this.genAI = null;
    this.model = null;
    this.initialized = false;
    this.requestCount = 0;
    this.lastError = null;

    logger.info('ğŸ§¹ Google AI Service ì •ë¦¬ ì™„ë£Œ');
  }
}
