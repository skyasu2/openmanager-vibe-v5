/**
 * ğŸ¤– Google AI Mode Processor - SimplifiedQueryEngine
 *
 * Handles Google AI mode query processing:
 * - Google AI API activation
 * - AI Assistant MCP activation (CloudContextLoader)
 * - Korean NLP processing
 * - GCP VM MCP server integration
 * - All advanced features included
 */

import { CloudContextLoader } from '../mcp/CloudContextLoader';
import { MockContextLoader } from './MockContextLoader';
import { validateGoogleAIMCPConfig } from '../../lib/env-safe';
import type {
  AIQueryContext,
  MCPContext,
  AIMetadata,
} from '../../types/ai-service-types';
import type {
  QueryRequest,
  QueryResponse,
} from './SimplifiedQueryEngine.types';
import { SimplifiedQueryEngineUtils } from './SimplifiedQueryEngine.utils';
import { SimplifiedQueryEngineHelpers } from './SimplifiedQueryEngine.processors.helpers';
import { LocalAIModeProcessor } from './SimplifiedQueryEngine.processors.localai';

/**
 * ğŸ¤– êµ¬ê¸€ AI ëª¨ë“œ í”„ë¡œì„¸ì„œ
 */
export class GoogleAIModeProcessor {
  private utils: SimplifiedQueryEngineUtils;
  private contextLoader: CloudContextLoader;
  private mockContextLoader: MockContextLoader;
  private helpers: SimplifiedQueryEngineHelpers;
  private localAIProcessor: LocalAIModeProcessor;

  constructor(
    utils: SimplifiedQueryEngineUtils,
    contextLoader: CloudContextLoader,
    mockContextLoader: MockContextLoader,
    helpers: SimplifiedQueryEngineHelpers,
    localAIProcessor: LocalAIModeProcessor
  ) {
    this.utils = utils;
    this.contextLoader = contextLoader;
    this.mockContextLoader = mockContextLoader;
    this.helpers = helpers;
    this.localAIProcessor = localAIProcessor;
  }

  /**
   * êµ¬ê¸€ AI ëª¨ë“œ ì¿¼ë¦¬ ì²˜ë¦¬
   * - Google AI API í™œì„±í™”
   * - AI ì–´ì‹œìŠ¤í„´íŠ¸ MCP í™œì„±í™” (CloudContextLoader)
   * - í•œêµ­ì–´ NLP ì²˜ë¦¬
   * - ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
   */
  async processGoogleAIModeQuery(
    query: string,
    context: AIQueryContext | undefined,
    options: QueryRequest['options'],
    mcpContext: MCPContext | null,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number,
    modeConfig: {
      enableGoogleAI: boolean;
      enableAIAssistantMCP: boolean;
      enableKoreanNLP: boolean;
      enableVMBackend: boolean;
    }
  ): Promise<QueryResponse> {
    const {
      enableGoogleAI,
      enableAIAssistantMCP,
      enableKoreanNLP,
      enableVMBackend,
    } = modeConfig;

    // 1ë‹¨ê³„: í•œêµ­ì–´ NLP ì²˜ë¦¬ (í™œì„±í™”ëœ ê²½ìš°)
    if (enableKoreanNLP) {
      const nlpStepStart = Date.now();
      thinkingSteps.push({
        step: 'í•œêµ­ì–´ NLP ì²˜ë¦¬',
        description: 'í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë° ì˜ë„ ë¶„ì„',
        status: 'pending',
        timestamp: nlpStepStart,
      });

      try {
        const koreanRatio = this.utils.calculateKoreanRatio(query);

        if (koreanRatio > 0.3) {
          // Korean NLP ì—”ì§„ (Google AI modeì—ì„œëŠ” Gemini APIê°€ ìì²´ ì²˜ë¦¬)
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description =
            `í•œêµ­ì–´ ë¹„ìœ¨ ${Math.round(koreanRatio * 100)}% - NLP ì²˜ë¦¬ ì™„ë£Œ`;
        } else {
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description =
            `ì˜ì–´ ì¿¼ë¦¬ ê°ì§€ - NLP ê±´ë„ˆë›°ê¸°`;
        }

        thinkingSteps[thinkingSteps.length - 1].duration =
          Date.now() - nlpStepStart;
      } catch (error) {
        console.warn('í•œêµ­ì–´ NLP ì²˜ë¦¬ ì‹¤íŒ¨:', error);
        thinkingSteps[thinkingSteps.length - 1].status = 'failed';
        thinkingSteps[thinkingSteps.length - 1].duration =
          Date.now() - nlpStepStart;
      }
    }

    // 2ë‹¨ê³„: Google AI API ì²˜ë¦¬ (í•µì‹¬ ê¸°ëŠ¥)
    const googleStepStart = Date.now();
    thinkingSteps.push({
      step: 'Google AI ì²˜ë¦¬',
      description: 'Gemini API í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„±',
      status: 'pending',
      timestamp: googleStepStart,
    });

    try {
      if (!enableGoogleAI) {
        throw new Error('Google AI APIê°€ ë¹„í™œì„±í™”ë¨');
      }

      // ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
      const prompt = this.helpers.buildGoogleAIPrompt(
        query,
        context,
        mcpContext
      );

      // Google AI API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), 400); // 400ms íƒ€ì„ì•„ì›ƒ

      const response = await fetch('/api/ai/google-ai/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          prompt,
          temperature: 0.7, // ê³ ì •ê°’ (ë³µì¡ë„ ë¶„ì„ ì—†ìŒ)
          maxTokens: 1000, // ê³ ì •ê°’
        }),
        signal: controller.signal,
      });

      clearTimeout(timeout);

      if (!response.ok) {
        throw new Error(`Google AI API ì˜¤ë¥˜: ${response.statusText}`);
      }

      const data = await response.json();

      thinkingSteps[thinkingSteps.length - 1].status = 'completed';
      thinkingSteps[thinkingSteps.length - 1].description =
        'Gemini API ì‘ë‹µ ìˆ˜ì‹ ';
      thinkingSteps[thinkingSteps.length - 1].duration =
        Date.now() - googleStepStart;

      // GCP VM MCP ì œê±°ë¨ (VM ì œê±°ë¡œ ì¸í•´ ë¶ˆí•„ìš”)

      // VM ë°±ì—”ë“œ ì—°ë™ ì œê±°ë¨ (GCP VM ì œê±°ë¡œ ì¸í•´)

      // Google AI ì§ì ‘ ì‘ë‹µ (VM MCP ì œê±°ë¡œ ì¸í•´ ë‹¨ìˆœí™”)
      const finalResponse =
        data.response || data.text || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      const finalConfidence = data.confidence || 0.9;

      return {
        success: true,
        response: finalResponse,
        engine: 'google-ai',
        confidence: finalConfidence,
        thinkingSteps,
        metadata: {
          model: data.model || 'gemini-pro',
          tokensUsed: data.tokensUsed,
          mcpUsed: !!(mcpContext && enableAIAssistantMCP),
          aiAssistantMCPUsed: enableAIAssistantMCP,
          koreanNLPUsed: enableKoreanNLP,
          // GCP VM MCP ì œê±°ë¨ - Cloud Functions ì „ìš©ìœ¼ë¡œ ë‹¨ìˆœí™”
          mockMode: !!this.mockContextLoader.getMockContext(),
          mode: 'google-ai',
        } as unknown as AIMetadata & {
          aiAssistantMCPUsed?: boolean;
          koreanNLPUsed?: boolean;
          // GCP VM MCP íƒ€ì… ì œê±°ë¨
          mockMode?: boolean;
        },
        processingTime: Date.now() - startTime,
      };
    } catch (error) {
      console.error('Google AI ì²˜ë¦¬ ì˜¤ë¥˜:', error);

      // í´ë°±: ë¡œì»¬ AI ëª¨ë“œë¡œ ì „í™˜
      thinkingSteps[thinkingSteps.length - 1].status = 'failed';
      thinkingSteps[thinkingSteps.length - 1].description =
        'Google AI ì‹¤íŒ¨, ë¡œì»¬ AI ëª¨ë“œë¡œ ì „í™˜';
      thinkingSteps[thinkingSteps.length - 1].duration =
        Date.now() - googleStepStart;

      return await this.localAIProcessor.processLocalAIModeQuery(
        query,
        context,
        options,
        mcpContext,
        thinkingSteps,
        startTime,
        { enableKoreanNLP: true, enableVMBackend: false }
      );
    }
  }
}
