/**
 * ğŸ¤– Google AI Mode Processor - SimplifiedQueryEngine
 * 
 * Handles Google AI mode query processing:
 * - Google AI API activation
 * - AI Assistant MCP activation (CloudContextLoader)
 * - Korean NLP processing
 * - VM Backend integration
 * - GCP VM MCP server integration
 * - All advanced features included
 */

import { CloudContextLoader } from '@/services/mcp/CloudContextLoader';
import { MockContextLoader } from './MockContextLoader';
import { vmBackendConnector } from '@/services/vm/VMBackendConnector';
import { 
  validateGoogleAIMCPConfig,
  getGCPVMMCPEnv 
} from '@/lib/env-safe';
import type {
  AIQueryContext,
  MCPContext,
  AIMetadata,
} from '@/types/ai-service-types';
import type {
  QueryRequest,
  QueryResponse,
  GCPVMMCPResult,
} from './SimplifiedQueryEngine.types';
import { SimplifiedQueryEngineUtils } from './SimplifiedQueryEngine.utils';
import { SimplifiedQueryEngineHelpers } from './SimplifiedQueryEngine.processors.helpers';
import { LocalAIModeProcessor } from './SimplifiedQueryEngine.processors.localai';

/**
 * ğŸ¤– êµ¬ê¸€ AI ëª¨ë“œ í”„ë¡œì„¸ì„œ
 */
export class GoogleAIModeProcessor {
  private utils: SimplifiedQueryEngineUtils;
  private contextLoader: CloudContextLoader;
  private mockContextLoader: MockContextLoader;
  private helpers: SimplifiedQueryEngineHelpers;
  private localAIProcessor: LocalAIModeProcessor;

  constructor(
    utils: SimplifiedQueryEngineUtils,
    contextLoader: CloudContextLoader,
    mockContextLoader: MockContextLoader,
    helpers: SimplifiedQueryEngineHelpers,
    localAIProcessor: LocalAIModeProcessor
  ) {
    this.utils = utils;
    this.contextLoader = contextLoader;
    this.mockContextLoader = mockContextLoader;
    this.helpers = helpers;
    this.localAIProcessor = localAIProcessor;
  }

  /**
   * êµ¬ê¸€ AI ëª¨ë“œ ì¿¼ë¦¬ ì²˜ë¦¬
   * - Google AI API í™œì„±í™”
   * - AI ì–´ì‹œìŠ¤í„´íŠ¸ MCP í™œì„±í™” (CloudContextLoader)
   * - í•œêµ­ì–´ NLP ì²˜ë¦¬
   * - VM ë°±ì—”ë“œ ì—°ë™
   * - ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
   */
  async processGoogleAIModeQuery(
    query: string,
    context: AIQueryContext | undefined,
    options: QueryRequest['options'],
    mcpContext: MCPContext | null,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number,
    modeConfig: { 
      enableGoogleAI: boolean; 
      enableAIAssistantMCP: boolean; 
      enableKoreanNLP: boolean; 
      enableVMBackend: boolean;
    }
  ): Promise<QueryResponse> {
    const { enableGoogleAI, enableAIAssistantMCP, enableKoreanNLP, enableVMBackend } = modeConfig;

    // 1ë‹¨ê³„: í•œêµ­ì–´ NLP ì²˜ë¦¬ (í™œì„±í™”ëœ ê²½ìš°)
    if (enableKoreanNLP) {
      const nlpStepStart = Date.now();
      thinkingSteps.push({
        step: 'í•œêµ­ì–´ NLP ì²˜ë¦¬',
        description: 'í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë° ì˜ë„ ë¶„ì„',
        status: 'pending',
        timestamp: nlpStepStart,
      });

      try {
        const koreanRatio = this.utils.calculateKoreanRatio(query);
        
        if (koreanRatio > 0.3) {
          // Korean NLP ì—”ì§„ (Google AI modeì—ì„œëŠ” Gemini APIê°€ ìì²´ ì²˜ë¦¬)
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description = 
            `í•œêµ­ì–´ ë¹„ìœ¨ ${Math.round(koreanRatio * 100)}% - NLP ì²˜ë¦¬ ì™„ë£Œ`;
        } else {
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description = 
            `ì˜ì–´ ì¿¼ë¦¬ ê°ì§€ - NLP ê±´ë„ˆë›°ê¸°`;
        }
        
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - nlpStepStart;
      } catch (error) {
        console.warn('í•œêµ­ì–´ NLP ì²˜ë¦¬ ì‹¤íŒ¨:', error);
        thinkingSteps[thinkingSteps.length - 1].status = 'failed';
        thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - nlpStepStart;
      }
    }

    // 2ë‹¨ê³„: Google AI API ì²˜ë¦¬ (í•µì‹¬ ê¸°ëŠ¥)
    const googleStepStart = Date.now();
    thinkingSteps.push({
      step: 'Google AI ì²˜ë¦¬',
      description: 'Gemini API í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„±',
      status: 'pending',
      timestamp: googleStepStart,
    });

    try {
      if (!enableGoogleAI) {
        throw new Error('Google AI APIê°€ ë¹„í™œì„±í™”ë¨');
      }

      // ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
      const prompt = this.helpers.buildGoogleAIPrompt(query, context, mcpContext);

      // Google AI API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), 400); // 400ms íƒ€ì„ì•„ì›ƒ

      const response = await fetch('/api/ai/google-ai/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          prompt,
          temperature: 0.7, // ê³ ì •ê°’ (ë³µì¡ë„ ë¶„ì„ ì—†ìŒ)
          maxTokens: 1000,  // ê³ ì •ê°’
        }),
        signal: controller.signal,
      });

      clearTimeout(timeout);

      if (!response.ok) {
        throw new Error(`Google AI API ì˜¤ë¥˜: ${response.statusText}`);
      }

      const data = await response.json();

      thinkingSteps[thinkingSteps.length - 1].status = 'completed';
      thinkingSteps[thinkingSteps.length - 1].description = 'Gemini API ì‘ë‹µ ìˆ˜ì‹ ';
      thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - googleStepStart;

      // 2.5ë‹¨ê³„: GCP VM MCP ì„œë²„ ì§ì ‘ í˜¸ì¶œ (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤ ì ìš©)
      let gcpMcpResult = null;
      const mcpConfig = validateGoogleAIMCPConfig();
      
      if (mcpConfig.isValid && mcpConfig.config.gcpVMMCP.integrationEnabled) {
        const mcpStepStart = Date.now();
        thinkingSteps.push({
          step: 'GCP VM MCP ìì—°ì–´ ì²˜ë¦¬',
          description: 'MCP ì„œë²„ë¡œ Google AI ê²°ê³¼ ë³´ê°• ì¤‘',
          status: 'pending',
          timestamp: mcpStepStart,
        });

        try {
          const { serverUrl, timeout } = mcpConfig.config.gcpVMMCP;
          
          // JSON-RPC í‘œì¤€ ì¤€ìˆ˜ (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤)
          const mcpRequest = {
            jsonrpc: '2.0',
            id: `mcp-${Date.now()}`,
            method: 'query',
            params: {
              query,
              mode: 'natural-language',
              context: {
                googleAIResponse: data.response || data.text,
                originalQuery: query,
                timestamp: new Date().toISOString(),
                mcpContext: mcpContext
              },
              options: {
                temperature: 0.7,
                maxTokens: 500,
                includeMetrics: true,
                source: 'google-ai-mode'
              }
            }
          };

          // íƒ€ì„ì•„ì›ƒ ì„¤ì • (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤)
          const controller = new AbortController();
          const mcpTimeout = setTimeout(() => {
            controller.abort();
            console.warn(`âš ï¸ GCP VM MCP íƒ€ì„ì•„ì›ƒ (${timeout}ms)`);
          }, timeout);

          // GCP VM MCP ì„œë²„ ì§ì ‘ í˜¸ì¶œ
          console.log(`ğŸŒ GCP VM MCP ì„œë²„ í˜¸ì¶œ: ${serverUrl}`);
          
          const mcpResponse = await fetch(`${serverUrl}/mcp/query`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'X-MCP-Type': 'google-ai',
              'X-Client': 'openmanager-vibe-v5-simplified-engine',
              'X-Request-ID': mcpRequest.id,
            },
            body: JSON.stringify(mcpRequest.params), // MCP ì„œë²„ê°€ paramsë§Œ ì²˜ë¦¬í•˜ëŠ” ê²½ìš°
            signal: controller.signal,
          });

          clearTimeout(mcpTimeout);

          if (!mcpResponse.ok) {
            throw new Error(`GCP VM MCP ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: ${mcpResponse.status} ${mcpResponse.statusText}`);
          }

          const mcpData = await mcpResponse.json();
          
          // ì‘ë‹µ ê²€ì¦ (JSON-RPC í‘œì¤€)
          if (mcpData.success !== undefined ? mcpData.success : true) {
            gcpMcpResult = {
              enhanced: mcpData.response || mcpData.result,
              processingTime: Date.now() - mcpStepStart,
              serverUsed: 'gcp-vm-mcp',
              metadata: mcpData.metadata || {
                mcpType: 'google-ai',
                aiMode: 'natural-language-processing'
              }
            };

            thinkingSteps[thinkingSteps.length - 1].status = 'completed';
            thinkingSteps[thinkingSteps.length - 1].description = 
              `MCP ìì—°ì–´ ì²˜ë¦¬ ì™„ë£Œ (${gcpMcpResult.processingTime}ms)`;
            
            console.log(`âœ… GCP VM MCP í˜¸ì¶œ ì„±ê³µ: ${gcpMcpResult.processingTime}ms`);
          } else {
            throw new Error(mcpData.error || 'MCP ì„œë²„ì—ì„œ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°˜í™˜');
          }

          thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - mcpStepStart;
          
        } catch (error) {
          // ìƒì„¸í•œ ì—ëŸ¬ í•¸ë“¤ë§ (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤)
          const errorMsg = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
          
          console.warn(`âš ï¸ GCP VM MCP í˜¸ì¶œ ì‹¤íŒ¨: ${errorMsg}`);
          
          thinkingSteps[thinkingSteps.length - 1].status = 'failed';
          thinkingSteps[thinkingSteps.length - 1].description = `MCP ì„œë²„ ì˜¤ë¥˜: ${errorMsg}`;
          thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - mcpStepStart;
          
          // MCP ì‹¤íŒ¨ëŠ” ì „ì²´ ì‘ë‹µì„ ë°©í•´í•˜ì§€ ì•ŠìŒ (í´ë°±)
          gcpMcpResult = {
            fallback: true,
            error: errorMsg,
            processingTime: Date.now() - mcpStepStart
          };
        }
      } else {
        // í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì • ì‹œ ë¡œê¹… (ë² ìŠ¤íŠ¸ í”„ë ‰í‹°ìŠ¤)
        if (!mcpConfig.isValid) {
          console.log(`ğŸ”§ GCP VM MCP ë¹„í™œì„±í™”: ${mcpConfig.errors.join(', ')}`);
        } else {
          console.log('ğŸ”§ GCP VM MCP í†µí•© ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤');
        }
      }

      // 3ë‹¨ê³„: VM ë°±ì—”ë“œ ì—°ë™ (í™œì„±í™”ëœ ê²½ìš°)
      let vmBackendResult = null;
      if (enableVMBackend) {
        const vmStepStart = Date.now();
        thinkingSteps.push({
          step: 'VM ë°±ì—”ë“œ ê³ ê¸‰ ì²˜ë¦¬',
          description: 'GCP VMì˜ DeepAnalyzer, StreamProcessor ì—°ë™',
          status: 'pending',
          timestamp: vmStepStart,
        });

        try {
          // VM ë°±ì—”ë“œ ê³ ê¸‰ ê¸°ëŠ¥ ì—°ë™ êµ¬í˜„
          if (vmBackendConnector.isEnabled) {
            try {
              // 1. ì„¸ì…˜ ìƒì„± ë° ë©”ì‹œì§€ ê¸°ë¡
              const session = await vmBackendConnector.createSession('google-ai-user', {
                query,
                mode: 'google-ai',
                googleAIResponse: data.response,
                mcpUsed: !!mcpContext && enableAIAssistantMCP
              });

              if (session) {
                await vmBackendConnector.addMessage(session.id, {
                  role: 'user',
                  content: query,
                  metadata: { mode: 'google-ai', mcpContext: !!mcpContext }
                });

                await vmBackendConnector.addMessage(session.id, {
                  role: 'assistant',
                  content: data.response || data.text,
                  metadata: { 
                    model: data.model,
                    tokensUsed: data.tokensUsed,
                    confidence: data.confidence
                  }
                });

                // 2. ì‹¬ì¸µ ë¶„ì„ ì‹œì‘ (ë¹„ë™ê¸°)
                const analysisJob = await vmBackendConnector.startDeepAnalysis(
                  'pattern',
                  query,
                  {
                    googleAIResponse: data.response,
                    sessionId: session.id,
                    mcpContext: mcpContext
                  }
                );

                // 3. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¤€ë¹„
                if (enableVMBackend) {
                  await vmBackendConnector.subscribeToSession(session.id);
                }

                vmBackendResult = {
                  sessionId: session.id,
                  analysisJobId: analysisJob?.id,
                  deepAnalysisStarted: !!analysisJob,
                  streamingEnabled: true
                };
              }
            } catch (vmError) {
              console.warn('VM ë°±ì—”ë“œ ê³ ê¸‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', vmError);
              // VM ë°±ì—”ë“œ ì˜¤ë¥˜ëŠ” ì „ì²´ ì‘ë‹µì„ ë°©í•´í•˜ì§€ ì•ŠìŒ
            }
          }
          
          thinkingSteps[thinkingSteps.length - 1].status = 'completed';
          thinkingSteps[thinkingSteps.length - 1].description = 'VM ë°±ì—”ë“œ ê³ ê¸‰ ì²˜ë¦¬ ì™„ë£Œ';
          thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - vmStepStart;
        } catch (error) {
          console.warn('VM ë°±ì—”ë“œ ê³ ê¸‰ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
          thinkingSteps[thinkingSteps.length - 1].status = 'failed';
          thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - vmStepStart;
        }
      }

      // Google AI ì‘ë‹µê³¼ GCP VM MCP ê²°ê³¼ í†µí•©
      let finalResponse = data.response || data.text || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      let finalConfidence = data.confidence || 0.9;
      
      // GCP VM MCP ê²°ê³¼ê°€ ìˆê³  ì„±ê³µì ì´ë©´ ì‘ë‹µ í–¥ìƒ
      if (gcpMcpResult && !gcpMcpResult.fallback && gcpMcpResult.enhanced) {
        // MCPê°€ ì‘ë‹µì„ ë³´ê°•í•œ ê²½ìš°
        finalResponse = gcpMcpResult.enhanced;
        finalConfidence = Math.min(finalConfidence + 0.1, 1.0); // ì‹ ë¢°ë„ 10% í–¥ìƒ (ìµœëŒ€ 1.0)
        
        console.log(`âœ¨ GCP VM MCPë¡œ ì‘ë‹µ ë³´ê°• ì™„ë£Œ (ì‹ ë¢°ë„: ${finalConfidence})`);
      } else if (gcpMcpResult && gcpMcpResult.fallback) {
        console.log(`âš ï¸ GCP VM MCP í´ë°± ëª¨ë“œ: ${gcpMcpResult.error}`);
      }

      return {
        success: true,
        response: finalResponse,
        engine: 'google-ai',
        confidence: finalConfidence,
        thinkingSteps,
        metadata: {
          model: data.model || 'gemini-pro',
          tokensUsed: data.tokensUsed,
          mcpUsed: !!(mcpContext && enableAIAssistantMCP) || !!gcpMcpResult,
          aiAssistantMCPUsed: enableAIAssistantMCP,
          koreanNLPUsed: enableKoreanNLP,
          vmBackendUsed: enableVMBackend && !!vmBackendResult,
          gcpVMMCPUsed: !!gcpMcpResult && !gcpMcpResult.fallback, // ğŸ¯ GCP VM MCP ì‚¬ìš© ì—¬ë¶€
          gcpVMMCPResult: gcpMcpResult ? {
            success: !gcpMcpResult.fallback,
            data: {
              response: gcpMcpResult.fallback ? '' : (gcpMcpResult.enhanced || ''),
              confidence: gcpMcpResult.fallback ? 0 : 0.85,
              metadata: gcpMcpResult.metadata || {}
            }
          } : undefined,
          mockMode: !!this.mockContextLoader.getMockContext(),
          mode: 'google-ai',
        } as unknown as AIMetadata & { 
          aiAssistantMCPUsed?: boolean; 
          koreanNLPUsed?: boolean; 
          vmBackendUsed?: boolean; 
          gcpVMMCPUsed?: boolean;
          gcpVMMCPResult?: GCPVMMCPResult;
          mockMode?: boolean;
        },
        processingTime: Date.now() - startTime,
      };
    } catch (error) {
      console.error('Google AI ì²˜ë¦¬ ì˜¤ë¥˜:', error);

      // í´ë°±: ë¡œì»¬ AI ëª¨ë“œë¡œ ì „í™˜
      thinkingSteps[thinkingSteps.length - 1].status = 'failed';
      thinkingSteps[thinkingSteps.length - 1].description = 'Google AI ì‹¤íŒ¨, ë¡œì»¬ AI ëª¨ë“œë¡œ ì „í™˜';
      thinkingSteps[thinkingSteps.length - 1].duration = Date.now() - googleStepStart;

      return await this.localAIProcessor.processLocalAIModeQuery(
        query,
        context,
        options,
        mcpContext,
        thinkingSteps,
        startTime,
        { enableKoreanNLP: true, enableVMBackend: true }
      );
    }
  }
}