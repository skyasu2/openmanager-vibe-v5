/**
 * ğŸ¤– Google AI Mode Processor - SimplifiedQueryEngine
 *
 * Handles Google AI mode query processing:
 * - Google AI API activation
 * - AI Assistant MCP activation (CloudContextLoader)
 * - Korean NLP processing
 * - GCP VM MCP server integration
 * - All advanced features included
 */

import { CloudContextLoader } from '../mcp/CloudContextLoader';
import { MockContextLoader } from './MockContextLoader';
import { validateGoogleAIMCPConfig } from '../../lib/env-safe';
import type {
  AIQueryContext,
  MCPContext,
  AIMetadata,
} from '../../types/ai-service-types';
import type {
  QueryRequest,
  QueryResponse,
} from './SimplifiedQueryEngine.types';
import { SimplifiedQueryEngineUtils } from './SimplifiedQueryEngine.utils';
import { SimplifiedQueryEngineHelpers } from './SimplifiedQueryEngine.processors.helpers';
import { LocalAIModeProcessor } from './SimplifiedQueryEngine.processors.localai';
import { getQueryDifficultyAnalyzer, type GoogleAIModel } from './QueryDifficultyAnalyzer';
import { getGoogleAIUsageTracker } from './GoogleAIUsageTracker';
// ğŸ”§ íƒ€ì„ì•„ì›ƒ ì„¤ì • (í†µí•© ìœ í‹¸ë¦¬í‹° ì‚¬ìš©)
import { getEnvironmentTimeouts } from '@/utils/timeout-config';
// ğŸš€ ì•„í‚¤í…ì²˜ ê°œì„ : ì§ì ‘ Google AI SDK í†µí•©
import { getDirectGoogleAIService } from './DirectGoogleAIService';

/**
 * ğŸ¤– êµ¬ê¸€ AI ëª¨ë“œ í”„ë¡œì„¸ì„œ
 */
export class GoogleAIModeProcessor {
  private utils: SimplifiedQueryEngineUtils;
  private contextLoader: CloudContextLoader;
  private mockContextLoader: MockContextLoader;
  private helpers: SimplifiedQueryEngineHelpers;
  private localAIProcessor: LocalAIModeProcessor;

  constructor(
    utils: SimplifiedQueryEngineUtils,
    contextLoader: CloudContextLoader,
    mockContextLoader: MockContextLoader,
    helpers: SimplifiedQueryEngineHelpers,
    localAIProcessor: LocalAIModeProcessor
  ) {
    this.utils = utils;
    this.contextLoader = contextLoader;
    this.mockContextLoader = mockContextLoader;
    this.helpers = helpers;
    this.localAIProcessor = localAIProcessor;
  }

  /**
   * êµ¬ê¸€ AI ëª¨ë“œ ì¿¼ë¦¬ ì²˜ë¦¬
   * - Google AI API í™œì„±í™”
   * - AI ì–´ì‹œìŠ¤í„´íŠ¸ MCP í™œì„±í™” (CloudContextLoader)
   * - í•œêµ­ì–´ NLP ì²˜ë¦¬
   * - ëª¨ë“  ê¸°ëŠ¥ í¬í•¨
   */
  async processGoogleAIModeQuery(
    query: string,
    context: AIQueryContext | undefined,
    options: QueryRequest['options'],
    mcpContext: MCPContext | null,
    thinkingSteps: QueryResponse['thinkingSteps'],
    startTime: number,
    modeConfig: {
      enableGoogleAI: boolean;
      enableAIAssistantMCP: boolean;
      enableKoreanNLP: boolean;
      enableVMBackend: boolean;
    }
  ): Promise<QueryResponse> {
    const {
      enableGoogleAI,
      enableAIAssistantMCP,
      enableKoreanNLP,
      enableVMBackend,
    } = modeConfig;

    // 1ë‹¨ê³„: í•œêµ­ì–´ NLP ì²˜ë¦¬ (í™œì„±í™”ëœ ê²½ìš°)
    if (enableKoreanNLP) {
      const nlpStepStart = Date.now();
      thinkingSteps.push({
        step: 'í•œêµ­ì–´ NLP ì²˜ë¦¬',
        description: 'í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ ë° ì˜ë„ ë¶„ì„',
        status: 'pending',
        timestamp: nlpStepStart,
      });

      try {
        const koreanRatio = this.utils.calculateKoreanRatio(query);

        if (koreanRatio > 0.3) {
          // Korean NLP ì—”ì§„ (Google AI modeì—ì„œëŠ” Gemini APIê°€ ìì²´ ì²˜ë¦¬)
          const nlpStep = thinkingSteps[thinkingSteps.length - 1];
          if (nlpStep) {
            nlpStep.status = 'completed';
            nlpStep.description = `í•œêµ­ì–´ ë¹„ìœ¨ ${Math.round(koreanRatio * 100)}% - NLP ì²˜ë¦¬ ì™„ë£Œ`;
          }
        } else {
          const nlpEnglishStep = thinkingSteps[thinkingSteps.length - 1];
          if (nlpEnglishStep) {
            nlpEnglishStep.status = 'completed';
            nlpEnglishStep.description = `ì˜ì–´ ì¿¼ë¦¬ ê°ì§€ - NLP ê±´ë„ˆë›°ê¸°`;
          }
        }

        const nlpDurationStep = thinkingSteps[thinkingSteps.length - 1];
        if (nlpDurationStep) {
          nlpDurationStep.duration = Date.now() - nlpStepStart;
        }
      } catch (error) {
        console.warn('í•œêµ­ì–´ NLP ì²˜ë¦¬ ì‹¤íŒ¨:', error);
        const nlpFailedStep = thinkingSteps[thinkingSteps.length - 1];
        if (nlpFailedStep) {
          nlpFailedStep.status = 'failed';
          nlpFailedStep.duration = Date.now() - nlpStepStart;
        }
      }
    }

    // 2ë‹¨ê³„: ê¸°ë³¸ ëª¨ë¸ ê³ ì • (ë¬´ë£Œ í‹°ì–´ ì•ˆì •ì„± ìš°ì„ )
    const modelStepStart = Date.now();
    thinkingSteps.push({
      step: 'ëª¨ë¸ ì„ íƒ',
      description: 'Flash-Lite ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš© (ë¬´ë£Œ í‹°ì–´ ìµœì í™”)',
      status: 'pending',
      timestamp: modelStepStart,
    });

    // ğŸ¯ ë¬´ë£Œ í‹°ì–´ ì•ˆì •ì„± ìš°ì„ : Flash-Lite ê³ ì • ì‚¬ìš©
    const selectedModel: GoogleAIModel = 'gemini-2.5-flash-lite';
    const difficultyScore = 0; // ë‹¨ìˆœí™”: ë¶„ì„ ìƒëµ
    const difficultyLevel = 'standard'; // í‘œì¤€ ì²˜ë¦¬

    const modelStep = thinkingSteps[thinkingSteps.length - 1];
    if (modelStep) {
      modelStep.status = 'completed';
      modelStep.description = `Flash-Lite ëª¨ë¸ ì„ íƒ (RPD 1,000ê°œ, ì•ˆì •ì„± ìš°ì„ )`;
      modelStep.duration = Date.now() - modelStepStart;
    }

    console.log(`ğŸ¯ ëª¨ë¸ ê³ ì •: ${selectedModel} (ë¬´ë£Œ í‹°ì–´ ìµœì í™”)`);

    // ğŸ¯ ê¸°ë³¸ ëª¨ë¸ ê³ ì •: í‘œì¤€ íŒŒë¼ë¯¸í„° ì‚¬ìš© (ìŠ¤ì½”í”„ ì™¸ë¶€ì—ì„œ ì •ì˜)
    const standardTemperature = 0.7; // ê· í˜•ì¡íŒ ì°½ì˜ì„±
    const standardMaxTokens = 1000;  // ì¶©ë¶„í•œ ì‘ë‹µ ê¸¸ì´

    // 3ë‹¨ê³„: Google AI API ì²˜ë¦¬ (ì„ íƒëœ ëª¨ë¸ ì‚¬ìš©)
    const googleStepStart = Date.now();
    thinkingSteps.push({
      step: 'Google AI ì²˜ë¦¬',
      description: `${selectedModel} ëª¨ë¸ë¡œ API í˜¸ì¶œ`,
      status: 'pending',
      timestamp: googleStepStart,
    });

    try {
      if (!enableGoogleAI) {
        throw new Error('Google AI APIê°€ ë¹„í™œì„±í™”ë¨');
      }

      // ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
      const prompt = this.helpers.buildGoogleAIPrompt(
        query,
        context,
        mcpContext
      );

      // ğŸš€ ì•„í‚¤í…ì²˜ ê°œì„ : ì§ì ‘ Google AI SDK í˜¸ì¶œ (ì¤‘ê°„ API Route ì œê±°)
      const timeouts = getEnvironmentTimeouts();

      // DirectGoogleAIService ì‚¬ìš© (API Wrapper Anti-Pattern ì œê±°)
      const directGoogleAI = getDirectGoogleAIService();
      const apiResponse = await directGoogleAI.generateContent(prompt, {
        model: selectedModel,
        temperature: standardTemperature,
        maxTokens: standardMaxTokens,
        timeout: timeouts.GOOGLE_AI // ğŸ¯ ë„‰ë„‰í•œ íƒ€ì„ì•„ì›ƒ: timeout-config.ts ì„¤ì • ì‚¬ìš© (8ì´ˆ)
      });

      if (!apiResponse.success) {
        throw new Error(`Google AI ì§ì ‘ í˜¸ì¶œ ì˜¤ë¥˜: ${apiResponse.error}`);
      }

      const googleStep = thinkingSteps[thinkingSteps.length - 1];
      if (googleStep) {
        googleStep.status = 'completed';
        googleStep.description = 'Gemini API ì‘ë‹µ ìˆ˜ì‹ ';
        googleStep.duration = Date.now() - googleStepStart;
      }

      // ğŸ”„ ì‚¬ìš©ëŸ‰ ì¶”ì : ì„±ê³µí•œ API í˜¸ì¶œ ê¸°ë¡
      const usageTracker = getGoogleAIUsageTracker();
      usageTracker.recordUsage({
        model: selectedModel,
        timestamp: Date.now(),
        requestCount: 1,
        tokenCount: apiResponse.usage?.totalTokens || 0,
        latency: apiResponse.responseTime,
        success: true,
        difficultyScore,
      });

      // ğŸš€ ì§ì ‘ ì‘ë‹µ ì‚¬ìš© (êµ¬ì¡° ë‹¨ìˆœí™”)
      const finalResponse = apiResponse.content || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
      const finalConfidence = 0.9; // DirectGoogleAIServiceëŠ” í•­ìƒ ë†’ì€ ì‹ ë¢°ë„

      return {
        success: true,
        response: finalResponse,
        engine: 'google-ai',
        confidence: finalConfidence,
        thinkingSteps,
        metadata: {
          model: selectedModel,
          tokensUsed: apiResponse.usage?.totalTokens || 0,
          mcpUsed: !!(mcpContext && enableAIAssistantMCP),
          aiAssistantMCPUsed: enableAIAssistantMCP,
          koreanNLPUsed: enableKoreanNLP,
          // GCP VM MCP ì œê±°ë¨ - Cloud Functions ì „ìš©ìœ¼ë¡œ ë‹¨ìˆœí™”
          mockMode: !!this.mockContextLoader.getMockContext(),
          mode: 'google-ai',
          // ê¸°ë³¸ ëª¨ë¸ ê³ ì • ì •ë³´
          modelInfo: {
            selectedModel,
            temperature: standardTemperature,
            maxTokens: standardMaxTokens,
            strategy: 'fixed-model', // ê³ ì • ëª¨ë¸ ì „ëµ
          },
        } as unknown as AIMetadata & {
          aiAssistantMCPUsed?: boolean;
          koreanNLPUsed?: boolean;
          mockMode?: boolean;
          modelInfo?: {
            selectedModel: GoogleAIModel;
            temperature: number;
            maxTokens: number;
            strategy: string;
          };
        },
        processingTime: Date.now() - startTime,
      };
    } catch (error) {
      console.error('Google AI ì²˜ë¦¬ ì˜¤ë¥˜:', error);

      // ğŸ”„ ì‚¬ìš©ëŸ‰ ì¶”ì : ì‹¤íŒ¨í•œ API í˜¸ì¶œ ê¸°ë¡
      const usageTracker = getGoogleAIUsageTracker();
      usageTracker.recordUsage({
        model: selectedModel,
        timestamp: Date.now(),
        requestCount: 1,
        tokenCount: 0,
        latency: Date.now() - googleStepStart,
        success: false,
        difficultyScore,
      });

      // ğŸš¨ í´ë°± ì œê±°: ì—ëŸ¬ ì§ì ‘ ë°˜í™˜
      const googleFailedStep = thinkingSteps[thinkingSteps.length - 1];
      if (googleFailedStep) {
        googleFailedStep.status = 'failed';
        googleFailedStep.description = 'Google AI ì²˜ë¦¬ ì‹¤íŒ¨';
        googleFailedStep.duration = Date.now() - googleStepStart;
      }

      // Google AI ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ ë°˜í™˜ (í´ë°± ì—†ìŒ)
      return {
        success: false,
        response: 'Google AI ëª¨ë“œì—ì„œ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        engine: 'google-ai',
        confidence: 0,
        thinkingSteps,
        error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜',
        metadata: {
          model: selectedModel,
          aiAssistantMCPUsed: enableAIAssistantMCP,
          koreanNLPUsed: enableKoreanNLP,
          mockMode: !!this.mockContextLoader.getMockContext(),
          mode: 'google-ai',
          // ê¸°ë³¸ ëª¨ë¸ ê³ ì • ì •ë³´ (ì—ëŸ¬ ì‹œì—ë„ í¬í•¨)
          modelInfo: {
            selectedModel,
            temperature: standardTemperature,
            maxTokens: standardMaxTokens,
            strategy: 'fixed-model', // ê³ ì • ëª¨ë¸ ì „ëµ
          },
        } as AIMetadata & {
          aiAssistantMCPUsed?: boolean;
          koreanNLPUsed?: boolean;
          mockMode?: boolean;
          modelInfo?: {
            selectedModel: GoogleAIModel;
            temperature: number;
            maxTokens: number;
            strategy: string;
          };
        },
        processingTime: Date.now() - startTime,
      };
    }
  }
}
