/**
 * SupabaseTimeSeriesManager - Supabase ì‹œê³„ì—´ ë°ì´í„° ê´€ë¦¬ì
 * Phase 2: Supabase ì‹œê³„ì—´ DB ì‹œìŠ¤í…œ
 *
 * ğŸŸ¢ Green ë‹¨ê³„: ìµœì†Œ êµ¬í˜„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼
 *
 * ëª©í‘œ:
 * - Firestore 120% ì‚¬ìš©ëŸ‰ì„ Supabase 60% ì‚¬ìš©ëŸ‰ìœ¼ë¡œ ë¶„ì‚°
 * - ì‹œê³„ì—´ ë°ì´í„° 7ì¼ TTL ì €ì¥
 * - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
 * - ì§‘ê³„ í†µê³„ ë° ë¶„ì„ ê¸°ëŠ¥
 */

import type { ServerMetric } from '@/types/server-metrics';

export interface SupabaseClient {
  from(table: string): SupabaseQueryBuilder;
  rpc<T = unknown>(
    fn: string,
    args?: Record<string, unknown>
  ): Promise<{ data: T | null; error: Error | null }>;
  storage: {
    from(bucket: string): SupabaseStorageBucket;
  };
}

export interface SupabaseQueryBuilder {
  insert<T = unknown>(
    values: T[] | T
  ): Promise<{ data: T[] | null; error: Error | null }>;
  select(columns?: string): SupabaseQueryBuilder;
  delete(): SupabaseQueryBuilder;
  update<T = unknown>(values: T): SupabaseQueryBuilder;
  upsert<T = unknown>(
    values: T[] | T
  ): Promise<{ data: T[] | null; error: Error | null }>;
  eq(column: string, value: unknown): SupabaseQueryBuilder;
  gte(column: string, value: unknown): SupabaseQueryBuilder;
  lte(column: string, value: unknown): SupabaseQueryBuilder;
  order(
    column: string,
    options?: { ascending?: boolean }
  ): SupabaseQueryBuilder;
  limit(count: number): SupabaseQueryBuilder;
  range(from: number, to: number): SupabaseQueryBuilder;

  // ğŸ”§ Promiseë¥¼ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œë“¤ ì¶”ê°€
  then<T>(
    onfulfilled?: (value: { data: unknown; error: Error | null }) => T
  ): Promise<T>;
  catch<T>(onrejected?: (reason: unknown) => T): Promise<T>;
}

export interface SupabaseStorageBucket {
  upload(
    path: string,
    file: File | Blob | ArrayBuffer,
    options?: { contentType?: string; cacheControl?: string; upsert?: boolean }
  ): Promise<{ data: { path: string } | null; error: Error | null }>;
  download(path: string): Promise<{ data: Blob | null; error: Error | null }>;
  remove(
    paths: string[]
  ): Promise<{ data: string[] | null; error: Error | null }>;
  list(
    path?: string,
    options?: { limit?: number; offset?: number }
  ): Promise<{
    data: Array<{
      name: string;
      id: string;
      updated_at: string;
      created_at: string;
    }> | null;
    error: Error | null;
  }>;
}

export interface TimeSeriesRecord {
  session_id: string;
  server_id: string;
  timestamp: string;
  cpu_usage: number;
  memory_usage: number;
  disk_usage: number;
  network_usage: number;
  request_count: number;
  error_rate: number;
  response_time: number; // DB column name
  created_at: string;
}

export interface TimeSeriesQuery {
  sessionId?: string;
  serverId?: string;
  startTime?: Date;
  endTime?: Date;
  limit?: number;
  orderBy?: string;
  ascending?: boolean;
}

export interface AggregatedStats {
  sessionId: string;
  serverId?: string;
  timeRange: {
    start: Date;
    end: Date;
  };
  metrics: {
    avgCpuUsage: number;
    maxCpuUsage: number;
    avgMemoryUsage: number;
    maxMemoryUsage: number;
    avgDiskUsage: number;
    avgNetworkUsage: number;
    totalRequests: number;
    avgResponseTime: number;
    maxResponseTime: number;
    avgErrorRate: number;
    maxErrorRate: number;
  };
  dataPoints: number;
}

export interface AlertThreshold {
  metric:
    | 'cpu_usage'
    | 'memory_usage'
    | 'disk_usage'
    | 'error_rate'
    | 'response_time';
  operator: '>' | '<' | '>=' | '<=' | '=';
  value: number;
  duration: number; // seconds
}

export class SupabaseTimeSeriesManager {
  private readonly TABLE_NAME = 'server_metrics_timeseries';
  private readonly TTL_DAYS = 7;
  private readonly BATCH_SIZE = 1000;

  constructor(private supabase: SupabaseClient) {}

  /**
   * ğŸŸ¢ GREEN: ë°°ì¹˜ ë©”íŠ¸ë¦­ ì‚½ì…
   */
  async batchInsertMetrics(
    sessionId: string,
    metrics: ServerMetric[]
  ): Promise<void> {
    const records = this.transformToTimeSeriesRecords(sessionId, metrics);

    // ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
    for (let i = 0; i < records.length; i += this.BATCH_SIZE) {
      const batch = records.slice(i, i + this.BATCH_SIZE);
      await this.supabase.from(this.TABLE_NAME).insert(batch);
    }
  }

  /**
   * ğŸŸ¢ GREEN: ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ
   */
  async queryTimeSeriesData(
    query: TimeSeriesQuery
  ): Promise<TimeSeriesRecord[]> {
    let queryBuilder = this.supabase.from(this.TABLE_NAME).select('*');

    if (query.sessionId) {
      queryBuilder = queryBuilder.eq('session_id', query.sessionId);
    }

    if (query.serverId) {
      queryBuilder = queryBuilder.eq('server_id', query.serverId);
    }

    if (query.startTime) {
      queryBuilder = queryBuilder.gte(
        'timestamp',
        query.startTime.toISOString()
      );
    }

    if (query.endTime) {
      queryBuilder = queryBuilder.lte('timestamp', query.endTime.toISOString());
    }

    if (query.orderBy) {
      queryBuilder = queryBuilder.order(query.orderBy, {
        ascending: query.ascending ?? false,
      });
    }

    if (query.limit) {
      queryBuilder = queryBuilder.limit(query.limit);
    }

    const { data, error } = await queryBuilder;
    if (error) {
      throw new Error(`ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: ${error.message}`);
    }

    return (data as TimeSeriesRecord[]) || [];
  }

  /**
   * ğŸŸ¢ GREEN: ì„¸ì…˜ë³„ ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
   */
  async getSessionMetricsHistory(
    sessionId: string,
    startTime?: Date,
    endTime?: Date
  ): Promise<ServerMetric[]> {
    const query: TimeSeriesQuery = {
      sessionId,
      startTime,
      endTime,
      orderBy: 'timestamp',
      ascending: true,
    };

    const records = await this.queryTimeSeriesData(query);
    return this.transformFromTimeSeriesRecords(records);
  }

  /**
   * ğŸŸ¢ GREEN: ì„œë²„ë³„ ì‹œê³„ì—´ ë¶„ì„
   */
  async getServerTimeSeriesAnalysis(
    serverId: string,
    timeRange: { start: Date; end: Date }
  ): Promise<AggregatedStats> {
    const query: TimeSeriesQuery = {
      serverId,
      startTime: timeRange.start,
      endTime: timeRange.end,
    };

    const records = await this.queryTimeSeriesData(query);
    return this.calculateAggregatedStats(records, serverId, timeRange);
  }

  /**
   * ğŸŸ¢ GREEN: TTL ê¸°ë°˜ ìë™ ì •ë¦¬
   */
  async cleanupExpiredData(): Promise<number> {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - this.TTL_DAYS);

    const { data, error } = await this.supabase
      .from(this.TABLE_NAME)
      .delete()
      .lte('created_at', cutoffDate.toISOString());

    if (error) {
      throw new Error(`ë§Œë£Œ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: ${error.message}`);
    }

    return Array.isArray(data) ? data.length : 0;
  }

  /**
   * ğŸŸ¢ GREEN: ì§‘ê³„ í†µê³„ ê³„ì‚°
   */
  async calculateSessionAggregates(
    sessionId: string
  ): Promise<AggregatedStats> {
    const records = await this.queryTimeSeriesData({ sessionId });

    if (records.length === 0) {
      throw new Error(`ì„¸ì…˜ ${sessionId}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.`);
    }

    const timeRange = {
      start: new Date(
        Math.min(...records.map((r) => new Date(r.timestamp).getTime()))
      ),
      end: new Date(
        Math.max(...records.map((r) => new Date(r.timestamp).getTime()))
      ),
    };

    return this.calculateAggregatedStats(
      records,
      undefined,
      timeRange,
      sessionId
    );
  }

  /**
   * ğŸ—ƒï¸ ì˜¤ë˜ëœ ë°ì´í„° ì•„ì¹´ì´ë¸Œ (30ì¼ ì´ìƒ)
   * ğŸš¨ ë² ë¥´ì…€ í™˜ê²½ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ ë¬´ë ¥í™” - ë¬´ë£Œí‹°ì–´ ìµœì í™”
   */
  async archiveOldData(daysOld: number = 30): Promise<string> {
    const cutoffDate = new Date(Date.now() - daysOld * 24 * 60 * 60 * 1000);

    const { data: oldData, error } = await this.supabase
      .from(this.TABLE_NAME)
      .select('*')
      .lte('created_at', cutoffDate.toISOString());

    if (error) {
      throw new Error(`ì•„ì¹´ì´ë¸Œ ëŒ€ìƒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: ${error.message}`);
    }

    if (!oldData || !Array.isArray(oldData) || oldData.length === 0) {
      return 'ì•„ì¹´ì´ë¸Œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.';
    }

    // ğŸš¨ ë² ë¥´ì…€ í™˜ê²½ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ ê±´ë„ˆë›°ê¸°
    if (process.env.VERCEL || process.env.NODE_ENV === 'production') {
      // ë² ë¥´ì…€ í™˜ê²½ì—ì„œëŠ” ë°ì´í„° ì‚­ì œë§Œ ìˆ˜í–‰ (ì—…ë¡œë“œ ì—†ì´)
      console.log(
        `âš ï¸ [SupabaseTimeSeriesManager] ë² ë¥´ì…€ í™˜ê²½ì—ì„œ íŒŒì¼ ì—…ë¡œë“œ ë¬´ë ¥í™” - ë°ì´í„° ì‚­ì œë§Œ ìˆ˜í–‰`
      );

      await this.supabase
        .from(this.TABLE_NAME)
        .delete()
        .lte('created_at', cutoffDate.toISOString());

      return `${oldData.length}ê°œ ë ˆì½”ë“œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤ (ë² ë¥´ì…€ í™˜ê²½ì—ì„œ ì•„ì¹´ì´ë¸Œ ì—…ë¡œë“œ ê±´ë„ˆë›°ê¸°).`;
    }

    // ê°œë°œ í™˜ê²½ì—ì„œë§Œ ì‹¤ì œ íŒŒì¼ ì—…ë¡œë“œ ìˆ˜í–‰
    const archiveFileName = `archive_${cutoffDate.getFullYear()}_${cutoffDate.getMonth() + 1}_${cutoffDate.getDate()}.json`;
    const archiveData = {
      archivedAt: new Date().toISOString(),
      cutoffDate: cutoffDate.toISOString(),
      recordCount: oldData.length,
      data: oldData,
    };

    const compressedData = JSON.stringify(archiveData);

    await this.supabase.storage
      .from('metrics-archive')
      .upload(
        archiveFileName,
        new Blob([compressedData], { type: 'application/json' })
      );

    // ì›ë³¸ ë°ì´í„° ì‚­ì œ
    await this.supabase
      .from(this.TABLE_NAME)
      .delete()
      .lte('created_at', cutoffDate.toISOString());

    return `${archiveData.recordCount}ê°œ ë ˆì½”ë“œê°€ ${archiveFileName}ë¡œ ì•„ì¹´ì´ë¸Œë˜ì—ˆìŠµë‹ˆë‹¤.`;
  }

  /**
   * ğŸ”„ REFACTOR: ì‹¤ì‹œê°„ ì•Œë¦¼ íŠ¸ë¦¬ê±°
   */
  async checkAlertThresholds(
    sessionId: string,
    thresholds: AlertThreshold[]
  ): Promise<
    { metric: string; value: number; threshold: number; serverId: string }[]
  > {
    const recentData = await this.queryTimeSeriesData({
      sessionId,
      startTime: new Date(Date.now() - 5 * 60 * 1000), // ìµœê·¼ 5ë¶„
      orderBy: 'timestamp',
      ascending: false,
    });

    const alerts: {
      metric: string;
      value: number;
      threshold: number;
      serverId: string;
    }[] = [];

    for (const threshold of thresholds) {
      for (const record of recentData) {
        const value = this.getMetricValue(record, threshold.metric);

        if (
          this.evaluateThreshold(value, threshold.operator, threshold.value)
        ) {
          alerts.push({
            metric: threshold.metric,
            value,
            threshold: threshold.value,
            serverId: record.server_id,
          });
        }
      }
    }

    return alerts;
  }

  /**
   * ğŸ”„ REFACTOR: ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
   */
  async validateDataIntegrity(sessionId: string): Promise<{
    isValid: boolean;
    issues: string[];
    totalRecords: number;
    validRecords: number;
  }> {
    const records = await this.queryTimeSeriesData({ sessionId });
    const issues: string[] = [];
    let validRecords = 0;

    for (const record of records) {
      let isRecordValid = true;

      // í•„ìˆ˜ í•„ë“œ ê²€ì¦
      if (!record.server_id || !record.timestamp) {
        issues.push(
          `ë ˆì½”ë“œ ${record.server_id || 'unknown'}ì— í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë¨`
        );
        isRecordValid = false;
      }

      // ë©”íŠ¸ë¦­ ë²”ìœ„ ê²€ì¦
      if (record.cpu_usage < 0 || record.cpu_usage > 100) {
        issues.push(
          `ì„œë²„ ${record.server_id}ì˜ CPU ì‚¬ìš©ë¥ ì´ ìœ íš¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨: ${record.cpu_usage}`
        );
        isRecordValid = false;
      }

      if (record.memory_usage < 0 || record.memory_usage > 100) {
        issues.push(
          `ì„œë²„ ${record.server_id}ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ìœ íš¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨: ${record.memory_usage}`
        );
        isRecordValid = false;
      }

      if (record.error_rate < 0 || record.error_rate > 100) {
        issues.push(
          `ì„œë²„ ${record.server_id}ì˜ ì—ëŸ¬ìœ¨ì´ ìœ íš¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨: ${record.error_rate}`
        );
        isRecordValid = false;
      }

      if (isRecordValid) {
        validRecords++;
      }
    }

    return {
      isValid: issues.length === 0,
      issues,
      totalRecords: records.length,
      validRecords,
    };
  }

  /**
   * Private: ServerMetricì„ TimeSeriesRecordë¡œ ë³€í™˜
   */
  private transformToTimeSeriesRecords(
    sessionId: string,
    metrics: ServerMetric[]
  ): TimeSeriesRecord[] {
    return metrics.map((metric) => {
      // ë ˆê±°ì‹œ í˜•ì‹ê³¼ ìƒˆ í˜•ì‹ ëª¨ë‘ ì§€ì›
      const cpu = metric.cpu ?? metric.systemMetrics?.cpuUsage ?? 0;
      const memory = metric.memory ?? metric.systemMetrics?.memoryUsage ?? 0;
      const disk = metric.disk ?? metric.systemMetrics?.diskUsage ?? 0;
      const networkUsage = metric.network
        ? (metric.network.in + metric.network.out) / 2
        : (metric.systemMetrics?.networkUsage ?? 0);
      const requestCount =
        metric.activeConnections ??
        metric.applicationMetrics?.requestCount ??
        0;
      const errorRate = metric.applicationMetrics?.errorRate ?? 0;
      const responseTime =
        metric.responseTime ?? metric.applicationMetrics?.responseTime ?? 0;

      return {
        session_id: sessionId,
        server_id: metric.serverId,
        timestamp: metric.timestamp.toISOString(),
        cpu_usage: cpu,
        memory_usage: memory,
        disk_usage: disk,
        network_usage: networkUsage,
        request_count: requestCount,
        error_rate: errorRate,
        response_time: responseTime,
        created_at: new Date().toISOString(),
      };
    });
  }

  /**
   * Private: TimeSeriesRecordë¥¼ ServerMetricìœ¼ë¡œ ë³€í™˜
   */
  private transformFromTimeSeriesRecords(
    records: TimeSeriesRecord[]
  ): ServerMetric[] {
    return records.map((record) => ({
      timestamp: new Date(record.timestamp),
      serverId: record.server_id,
      cpu: record.cpu_usage,
      memory: record.memory_usage,
      disk: record.disk_usage,
      network: {
        in: record.network_usage / 2,
        out: record.network_usage / 2,
      },
      status: 'healthy' as const,
      responseTime: record.response_time,
      activeConnections: record.request_count,
      // ì„ íƒì  í•„ë“œë“¤
      systemMetrics: {
        cpuUsage: record.cpu_usage,
        memoryUsage: record.memory_usage,
        diskUsage: record.disk_usage,
        networkUsage: record.network_usage,
      },
      applicationMetrics: {
        requestCount: record.request_count,
        errorRate: record.error_rate,
        responseTime: record.response_time,
      },
    }));
  }

  /**
   * Private: ì§‘ê³„ í†µê³„ ê³„ì‚°
   */
  private calculateAggregatedStats(
    records: TimeSeriesRecord[],
    serverId?: string,
    timeRange?: { start: Date; end: Date },
    sessionId?: string
  ): AggregatedStats {
    if (records.length === 0) {
      throw new Error('ì§‘ê³„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
    }

    const cpuUsages = records.map((r) => r.cpu_usage);
    const memoryUsages = records.map((r) => r.memory_usage);
    const diskUsages = records.map((r) => r.disk_usage);
    const networkUsages = records.map((r) => r.network_usage);
    const requestCounts = records.map((r) => r.request_count);
    const responseTimes = records.map((r) => r.response_time);
    const errorRates = records.map((r) => r.error_rate);

    return {
      sessionId: sessionId || records[0].session_id,
      serverId,
      timeRange: timeRange || {
        start: new Date(
          Math.min(...records.map((r) => new Date(r.timestamp).getTime()))
        ),
        end: new Date(
          Math.max(...records.map((r) => new Date(r.timestamp).getTime()))
        ),
      },
      metrics: {
        avgCpuUsage: cpuUsages.reduce((a, b) => a + b, 0) / cpuUsages.length,
        maxCpuUsage: Math.max(...cpuUsages),
        avgMemoryUsage:
          memoryUsages.reduce((a, b) => a + b, 0) / memoryUsages.length,
        maxMemoryUsage: Math.max(...memoryUsages),
        avgDiskUsage: diskUsages.reduce((a, b) => a + b, 0) / diskUsages.length,
        avgNetworkUsage:
          networkUsages.reduce((a, b) => a + b, 0) / networkUsages.length,
        totalRequests: requestCounts.reduce((a, b) => a + b, 0),
        avgResponseTime:
          responseTimes.reduce((a, b) => a + b, 0) / responseTimes.length,
        maxResponseTime: Math.max(...responseTimes),
        avgErrorRate: errorRates.reduce((a, b) => a + b, 0) / errorRates.length,
        maxErrorRate: Math.max(...errorRates),
      },
      dataPoints: records.length,
    };
  }

  /**
   * Private: ë©”íŠ¸ë¦­ ê°’ ì¶”ì¶œ
   */
  private getMetricValue(record: TimeSeriesRecord, metric: string): number {
    switch (metric) {
      case 'cpu_usage':
        return record.cpu_usage;
      case 'memory_usage':
        return record.memory_usage;
      case 'disk_usage':
        return record.disk_usage;
      case 'error_rate':
        return record.error_rate;
      case 'response_time':
        return record.response_time;
      default:
        return 0;
    }
  }

  /**
   * Private: ì„ê³„ê°’ í‰ê°€
   */
  private evaluateThreshold(
    value: number,
    operator: string,
    threshold: number
  ): boolean {
    switch (operator) {
      case '>':
        return value > threshold;
      case '<':
        return value < threshold;
      case '>=':
        return value >= threshold;
      case '<=':
        return value <= threshold;
      case '=':
        return value === threshold;
      default:
        return false;
    }
  }
}
