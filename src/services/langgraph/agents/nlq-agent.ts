/**
 * NLQ (Natural Language Query) Agent
 * ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒë¡œ ë³€í™˜
 *
 * ì—­í• :
 * - ì„œë²„ ìƒíƒœ ì¡°íšŒ (CPU, Memory, Disk)
 * - ë‹¨ìˆœ ë©”íŠ¸ë¦­ ì§ˆì˜ ì‘ë‹µ
 * - ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ê¸°ë°˜ ì‘ë‹µ
 */

import { AIMessage } from '@langchain/core/messages';
import { tool } from '@langchain/core/tools';
import { ChatGoogleGenerativeAI } from '@langchain/google-genai';
import { z } from 'zod';
import { loadHourlyScenarioData } from '@/services/scenario/scenario-loader';
import type { AgentStateType, ToolResult } from '../state-definition';

// ============================================================================
// 1. Model Configuration
// ============================================================================

import { AI_MODELS } from '@/config/ai-engine';

function getNLQModel(): ChatGoogleGenerativeAI {
  const apiKey = process.env.GOOGLE_API_KEY;
  if (!apiKey) {
    throw new Error('GOOGLE_API_KEY is not configured');
  }

  return new ChatGoogleGenerativeAI({
    apiKey,
    model: AI_MODELS.FLASH,
    temperature: 0.3,
    maxOutputTokens: 1024,
  });
}

// ============================================================================
// 2. Tools Definition
// ============================================================================

const getServerMetricsTool = tool(
  async ({ serverId, metric }) => {
    const allServers = await loadHourlyScenarioData();
    const target = serverId
      ? allServers.find((s) => s.id === serverId)
      : allServers;

    const servers = Array.isArray(target)
      ? target
      : target
        ? [target]
        : allServers;

    return {
      success: true,
      servers: servers.map((s) => ({
        id: s.id,
        name: s.name,
        status: s.status,
        cpu: s.cpu,
        memory: s.memory,
        disk: s.disk,
      })),
      summary: {
        total: servers.length,
        alertCount: servers.filter(
          (s) => s.status === 'warning' || s.status === 'critical'
        ).length,
      },
      timestamp: new Date().toISOString(),
      _dataSource: 'scenario-loader',
    };
  },
  {
    name: 'getServerMetrics',
    description:
      'ì„œë²„ CPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜)',
    schema: z.object({
      serverId: z.string().optional().describe('ì¡°íšŒí•  ì„œë²„ ID (ì„ íƒ)'),
      metric: z
        .enum(['cpu', 'memory', 'disk', 'all'])
        .describe('ì¡°íšŒí•  ë©”íŠ¸ë¦­ íƒ€ì…'),
    }),
  }
);

// ============================================================================
// 3. NLQ Agent Node Function
// ============================================================================

/**
 * NLQ Agent ë…¸ë“œ í•¨ìˆ˜
 */
export async function nlqAgentNode(
  state: AgentStateType
): Promise<Partial<AgentStateType>> {
  const lastMessage = state.messages[state.messages.length - 1];
  const userQuery =
    typeof lastMessage?.content === 'string'
      ? lastMessage.content
      : 'Show server status';

  try {
    const model = getNLQModel();

    // ë„êµ¬ ë°”ì¸ë”©
    const modelWithTools = model.bindTools([getServerMetricsTool]);

    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ í˜¸ì¶œ
    const response = await modelWithTools.invoke([
      {
        role: 'system',
        content: `ë‹¹ì‹ ì€ OpenManager VIBEì˜ NLQ Agentì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ê°€ëŠ¥í•œ ì‘ì—…:
- ì„œë²„ ìƒíƒœ ì¡°íšŒ (CPU, Memory, Disk)
- íŠ¹ì • ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ
- ì „ì²´ ì„œë²„ ìš”ì•½

ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•œ í›„, ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.`,
      },
      { role: 'user', content: userQuery },
    ]);

    // ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
    const toolCalls = response.tool_calls || [];
    const toolResults: ToolResult[] = [];

    for (const toolCall of toolCalls) {
      if (toolCall.name === 'getServerMetrics') {
        const result = await getServerMetricsTool.invoke(
          toolCall.args as {
            serverId?: string;
            metric: 'cpu' | 'memory' | 'disk' | 'all';
          }
        );
        toolResults.push({
          toolName: 'getServerMetrics',
          success: true,
          data: result,
          executedAt: new Date().toISOString(),
        });
      }
    }

    // ê²°ê³¼ ìš”ì•½ ìƒì„±
    let finalContent = '';
    const firstToolResult = toolResults[0];
    if (toolResults.length > 0 && firstToolResult) {
      const metricsResult = firstToolResult.data as {
        servers: Array<{
          id: string;
          name: string;
          status: string;
          cpu: number;
          memory: number;
          disk: number;
        }>;
        summary: { total: number; alertCount: number };
      };

      // ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±
      const summaryResponse = await model.invoke([
        {
          role: 'system',
          content:
            'ì„œë²„ ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. ì¤‘ìš”í•œ ì •ë³´ë§Œ ê°„ê²°í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”.',
        },
        {
          role: 'user',
          content: `ë‹¤ìŒ ì„œë²„ ë°ì´í„°ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”: ${JSON.stringify(metricsResult)}`,
        },
      ]);

      finalContent =
        typeof summaryResponse.content === 'string'
          ? summaryResponse.content
          : JSON.stringify(metricsResult);
    } else {
      finalContent =
        typeof response.content === 'string'
          ? response.content
          : 'ì„œë²„ ìƒíƒœë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
    }

    console.log(
      `ğŸ” [NLQ Agent] Processed query with ${toolResults.length} tool calls`
    );

    return {
      messages: [new AIMessage(finalContent)],
      toolResults,
      finalResponse: finalContent,
    };
  } catch (error) {
    console.error('âŒ NLQ Agent Error:', error);
    return {
      finalResponse: 'ì„œë²„ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      toolResults: [
        {
          toolName: 'nlq_error',
          success: false,
          data: null,
          error: String(error),
          executedAt: new Date().toISOString(),
        },
      ],
    };
  }
}
