/**
 * LangGraph Multi-Agent Graph Builder
 * Supervisor-Worker íŒ¨í„´ì˜ StateGraph ì¡°ë¦½
 */
import { END, START, StateGraph } from '@langchain/langgraph';
import { analystAgentNode } from './agents/analyst-agent';
import { nlqAgentNode } from './agents/nlq-agent';
import { reporterAgentNode } from './agents/reporter-agent';
import { routeFromSupervisor, supervisorNode } from './agents/supervisor';
import { createSessionConfig, getAutoCheckpointer } from './checkpointer';
import {
  AgentState,
  type AgentStateType,
  ANALYST_NODE,
  NLQ_NODE,
  REPORTER_NODE,
  SUPERVISOR_NODE,
} from './state-definition';

// ============================================================================
// 1. Graph Building
// ============================================================================

/**
 * ë©€í‹°ì—ì´ì „íŠ¸ StateGraph ìƒì„±
 *
 * Flow:
 * START â†’ supervisor â†’ [nlq_agent | analyst_agent | reporter_agent | END]
 *                   â†“
 *                 END
 */
export async function createMultiAgentGraph() {
  const checkpointer = await getAutoCheckpointer();

  // StateGraph ìƒì„±
  const graph = new StateGraph(AgentState)
    // ë…¸ë“œ ë“±ë¡
    .addNode(SUPERVISOR_NODE, supervisorNode)
    .addNode(NLQ_NODE, nlqAgentNode)
    .addNode(ANALYST_NODE, analystAgentNode)
    .addNode(REPORTER_NODE, reporterAgentNode)

    // ì—£ì§€ ì„¤ì •
    .addEdge(START, SUPERVISOR_NODE)
    .addConditionalEdges(SUPERVISOR_NODE, routeFromSupervisor, {
      nlq_agent: NLQ_NODE,
      analyst_agent: ANALYST_NODE,
      reporter_agent: REPORTER_NODE,
      __end__: END,
    })

    // Worker â†’ END
    .addEdge(NLQ_NODE, END)
    .addEdge(ANALYST_NODE, END)
    .addEdge(REPORTER_NODE, END);

  // ì»´íŒŒì¼
  return graph.compile({ checkpointer });
}

// ============================================================================
// 2. Graph Execution
// ============================================================================

export interface GraphExecutionOptions {
  sessionId?: string;
  stream?: boolean;
}

/**
 * ê·¸ë˜í”„ ì‹¤í–‰ (ë‹¨ì¼ ì‘ë‹µ)
 */
export async function executeGraph(
  query: string,
  options: GraphExecutionOptions = {}
): Promise<{
  response: string;
  toolResults: AgentStateType['toolResults'];
  targetAgent: AgentStateType['targetAgent'];
  sessionId: string;
}> {
  const graph = await createMultiAgentGraph();
  const sessionId = options.sessionId || `session_${Date.now()}`;
  const config = createSessionConfig(sessionId);

  const { HumanMessage } = await import('@langchain/core/messages');

  const result = await graph.invoke(
    {
      messages: [new HumanMessage(query)],
      sessionId,
    },
    config
  );

  return {
    response: result.finalResponse || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
    toolResults: result.toolResults || [],
    targetAgent: result.targetAgent,
    sessionId,
  };
}

/**
 * ê·¸ë˜í”„ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
 */
export async function* streamGraph(
  query: string,
  options: GraphExecutionOptions = {}
): AsyncGenerator<{
  type: 'token' | 'tool_result' | 'final';
  content: string;
  metadata?: Record<string, unknown>;
}> {
  const graph = await createMultiAgentGraph();
  const sessionId = options.sessionId || `session_${Date.now()}`;
  const config = createSessionConfig(sessionId);

  const { HumanMessage } = await import('@langchain/core/messages');

  const stream = await graph.streamEvents(
    {
      messages: [new HumanMessage(query)],
      sessionId,
    },
    {
      version: 'v2',
      ...config,
    }
  );

  for await (const event of stream) {
    // LLM í† í° ìŠ¤íŠ¸ë¦¬ë°
    if (event.event === 'on_chat_model_stream') {
      const chunk = event.data?.chunk;
      if (chunk?.content) {
        yield {
          type: 'token',
          content: typeof chunk.content === 'string' ? chunk.content : '',
          metadata: { node: event.name },
        };
      }
    }

    // ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
    if (event.event === 'on_tool_end') {
      yield {
        type: 'tool_result',
        content: JSON.stringify(event.data?.output),
        metadata: { toolName: event.name },
      };
    }

    // ê·¸ë˜í”„ ì¢…ë£Œ
    if (event.event === 'on_chain_end' && event.name === 'LangGraph') {
      const output = event.data?.output;
      if (output?.finalResponse) {
        yield {
          type: 'final',
          content: output.finalResponse,
          metadata: {
            targetAgent: output.targetAgent,
            toolResults: output.toolResults,
          },
        };
      }
    }
  }
}

// ============================================================================
// 3. Express/Next.js Streaming Adapter
// ============================================================================

/**
 * Next.js API Routeìš© ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
 */
export async function createStreamingResponse(
  query: string,
  sessionId?: string
): Promise<ReadableStream<Uint8Array>> {
  const encoder = new TextEncoder();

  return new ReadableStream({
    async start(controller) {
      try {
        const generator = streamGraph(query, { sessionId });

        for await (const chunk of generator) {
          if (chunk.type === 'token') {
            controller.enqueue(encoder.encode(chunk.content));
          } else if (chunk.type === 'final') {
            // ìµœì¢… ì‘ë‹µì€ ì´ë¯¸ í† í°ìœ¼ë¡œ ì „ì†¡ë¨
            console.log('ğŸ“¤ Stream completed');
          }
        }

        controller.close();
      } catch (error) {
        console.error('âŒ Streaming error:', error);
        controller.error(error);
      }
    },
  });
}
