/**
 * ğŸ“Š Prometheus ë©”íŠ¸ë¦­ í¬ë§·í„°
 * 
 * ê¸°ì¡´ ì„œë²„ ë©”íŠ¸ë¦­ì„ Prometheus í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
 * - í‘œì¤€ ë©”íŠ¸ë¦­ ë„¤ì´ë° ì»¨ë²¤ì…˜
 * - ë¼ë²¨ ê¸°ë°˜ ë©”íŠ¸ë¦­ êµ¬ì¡°
 * - Counter, Gauge, Histogram ì§€ì›
 * - ì‹¤ì œ /metrics ì—”ë“œí¬ì¸íŠ¸ í˜¸í™˜
 */

export interface PrometheusMetric {
  name: string;
  type: 'counter' | 'gauge' | 'histogram' | 'summary';
  help: string;
  labels: Record<string, string>;
  value: number;
  timestamp?: number;
}

export interface PrometheusHistogramBucket {
  le: string;
  value: number;
}

export interface PrometheusHistogramMetric extends Omit<PrometheusMetric, 'value'> {
  type: 'histogram';
  buckets: PrometheusHistogramBucket[];
  count: number;
  sum: number;
}

export interface ServerMetricsForPrometheus {
  id: string;
  hostname: string;
  environment: string;
  role: string;
  status: string;
  cpu_usage: number;
  memory_usage: number;
  disk_usage: number;
  network_in: number;
  network_out: number;
  response_time: number;
  uptime: number;
  pattern_info?: any;
  correlation_metrics?: any;
}

export class PrometheusMetricsFormatter {
  private static instance: PrometheusMetricsFormatter;

  static getInstance(): PrometheusMetricsFormatter {
    if (!PrometheusMetricsFormatter.instance) {
      PrometheusMetricsFormatter.instance = new PrometheusMetricsFormatter();
    }
    return PrometheusMetricsFormatter.instance;
  }

  /**
   * ğŸ”„ ì„œë²„ ë©”íŠ¸ë¦­ì„ Prometheus í˜•ì‹ìœ¼ë¡œ ë³€í™˜
   */
  formatServerMetrics(server: ServerMetricsForPrometheus): PrometheusMetric[] {
    const timestamp = Date.now();
    const baseLabels = {
      server_id: server.id,
      hostname: server.hostname,
      environment: server.environment,
      role: server.role,
      status: server.status
    };

    const metrics: PrometheusMetric[] = [];

    // ğŸ–¥ï¸ CPU ë©”íŠ¸ë¦­ (í‘œì¤€ Prometheus í˜•ì‹)
    metrics.push({
      name: 'node_cpu_usage_percent',
      type: 'gauge',
      help: 'Current CPU usage percentage',
      labels: { ...baseLabels, mode: 'total' },
      value: server.cpu_usage,
      timestamp
    });

    // CPU ì‹œê°„ ëˆ„ì  (ì‹¤ì œ Prometheus node_exporter ìŠ¤íƒ€ì¼)
    const cpuSeconds = (server.uptime * 3600 * server.cpu_usage) / 100;
    metrics.push({
      name: 'node_cpu_seconds_total',
      type: 'counter',
      help: 'Seconds the CPUs spent in each mode',
      labels: { ...baseLabels, cpu: '0', mode: 'user' },
      value: cpuSeconds * 0.6, // 60% user mode
      timestamp
    });

    metrics.push({
      name: 'node_cpu_seconds_total',
      type: 'counter',
      help: 'Seconds the CPUs spent in each mode',
      labels: { ...baseLabels, cpu: '0', mode: 'system' },
      value: cpuSeconds * 0.3, // 30% system mode
      timestamp
    });

    metrics.push({
      name: 'node_cpu_seconds_total',
      type: 'counter',
      help: 'Seconds the CPUs spent in each mode',
      labels: { ...baseLabels, cpu: '0', mode: 'idle' },
      value: (server.uptime * 3600) - cpuSeconds, // ë‚˜ë¨¸ì§€ëŠ” idle
      timestamp
    });

    // ğŸ’¾ ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­
    const totalMemory = 8 * 1024 * 1024 * 1024; // 8GB ê°€ì •
    const usedMemory = (totalMemory * server.memory_usage) / 100;

    metrics.push({
      name: 'node_memory_MemTotal_bytes',
      type: 'gauge',
      help: 'Memory information field MemTotal_bytes',
      labels: baseLabels,
      value: totalMemory,
      timestamp
    });

    metrics.push({
      name: 'node_memory_MemAvailable_bytes',
      type: 'gauge',
      help: 'Memory information field MemAvailable_bytes',
      labels: baseLabels,
      value: totalMemory - usedMemory,
      timestamp
    });

    metrics.push({
      name: 'node_memory_MemUsed_bytes',
      type: 'gauge',
      help: 'Memory information field MemUsed_bytes',
      labels: baseLabels,
      value: usedMemory,
      timestamp
    });

    metrics.push({
      name: 'node_memory_usage_percent',
      type: 'gauge',
      help: 'Memory usage percentage',
      labels: baseLabels,
      value: server.memory_usage,
      timestamp
    });

    // ğŸ’¿ ë””ìŠ¤í¬ ë©”íŠ¸ë¦­
    const totalDisk = 500 * 1024 * 1024 * 1024; // 500GB ê°€ì •
    const usedDisk = (totalDisk * server.disk_usage) / 100;

    metrics.push({
      name: 'node_filesystem_size_bytes',
      type: 'gauge',
      help: 'Filesystem size in bytes',
      labels: { ...baseLabels, device: '/dev/sda1', fstype: 'ext4', mountpoint: '/' },
      value: totalDisk,
      timestamp
    });

    metrics.push({
      name: 'node_filesystem_avail_bytes',
      type: 'gauge',
      help: 'Filesystem space available to non-root users in bytes',
      labels: { ...baseLabels, device: '/dev/sda1', fstype: 'ext4', mountpoint: '/' },
      value: totalDisk - usedDisk,
      timestamp
    });

    metrics.push({
      name: 'node_filesystem_free_bytes',
      type: 'gauge',
      help: 'Filesystem free space in bytes',
      labels: { ...baseLabels, device: '/dev/sda1', fstype: 'ext4', mountpoint: '/' },
      value: totalDisk - usedDisk,
      timestamp
    });

    metrics.push({
      name: 'node_disk_usage_percent',
      type: 'gauge',
      help: 'Disk usage percentage',
      labels: { ...baseLabels, device: '/dev/sda1' },
      value: server.disk_usage,
      timestamp
    });

    // ğŸŒ ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­
    const networkBytesIn = server.network_in * 1024 * 1024; // MBë¥¼ bytesë¡œ
    const networkBytesOut = server.network_out * 1024 * 1024;

    metrics.push({
      name: 'node_network_receive_bytes_total',
      type: 'counter',
      help: 'Network device statistic receive_bytes',
      labels: { ...baseLabels, device: 'eth0' },
      value: networkBytesIn * server.uptime, // ëˆ„ì ê°’ìœ¼ë¡œ ë³€í™˜
      timestamp
    });

    metrics.push({
      name: 'node_network_transmit_bytes_total',
      type: 'counter',
      help: 'Network device statistic transmit_bytes',
      labels: { ...baseLabels, device: 'eth0' },
      value: networkBytesOut * server.uptime,
      timestamp
    });

    metrics.push({
      name: 'node_network_receive_rate_mbps',
      type: 'gauge',
      help: 'Current network receive rate in Mbps',
      labels: { ...baseLabels, device: 'eth0' },
      value: server.network_in,
      timestamp
    });

    metrics.push({
      name: 'node_network_transmit_rate_mbps',
      type: 'gauge',
      help: 'Current network transmit rate in Mbps',
      labels: { ...baseLabels, device: 'eth0' },
      value: server.network_out,
      timestamp
    });

    // âš¡ ì‘ë‹µ ì‹œê°„ ë©”íŠ¸ë¦­ (Histogramìœ¼ë¡œ êµ¬ì„±)
    metrics.push({
      name: 'http_request_duration_seconds',
      type: 'gauge',
      help: 'HTTP request latency in seconds',
      labels: { ...baseLabels, method: 'GET', handler: 'api' },
      value: server.response_time / 1000, // msë¥¼ ì´ˆë¡œ ë³€í™˜
      timestamp
    });

    // ğŸ”„ ì—…íƒ€ì„ ë©”íŠ¸ë¦­
    metrics.push({
      name: 'node_boot_time_seconds',
      type: 'gauge',
      help: 'Node boot time, in unixtime',
      labels: baseLabels,
      value: timestamp/1000 - (server.uptime * 3600), // í˜„ì¬ì‹œê°„ - ì—…íƒ€ì„
      timestamp
    });

    metrics.push({
      name: 'node_uptime_seconds',
      type: 'gauge',
      help: 'System uptime in seconds',
      labels: baseLabels,
      value: server.uptime * 3600, // ì‹œê°„ì„ ì´ˆë¡œ ë³€í™˜
      timestamp
    });

    // ğŸ¤– AI íŒ¨í„´ ë©”íŠ¸ë¦­ (ì»¤ìŠ¤í…€)
    if (server.pattern_info) {
      metrics.push({
        name: 'openmanager_server_load_level',
        type: 'gauge',
        help: 'Current server load level (0=low, 1=medium, 2=high)',
        labels: { ...baseLabels, load_type: server.pattern_info.current_load },
        value: server.pattern_info.current_load === 'low' ? 0 : 
               server.pattern_info.current_load === 'medium' ? 1 : 2,
        timestamp
      });

      metrics.push({
        name: 'openmanager_time_multiplier',
        type: 'gauge',
        help: 'Time-based load multiplier from AI pattern engine',
        labels: baseLabels,
        value: server.pattern_info.time_multiplier || 1.0,
        timestamp
      });

      metrics.push({
        name: 'openmanager_seasonal_multiplier',
        type: 'gauge',
        help: 'Seasonal load multiplier from AI pattern engine',
        labels: baseLabels,
        value: server.pattern_info.seasonal_multiplier || 1.0,
        timestamp
      });

      metrics.push({
        name: 'openmanager_burst_active',
        type: 'gauge',
        help: 'Whether server is experiencing burst activity (0=no, 1=yes)',
        labels: baseLabels,
        value: server.pattern_info.burst_active ? 1 : 0,
        timestamp
      });
    }

    // ğŸ“Š ìƒê´€ê´€ê³„ ë©”íŠ¸ë¦­
    if (server.correlation_metrics) {
      metrics.push({
        name: 'openmanager_cpu_memory_correlation',
        type: 'gauge',
        help: 'CPU-Memory correlation coefficient (-1 to 1)',
        labels: baseLabels,
        value: server.correlation_metrics.cpu_memory_correlation || 0,
        timestamp
      });

      metrics.push({
        name: 'openmanager_stability_score',
        type: 'gauge',
        help: 'Server stability score (0 to 1)',
        labels: baseLabels,
        value: server.correlation_metrics.stability_score || 0,
        timestamp
      });
    }

    return metrics;
  }

  /**
   * ğŸ“ Prometheus í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
   */
  formatToPrometheusText(metrics: PrometheusMetric[]): string {
    const metricGroups: Record<string, PrometheusMetric[]> = {};
    
    // ë©”íŠ¸ë¦­ ì´ë¦„ë³„ë¡œ ê·¸ë£¹í™”
    metrics.forEach(metric => {
      if (!metricGroups[metric.name]) {
        metricGroups[metric.name] = [];
      }
      metricGroups[metric.name].push(metric);
    });

    let output = '';
    
    Object.entries(metricGroups).forEach(([metricName, metricList]) => {
      // HELP ë° TYPE ì •ë³´ (í•œ ë²ˆë§Œ)
      const firstMetric = metricList[0];
      output += `# HELP ${metricName} ${firstMetric.help}\n`;
      output += `# TYPE ${metricName} ${firstMetric.type}\n`;
      
      // ê° ë©”íŠ¸ë¦­ ê°’ë“¤
      metricList.forEach(metric => {
        const labelString = Object.entries(metric.labels)
          .map(([key, value]) => `${key}="${value}"`)
          .join(',');
        
        const timestamp = metric.timestamp ? ` ${metric.timestamp}` : '';
        output += `${metricName}{${labelString}} ${metric.value}${timestamp}\n`;
      });
      
      output += '\n'; // ë©”íŠ¸ë¦­ ê·¸ë£¹ ê°„ êµ¬ë¶„
    });

    return output;
  }

  /**
   * ğŸ“Š ì‘ë‹µ ì‹œê°„ íˆìŠ¤í† ê·¸ë¨ ìƒì„±
   */
  createResponseTimeHistogram(
    server: ServerMetricsForPrometheus,
    responseTime: number
  ): PrometheusHistogramMetric {
    const buckets = [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]; // seconds
    const responseTimeSeconds = responseTime / 1000;
    
    const histogramBuckets: PrometheusHistogramBucket[] = buckets.map(le => ({
      le: le.toString(),
      value: responseTimeSeconds <= le ? 1 : 0
    }));

    // +Inf ë²„í‚· ì¶”ê°€
    histogramBuckets.push({
      le: '+Inf',
      value: 1
    });

    return {
      name: 'http_request_duration_seconds',
      type: 'histogram',
      help: 'HTTP request latency histogram',
      labels: {
        server_id: server.id,
        hostname: server.hostname,
        environment: server.environment,
        role: server.role,
        method: 'GET',
        handler: 'api'
      },
      buckets: histogramBuckets,
      count: 1,
      sum: responseTimeSeconds,
      timestamp: Date.now()
    };
  }

  /**
   * ğŸ” ë©”íŠ¸ë¦­ í•„í„°ë§ (ë¼ë²¨ ê¸°ë°˜)
   */
  filterMetrics(
    metrics: PrometheusMetric[],
    filters: Record<string, string>
  ): PrometheusMetric[] {
    return metrics.filter(metric => {
      return Object.entries(filters).every(([key, value]) => 
        metric.labels[key] === value
      );
    });
  }

  /**
   * ğŸ“ˆ ë©”íŠ¸ë¦­ ì§‘ê³„ (ë™ì¼í•œ ì´ë¦„ì˜ ë©”íŠ¸ë¦­ë“¤)
   */
  aggregateMetrics(
    metrics: PrometheusMetric[],
    operation: 'sum' | 'avg' | 'max' | 'min' = 'sum'
  ): Record<string, number> {
    const aggregated: Record<string, number[]> = {};
    
    metrics.forEach(metric => {
      if (!aggregated[metric.name]) {
        aggregated[metric.name] = [];
      }
      aggregated[metric.name].push(metric.value);
    });

    const result: Record<string, number> = {};
    
    Object.entries(aggregated).forEach(([name, values]) => {
      switch (operation) {
        case 'sum':
          result[name] = values.reduce((sum, val) => sum + val, 0);
          break;
        case 'avg':
          result[name] = values.reduce((sum, val) => sum + val, 0) / values.length;
          break;
        case 'max':
          result[name] = Math.max(...values);
          break;
        case 'min':
          result[name] = Math.min(...values);
          break;
      }
    });

    return result;
  }

  /**
   * ğŸ·ï¸ ë¼ë²¨ ì •ê·œí™”
   */
  normalizeLabels(labels: Record<string, any>): Record<string, string> {
    const normalized: Record<string, string> = {};
    
    Object.entries(labels).forEach(([key, value]) => {
      // Prometheus ë¼ë²¨ ê·œì¹™ì— ë§ê²Œ ì •ê·œí™”
      const normalizedKey = key.replace(/[^a-zA-Z0-9_]/g, '_');
      const normalizedValue = String(value).replace(/["\n\r\\]/g, '');
      normalized[normalizedKey] = normalizedValue;
    });

    return normalized;
  }

  /**
   * ğŸ“Š ì‹œìŠ¤í…œ ì „ì²´ ìš”ì•½ ë©”íŠ¸ë¦­
   */
  generateSystemSummaryMetrics(servers: ServerMetricsForPrometheus[]): PrometheusMetric[] {
    const timestamp = Date.now();
    const metrics: PrometheusMetric[] = [];

    // ì „ì²´ ì„œë²„ ìˆ˜
    metrics.push({
      name: 'openmanager_total_servers',
      type: 'gauge',
      help: 'Total number of monitored servers',
      labels: {},
      value: servers.length,
      timestamp
    });

    // í™˜ê²½ë³„ ì„œë²„ ìˆ˜
    const envCounts: Record<string, number> = {};
    servers.forEach(server => {
      envCounts[server.environment] = (envCounts[server.environment] || 0) + 1;
    });

    Object.entries(envCounts).forEach(([env, count]) => {
      metrics.push({
        name: 'openmanager_servers_by_environment',
        type: 'gauge',
        help: 'Number of servers by environment',
        labels: { environment: env },
        value: count,
        timestamp
      });
    });

    // í‰ê·  ë©”íŠ¸ë¦­
    const avgCpu = servers.reduce((sum, s) => sum + s.cpu_usage, 0) / servers.length;
    const avgMemory = servers.reduce((sum, s) => sum + s.memory_usage, 0) / servers.length;
    const avgDisk = servers.reduce((sum, s) => sum + s.disk_usage, 0) / servers.length;

    metrics.push(
      {
        name: 'openmanager_avg_cpu_usage_percent',
        type: 'gauge',
        help: 'Average CPU usage across all servers',
        labels: {},
        value: Math.round(avgCpu * 100) / 100,
        timestamp
      },
      {
        name: 'openmanager_avg_memory_usage_percent',
        type: 'gauge',
        help: 'Average memory usage across all servers',
        labels: {},
        value: Math.round(avgMemory * 100) / 100,
        timestamp
      },
      {
        name: 'openmanager_avg_disk_usage_percent',
        type: 'gauge',
        help: 'Average disk usage across all servers',
        labels: {},
        value: Math.round(avgDisk * 100) / 100,
        timestamp
      }
    );

    return metrics;
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const prometheusFormatter = PrometheusMetricsFormatter.getInstance(); 