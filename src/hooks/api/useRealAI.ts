/**
 * ğŸ§  ì‹¤ì œ AI ì„œë¹„ìŠ¤ React í›…
 * 
 * ê¸°ëŠ¥:
 * - í†µí•© AI ë¶„ì„ ìš”ì²­
 * - ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ë¶„ì„
 * - ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§
 * - ìºì‹± ë° ì˜¤ë¥˜ ì²˜ë¦¬
 */

import { useState, useCallback, useRef } from 'react';

interface UseRealAIOptions {
  enablePython?: boolean;
  enableMCP?: boolean;
  aiModel?: 'gpt-3.5-turbo' | 'claude-3-haiku' | 'gemini-1.5-flash' | 'local-analyzer';
  realTime?: boolean;
  autoRefresh?: boolean;
  refreshInterval?: number;
}

interface AIAnalysisRequest {
  query: string;
  type?: 'analysis' | 'monitoring' | 'prediction' | 'optimization' | 'troubleshooting';
  includeMetrics?: boolean;
  includeLogs?: boolean;
}

interface AIAnalysisResponse {
  success: boolean;
  timestamp: string;
  query: string;
  type: string;
  analysis: {
    intent: string;
    confidence: number;
    summary: string;
    details: string[];
    urgency: string;
  };
  data: {
    metrics?: any;
    logs?: any[];
    systemStatus?: any;
    predictions?: any;
    recommendations?: string[];
  };
  sources: {
    ai: boolean;
    prometheus: boolean;
    python: boolean;
    mcp: boolean;
    redis: boolean;
  };
  performance: {
    totalTime: number;
    aiTime: number;
    dataCollectionTime: number;
    cacheHits: number;
    fallbacks: number;
  };
  metadata: {
    version: string;
    sessionId: string;
    cached: boolean;
    model: string;
    confidence: number;
  };
  error?: string;
}

interface SystemHealth {
  ai: { status: string };
  prometheus: { status: string };
  python: { status: string };
  mcp: { status: string };
  redis: { status: string };
  overall: 'healthy' | 'degraded' | 'critical';
}

// í† ìŠ¤íŠ¸ ëŒ€ì²´ í•¨ìˆ˜
const showToast = {
  success: (message: string) => console.log(`âœ… ${message}`),
  warning: (message: string) => console.warn(`âš ï¸ ${message}`),
  error: (message: string) => console.error(`âŒ ${message}`),
  info: (message: string) => console.info(`â„¹ï¸ ${message}`)
};

export function useRealAI(options: UseRealAIOptions = {}) {
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [lastResponse, setLastResponse] = useState<AIAnalysisResponse | null>(null);
  const [systemHealth, setSystemHealth] = useState<SystemHealth | null>(null);
  const [isHealthChecking, setIsHealthChecking] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const abortControllerRef = useRef<AbortController | null>(null);

  /**
   * ğŸ§  í†µí•© AI ë¶„ì„ ì‹¤í–‰
   */
  const analyze = useCallback(async (request: AIAnalysisRequest): Promise<AIAnalysisResponse | null> => {
    if (isAnalyzing) {
      showToast.warning('ì´ë¯¸ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤');
      return null;
    }

    setIsAnalyzing(true);
    setError(null);

    // ì´ì „ ìš”ì²­ ì·¨ì†Œ
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }

    abortControllerRef.current = new AbortController();

    try {
      const response = await fetch('/api/v1/ai/unified', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          query: request.query,
          type: request.type || 'analysis',
          options: {
            includeMetrics: request.includeMetrics !== false,
            includeLogs: request.includeLogs || false,
            usePython: options.enablePython || false,
            useMCP: options.enableMCP !== false,
            aiModel: options.aiModel || 'local-analyzer',
            realTime: options.realTime !== false
          },
          context: {
            sessionId: `web_${Date.now()}`,
            priority: 'medium'
          }
        }),
        signal: abortControllerRef.current.signal
      });

      if (!response.ok) {
        throw new Error(`ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨: ${response.status}`);
      }

      const result: AIAnalysisResponse = await response.json();
      
      if (result.success) {
        setLastResponse(result);
        showToast.success(`AI ë¶„ì„ ì™„ë£Œ (${result.performance.totalTime}ms)`);
        
        // ê¸´ê¸‰ë„ì— ë”°ë¥¸ ì¶”ê°€ ì•Œë¦¼
        if (result.analysis.urgency === 'critical') {
          showToast.error('âš ï¸ ì¤‘ìš”í•œ ì‹œìŠ¤í…œ ì´ìŠˆê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!');
        } else if (result.analysis.urgency === 'high') {
          showToast.warning('âš ï¸ ì‹œìŠ¤í…œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤');
        }
        
        return result;
      } else {
        throw new Error(result.error || 'ë¶„ì„ ì‹¤íŒ¨');
      }

    } catch (error: any) {
      if (error.name === 'AbortError') {
        showToast.info('ë¶„ì„ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤');
        return null;
      }

      const errorMessage = error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
      setError(errorMessage);
      showToast.error(`AI ë¶„ì„ ì‹¤íŒ¨: ${errorMessage}`);
      
      console.error('AI ë¶„ì„ ì˜¤ë¥˜:', error);
      return null;

    } finally {
      setIsAnalyzing(false);
      abortControllerRef.current = null;
    }
  }, [isAnalyzing, options]);

  /**
   * ğŸ“Š ë©”íŠ¸ë¦­ ë¶„ì„ (íŠ¹í™” ë²„ì „)
   */
  const analyzeMetrics = useCallback(async (metrics: any[], analysisType: 'performance' | 'anomaly' | 'trend' = 'performance') => {
    try {
      const response = await fetch('/api/v1/ai/metrics', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          metrics,
          analysisType,
          sessionId: `metrics_${Date.now()}`
        })
      });

      if (!response.ok) {
        throw new Error(`ë©”íŠ¸ë¦­ ë¶„ì„ ì‹¤íŒ¨: ${response.status}`);
      }

      const result = await response.json();
      
      if (result.success) {
        showToast.success('ë©”íŠ¸ë¦­ ë¶„ì„ ì™„ë£Œ');
        return result;
      } else {
        throw new Error(result.error || 'ë©”íŠ¸ë¦­ ë¶„ì„ ì‹¤íŒ¨');
      }

    } catch (error: any) {
      const errorMessage = error.message || 'ë©”íŠ¸ë¦­ ë¶„ì„ ì˜¤ë¥˜';
      showToast.error(errorMessage);
      console.error('ë©”íŠ¸ë¦­ ë¶„ì„ ì˜¤ë¥˜:', error);
      return null;
    }
  }, []);

  /**
   * ğŸ¥ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
   */
  const checkHealth = useCallback(async (): Promise<SystemHealth | null> => {
    if (isHealthChecking) return systemHealth;

    setIsHealthChecking(true);
    setError(null);

    try {
      const response = await fetch('/api/v1/ai/unified?action=health');
      
      if (!response.ok) {
        throw new Error(`ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: ${response.status}`);
      }

      const result = await response.json();
      
      if (result.success) {
        setSystemHealth(result.health);
        return result.health;
      } else {
        throw new Error(result.error || 'ìƒíƒœ í™•ì¸ ì‹¤íŒ¨');
      }

    } catch (error: any) {
      const errorMessage = error.message || 'ìƒíƒœ í™•ì¸ ì˜¤ë¥˜';
      setError(errorMessage);
      console.error('ìƒíƒœ í™•ì¸ ì˜¤ë¥˜:', error);
      return null;

    } finally {
      setIsHealthChecking(false);
    }
  }, [isHealthChecking, systemHealth]);

  /**
   * ğŸ¯ ìŠ¤ë§ˆíŠ¸ ì§ˆë¬¸ ì²˜ë¦¬
   */
  const askQuestion = useCallback(async (question: string) => {
    // í•œêµ­ì–´ ì§ˆë¬¸ì„ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì ì ˆí•œ ë¶„ì„ íƒ€ì… ê²°ì •
    let analysisType: AIAnalysisRequest['type'] = 'analysis';
    
    if (question.includes('ì„±ëŠ¥') || question.includes('ì†ë„') || question.includes('ëŠë¦¼')) {
      analysisType = 'monitoring';
    } else if (question.includes('ì˜ˆì¸¡') || question.includes('ì•ìœ¼ë¡œ') || question.includes('í–¥í›„')) {
      analysisType = 'prediction';
    } else if (question.includes('ìµœì í™”') || question.includes('ê°œì„ ') || question.includes('ë¹ ë¥´ê²Œ')) {
      analysisType = 'optimization';
    } else if (question.includes('ë¬¸ì œ') || question.includes('ì˜¤ë¥˜') || question.includes('ì¥ì• ')) {
      analysisType = 'troubleshooting';
    }

    return await analyze({
      query: question,
      type: analysisType,
      includeMetrics: true,
      includeLogs: question.includes('ë¡œê·¸') || question.includes('ì˜¤ë¥˜')
    });
  }, [analyze]);

  /**
   * ğŸ”„ ë¶„ì„ ì·¨ì†Œ
   */
  const cancelAnalysis = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      showToast.info('ë¶„ì„ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤');
    }
  }, []);

  /**
   * ğŸ§¹ ìƒíƒœ ì´ˆê¸°í™”
   */
  const reset = useCallback(() => {
    setLastResponse(null);
    setSystemHealth(null);
    setError(null);
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }
  }, []);

  /**
   * ğŸ“ˆ ì„±ëŠ¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
   */
  const getPerformanceInfo = useCallback(() => {
    if (!lastResponse) return null;

    return {
      totalTime: lastResponse.performance.totalTime,
      aiTime: lastResponse.performance.aiTime,
      dataCollectionTime: lastResponse.performance.dataCollectionTime,
      cacheHits: lastResponse.performance.cacheHits,
      fallbacks: lastResponse.performance.fallbacks,
      sources: lastResponse.sources,
      model: lastResponse.metadata.model,
      cached: lastResponse.metadata.cached,
      confidence: lastResponse.metadata.confidence
    };
  }, [lastResponse]);

  /**
   * ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½
   */
  const getSystemSummary = useCallback(() => {
    if (!systemHealth) return null;

    const healthyServices = Object.values(systemHealth)
      .filter(service => typeof service === 'object' && service.status === 'healthy' || service.status === 'connected')
      .length;

    const totalServices = Object.keys(systemHealth).length - 1; // 'overall' ì œì™¸

    return {
      healthyServices,
      totalServices,
      healthPercentage: Math.round((healthyServices / totalServices) * 100),
      overall: systemHealth.overall,
      hasIssues: systemHealth.overall !== 'healthy'
    };
  }, [systemHealth]);

  return {
    // ìƒíƒœ
    isAnalyzing,
    isHealthChecking,
    lastResponse,
    systemHealth,
    error,

    // ì•¡ì…˜
    analyze,
    analyzeMetrics,
    checkHealth,
    askQuestion,
    cancelAnalysis,
    reset,

    // ìœ í‹¸ë¦¬í‹°
    getPerformanceInfo,
    getSystemSummary,

    // í¸ì˜ ìƒíƒœ
    hasResponse: !!lastResponse,
    isHealthy: systemHealth?.overall === 'healthy',
    confidence: lastResponse?.metadata.confidence || 0,
    urgency: lastResponse?.analysis.urgency || 'low'
  };
} 