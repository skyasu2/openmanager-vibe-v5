import { NextRequest, NextResponse } from 'next/server';
import { monitoringService } from '@/services/ai/MonitoringService';
import { rateLimiters, withRateLimit } from '@/lib/rate-limiter';

/**
 * ğŸ“Š AI ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ API
 * GET: ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì¡°íšŒ (Rate Limited: 1ë¶„ì— 30íšŒ)
 * POST: í—¬ìŠ¤ì²´í¬ ì‹¤í–‰ (Rate Limited: 1ë¶„ì— 30íšŒ)
 */

async function handleGET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const type = searchParams.get('type') || 'all';

    switch (type) {
      case 'metrics':
        return NextResponse.json({
          success: true,
          data: monitoringService.getAllMetrics()
        });

      case 'realtime':
        return NextResponse.json({
          success: true,
          data: monitoringService.getRealTimeStats()
        });

      case 'health':
        const healthCheck = await monitoringService.performHealthCheck();
        return NextResponse.json({
          success: true,
          data: healthCheck
        });

      case 'warmup':
        const allMetrics = monitoringService.getAllMetrics();
        return NextResponse.json({
          success: true,
          data: {
            warmup: allMetrics.warmup,
            pythonStatus: allMetrics.health.pythonServiceStatus,
            warmupHealth: allMetrics.health.warmupHealth
          }
        });

      case 'performance':
        const perfMetrics = monitoringService.getAllMetrics();
        return NextResponse.json({
          success: true,
          data: {
            performance: perfMetrics.performance,
            summary: perfMetrics.summary
          }
        });

      case 'errors':
        const errorMetrics = monitoringService.getAllMetrics();
        return NextResponse.json({
          success: true,
          data: {
            errors: errorMetrics.errors,
            systemStatus: errorMetrics.health.status
          }
        });

      default: // 'all'
        return NextResponse.json({
          success: true,
          data: monitoringService.getAllMetrics()
        });
    }

  } catch (error: any) {
    console.error('ëª¨ë‹ˆí„°ë§ API ì˜¤ë¥˜:', error);
    return NextResponse.json({
      success: false,
      error: 'Failed to fetch monitoring data',
      message: error.message
    }, { status: 500 });
  }
}

// Rate Limited exports
export const GET = withRateLimit(rateLimiters.monitoring, handleGET);
export const POST = withRateLimit(rateLimiters.monitoring, handlePOST);

/**
 * POST: í—¬ìŠ¤ì²´í¬ ë° ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
 */
async function handlePOST(request: NextRequest) {
  try {
    const body = await request.json().catch(() => ({}));
    
    if (body.action === 'healthcheck') {
      const healthCheck = await monitoringService.performHealthCheck();
      
      return NextResponse.json({
        success: true,
        data: healthCheck,
        timestamp: new Date().toISOString()
      });
    }
    
    if (body.action === 'reset-metrics') {
      // ë©”íŠ¸ë¦­ ë¦¬ì…‹ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
      const newMonitoringService = await import('@/services/ai/MonitoringService');
      
      return NextResponse.json({
        success: true,
        message: 'ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ì´ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤',
        timestamp: new Date().toISOString()
      });
    }

    // ê¸°ë³¸ì ìœ¼ë¡œ í—¬ìŠ¤ì²´í¬ ì‹¤í–‰
    const healthCheck = await monitoringService.performHealthCheck();
    
    return NextResponse.json({
      success: true,
      data: healthCheck,
      timestamp: new Date().toISOString()
    });

  } catch (error: any) {
    console.error('ëª¨ë‹ˆí„°ë§ í—¬ìŠ¤ì²´í¬ ì˜¤ë¥˜:', error);
    return NextResponse.json({
      success: false,
      error: 'Health check failed',
      message: error.message
    }, { status: 500 });
  }
} 