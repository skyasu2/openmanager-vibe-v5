/**
 * ğŸ¤– AI í†µí•© ìŠ¤íŠ¸ë¦¬ë° API (Vercel AI SDK)
 *
 * ëª©í‘œ: í¬íŠ¸í´ë¦¬ì˜¤ìš© AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
 * - Vercel AI SDK streamText ì‚¬ìš©
 * - Tool Calling (4ê°œ í¬íŠ¸í´ë¦¬ì˜¤ìš© Tools)
 * - ì‹¤ì‹œê°„ Thinking Process ì‹œê°í™”
 * - Mock ë°ì´í„° ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜
 *
 * POST /api/ai/unified-stream
 */

import { google } from '@ai-sdk/google';
import { streamText, tool } from 'ai';
import { z } from 'zod';
import { getGoogleAIKey } from '@/lib/ai/google-ai-manager';
import { loadHourlyScenarioData } from '@/services/scenario/scenario-loader';
import { SupabaseRAGEngine } from '@/services/ai/supabase-rag-engine';
import { createClient } from '@/lib/supabase/server';
import { NextRequest } from 'next/server';
import { withAuth } from '@/lib/auth/api-auth';

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

/**
 * ğŸ“Š Tool 1: ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ (ê¸°ì¡´ 15ê°œ ì„œë²„ ë°ì´í„° í™œìš©)
 * scenario-loaderì˜ ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©
 */
const getServerMetrics = tool({
  description:
    'ì„œë²„ CPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜)',
  inputSchema: z.object({
    serverId: z.string().optional().describe('ì¡°íšŒí•  ì„œë²„ ID (ì„ íƒ)'),
    metric: z
      .enum(['cpu', 'memory', 'disk', 'all'])
      .describe('ì¡°íšŒí•  ë©”íŠ¸ë¦­ íƒ€ì…'),
  }),
  execute: async ({
    serverId,
    metric,
  }: {
    serverId?: string;
    metric: 'cpu' | 'memory' | 'disk' | 'all';
  }) => {
    // ğŸ¯ ê¸°ì¡´ 15ê°œ ì„œë²„ ë°ì´í„° ë¡œë“œ (scenario-loader)
    const allServers = await loadHourlyScenarioData();

    const target = serverId
      ? allServers.find((s) => s.id === serverId)
      : allServers;

    const servers = Array.isArray(target)
      ? target
      : target
        ? [target]
        : allServers;

    // í‰ê·  ê³„ì‚°
    const avgCpu = servers.reduce((sum, s) => sum + s.cpu, 0) / servers.length;
    const avgMemory =
      servers.reduce((sum, s) => sum + s.memory, 0) / servers.length;
    const avgDisk =
      servers.reduce((sum, s) => sum + s.disk, 0) / servers.length;

    return {
      success: true,
      servers: servers.map((s) => ({
        id: s.id,
        name: s.name,
        status: s.status,
        cpu: s.cpu,
        memory: s.memory,
        disk: s.disk,
        network: s.network,
      })),
      summary: {
        total: servers.length,
        avgCpu: Math.round(avgCpu),
        avgMemory: Math.round(avgMemory),
        avgDisk: Math.round(avgDisk),
        alertCount: servers.filter(
          (s) => s.status === 'warning' || s.status === 'critical'
        ).length,
      },
      timestamp: new Date().toISOString(),
      _dataSource: 'scenario-loader (15 servers)',
      _note: 'ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ê¸°ì¡´ ì‹œìŠ¤í…œ í™œìš©)',
    };
  },
});

/**
 * ğŸ”® Tool 2: ML ì¥ì•  ì˜ˆì¸¡ (ì‹¤ì œ GCP Cloud Functions)
 * GCP ML Analytics Engineì„ ì‚¬ìš©í•œ ì‹¤ì œ ì¥ì•  ì˜ˆì¸¡
 */
const predictIncident = tool({
  description: 'ML ëª¨ë¸ë¡œ ì„œë²„ ì¥ì•  ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤ (GCP Cloud Functions)',
  inputSchema: z.object({
    serverId: z.string().describe('ì˜ˆì¸¡í•  ì„œë²„ ID'),
  }),
  execute: async ({ serverId }: { serverId: string }) => {
    try {
      // ğŸš€ ì‹¤ì œ GCP ML Analytics Engine í˜¸ì¶œ
      const gcpEndpoint =
        process.env.NEXT_PUBLIC_GCP_ML_ANALYTICS_ENDPOINT ||
        'https://asia-northeast3-openmanager-free-tier.cloudfunctions.net/ml-analytics-engine';

      // ğŸ¯ ê¸°ì¡´ 15ê°œ ì„œë²„ ë°ì´í„° ë¡œë“œ
      const allServers = await loadHourlyScenarioData();

      const server = allServers.find((s) => s.id === serverId);
      if (!server) {
        return {
          success: false,
          error: `Server ${serverId} not found (total: ${allServers.length} servers)`,
          timestamp: new Date().toISOString(),
        };
      }

      // 24ì‹œê°„ ë©”íŠ¸ë¦­ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ)
      const metrics = [];
      const now = new Date();
      for (let i = 0; i < 24; i++) {
        const timestamp = new Date(now.getTime() - i * 3600000);
        metrics.push(
          {
            timestamp: timestamp.toISOString(),
            value: server.cpu + (Math.random() - 0.5) * 10,
            server_id: serverId,
            metric_type: 'cpu',
          },
          {
            timestamp: timestamp.toISOString(),
            value: server.memory + (Math.random() - 0.5) * 10,
            server_id: serverId,
            metric_type: 'memory',
          }
        );
      }

      // GCP ML Analytics Engine í˜¸ì¶œ
      const response = await fetch(gcpEndpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          metrics,
          context: {
            analysis_type: 'anomaly_detection',
            threshold: 0.8,
          },
        }),
        signal: AbortSignal.timeout(10000),
      });

      if (!response.ok) {
        throw new Error(`GCP ML API error: ${response.status}`);
      }

      const result = await response.json();

      // ì´ìƒ íƒì§€ ê²°ê³¼ ê¸°ë°˜ ì¥ì•  í™•ë¥  ê³„ì‚°
      const anomalies = result.data?.anomalies || [];
      const highSeverityAnomalies = anomalies.filter(
        (a: any) => a.severity === 'high'
      );
      const probability = Math.min(highSeverityAnomalies.length * 0.2, 0.95);

      const riskFactors = anomalies.map((a: any) => ({
        metric: a.timestamp,
        severity: a.severity,
        value: a.value,
      }));

      return {
        success: true,
        serverId,
        prediction: {
          probability: Number(probability.toFixed(2)),
          timeframe: '1h',
          confidence: result.data?.trend?.confidence || 0.85,
          riskLevel:
            probability > 0.7 ? 'high' : probability > 0.4 ? 'medium' : 'low',
          factors: riskFactors,
          trend: result.data?.trend,
          recommendations: result.data?.recommendations || [],
        },
        timestamp: new Date().toISOString(),
        _realGCP: true,
        _endpoint: gcpEndpoint,
        _performance: result.performance,
      };
    } catch (error) {
      console.error('âŒ GCP ML ì˜ˆì¸¡ ì‹¤íŒ¨:', error);

      // Fallback: ê°„ë‹¨í•œ ë¡œì»¬ ì˜ˆì¸¡ (ê¸°ì¡´ ì„œë²„ ë°ì´í„° ì‚¬ìš©)
      const allServers = await loadHourlyScenarioData();
      const server = allServers.find((s) => s.id === serverId);

      if (!server) {
        return {
          success: false,
          error: `Fallback: Server ${serverId} not found`,
          timestamp: new Date().toISOString(),
        };
      }

      const cpuRisk = server.cpu > 80 ? 0.7 : server.cpu > 60 ? 0.4 : 0.1;
      const memRisk = server.memory > 85 ? 0.8 : server.memory > 70 ? 0.5 : 0.2;
      const probability = Math.max(cpuRisk, memRisk);

      return {
        success: true,
        serverId,
        prediction: {
          probability: Number(probability.toFixed(2)),
          timeframe: '1h',
          confidence: 0.6,
          riskLevel:
            probability > 0.7 ? 'high' : probability > 0.4 ? 'medium' : 'low',
          factors: [
            cpuRisk > 0.5 ? `High CPU usage (${server.cpu}%)` : null,
            memRisk > 0.5 ? `High memory usage (${server.memory}%)` : null,
          ].filter(Boolean),
        },
        timestamp: new Date().toISOString(),
        _fallback: true,
        _error: error instanceof Error ? error.message : 'Unknown error',
      };
    }
  },
});

/**
 * ğŸ“š Tool 3: RAG ì§€ì‹ë² ì´ìŠ¤ ì‹œë®¬ë ˆì´ì…˜
 * í•˜ë“œì½”ë”©ëœ Mock ì§€ì‹ë² ì´ìŠ¤
 */
/**
 * ğŸ“š Tool 3: RAG ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ (Real RAG)
 * Supabase pgvector ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
 */
const searchKnowledgeBase = tool({
  description: 'ê³¼ê±° ì¥ì•  ì´ë ¥ ë° í•´ê²° ë°©ë²•ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤ (Real RAG)',
  inputSchema: z.object({
    query: z.string().describe('ê²€ìƒ‰ ì¿¼ë¦¬'),
  }),
  execute: async ({ query }: { query: string }) => {
    try {
      // ğŸš€ Real RAG Engine ì´ˆê¸°í™”
      const supabase = await createClient();
      const ragEngine = new SupabaseRAGEngine(supabase);

      // í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
      const searchResult = await ragEngine.searchHybrid(query, {
        maxResults: 3,
        enableKeywordFallback: true,
      });

      if (!searchResult.success || searchResult.results.length === 0) {
        return {
          success: false,
          query,
          message: 'ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
          timestamp: new Date().toISOString(),
        };
      }

      return {
        success: true,
        query,
        results: searchResult.results.map((r) => ({
          content: r.content,
          similarity: r.similarity,
          metadata: r.metadata,
        })),
        totalMatches: searchResult.totalResults,
        timestamp: new Date().toISOString(),
        _source: 'Supabase pgvector (Real RAG)',
      };
    } catch (error) {
      console.error('âŒ RAG ê²€ìƒ‰ ì‹¤íŒ¨:', error);
      return {
        success: false,
        error: 'ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        timestamp: new Date().toISOString(),
      };
    }
  },
});

/**
 * ğŸ“ˆ Tool 4: ì„œë²„ ìƒíƒœ ì¢…í•© ë¶„ì„
 * í†µê³„ ê¸°ë°˜ ê±´ê°•ë„ ë¶„ì„
 */
const analyzeServerHealth = tool({
  description: 'ì „ì²´ ì„œë²„ì˜ ê±´ê°•ë„ë¥¼ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤ (í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜)',
  inputSchema: z.object({}),
  execute: async () => {
    // ğŸ¯ ê¸°ì¡´ 15ê°œ ì„œë²„ ë°ì´í„° ë¡œë“œ
    const allServers = await loadHourlyScenarioData();

    // ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚° (0-100)
    const healthScore =
      allServers.reduce((sum, s) => {
        const cpuScore = (100 - s.cpu) / 100;
        const memScore = (100 - s.memory) / 100;
        const diskScore = (100 - s.disk) / 100;
        return sum + (cpuScore + memScore + diskScore) / 3;
      }, 0) / allServers.length;

    const criticalServers = allServers.filter((s) => s.status === 'critical');
    const warningServers = allServers.filter((s) => s.status === 'warning');
    const healthyServers = allServers.filter((s) => s.status === 'online');

    // ê¶Œì¥ì‚¬í•­ ìƒì„±
    const recommendations = [
      healthScore < 0.6 ? 'ì¼ë¶€ ì„œë²„ ë¦¬ì†ŒìŠ¤ í™•ì¥ í•„ìš”' : null,
      allServers.some((s) => s.cpu > 80) ? 'CPU ë¶€í•˜ ë¶„ì‚° ê¶Œì¥' : null,
      allServers.some((s) => s.memory > 85) ? 'ë©”ëª¨ë¦¬ ìµœì í™” í•„ìš”' : null,
      criticalServers.length > 0
        ? `ê¸´ê¸‰: ${criticalServers.length}ëŒ€ ì„œë²„ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”`
        : null,
    ].filter(Boolean);

    return {
      success: true,
      analysis: {
        overallHealth: Math.round(healthScore * 100),
        healthGrade: healthScore > 0.8 ? 'A' : healthScore > 0.6 ? 'B' : 'C',
        serverCount: {
          total: allServers.length,
          healthy: healthyServers.length,
          warning: warningServers.length,
          critical: criticalServers.length,
        },
        recommendations,
      },
      timestamp: new Date().toISOString(),
      _dataSource: 'scenario-loader (Simulation)',
    };
  },
});

/**
 * âš¡ Tool 5: íŒ¨í„´ ë¶„ì„ (Offline Capability)
 * ì •ê·œì‹ ê¸°ë°˜ì˜ ë¹ ë¥¸ ì˜ë„ íŒŒì•…
 */
const analyzePattern = tool({
  description:
    'ì‚¬ìš©ì ì§ˆë¬¸ì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì¦‰ê°ì ì¸ ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤ (Offline)',
  inputSchema: z.object({
    query: z.string().describe('ë¶„ì„í•  ì‚¬ìš©ì ì§ˆë¬¸'),
  }),
  execute: async ({ query }: { query: string }) => {
    const patterns: string[] = [];
    const q = query.toLowerCase();

    // ì‹œìŠ¤í…œ ê´€ë ¨ íŒ¨í„´ ë§¤ì¹­
    if (/cpu|í”„ë¡œì„¸ì„œ|ì„±ëŠ¥/i.test(q)) patterns.push('system_performance');
    if (/ë©”ëª¨ë¦¬|ram|memory/i.test(q)) patterns.push('memory_status');
    if (/ë””ìŠ¤í¬|ì €ì¥ì†Œ|ìš©ëŸ‰/i.test(q)) patterns.push('storage_info');
    if (/ë„¤íŠ¸ì›Œí¬|ì¸í„°ë„·|ì—°ê²°/i.test(q)) patterns.push('network_status');
    if (/ì„œë²„|ì‹œìŠ¤í…œ|ìƒíƒœ/i.test(q)) patterns.push('server_status');

    if (patterns.length === 0) {
      return {
        success: false,
        message: 'ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.',
      };
    }

    return {
      success: true,
      patterns,
      detectedIntent: patterns[0],
      timestamp: new Date().toISOString(),
      _mode: 'offline-pattern-match',
    };
  },
});

/**
 * âŒ¨ï¸ Tool 6: ëª…ë ¹ì–´ ì¶”ì²œ (Offline Capability)
 * í‚¤ì›Œë“œ ê¸°ë°˜ CLI ëª…ë ¹ì–´ ì¶”ì²œ
 */
const recommendCommands = tool({
  description: 'ì‚¬ìš©ì ì§ˆë¬¸ì— ì í•©í•œ CLI ëª…ë ¹ì–´ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤ (Offline)',
  inputSchema: z.object({
    keywords: z.array(z.string()).describe('ì§ˆë¬¸ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ í‚¤ì›Œë“œ'),
  }),
  execute: async ({ keywords }: { keywords: string[] }) => {
    const recommendations = [
      {
        keywords: ['ì„œë²„', 'ëª©ë¡', 'ì¡°íšŒ', 'ë¦¬ìŠ¤íŠ¸'],
        command: 'list servers',
        description: 'í˜„ì¬ ë“±ë¡ëœ ëª¨ë“  ì„œë²„ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.',
      },
      {
        keywords: ['ìƒíƒœ', 'ì²´í¬', 'í™•ì¸', 'status'],
        command: 'status check',
        description: 'ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœë¥¼ ì ê²€í•©ë‹ˆë‹¤.',
      },
      {
        keywords: ['ì„±ëŠ¥', 'ëª¨ë‹ˆí„°ë§', 'cpu', 'ë©”ëª¨ë¦¬'],
        command: 'monitor performance',
        description: 'ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.',
      },
      {
        keywords: ['ë¡œê·¸', 'ë¶„ì„', 'ì—ëŸ¬'],
        command: 'analyze logs',
        description: 'ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.',
      },
      {
        keywords: ['ì•Œë¦¼', 'ì„¤ì •', 'alert'],
        command: 'configure alerts',
        description: 'ì•Œë¦¼ ê·œì¹™ì„ ì„¤ì •í•©ë‹ˆë‹¤.',
      },
    ];

    const matched = recommendations.filter((rec) =>
      keywords.some((k) =>
        rec.keywords.some((rk) => rk.includes(k) || k.includes(rk))
      )
    );

    return {
      success: true,
      recommendations:
        matched.length > 0 ? matched : recommendations.slice(0, 3), // ë§¤ì¹­ ì—†ìœ¼ë©´ ê¸°ë³¸ 3ê°œ
      timestamp: new Date().toISOString(),
      _mode: 'offline-command-recommendation',
    };
  },
});

// ============================================================================
// ğŸ§  Extended Thinking Tools - AI ì‚¬ê³  ê³¼ì • ì‹œê°í™”
// ============================================================================

/**
 * ğŸ’¡ Thinking Tool 1: ì§ˆë¬¸ ì˜ë„ ë¶„ì„
 */
const analyzeIntent = tool({
  description: 'ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    query: z.string().describe('ì‚¬ìš©ì ì§ˆë¬¸'),
  }),
  execute: async ({ query }: { query: string }) => {
    const lowerQuery = query.toLowerCase();

    // í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜
    let intent = 'general';
    let category = 'information';
    let confidence = 0.7;

    if (
      lowerQuery.includes('cpu') ||
      lowerQuery.includes('ë©”ëª¨ë¦¬') ||
      lowerQuery.includes('ë””ìŠ¤í¬')
    ) {
      intent = 'metric_query';
      category = 'monitoring';
      confidence = 0.9;
    } else if (lowerQuery.includes('ìƒíƒœ') || lowerQuery.includes('status')) {
      intent = 'status_check';
      category = 'monitoring';
      confidence = 0.85;
    } else if (
      lowerQuery.includes('ì¥ì• ') ||
      lowerQuery.includes('ì—ëŸ¬') ||
      lowerQuery.includes('ë¬¸ì œ')
    ) {
      intent = 'incident_analysis';
      category = 'troubleshooting';
      confidence = 0.9;
    } else if (lowerQuery.includes('ì˜ˆì¸¡') || lowerQuery.includes('ê°€ëŠ¥ì„±')) {
      intent = 'prediction';
      category = 'analytics';
      confidence = 0.85;
    } else if (lowerQuery.includes('ìµœì í™”') || lowerQuery.includes('ê°œì„ ')) {
      intent = 'optimization';
      category = 'improvement';
      confidence = 0.8;
    }

    return {
      intent,
      category,
      confidence,
      reasoning: `ì§ˆë¬¸ì—ì„œ "${intent}" ì˜ë„ë¥¼ ê°ì§€í–ˆìŠµë‹ˆë‹¤.`,
      suggestedTools:
        intent === 'metric_query'
          ? ['getServerMetrics']
          : intent === 'prediction'
            ? ['predictIncident']
            : intent === 'incident_analysis'
              ? ['searchKnowledgeBase']
              : [],
    };
  },
});

/**
 * ğŸ’¡ Thinking Tool 2: ë³µì¡ë„ ë¶„ì„
 */
const analyzeComplexity = tool({
  description:
    'ì§ˆë¬¸ì˜ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì  ì²˜ë¦¬ ì „ëµì„ ê²°ì •í•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    query: z.string().describe('ì‚¬ìš©ì ì§ˆë¬¸'),
    intent: z.string().optional().describe('ë¶„ì„ëœ ì˜ë„'),
  }),
  execute: async ({ query, intent }: { query: string; intent?: string }) => {
    const words = query.split(' ').length;
    const hasMultipleQuestions =
      query.includes('?') && query.split('?').length > 2;
    const requiresAggregation =
      query.includes('ì „ì²´') ||
      query.includes('ëª¨ë“ ') ||
      query.includes('ì¢…í•©');

    // ë³µì¡ë„ ì ìˆ˜ (1-5)
    let score = 1;
    if (words > 20) score += 1;
    if (hasMultipleQuestions) score += 1;
    if (requiresAggregation) score += 1;
    if (intent === 'incident_analysis' || intent === 'optimization') score += 1;

    const recommendation =
      score >= 4 ? 'multi-tool' : score >= 3 ? 'single-tool' : 'direct-answer';

    return {
      score,
      level: score >= 4 ? 'complex' : score >= 3 ? 'moderate' : 'simple',
      recommendation,
      reasoning: `ì§ˆë¬¸ ê¸¸ì´ ${words}ë‹¨ì–´, ë³µì¡ë„ ${score}/5ì ìœ¼ë¡œ "${recommendation}" ì „ëµì„ ê¶Œì¥í•©ë‹ˆë‹¤.`,
      estimatedTools: score >= 4 ? 3 : score >= 3 ? 1 : 0,
    };
  },
});

/**
 * ğŸ’¡ Thinking Tool 3: ë¼ìš°íŒ… ê²°ì •
 */
const selectRoute = tool({
  description: 'ìµœì ì˜ ì²˜ë¦¬ ê²½ë¡œë¥¼ ì„ íƒí•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    complexity: z.number().describe('ë³µì¡ë„ ì ìˆ˜ (1-5)'),
    intent: z.string().describe('ì§ˆë¬¸ ì˜ë„'),
  }),
  execute: async ({
    complexity,
    intent,
  }: {
    complexity: number;
    intent: string;
  }) => {
    const route =
      complexity >= 4
        ? 'comprehensive-analysis'
        : complexity >= 3
          ? 'targeted-query'
          : 'quick-response';

    const toolSequence =
      intent === 'prediction'
        ? ['getServerMetrics', 'predictIncident']
        : intent === 'incident_analysis'
          ? ['searchKnowledgeBase', 'getServerMetrics']
          : intent === 'optimization'
            ? ['analyzeServerHealth', 'searchKnowledgeBase']
            : ['getServerMetrics'];

    const costEstimate =
      complexity >= 4 ? '$0.003' : complexity >= 3 ? '$0.001' : '$0';

    return {
      route,
      strategy:
        complexity >= 4
          ? 'Multi-tool ì¢…í•© ë¶„ì„'
          : complexity >= 3
            ? 'Single-tool íƒ€ê²ŸíŒ…'
            : 'Direct ì¦‰ì‹œ ì‘ë‹µ',
      toolSequence,
      reasoning: `ë³µì¡ë„ ${complexity}ì , ${intent} ì˜ë„ â†’ "${route}" ê²½ë¡œ ì„ íƒ`,
      costEstimate,
      freeOptimized: costEstimate === '$0',
    };
  },
});

/**
 * ğŸ’¡ Thinking Tool 4: ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
 */
const searchContext = tool({
  description: 'ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    query: z.string().describe('ê²€ìƒ‰ ì¿¼ë¦¬'),
    scope: z.enum(['servers', 'knowledge', 'history']).describe('ê²€ìƒ‰ ë²”ìœ„'),
  }),
  execute: async ({
    query,
    scope,
  }: {
    query: string;
    scope: 'servers' | 'knowledge' | 'history';
  }) => {
    const results = {
      servers: {
        found: 4,
        relevant: ['server-2', 'server-4'],
        summary: '2ëŒ€ ì„œë²„ì—ì„œ ê´€ë ¨ ë©”íŠ¸ë¦­ ë°œê²¬',
      },
      knowledge: {
        found: 3,
        relevant: ['CPU ê³¼ë¶€í•˜', 'ë©”ëª¨ë¦¬ ëˆ„ìˆ˜'],
        summary: 'ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ 2ê±´ ë°œê²¬',
      },
      history: {
        found: 5,
        relevant: ['2024-11-20 ì¥ì• ', '2024-11-15 ìµœì í™”'],
        summary: 'ìµœê·¼ 2ì£¼ ë‚´ ê´€ë ¨ ì´ë²¤íŠ¸ 2ê±´',
      },
    };

    const result = results[scope];

    return {
      scope,
      ...result,
      reasoning: `"${scope}" ë²”ìœ„ì—ì„œ ${result.found}ê±´ ê²€ìƒ‰, ${result.relevant.length}ê±´ ê´€ë ¨`,
      confidence: result.relevant.length / result.found,
    };
  },
});

/**
 * ğŸ’¡ Thinking Tool 5: ì¸ì‚¬ì´íŠ¸ ìƒì„±
 */
const generateInsight = tool({
  description: 'ìˆ˜ì§‘ëœ ë°ì´í„°ì—ì„œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    dataPoints: z.array(z.string()).describe('ìˆ˜ì§‘ëœ ë°ì´í„° í¬ì¸íŠ¸'),
  }),
  execute: async ({ dataPoints }: { dataPoints: string[] }) => {
    const insights = [];

    if (dataPoints.some((d) => d.includes('cpu') || d.includes('CPU'))) {
      insights.push({
        type: 'performance',
        message: 'CPU ì‚¬ìš©ë¥  íŒ¨í„´ ë¶„ì„ ì™„ë£Œ',
        priority: 'medium',
      });
    }

    if (
      dataPoints.some((d) => d.includes('critical') || d.includes('warning'))
    ) {
      insights.push({
        type: 'alert',
        message: 'ê¸´ê¸‰ ì¡°ì¹˜ í•„ìš” ì„œë²„ ê°ì§€',
        priority: 'high',
      });
    }

    if (dataPoints.length >= 3) {
      insights.push({
        type: 'correlation',
        message: 'ì—¬ëŸ¬ ë©”íŠ¸ë¦­ ê°„ ìƒê´€ê´€ê³„ ë°œê²¬',
        priority: 'low',
      });
    }

    return {
      insights,
      count: insights.length,
      summary: `${dataPoints.length}ê°œ ë°ì´í„° í¬ì¸íŠ¸ì—ì„œ ${insights.length}ê°œ ì¸ì‚¬ì´íŠ¸ ìƒì„±`,
      reasoning: 'ë°ì´í„° íŒ¨í„´ ë¶„ì„ ë° ìš°ì„ ìˆœìœ„ ë¶„ë¥˜ ì™„ë£Œ',
    };
  },
});

/**
 * POST í•¸ë“¤ëŸ¬ - Vercel AI SDK streamText ì‚¬ìš©
 */
export const POST = withAuth(async (req: NextRequest) => {
  try {
    const { messages } = await req.json();
    const apiKey = getGoogleAIKey();

    if (!apiKey) {
      return new Response('Google AI API Key not found', { status: 500 });
    }

    // ğŸš€ Vercel AI SDK streamText
    const result = streamText({
      model: google('gemini-1.5-flash'),
      messages,
      tools: {
        // ğŸ§  Extended Thinking Tools (5ê°œ)
        analyzeIntent,
        analyzeComplexity,
        selectRoute,
        searchContext,
        generateInsight,
        // ğŸ“Š Action Tools (4ê°œ)
        getServerMetrics,
        predictIncident,
        searchKnowledgeBase,
        analyzeServerHealth,
        analyzePattern,
        recommendCommands,
      },
      system: `ë‹¹ì‹ ì€ **OpenManager Vibe**ì˜ **ì„œë²„ ëª¨ë‹ˆí„°ë§ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸**ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ í•µì‹¬ ì„ë¬´ëŠ” **ì„œë²„ ë°ì´í„°ë¥¼ ë¶„ì„**í•˜ê³ , **ì¥ì•  ì›ì¸ì„ ê·œëª…**í•˜ë©°, **í•´ê²°ì±…ì„ ì œì‹œ**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

**ğŸš¨ í•µì‹¬ ì›ì¹™ (CRITICAL INSTRUCTIONS)**
1. **ë°ì´í„° ê¸°ë°˜ ë‹µë³€ (Data-Driven)**: ì ˆëŒ€ ì¶”ì¸¡ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë°˜ë“œì‹œ getServerMetricsë‚˜ analyzeServerHealth ë„êµ¬ë¡œ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ í™•ì¸í•œ í›„ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
2. **ì§€ì‹ ê²€ìƒ‰ ìš°ì„  (RAG First)**: ì¥ì•  ì›ì¸ì´ë‚˜ í•´ê²° ë°©ë²• ì§ˆë¬¸ ì‹œ, ë°˜ë“œì‹œ searchKnowledgeBaseë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ê³¼ê±° ì‚¬ë¡€ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
3. **ì˜¤í”„ë¼ì¸ ë„êµ¬ í™œìš© (Hybrid Engine)**: "CPU ìƒíƒœ ì–´ë•Œ?" ê°™ì€ ë‹¨ìˆœ ìƒíƒœ í™•ì¸ ì§ˆë¬¸ì´ë‚˜ ëª…ë ¹ì–´ ìš”ì²­ ì‹œ, LLM ì¶”ë¡ ë³´ë‹¤ analyzePatternì´ë‚˜ recommendCommands ë„êµ¬ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
4. **ë„êµ¬ ì‹¤í–‰ í•„ìˆ˜ (Tools Before Talk)**: ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ì „, í•„ìš”í•œ ë„êµ¬ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™•ë³´í•´ì•¼ í•©ë‹ˆë‹¤.

**ğŸ§  Thinking Process (ì‚¬ê³  ê³¼ì • ì‹œê°í™” ìˆœì„œ)**
1. **analyzeIntent**: ì§ˆë¬¸ ì˜ë„ íŒŒì•…
2. **analyzeComplexity**: ë³µì¡ë„ ë¶„ì„ (Simpleì¸ ê²½ìš° ì˜¤í”„ë¼ì¸ ë„êµ¬ ìš°ì„  ê³ ë ¤)
3. **selectRoute**: ìµœì ì˜ ë„êµ¬ ê²½ë¡œ ì„ íƒ
4. **Action Tools ì‹¤í–‰**:
   - ë‹¨ìˆœ í™•ì¸: \`analyzePattern\`, \`recommendCommands\`
   - ìƒíƒœ í™•ì¸: \`getServerMetrics\`, \`analyzeServerHealth\`
   - ì›ì¸ ë¶„ì„: \`searchKnowledgeBase\` (RAG), \`predictIncident\` (GCP)
5. **generateInsight**: ìˆ˜ì§‘ëœ ë°ì´í„° ì¢…í•© ë¶„ì„
6. **ìµœì¢… ë‹µë³€**: í™•ë³´ëœ íŒ©íŠ¸(Facts)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ë¬¸ì ì¸ ì¡°ì–¸ ì œê³µ

**í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸:**
- ì„œë²„ ë©”íŠ¸ë¦­: 24ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©
- ì¥ì•  ì˜ˆì¸¡: ì‹¤ì œ GCP Cloud Functions ì—°ë™
- ì§€ì‹ ê²€ìƒ‰: ì‹¤ì œ Supabase pgvector RAG ì—°ë™
- ì˜¤í”„ë¼ì¸ ê¸°ëŠ¥: íŒ¨í„´ ë§¤ì¹­ ë° ëª…ë ¹ì–´ ì¶”ì²œ ë‚´ì¥

ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤ìœ¼ë¡œ, ê°œë°œìë‚˜ ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ì‹­ì‹œì˜¤.`,
    });

    return result.toTextStreamResponse();
  } catch (error) {
    console.error('âŒ AI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹¤íŒ¨:', error);
    return new Response('AI streaming failed', { status: 500 });
  }
});
