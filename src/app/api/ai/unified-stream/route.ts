/**
 * ğŸ¤– AI í†µí•© ìŠ¤íŠ¸ë¦¬ë° API (Vercel AI SDK)
 *
 * ëª©í‘œ: í¬íŠ¸í´ë¦¬ì˜¤ìš© AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
 * - Vercel AI SDK streamText ì‚¬ìš©
 * - Tool Calling (4ê°œ í¬íŠ¸í´ë¦¬ì˜¤ìš© Tools)
 * - ì‹¤ì‹œê°„ Thinking Process ì‹œê°í™”
 * - Mock ë°ì´í„° ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜
 *
 * POST /api/ai/unified-stream
 */

import { google } from '@ai-sdk/google';
import { streamText, tool } from 'ai';
import { z } from 'zod';
import { getGoogleAIKey } from '@/lib/ai/google-ai-manager';
import { loadHourlyScenarioData } from '@/services/scenario/scenario-loader';

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

/**
 * ğŸ“Š Tool 1: ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ (ê¸°ì¡´ 15ê°œ ì„œë²„ ë°ì´í„° í™œìš©)
 * scenario-loaderì˜ ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©
 */
const getServerMetrics = tool({
  description: 'ì„œë²„ CPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜)',
  inputSchema: z.object({
    serverId: z.string().optional().describe('ì¡°íšŒí•  ì„œë²„ ID (ì„ íƒ)'),
    metric: z.enum(['cpu', 'memory', 'disk', 'all']).describe('ì¡°íšŒí•  ë©”íŠ¸ë¦­ íƒ€ì…'),
  }),
  execute: async ({ serverId, metric }: { serverId?: string; metric: 'cpu' | 'memory' | 'disk' | 'all' }) => {
    // ğŸ¯ ê¸°ì¡´ 15ê°œ ì„œë²„ ë°ì´í„° ë¡œë“œ (scenario-loader)
    const allServers = await loadHourlyScenarioData();

    const target = serverId
      ? allServers.find(s => s.id === serverId)
      : allServers;

    const servers = Array.isArray(target) ? target : target ? [target] : allServers;

    // í‰ê·  ê³„ì‚°
    const avgCpu = servers.reduce((sum, s) => sum + s.cpu, 0) / servers.length;
    const avgMemory = servers.reduce((sum, s) => sum + s.memory, 0) / servers.length;
    const avgDisk = servers.reduce((sum, s) => sum + s.disk, 0) / servers.length;

    return {
      success: true,
      servers: servers.map(s => ({
        id: s.id,
        name: s.name,
        status: s.status,
        cpu: s.cpu,
        memory: s.memory,
        disk: s.disk,
        network: s.network,
      })),
      summary: {
        total: servers.length,
        avgCpu: Math.round(avgCpu),
        avgMemory: Math.round(avgMemory),
        avgDisk: Math.round(avgDisk),
        alertCount: servers.filter(s => s.status === 'warning' || s.status === 'critical').length,
      },
      timestamp: new Date().toISOString(),
      _dataSource: 'scenario-loader (15 servers)',
      _note: 'ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ê¸°ì¡´ ì‹œìŠ¤í…œ í™œìš©)',
    };
  },
});

/**
 * ğŸ”® Tool 2: ML ì¥ì•  ì˜ˆì¸¡ (ì‹¤ì œ GCP Cloud Functions)
 * GCP ML Analytics Engineì„ ì‚¬ìš©í•œ ì‹¤ì œ ì¥ì•  ì˜ˆì¸¡
 */
const predictIncident = tool({
  description: 'ML ëª¨ë¸ë¡œ ì„œë²„ ì¥ì•  ê°€ëŠ¥ì„±ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤ (GCP Cloud Functions)',
  inputSchema: z.object({
    serverId: z.string().describe('ì˜ˆì¸¡í•  ì„œë²„ ID'),
  }),
  execute: async ({ serverId }: { serverId: string }) => {
    try {
      // ğŸš€ ì‹¤ì œ GCP ML Analytics Engine í˜¸ì¶œ
      const gcpEndpoint =
        process.env.NEXT_PUBLIC_GCP_ML_ANALYTICS_ENDPOINT ||
        'https://asia-northeast3-openmanager-free-tier.cloudfunctions.net/ml-analytics-engine';

      // ğŸ¯ ê¸°ì¡´ 15ê°œ ì„œë²„ ë°ì´í„° ë¡œë“œ
      const allServers = await loadHourlyScenarioData();

      const server = allServers.find(s => s.id === serverId);
      if (!server) {
        return {
          success: false,
          error: `Server ${serverId} not found (total: ${allServers.length} servers)`,
          timestamp: new Date().toISOString(),
        };
      }

      // 24ì‹œê°„ ë©”íŠ¸ë¦­ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ)
      const metrics = [];
      const now = new Date();
      for (let i = 0; i < 24; i++) {
        const timestamp = new Date(now.getTime() - i * 3600000);
        metrics.push(
          {
            timestamp: timestamp.toISOString(),
            value: server.cpu + (Math.random() - 0.5) * 10,
            server_id: serverId,
            metric_type: 'cpu',
          },
          {
            timestamp: timestamp.toISOString(),
            value: server.memory + (Math.random() - 0.5) * 10,
            server_id: serverId,
            metric_type: 'memory',
          }
        );
      }

      // GCP ML Analytics Engine í˜¸ì¶œ
      const response = await fetch(gcpEndpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          metrics,
          context: {
            analysis_type: 'anomaly_detection',
            threshold: 0.8,
          },
        }),
        signal: AbortSignal.timeout(10000),
      });

      if (!response.ok) {
        throw new Error(`GCP ML API error: ${response.status}`);
      }

      const result = await response.json();

      // ì´ìƒ íƒì§€ ê²°ê³¼ ê¸°ë°˜ ì¥ì•  í™•ë¥  ê³„ì‚°
      const anomalies = result.data?.anomalies || [];
      const highSeverityAnomalies = anomalies.filter((a: any) => a.severity === 'high');
      const probability = Math.min(highSeverityAnomalies.length * 0.2, 0.95);

      const riskFactors = anomalies.map((a: any) => ({
        metric: a.timestamp,
        severity: a.severity,
        value: a.value,
      }));

      return {
        success: true,
        serverId,
        prediction: {
          probability: Number(probability.toFixed(2)),
          timeframe: '1h',
          confidence: result.data?.trend?.confidence || 0.85,
          riskLevel: probability > 0.7 ? 'high' : probability > 0.4 ? 'medium' : 'low',
          factors: riskFactors,
          trend: result.data?.trend,
          recommendations: result.data?.recommendations || [],
        },
        timestamp: new Date().toISOString(),
        _realGCP: true,
        _endpoint: gcpEndpoint,
        _performance: result.performance,
      };
    } catch (error) {
      console.error('âŒ GCP ML ì˜ˆì¸¡ ì‹¤íŒ¨:', error);

      // Fallback: ê°„ë‹¨í•œ ë¡œì»¬ ì˜ˆì¸¡ (ê¸°ì¡´ ì„œë²„ ë°ì´í„° ì‚¬ìš©)
      const allServers = await loadHourlyScenarioData();
      const server = allServers.find(s => s.id === serverId);

      if (!server) {
        return {
          success: false,
          error: `Fallback: Server ${serverId} not found`,
          timestamp: new Date().toISOString(),
        };
      }

      const cpuRisk = server.cpu > 80 ? 0.7 : server.cpu > 60 ? 0.4 : 0.1;
      const memRisk = server.memory > 85 ? 0.8 : server.memory > 70 ? 0.5 : 0.2;
      const probability = Math.max(cpuRisk, memRisk);

      return {
        success: true,
        serverId,
        prediction: {
          probability: Number(probability.toFixed(2)),
          timeframe: '1h',
          confidence: 0.6,
          riskLevel: probability > 0.7 ? 'high' : probability > 0.4 ? 'medium' : 'low',
          factors: [
            cpuRisk > 0.5 ? `High CPU usage (${server.cpu}%)` : null,
            memRisk > 0.5 ? `High memory usage (${server.memory}%)` : null,
          ].filter(Boolean),
        },
        timestamp: new Date().toISOString(),
        _fallback: true,
        _error: error instanceof Error ? error.message : 'Unknown error',
      };
    }
  },
});

/**
 * ğŸ“š Tool 3: RAG ì§€ì‹ë² ì´ìŠ¤ ì‹œë®¬ë ˆì´ì…˜
 * í•˜ë“œì½”ë”©ëœ Mock ì§€ì‹ë² ì´ìŠ¤
 */
const searchKnowledgeBase = tool({
  description: 'ê³¼ê±° ì¥ì•  ì´ë ¥ ë° í•´ê²° ë°©ë²•ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤ (í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜)',
  inputSchema: z.object({
    query: z.string().describe('ê²€ìƒ‰ ì¿¼ë¦¬'),
  }),
  execute: async ({ query }: { query: string }) => {
    // ğŸ’¡ í¬íŠ¸í´ë¦¬ì˜¤: Mock ì§€ì‹ë² ì´ìŠ¤
    const mockKnowledge = [
      {
        incident: 'CPU ê³¼ë¶€í•˜',
        solution: 'PM2 í´ëŸ¬ìŠ¤í„° ëª¨ë“œ í™•ì¥ ë° ë¡œë“œë°¸ëŸ°ì‹± ì ìš©',
        similarity: 0.92,
        tags: ['cpu', 'performance', 'scaling'],
      },
      {
        incident: 'ë©”ëª¨ë¦¬ ëˆ„ìˆ˜',
        solution: 'Node.js ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ í›„ ìºì‹œ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€',
        similarity: 0.85,
        tags: ['memory', 'leak', 'profiling'],
      },
      {
        incident: 'ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±',
        solution: 'ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì • ë° ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ',
        similarity: 0.78,
        tags: ['disk', 'storage', 'cleanup'],
      },
    ];

    // ì¿¼ë¦¬ í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨í•œ ë§¤ì¹­
    const keywords = query.toLowerCase();
    const matches = mockKnowledge.filter(k => {
      const incidentMatch = k.incident.toLowerCase().includes(keywords);
      const tagMatch = k.tags.some(tag => keywords.includes(tag));
      return incidentMatch || tagMatch;
    });

    const results = matches.length > 0 ? matches : mockKnowledge;

    return {
      success: true,
      query,
      results: results.slice(0, 3).map(r => ({
        incident: r.incident,
        solution: r.solution,
        relevance: r.similarity,
        tags: r.tags,
      })),
      totalMatches: results.length,
      timestamp: new Date().toISOString(),
      _simulation: true,
      _note: 'í¬íŠ¸í´ë¦¬ì˜¤ìš© Mock ì§€ì‹ë² ì´ìŠ¤ (ì‹¤ì œë¡œëŠ” Supabase pgvector RAG)',
    };
  },
});

/**
 * ğŸ“ˆ Tool 4: ì„œë²„ ìƒíƒœ ì¢…í•© ë¶„ì„
 * í†µê³„ ê¸°ë°˜ ê±´ê°•ë„ ë¶„ì„
 */
const analyzeServerHealth = tool({
  description: 'ì „ì²´ ì„œë²„ì˜ ê±´ê°•ë„ë¥¼ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤ (í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜)',
  inputSchema: z.object({}),
  execute: async () => {
    // ğŸ¯ ê¸°ì¡´ 15ê°œ ì„œë²„ ë°ì´í„° ë¡œë“œ
    const allServers = await loadHourlyScenarioData();

    // ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚° (0-100)
    const healthScore = allServers.reduce((sum, s) => {
      const cpuScore = (100 - s.cpu) / 100;
      const memScore = (100 - s.memory) / 100;
      const diskScore = (100 - s.disk) / 100;
      return sum + (cpuScore + memScore + diskScore) / 3;
    }, 0) / allServers.length;

    const criticalServers = allServers.filter(s => s.status === 'critical');
    const warningServers = allServers.filter(s => s.status === 'warning');
    const healthyServers = allServers.filter(s => s.status === 'online');

    // ê¶Œì¥ì‚¬í•­ ìƒì„±
    const recommendations = [
      healthScore < 0.6 ? 'ì¼ë¶€ ì„œë²„ ë¦¬ì†ŒìŠ¤ í™•ì¥ í•„ìš”' : null,
      allServers.some(s => s.cpu > 80) ? 'CPU ë¶€í•˜ ë¶„ì‚° ê¶Œì¥' : null,
      allServers.some(s => s.memory > 85) ? 'ë©”ëª¨ë¦¬ ìµœì í™” í•„ìš”' : null,
      criticalServers.length > 0 ? `ê¸´ê¸‰: ${criticalServers.length}ëŒ€ ì„œë²„ ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”` : null,
    ].filter(Boolean);

    return {
      success: true,
      analysis: {
        overallHealth: Number((healthScore * 100).toFixed(1)),
        healthGrade: healthScore > 0.8 ? 'A' : healthScore > 0.6 ? 'B' : healthScore > 0.4 ? 'C' : 'D',
        serverCount: {
          total: allServers.length,
          healthy: healthyServers.length,
          warning: warningServers.length,
          critical: criticalServers.length,
        },
        recommendations,
      },
      timestamp: new Date().toISOString(),
      _dataSource: 'scenario-loader (15 servers)',
    };
  },
});

// ============================================================================
// ğŸ§  Extended Thinking Tools - AI ì‚¬ê³  ê³¼ì • ì‹œê°í™”
// ============================================================================

/**
 * ğŸ’¡ Thinking Tool 1: ì§ˆë¬¸ ì˜ë„ ë¶„ì„
 */
const analyzeIntent = tool({
  description: 'ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    query: z.string().describe('ì‚¬ìš©ì ì§ˆë¬¸'),
  }),
  execute: async ({ query }: { query: string }) => {
    const lowerQuery = query.toLowerCase();

    // í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜
    let intent = 'general';
    let category = 'information';
    let confidence = 0.7;

    if (lowerQuery.includes('cpu') || lowerQuery.includes('ë©”ëª¨ë¦¬') || lowerQuery.includes('ë””ìŠ¤í¬')) {
      intent = 'metric_query';
      category = 'monitoring';
      confidence = 0.9;
    } else if (lowerQuery.includes('ìƒíƒœ') || lowerQuery.includes('status')) {
      intent = 'status_check';
      category = 'monitoring';
      confidence = 0.85;
    } else if (lowerQuery.includes('ì¥ì• ') || lowerQuery.includes('ì—ëŸ¬') || lowerQuery.includes('ë¬¸ì œ')) {
      intent = 'incident_analysis';
      category = 'troubleshooting';
      confidence = 0.9;
    } else if (lowerQuery.includes('ì˜ˆì¸¡') || lowerQuery.includes('ê°€ëŠ¥ì„±')) {
      intent = 'prediction';
      category = 'analytics';
      confidence = 0.85;
    } else if (lowerQuery.includes('ìµœì í™”') || lowerQuery.includes('ê°œì„ ')) {
      intent = 'optimization';
      category = 'improvement';
      confidence = 0.8;
    }

    return {
      intent,
      category,
      confidence,
      reasoning: `ì§ˆë¬¸ì—ì„œ "${intent}" ì˜ë„ë¥¼ ê°ì§€í–ˆìŠµë‹ˆë‹¤.`,
      suggestedTools: intent === 'metric_query' ? ['getServerMetrics'] :
                      intent === 'prediction' ? ['predictIncident'] :
                      intent === 'incident_analysis' ? ['searchKnowledgeBase'] : [],
    };
  },
});

/**
 * ğŸ’¡ Thinking Tool 2: ë³µì¡ë„ ë¶„ì„
 */
const analyzeComplexity = tool({
  description: 'ì§ˆë¬¸ì˜ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì  ì²˜ë¦¬ ì „ëµì„ ê²°ì •í•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    query: z.string().describe('ì‚¬ìš©ì ì§ˆë¬¸'),
    intent: z.string().optional().describe('ë¶„ì„ëœ ì˜ë„'),
  }),
  execute: async ({ query, intent }: { query: string; intent?: string }) => {
    const words = query.split(' ').length;
    const hasMultipleQuestions = query.includes('?') && query.split('?').length > 2;
    const requiresAggregation = query.includes('ì „ì²´') || query.includes('ëª¨ë“ ') || query.includes('ì¢…í•©');

    // ë³µì¡ë„ ì ìˆ˜ (1-5)
    let score = 1;
    if (words > 20) score += 1;
    if (hasMultipleQuestions) score += 1;
    if (requiresAggregation) score += 1;
    if (intent === 'incident_analysis' || intent === 'optimization') score += 1;

    const recommendation = score >= 4 ? 'multi-tool' :
                          score >= 3 ? 'single-tool' :
                          'direct-answer';

    return {
      score,
      level: score >= 4 ? 'complex' : score >= 3 ? 'moderate' : 'simple',
      recommendation,
      reasoning: `ì§ˆë¬¸ ê¸¸ì´ ${words}ë‹¨ì–´, ë³µì¡ë„ ${score}/5ì ìœ¼ë¡œ "${recommendation}" ì „ëµì„ ê¶Œì¥í•©ë‹ˆë‹¤.`,
      estimatedTools: score >= 4 ? 3 : score >= 3 ? 1 : 0,
    };
  },
});

/**
 * ğŸ’¡ Thinking Tool 3: ë¼ìš°íŒ… ê²°ì •
 */
const selectRoute = tool({
  description: 'ìµœì ì˜ ì²˜ë¦¬ ê²½ë¡œë¥¼ ì„ íƒí•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    complexity: z.number().describe('ë³µì¡ë„ ì ìˆ˜ (1-5)'),
    intent: z.string().describe('ì§ˆë¬¸ ì˜ë„'),
  }),
  execute: async ({ complexity, intent }: { complexity: number; intent: string }) => {
    const route = complexity >= 4 ? 'comprehensive-analysis' :
                  complexity >= 3 ? 'targeted-query' :
                  'quick-response';

    const toolSequence =
      intent === 'prediction' ? ['getServerMetrics', 'predictIncident'] :
      intent === 'incident_analysis' ? ['searchKnowledgeBase', 'getServerMetrics'] :
      intent === 'optimization' ? ['analyzeServerHealth', 'searchKnowledgeBase'] :
      ['getServerMetrics'];

    const costEstimate = complexity >= 4 ? '$0.003' :
                        complexity >= 3 ? '$0.001' :
                        '$0';

    return {
      route,
      strategy: complexity >= 4 ? 'Multi-tool ì¢…í•© ë¶„ì„' :
               complexity >= 3 ? 'Single-tool íƒ€ê²ŸíŒ…' :
               'Direct ì¦‰ì‹œ ì‘ë‹µ',
      toolSequence,
      reasoning: `ë³µì¡ë„ ${complexity}ì , ${intent} ì˜ë„ â†’ "${route}" ê²½ë¡œ ì„ íƒ`,
      costEstimate,
      freeOptimized: costEstimate === '$0',
    };
  },
});

/**
 * ğŸ’¡ Thinking Tool 4: ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
 */
const searchContext = tool({
  description: 'ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    query: z.string().describe('ê²€ìƒ‰ ì¿¼ë¦¬'),
    scope: z.enum(['servers', 'knowledge', 'history']).describe('ê²€ìƒ‰ ë²”ìœ„'),
  }),
  execute: async ({ query, scope }: { query: string; scope: 'servers' | 'knowledge' | 'history' }) => {
    const results = {
      servers: {
        found: 4,
        relevant: ['server-2', 'server-4'],
        summary: '2ëŒ€ ì„œë²„ì—ì„œ ê´€ë ¨ ë©”íŠ¸ë¦­ ë°œê²¬',
      },
      knowledge: {
        found: 3,
        relevant: ['CPU ê³¼ë¶€í•˜', 'ë©”ëª¨ë¦¬ ëˆ„ìˆ˜'],
        summary: 'ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ 2ê±´ ë°œê²¬',
      },
      history: {
        found: 5,
        relevant: ['2024-11-20 ì¥ì• ', '2024-11-15 ìµœì í™”'],
        summary: 'ìµœê·¼ 2ì£¼ ë‚´ ê´€ë ¨ ì´ë²¤íŠ¸ 2ê±´',
      },
    };

    const result = results[scope];

    return {
      scope,
      ...result,
      reasoning: `"${scope}" ë²”ìœ„ì—ì„œ ${result.found}ê±´ ê²€ìƒ‰, ${result.relevant.length}ê±´ ê´€ë ¨`,
      confidence: result.relevant.length / result.found,
    };
  },
});

/**
 * ğŸ’¡ Thinking Tool 5: ì¸ì‚¬ì´íŠ¸ ìƒì„±
 */
const generateInsight = tool({
  description: 'ìˆ˜ì§‘ëœ ë°ì´í„°ì—ì„œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    dataPoints: z.array(z.string()).describe('ìˆ˜ì§‘ëœ ë°ì´í„° í¬ì¸íŠ¸'),
  }),
  execute: async ({ dataPoints }: { dataPoints: string[] }) => {
    const insights = [];

    if (dataPoints.some(d => d.includes('cpu') || d.includes('CPU'))) {
      insights.push({
        type: 'performance',
        message: 'CPU ì‚¬ìš©ë¥  íŒ¨í„´ ë¶„ì„ ì™„ë£Œ',
        priority: 'medium',
      });
    }

    if (dataPoints.some(d => d.includes('critical') || d.includes('warning'))) {
      insights.push({
        type: 'alert',
        message: 'ê¸´ê¸‰ ì¡°ì¹˜ í•„ìš” ì„œë²„ ê°ì§€',
        priority: 'high',
      });
    }

    if (dataPoints.length >= 3) {
      insights.push({
        type: 'correlation',
        message: 'ì—¬ëŸ¬ ë©”íŠ¸ë¦­ ê°„ ìƒê´€ê´€ê³„ ë°œê²¬',
        priority: 'low',
      });
    }

    return {
      insights,
      count: insights.length,
      summary: `${dataPoints.length}ê°œ ë°ì´í„° í¬ì¸íŠ¸ì—ì„œ ${insights.length}ê°œ ì¸ì‚¬ì´íŠ¸ ìƒì„±`,
      reasoning: 'ë°ì´í„° íŒ¨í„´ ë¶„ì„ ë° ìš°ì„ ìˆœìœ„ ë¶„ë¥˜ ì™„ë£Œ',
    };
  },
});

/**
 * POST í•¸ë“¤ëŸ¬ - Vercel AI SDK streamText ì‚¬ìš©
 */
export async function POST(req: Request) {
  try {
    const { messages } = await req.json();
    const apiKey = getGoogleAIKey();

    if (!apiKey) {
      return new Response('Google AI API Key not found', { status: 500 });
    }

    // ğŸš€ Vercel AI SDK streamText
    const result = streamText({
      model: google('gemini-1.5-flash'),
      messages,
      tools: {
        // ğŸ§  Extended Thinking Tools (5ê°œ)
        analyzeIntent,
        analyzeComplexity,
        selectRoute,
        searchContext,
        generateInsight,
        // ğŸ“Š Action Tools (4ê°œ)
        getServerMetrics,
        predictIncident,
        searchKnowledgeBase,
        analyzeServerHealth,
      },
      system: `ë‹¹ì‹ ì€ ì„œë²„ ëª¨ë‹ˆí„°ë§ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ğŸ§  Thinking Process (ì‚¬ê³  ê³¼ì • ì‹œê°í™”)**
ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ì „, ë‹¤ìŒ ìˆœì„œë¡œ Extended Thinking Toolsë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ê³  ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”:

1. **analyzeIntent**: ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¨¼ì € ë¶„ì„í•©ë‹ˆë‹¤
2. **analyzeComplexity**: ì§ˆë¬¸ì˜ ë³µì¡ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤
3. **selectRoute**: ìµœì ì˜ ì²˜ë¦¬ ì „ëµì„ ê²°ì •í•©ë‹ˆë‹¤
4. **searchContext**: (í•„ìš”ì‹œ) ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤
5. **Action Tools ì‹¤í–‰**: ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ (getServerMetrics, predictIncident ë“±)
6. **generateInsight**: ìˆ˜ì§‘ëœ ë°ì´í„°ì—ì„œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤

**í¬íŠ¸í´ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸:**
- ì„œë²„ ë©”íŠ¸ë¦­ì€ Mock ë°ì´í„° (24ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜)
- ML ì¥ì•  ì˜ˆì¸¡ì€ ì‹¤ì œ GCP Cloud Functions í˜¸ì¶œ
- ì „ë¬¸ì ì´ê³  ëª…í™•í•œ í•œêµ­ì–´ë¡œ ë‹µë³€

**ì‚¬ìš© ê°€ëŠ¥í•œ Tools (9ê°œ):**

ğŸ§  **Thinking Tools** (ì‚¬ê³  ê³¼ì •):
1. analyzeIntent - ì§ˆë¬¸ ì˜ë„ ë¶„ì„
2. analyzeComplexity - ë³µì¡ë„ ë¶„ì„
3. selectRoute - ë¼ìš°íŒ… ê²°ì •
4. searchContext - ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
5. generateInsight - ì¸ì‚¬ì´íŠ¸ ìƒì„±

ğŸ“Š **Action Tools** (ë°ì´í„° ìˆ˜ì§‘):
6. getServerMetrics - ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ
7. predictIncident - ML ì¥ì•  ì˜ˆì¸¡ (GCP)
8. searchKnowledgeBase - RAG ì§€ì‹ë² ì´ìŠ¤
9. analyzeServerHealth - ì¢…í•© ê±´ê°•ë„ ë¶„ì„

**ë‹µë³€ ìŠ¤íƒ€ì¼:**
- ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •ì„ íˆ¬ëª…í•˜ê²Œ ê³µê°œ
- ë°ì´í„° ê¸°ë°˜ì˜ êµ¬ì²´ì ì¸ ë¶„ì„
- ëª…í™•í•œ ê¶Œì¥ì‚¬í•­ ë° ìš°ì„ ìˆœìœ„ ì œì‹œ
- ë¹„ìš© íš¨ìœ¨ì ì¸ ë„êµ¬ ì„ íƒ ê°•ì¡°`,
    });

    return result.toTextStreamResponse();
  } catch (error) {
    console.error('âŒ AI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹¤íŒ¨:', error);
    return new Response('AI streaming failed', { status: 500 });
  }
}
