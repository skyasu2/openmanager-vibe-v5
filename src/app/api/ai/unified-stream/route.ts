/**
 * Unified AI Stream API Route
 * LangGraph Multi-Agent Systemì„ ì‚¬ìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
 *
 * Architecture (Hybrid Mode):
 * - Cloud Run AI Backend (CLOUD_RUN_ENABLED=true): ì™¸ë¶€ Cloud Runìœ¼ë¡œ í”„ë¡ì‹œ
 * - Local Mode (default): Next.js ë‚´ì¥ LangGraph ì‚¬ìš©
 *
 * Agents:
 * - Supervisor (Groq Llama-8b): ë¹ ë¥¸ ì¸í…íŠ¸ ë¶„ë¥˜ ë° ë¼ìš°íŒ…
 * - NLQ Agent (Gemini Flash): ì„œë²„ ë©”íŠ¸ë¦­ ì¡°íšŒ
 * - Analyst Agent (Gemini Pro): íŒ¨í„´ ë¶„ì„ ë° ì´ìƒ íƒì§€
 * - Reporter Agent (Llama 70b): ì¸ì‹œë˜íŠ¸ ë¦¬í¬íŠ¸ ë° RAG
 */

import type { NextRequest } from 'next/server';
import { z } from 'zod';
import { withAuth } from '@/lib/auth/api-auth';
import {
  isCloudRunEnabled,
  proxyStreamToCloudRun,
  proxyToCloudRun,
} from '@/lib/cloud-run/proxy';
import {
  createStreamingResponse,
  executeGraph,
} from '@/services/langgraph/graph-builder';
import { quickFilter, quickSanitize } from './security';

// Allow streaming responses up to 60 seconds
export const maxDuration = 60;

// ============================================================================
// ğŸ“‹ Request Schema (Zod Validation)
// ============================================================================

// AI SDK v5 UIMessage 'parts' í¬ë§·
const textPartSchema = z.object({
  type: z.literal('text'),
  text: z.string(),
});

const partSchema = z.discriminatedUnion('type', [
  textPartSchema,
  // ë‹¤ë¥¸ part íƒ€ì…ë“¤ (tool-invocation, tool-result ë“±)ì€ ë¬´ì‹œ
  z
    .object({ type: z.literal('tool-invocation') })
    .passthrough(),
  z.object({ type: z.literal('tool-result') }).passthrough(),
  z.object({ type: z.literal('file') }).passthrough(),
  z.object({ type: z.literal('reasoning') }).passthrough(),
]);

// í•˜ì´ë¸Œë¦¬ë“œ ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ: AI SDK v5 (parts) + ë ˆê±°ì‹œ (content) ëª¨ë‘ ì§€ì›
const messageSchema = z.object({
  id: z.string().optional(),
  role: z.enum(['user', 'assistant', 'system']),
  // AI SDK v5: parts ë°°ì—´ (UIMessage í¬ë§·)
  parts: z.array(partSchema).optional(),
  // ë ˆê±°ì‹œ: content ë¬¸ìì—´
  content: z.string().optional(),
  // ì¶”ê°€ ë©”íƒ€ë°ì´í„° í—ˆìš©
  createdAt: z.union([z.string(), z.date()]).optional(),
});

const requestSchema = z.object({
  messages: z.array(messageSchema).min(1).max(50),
  sessionId: z.string().optional(),
});

// ============================================================================
// ğŸ”§ Utility: UIMessageì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
// ============================================================================

/**
 * AI SDK v5 UIMessage ë˜ëŠ” ë ˆê±°ì‹œ ë©”ì‹œì§€ì—ì„œ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ì¶”ì¶œ
 */
function extractTextFromMessage(
  message: z.infer<typeof messageSchema>
): string {
  // 1. AI SDK v5 parts ë°°ì—´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  if (message.parts && Array.isArray(message.parts)) {
    const textParts = message.parts
      .filter(
        (part): part is z.infer<typeof textPartSchema> => part.type === 'text'
      )
      .map((part) => part.text);
    if (textParts.length > 0) {
      return textParts.join('\n');
    }
  }

  // 2. ë ˆê±°ì‹œ content í•„ë“œ ì‚¬ìš©
  if (typeof message.content === 'string') {
    return message.content;
  }

  return '';
}

// ============================================================================
// ğŸ§  Main Handler - LangGraph Multi-Agent System
// ============================================================================

export const POST = withAuth(async (req: NextRequest) => {
  try {
    // 1. Zod ìŠ¤í‚¤ë§ˆ ê²€ì¦
    const body = await req.json();
    const parseResult = requestSchema.safeParse(body);

    if (!parseResult.success) {
      console.warn(
        'âš ï¸ [Unified-Stream] Invalid payload:',
        parseResult.error.issues
      );
      return new Response(
        JSON.stringify({
          success: false,
          error: 'Invalid request payload',
          details: parseResult.error.issues.map((i) => i.message).join(', '),
        }),
        {
          status: 400,
          headers: { 'Content-Type': 'application/json' },
        }
      );
    }

    const { messages, sessionId: clientSessionId } = parseResult.data;

    // 2. ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ + ì…ë ¥ ì •ì œ
    const lastMessage =
      messages.length > 0 ? messages[messages.length - 1] : null;
    const rawQuery = lastMessage
      ? extractTextFromMessage(lastMessage)
      : 'System status check';

    // ë¹ˆ ì¿¼ë¦¬ ë°©ì–´
    if (!rawQuery || rawQuery.trim() === '') {
      return new Response(
        JSON.stringify({
          success: false,
          error: 'Empty query',
          message: 'ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.',
        }),
        {
          status: 400,
          headers: { 'Content-Type': 'application/json' },
        }
      );
    }

    const userQuery = quickSanitize(rawQuery);

    // 2. ì„¸ì…˜ ID ìƒì„±/ì‚¬ìš©
    const sessionId = clientSessionId || `session_${Date.now()}`;

    console.log(`ğŸš€ [Unified-Stream] Query: "${userQuery.slice(0, 50)}..."`);
    console.log(`ğŸ“¡ [Unified-Stream] Session: ${sessionId}`);

    // 3. ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì—¬ë¶€ í™•ì¸
    const acceptHeader = req.headers.get('accept') || '';
    const wantsStream =
      acceptHeader.includes('text/event-stream') ||
      acceptHeader.includes('text/plain');

    // 4. Cloud Run í”„ë¡ì‹œ ëª¨ë“œ (CLOUD_RUN_ENABLED=true)
    if (isCloudRunEnabled()) {
      console.log('â˜ï¸ [Unified-Stream] Using Cloud Run backend');

      if (wantsStream) {
        // Cloud Run ìŠ¤íŠ¸ë¦¬ë° í”„ë¡ì‹œ
        const cloudStream = await proxyStreamToCloudRun({
          path: '/api/ai/unified-stream',
          body: { messages, sessionId },
        });

        if (cloudStream) {
          return new Response(cloudStream, {
            headers: {
              'Content-Type': 'text/plain; charset=utf-8',
              'Cache-Control': 'no-cache',
              Connection: 'keep-alive',
              'X-Session-Id': sessionId,
              'X-Backend': 'cloud-run',
            },
          });
        }
        // Cloud Run ì‹¤íŒ¨ ì‹œ ë¡œì»¬ë¡œ í´ë°±
        console.warn('âš ï¸ Cloud Run stream failed, falling back to local');
      } else {
        // Cloud Run ë‹¨ì¼ ì‘ë‹µ í”„ë¡ì‹œ
        const proxyResult = await proxyToCloudRun({
          path: '/api/ai/unified-stream',
          body: { messages, sessionId },
        });

        if (proxyResult.success && proxyResult.data) {
          return Response.json({
            ...proxyResult.data,
            _backend: 'cloud-run',
          });
        }
        // Cloud Run ì‹¤íŒ¨ ì‹œ ë¡œì»¬ë¡œ í´ë°±
        console.warn('âš ï¸ Cloud Run request failed, falling back to local');
      }
    }

    // 5. ë¡œì»¬ ëª¨ë“œ (Next.js ë‚´ì¥ LangGraph)
    if (wantsStream) {
      // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (LangGraph streamEvents ì‚¬ìš©)
      try {
        const stream = await createStreamingResponse(userQuery, sessionId);

        return new Response(stream, {
          headers: {
            'Content-Type': 'text/plain; charset=utf-8',
            'Cache-Control': 'no-cache',
            Connection: 'keep-alive',
            'X-Session-Id': sessionId,
            'X-Backend': 'local',
          },
        });
      } catch (streamError) {
        console.error('âŒ Streaming Error:', streamError);
        // ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨ ì‹œ ë‹¨ì¼ ì‘ë‹µìœ¼ë¡œ í´ë°±
        const result = await executeGraph(userQuery, { sessionId });
        return new Response(result.response, {
          status: 200,
          headers: {
            'Content-Type': 'text/plain; charset=utf-8',
            'X-Session-Id': sessionId,
            'X-Target-Agent': result.targetAgent || 'unknown',
            'X-Backend': 'local',
          },
        });
      }
    } else {
      // ë‹¨ì¼ ì‘ë‹µ (invoke ì‚¬ìš©)
      const result = await executeGraph(userQuery, { sessionId });

      return Response.json({
        success: true,
        response: quickFilter(result.response),
        toolResults: result.toolResults,
        targetAgent: result.targetAgent,
        sessionId: result.sessionId,
        _backend: 'local',
      });
    }
  } catch (error) {
    console.error('âŒ AI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹¤íŒ¨:', error);

    // ì—ëŸ¬ ìƒì„¸ ì •ë³´ ë¡œê¹…
    if (error instanceof Error) {
      console.error('Error details:', {
        name: error.name,
        message: error.message,
        stack: error.stack?.slice(0, 500),
      });
    }

    return new Response(
      JSON.stringify({
        success: false,
        error: 'AI processing failed',
        message:
          error instanceof Error ? error.message : 'Unknown error occurred',
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' },
      }
    );
  }
});

// ============================================================================
// ğŸ“Š Legacy Tools Reference (Now integrated in LangGraph Agents)
// ============================================================================
//
// The following tools have been migrated to LangGraph agents:
//
// 1. getServerMetrics -> NLQ Agent (nlq-agent.ts)
//    - Queries server CPU/memory/disk status from scenario data
//
// 2. searchKnowledgeBase -> Reporter Agent (reporter-agent.ts)
//    - RAG search using Supabase pgvector (384 dimensions)
//
// 3. analyzePattern -> Analyst Agent (analyst-agent.ts)
//    - Pattern matching for system performance queries
//
// 4. recommendCommands -> Reporter Agent (reporter-agent.ts)
//    - CLI command recommendations based on keywords
//
// ============================================================================
