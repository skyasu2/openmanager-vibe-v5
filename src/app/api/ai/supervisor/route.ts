/**
 * Cloud Run AI Supervisor Proxy
 *
 * @endpoint POST /api/ai/supervisor
 *
 * Architecture (2025-12-17):
 * - Primary: Cloud Run ai-engine (LangGraph Multi-Agent)
 * - Fallback: Simple error response (no local LangGraph)
 *
 * Note: Vercel LangGraph removed to reduce bundle size (~2MB)
 * and simplify architecture. All AI processing handled by Cloud Run.
 *
 * Changes (2025-12-22 v5.83.9):
 * - Added normalizeMessagesForCloudRun(): AI SDK v5 parts[] â†’ Cloud Run content ë³€í™˜
 * - Added sessionId query parameter ì§€ì› (TextStreamChatTransport í˜¸í™˜)
 * - ë¬¸ì œ: AI SDK v5ëŠ” parts ë°°ì—´ í˜•ì‹, Cloud Runì€ content ë¬¸ìì—´ ê¸°ëŒ€
 * - í•´ê²°: ë©”ì‹œì§€ ì •ê·œí™” + transport í˜¸í™˜ì„± ê°œì„ 
 */

import type { NextRequest } from 'next/server';
import { NextResponse } from 'next/server';
import { z } from 'zod';
import { isCloudRunEnabled, proxyToCloudRun } from '@/lib/ai-proxy/proxy';
import { withAuth } from '@/lib/auth/api-auth';
import { rateLimiters, withRateLimit } from '@/lib/security/rate-limiter';
import { quickSanitize } from './security';

// ============================================================================
// ğŸ”§ Stream Transformer: Vercel Data Stream Protocol â†’ Plain Text
// ============================================================================
// Cloud Runì´ ë°˜í™˜í•˜ëŠ” Data Stream Protocolì„ íŒŒì‹±í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
//
// @see https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol
// ============================================================================

/**
 * Vercel AI SDK Data Stream Protocol ìƒìˆ˜
 *
 * @warning ì´ í”„ë¡œí† ì½œì€ Vercel AI SDK ë²„ì „ì— ì˜ì¡´í•©ë‹ˆë‹¤.
 *          SDK ì—…ê·¸ë ˆì´ë“œ ì‹œ í˜¸í™˜ì„± í™•ì¸ í•„ìš”
 *
 * @see https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol
 */
const DATA_STREAM_PREFIXES = {
  TEXT: '0', // í…ìŠ¤íŠ¸ ì½˜í…ì¸  (ì£¼ìš”)
  DATA: '2', // JSON ë°ì´í„° ë°°ì—´
  ERROR: '3', // ì—ëŸ¬ ë©”ì‹œì§€
  ANNOTATION: '8', // ë©”ì‹œì§€ ì£¼ì„
  FINISH: 'd', // ì™„ë£Œ ì‹ í˜¸
  START: 'e', // ì‹œì‘ ì‹ í˜¸
} as const;

/**
 * Data Stream Protocol ë¼ì¸ íŒŒì‹± ì •ê·œì‹
 *
 * @pattern ^(prefix):(content)$
 * - prefix: ìˆ«ì ë˜ëŠ” ì•ŒíŒŒë²³ í•œ ê¸€ì
 * - content: JSON ë¬¸ìì—´ ë˜ëŠ” ê°ì²´
 *
 * @fragility ì´ ì •ê·œì‹ì€ SDK í”„ë¡œí† ì½œ ë³€ê²½ì— ì·¨ì•½í•©ë‹ˆë‹¤.
 *            SDK ë²„ì „ ì—…ê·¸ë ˆì´ë“œ ì‹œ ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸ í•„ìš”
 */
const DATA_STREAM_LINE_REGEX = /^([0-9a-z]):(.*)$/;

/**
 * Data Stream Protocolì„ Plain Textë¡œ ë³€í™˜í•˜ëŠ” TransformStream
 *
 * @description
 * Cloud Runì´ ë°˜í™˜í•˜ëŠ” `0:"í…ìŠ¤íŠ¸"` í˜•ì‹ì„ íŒŒì‹±í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
 * TextStreamChatTransportì™€ í•¨ê»˜ ì‚¬ìš©ë©ë‹ˆë‹¤.
 *
 * @example
 * Input:  0:"Hello "\n0:"World"\nd:{"finishReason":"stop"}
 * Output: Hello World
 *
 * @warning
 * - Vercel AI SDK v5 Data Stream Protocolì— ì˜ì¡´
 * - Cloud Run ì‘ë‹µ í˜•ì‹ ë³€ê²½ ì‹œ íŒŒì‹± ì‹¤íŒ¨ ê°€ëŠ¥
 * - ì¥ê¸°ì ìœ¼ë¡œ SDKì˜ ê³µì‹ íŒŒì„œ ì‚¬ìš© ê¶Œì¥
 */
// NOTE: Reserved for future streaming implementation
function _createDataStreamParserTransform(): TransformStream<
  Uint8Array,
  Uint8Array
> {
  const decoder = new TextDecoder();
  const encoder = new TextEncoder();
  let buffer = '';

  /**
   * JSON ë¬¸ìì—´ ì•ˆì „í•˜ê²Œ íŒŒì‹±
   */
  const safeJsonParse = (str: string): unknown => {
    try {
      return JSON.parse(str);
    } catch {
      return null;
    }
  };

  /**
   * í…ìŠ¤íŠ¸ ì½˜í…ì¸  ì¶”ì¶œ (prefix: 0)
   */
  const extractTextContent = (content: string): string | null => {
    const parsed = safeJsonParse(content);
    if (typeof parsed === 'string') {
      return parsed;
    }
    // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ raw content ë°˜í™˜ (fallback)
    if (content.startsWith('"') && content.endsWith('"')) {
      return content.slice(1, -1);
    }
    return null;
  };

  /**
   * ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ (prefix: 3)
   */
  const extractErrorMessage = (content: string): string => {
    const parsed = safeJsonParse(content);

    if (typeof parsed === 'string') {
      // ì¤‘ì²©ëœ JSON ì—ëŸ¬ ì²˜ë¦¬
      const innerParsed = safeJsonParse(parsed);
      if (
        innerParsed &&
        typeof innerParsed === 'object' &&
        'error' in innerParsed
      ) {
        const errorObj = innerParsed as { error?: { message?: string } };
        return errorObj.error?.message || parsed;
      }
      return parsed;
    }

    if (parsed && typeof parsed === 'object' && 'message' in parsed) {
      return (parsed as { message: string }).message;
    }

    return content;
  };

  return new TransformStream({
    transform(chunk, controller) {
      buffer += decoder.decode(chunk, { stream: true });

      const lines = buffer.split('\n');
      buffer = lines.pop() || ''; // ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ë¼ì¸ì€ ë²„í¼ì— ìœ ì§€

      for (const line of lines) {
        const trimmed = line.trim();
        if (!trimmed) continue;

        const match = trimmed.match(DATA_STREAM_LINE_REGEX);
        if (!match?.[1] || match[2] === undefined) continue;

        const prefix = match[1];
        const content = match[2];

        switch (prefix) {
          case DATA_STREAM_PREFIXES.TEXT: {
            const text = extractTextContent(content);
            if (text) {
              controller.enqueue(encoder.encode(text));
            }
            break;
          }

          case DATA_STREAM_PREFIXES.ERROR: {
            const errorMsg = extractErrorMessage(content);
            controller.enqueue(encoder.encode(`\n\nâš ï¸ AI ì˜¤ë¥˜: ${errorMsg}`));
            break;
          }

          // DATA, ANNOTATION, FINISH, START: ë©”íƒ€ë°ì´í„°ëŠ” ë¬´ì‹œ
          // í•„ìš” ì‹œ ì—¬ê¸°ì— ì¶”ê°€ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥
        }
      }
    },

    flush(controller) {
      // ë²„í¼ì— ë‚¨ì€ ë¶ˆì™„ì „í•œ ë¼ì¸ ì²˜ë¦¬
      if (buffer.trim()) {
        const match = buffer.trim().match(DATA_STREAM_LINE_REGEX);
        if (match?.[1] === DATA_STREAM_PREFIXES.TEXT && match[2]) {
          const text = extractTextContent(match[2]);
          if (text) {
            controller.enqueue(encoder.encode(text));
          }
        }
      }
    },
  });
}

// Allow streaming responses up to 120 seconds (Vercel Pro: max 300s)
// Note: Increased from 60s to handle complex NLQ queries with tool calls
// Supervisor â†’ Agent â†’ Tool â†’ Verifier pipeline can take 60-90s
export const maxDuration = 120;

// ============================================================================
// ğŸ“‹ Request Schema (Zod Validation)
// ============================================================================

// AI SDK v5 UIMessage 'parts' í¬ë§·
const textPartSchema = z.object({
  type: z.literal('text'),
  text: z.string(),
});

const partSchema = z.discriminatedUnion('type', [
  textPartSchema,
  // ë‹¤ë¥¸ part íƒ€ì…ë“¤ (tool-invocation, tool-result ë“±)ì€ ë¬´ì‹œ
  z
    .object({ type: z.literal('tool-invocation') })
    .passthrough(),
  z.object({ type: z.literal('tool-result') }).passthrough(),
  z.object({ type: z.literal('file') }).passthrough(),
  z.object({ type: z.literal('reasoning') }).passthrough(),
]);

// í•˜ì´ë¸Œë¦¬ë“œ ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ: AI SDK v5 (parts) + ë ˆê±°ì‹œ (content) ëª¨ë‘ ì§€ì›
const messageSchema = z.object({
  id: z.string().optional(),
  role: z.enum(['user', 'assistant', 'system']),
  // AI SDK v5: parts ë°°ì—´ (UIMessage í¬ë§·)
  parts: z.array(partSchema).optional(),
  // ë ˆê±°ì‹œ: content ë¬¸ìì—´
  content: z.string().optional(),
  // ì¶”ê°€ ë©”íƒ€ë°ì´í„° í—ˆìš©
  createdAt: z.union([z.string(), z.date()]).optional(),
});

const requestSchema = z.object({
  messages: z.array(messageSchema).min(1).max(50),
  sessionId: z.string().optional(),
});

// ============================================================================
// ğŸ”§ Utility: UIMessageì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
// ============================================================================

/**
 * AI SDK v5 UIMessage ë˜ëŠ” ë ˆê±°ì‹œ ë©”ì‹œì§€ì—ì„œ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ì¶”ì¶œ
 */
function extractTextFromMessage(
  message: z.infer<typeof messageSchema>
): string {
  // 1. AI SDK v5 parts ë°°ì—´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  if (message.parts && Array.isArray(message.parts)) {
    const textParts = message.parts
      .filter(
        (part): part is z.infer<typeof textPartSchema> => part.type === 'text'
      )
      .map((part) => part.text);
    if (textParts.length > 0) {
      return textParts.join('\n');
    }
  }

  // 2. ë ˆê±°ì‹œ content í•„ë“œ ì‚¬ìš©
  if (typeof message.content === 'string') {
    return message.content;
  }

  return '';
}

/**
 * AI SDK v5 ë©”ì‹œì§€ë¥¼ Cloud Run í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”
 * parts ë°°ì—´ â†’ content ë¬¸ìì—´ë¡œ ë³€í™˜
 *
 * @description (2025-12-22 v5.83.9 ì¶”ê°€)
 * AI SDK v5 UIMessage í˜•ì‹:
 *   { role: 'user', parts: [{ type: 'text', text: '...' }] }
 *
 * Cloud Run ê¸°ëŒ€ í˜•ì‹:
 *   { role: 'user', content: '...' }
 *
 * ì´ í•¨ìˆ˜ê°€ ì—†ìœ¼ë©´ Cloud Runì´ ë¹ˆ ë©”ì‹œì§€ë¡œ ì²˜ë¦¬í•˜ì—¬ 503 ì—ëŸ¬ ë°œìƒ
 *
 * @note (2025-12-23 ê°œì„ )
 * - ë¹ˆ content í•„í„°ë§ ì œê±° â†’ ëŒ€í™” ë§¥ë½ ë³´ì¡´
 * - ì´ë¯¸ì§€/Tool Call ë©”ì‹œì§€ë„ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ë³´ì¡´
 * - Cloud Runì€ ë¹ˆ ë¬¸ìì—´ë„ ì²˜ë¦¬ ê°€ëŠ¥
 */
function normalizeMessagesForCloudRun(
  messages: z.infer<typeof messageSchema>[]
): { role: string; content: string }[] {
  return messages.map((msg) => {
    const content = extractTextFromMessage(msg);

    // ë¹ˆ contentì¸ ê²½ìš° í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš© (ë§¥ë½ ë³´ì¡´)
    // ì´ë¯¸ì§€, Tool Call ë“± ë¹„í…ìŠ¤íŠ¸ ë©”ì‹œì§€ì˜ ìœ„ì¹˜ë¥¼ ìœ ì§€
    if (!content || content.length === 0) {
      return {
        role: msg.role,
        content: '[Non-text content]',
      };
    }

    return {
      role: msg.role,
      content,
    };
  });
}

// ============================================================================
// ğŸ§  Main Handler - LangGraph Multi-Agent System
// ============================================================================

export const POST = withRateLimit(
  rateLimiters.aiAnalysis,
  withAuth(async (req: NextRequest) => {
    try {
      // 1. Zod ìŠ¤í‚¤ë§ˆ ê²€ì¦
      const body = await req.json();
      const parseResult = requestSchema.safeParse(body);

      if (!parseResult.success) {
        console.warn(
          'âš ï¸ [Supervisor] Invalid payload:',
          parseResult.error.issues
        );
        return NextResponse.json(
          {
            success: false,
            error: 'Invalid request payload',
            details: parseResult.error.issues.map((i) => i.message).join(', '),
          },
          { status: 400 }
        );
      }

      const { messages, sessionId: bodySessionId } = parseResult.data;

      // ====================================================================
      // sessionId ì¶”ì¶œ (2025-12-22 v5.83.9 ìˆ˜ì •)
      // ====================================================================
      // TextStreamChatTransportëŠ” body ì „ì†¡ì„ ì§€ì›í•˜ì§€ ì•Šì•„ query param ì‚¬ìš©
      // - í´ë¼ì´ì–¸íŠ¸: /api/ai/supervisor?sessionId=xxx
      // - body.sessionIdëŠ” ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
      // ====================================================================
      const url = new URL(req.url);
      const querySessionId = url.searchParams.get('sessionId');
      const clientSessionId = querySessionId || bodySessionId;

      // 2. ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ + ì…ë ¥ ì •ì œ
      const lastMessage =
        messages.length > 0 ? messages[messages.length - 1] : null;
      const rawQuery = lastMessage
        ? extractTextFromMessage(lastMessage)
        : 'System status check';

      // ë¹ˆ ì¿¼ë¦¬ ë°©ì–´
      if (!rawQuery || rawQuery.trim() === '') {
        return NextResponse.json(
          {
            success: false,
            error: 'Empty query',
            message: 'ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.',
          },
          { status: 400 }
        );
      }

      const userQuery = quickSanitize(rawQuery);

      // 2. ì„¸ì…˜ ID ìƒì„±/ì‚¬ìš©
      const sessionId = clientSessionId || `session_${Date.now()}`;

      console.log(`ğŸš€ [Supervisor] Query: "${userQuery.slice(0, 50)}..."`);
      console.log(`ğŸ“¡ [Supervisor] Session: ${sessionId}`);

      // 3. ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì—¬ë¶€ í™•ì¸
      // AI SDK v5 DefaultChatTransportëŠ” */* ë˜ëŠ” ë‹¤ì–‘í•œ Accept í—¤ë”ë¥¼ ë³´ëƒ„
      // supervisor ì—”ë“œí¬ì¸íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
      // ëª…ì‹œì ìœ¼ë¡œ application/jsonë§Œ ìš”ì²­í•˜ëŠ” ê²½ìš°ì—ë§Œ JSON ì‘ë‹µ
      const acceptHeader = req.headers.get('accept') || '';
      const wantsJsonOnly = acceptHeader === 'application/json';
      const wantsStream = !wantsJsonOnly;

      // 4. Cloud Run í”„ë¡ì‹œ ëª¨ë“œ (Primary - CLOUD_RUN_ENABLED=true)
      if (isCloudRunEnabled()) {
        console.log('â˜ï¸ [Supervisor] Using Cloud Run backend');

        // AI SDK v5 parts í˜•ì‹ â†’ Cloud Run content í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”
        const normalizedMessages = normalizeMessagesForCloudRun(messages);
        console.log(
          `ğŸ“ [Supervisor] Normalized ${messages.length} messages â†’ ${normalizedMessages.length} for Cloud Run`
        );

        if (wantsStream) {
          // ================================================================
          // ğŸ”§ Cloud Run JSON ì‘ë‹µ ì²˜ë¦¬ (2025-12-29 ìˆ˜ì •)
          // ================================================================
          // Cloud Runì€ í˜„ì¬ JSON ì‘ë‹µì„ ë°˜í™˜í•¨ (ìŠ¤íŠ¸ë¦¬ë° ë¯¸êµ¬í˜„)
          // JSON ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ plain textë¡œ ë°˜í™˜
          // ================================================================
          const proxyResult = await proxyToCloudRun({
            path: '/api/ai/supervisor',
            body: { messages: normalizedMessages, sessionId },
            timeout: 90000, // 90ì´ˆ íƒ€ì„ì•„ì›ƒ (ë³µì¡í•œ ì¿¼ë¦¬ ëŒ€ì‘)
          });

          if (proxyResult.success && proxyResult.data) {
            const data = proxyResult.data as {
              success?: boolean;
              response?: string;
              error?: string;
            };

            if (data.success && data.response) {
              // ì„±ê³µ: response í…ìŠ¤íŠ¸ë¥¼ plain textë¡œ ë°˜í™˜
              return new NextResponse(data.response, {
                headers: {
                  'Content-Type': 'text/plain; charset=utf-8',
                  'Cache-Control': 'no-cache',
                  'X-Session-Id': sessionId,
                  'X-Backend': 'cloud-run',
                  'X-Stream-Protocol': 'plain-text',
                },
              });
            } else if (data.error) {
              // ì—ëŸ¬: ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
              return new NextResponse(`âš ï¸ AI ì˜¤ë¥˜: ${data.error}`, {
                headers: {
                  'Content-Type': 'text/plain; charset=utf-8',
                  'X-Session-Id': sessionId,
                  'X-Backend': 'cloud-run',
                },
              });
            }
          }
          // Cloud Run ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ
          console.error('âŒ Cloud Run request failed:', proxyResult.error);
        } else {
          // Cloud Run ë‹¨ì¼ ì‘ë‹µ í”„ë¡ì‹œ
          const proxyResult = await proxyToCloudRun({
            path: '/api/ai/supervisor',
            body: { messages: normalizedMessages, sessionId },
          });

          if (proxyResult.success && proxyResult.data) {
            return NextResponse.json({
              ...(proxyResult.data as object),
              _backend: 'cloud-run',
            });
          }
          // Cloud Run ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ
          console.error('âŒ Cloud Run request failed:', proxyResult.error);
        }
      }

      // 5. Fallback: Cloud Run ë¹„í™œì„±í™” ë˜ëŠ” ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ
      // Note: Vercel LangGraph ì œê±°ë¨ (2025-12-17) - ë²ˆë“¤ ìµœì í™”
      console.warn('âš ï¸ [Supervisor] Cloud Run unavailable, returning error');

      return NextResponse.json(
        {
          success: false,
          error: 'AI service temporarily unavailable',
          message:
            'AI ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
          sessionId,
          _backend: 'fallback-error',
        },
        {
          status: 503,
          headers: {
            'X-Session-Id': sessionId,
            'Retry-After': '30',
          },
        }
      );
    } catch (error) {
      console.error('âŒ AI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹¤íŒ¨:', error);

      // ì—ëŸ¬ ìƒì„¸ ì •ë³´ ë¡œê¹…
      if (error instanceof Error) {
        console.error('Error details:', {
          name: error.name,
          message: error.message,
          stack: error.stack?.slice(0, 500),
        });
      }

      return NextResponse.json(
        {
          success: false,
          error: 'AI processing failed',
          message:
            error instanceof Error ? error.message : 'Unknown error occurred',
        },
        { status: 500 }
      );
    }
  })
);

// ============================================================================
// ğŸ“Š Architecture Note (2025-12-17)
// ============================================================================
//
// All LangGraph agents now run exclusively on Cloud Run ai-engine:
// - Supervisor (Groq Llama-8b): Intent classification & routing
// - NLQ Agent (Gemini Flash): Server metrics queries
// - Analyst Agent (Gemini Pro): Pattern analysis & anomaly detection
// - Reporter Agent (Llama 70b): Incident reports & RAG
//
// Vercel LangGraph code removed to reduce bundle size (~2MB) and
// simplify architecture. This proxy forwards all requests to Cloud Run.
//
// ============================================================================
