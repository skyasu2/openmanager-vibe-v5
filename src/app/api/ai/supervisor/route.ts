/**
 * Cloud Run AI Supervisor Proxy
 *
 * @endpoint POST /api/ai/supervisor
 *
 * Architecture (2025-12-17):
 * - Primary: Cloud Run ai-engine (LangGraph Multi-Agent)
 * - Fallback: Simple error response (no local LangGraph)
 *
 * Note: Vercel LangGraph removed to reduce bundle size (~2MB)
 * and simplify architecture. All AI processing handled by Cloud Run.
 */

import type { NextRequest } from 'next/server';
import { z } from 'zod';
import {
  isCloudRunEnabled,
  proxyStreamToCloudRun,
  proxyToCloudRun,
} from '@/lib/ai-proxy/proxy';
import { withAuth } from '@/lib/auth/api-auth';
import { rateLimiters, withRateLimit } from '@/lib/security/rate-limiter';
import { quickSanitize } from './security';

// Allow streaming responses up to 60 seconds (Vercel Hobby/Pro max duration)
export const maxDuration = 60;

// ============================================================================
// ğŸ“‹ Request Schema (Zod Validation)
// ============================================================================

// AI SDK v5 UIMessage 'parts' í¬ë§·
const textPartSchema = z.object({
  type: z.literal('text'),
  text: z.string(),
});

const partSchema = z.discriminatedUnion('type', [
  textPartSchema,
  // ë‹¤ë¥¸ part íƒ€ì…ë“¤ (tool-invocation, tool-result ë“±)ì€ ë¬´ì‹œ
  z
    .object({ type: z.literal('tool-invocation') })
    .passthrough(),
  z.object({ type: z.literal('tool-result') }).passthrough(),
  z.object({ type: z.literal('file') }).passthrough(),
  z.object({ type: z.literal('reasoning') }).passthrough(),
]);

// í•˜ì´ë¸Œë¦¬ë“œ ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ: AI SDK v5 (parts) + ë ˆê±°ì‹œ (content) ëª¨ë‘ ì§€ì›
const messageSchema = z.object({
  id: z.string().optional(),
  role: z.enum(['user', 'assistant', 'system']),
  // AI SDK v5: parts ë°°ì—´ (UIMessage í¬ë§·)
  parts: z.array(partSchema).optional(),
  // ë ˆê±°ì‹œ: content ë¬¸ìì—´
  content: z.string().optional(),
  // ì¶”ê°€ ë©”íƒ€ë°ì´í„° í—ˆìš©
  createdAt: z.union([z.string(), z.date()]).optional(),
});

const requestSchema = z.object({
  messages: z.array(messageSchema).min(1).max(50),
  sessionId: z.string().optional(),
});

// ============================================================================
// ğŸ”§ Utility: UIMessageì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
// ============================================================================

/**
 * AI SDK v5 UIMessage ë˜ëŠ” ë ˆê±°ì‹œ ë©”ì‹œì§€ì—ì„œ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ì¶”ì¶œ
 */
function extractTextFromMessage(
  message: z.infer<typeof messageSchema>
): string {
  // 1. AI SDK v5 parts ë°°ì—´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  if (message.parts && Array.isArray(message.parts)) {
    const textParts = message.parts
      .filter(
        (part): part is z.infer<typeof textPartSchema> => part.type === 'text'
      )
      .map((part) => part.text);
    if (textParts.length > 0) {
      return textParts.join('\n');
    }
  }

  // 2. ë ˆê±°ì‹œ content í•„ë“œ ì‚¬ìš©
  if (typeof message.content === 'string') {
    return message.content;
  }

  return '';
}

// ============================================================================
// ğŸ§  Main Handler - LangGraph Multi-Agent System
// ============================================================================

export const POST = withRateLimit(
  rateLimiters.aiAnalysis,
  withAuth(async (req: NextRequest) => {
    try {
      // 1. Zod ìŠ¤í‚¤ë§ˆ ê²€ì¦
      const body = await req.json();
      const parseResult = requestSchema.safeParse(body);

      if (!parseResult.success) {
        console.warn(
          'âš ï¸ [Supervisor] Invalid payload:',
          parseResult.error.issues
        );
        return new Response(
          JSON.stringify({
            success: false,
            error: 'Invalid request payload',
            details: parseResult.error.issues.map((i) => i.message).join(', '),
          }),
          {
            status: 400,
            headers: { 'Content-Type': 'application/json' },
          }
        );
      }

      const { messages, sessionId: clientSessionId } = parseResult.data;

      // 2. ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ + ì…ë ¥ ì •ì œ
      const lastMessage =
        messages.length > 0 ? messages[messages.length - 1] : null;
      const rawQuery = lastMessage
        ? extractTextFromMessage(lastMessage)
        : 'System status check';

      // ë¹ˆ ì¿¼ë¦¬ ë°©ì–´
      if (!rawQuery || rawQuery.trim() === '') {
        return new Response(
          JSON.stringify({
            success: false,
            error: 'Empty query',
            message: 'ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.',
          }),
          {
            status: 400,
            headers: { 'Content-Type': 'application/json' },
          }
        );
      }

      const userQuery = quickSanitize(rawQuery);

      // 2. ì„¸ì…˜ ID ìƒì„±/ì‚¬ìš©
      const sessionId = clientSessionId || `session_${Date.now()}`;

      console.log(`ğŸš€ [Supervisor] Query: "${userQuery.slice(0, 50)}..."`);
      console.log(`ğŸ“¡ [Supervisor] Session: ${sessionId}`);

      // 3. ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì—¬ë¶€ í™•ì¸
      // AI SDK v5 DefaultChatTransportëŠ” */* ë˜ëŠ” ë‹¤ì–‘í•œ Accept í—¤ë”ë¥¼ ë³´ëƒ„
      // supervisor ì—”ë“œí¬ì¸íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
      // ëª…ì‹œì ìœ¼ë¡œ application/jsonë§Œ ìš”ì²­í•˜ëŠ” ê²½ìš°ì—ë§Œ JSON ì‘ë‹µ
      const acceptHeader = req.headers.get('accept') || '';
      const wantsJsonOnly = acceptHeader === 'application/json';
      const wantsStream = !wantsJsonOnly;

      // 4. Cloud Run í”„ë¡ì‹œ ëª¨ë“œ (Primary - CLOUD_RUN_ENABLED=true)
      if (isCloudRunEnabled()) {
        console.log('â˜ï¸ [Supervisor] Using Cloud Run backend');

        if (wantsStream) {
          // Cloud Run ìŠ¤íŠ¸ë¦¬ë° í”„ë¡ì‹œ
          const cloudStream = await proxyStreamToCloudRun({
            path: '/api/ai/supervisor',
            body: { messages, sessionId },
          });

          if (cloudStream) {
            return new Response(cloudStream, {
              headers: {
                'Content-Type': 'text/plain; charset=utf-8',
                'Cache-Control': 'no-cache',
                Connection: 'keep-alive',
                'X-Session-Id': sessionId,
                'X-Backend': 'cloud-run',
              },
            });
          }
          // Cloud Run ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ
          console.error('âŒ Cloud Run stream failed');
        } else {
          // Cloud Run ë‹¨ì¼ ì‘ë‹µ í”„ë¡ì‹œ
          const proxyResult = await proxyToCloudRun({
            path: '/api/ai/supervisor',
            body: { messages, sessionId },
          });

          if (proxyResult.success && proxyResult.data) {
            return Response.json({
              ...proxyResult.data,
              _backend: 'cloud-run',
            });
          }
          // Cloud Run ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ
          console.error('âŒ Cloud Run request failed:', proxyResult.error);
        }
      }

      // 5. Fallback: Cloud Run ë¹„í™œì„±í™” ë˜ëŠ” ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ
      // Note: Vercel LangGraph ì œê±°ë¨ (2025-12-17) - ë²ˆë“¤ ìµœì í™”
      console.warn('âš ï¸ [Supervisor] Cloud Run unavailable, returning error');

      return new Response(
        JSON.stringify({
          success: false,
          error: 'AI service temporarily unavailable',
          message:
            'AI ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
          sessionId,
          _backend: 'fallback-error',
        }),
        {
          status: 503,
          headers: {
            'Content-Type': 'application/json',
            'X-Session-Id': sessionId,
            'Retry-After': '30',
          },
        }
      );
    } catch (error) {
      console.error('âŒ AI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹¤íŒ¨:', error);

      // ì—ëŸ¬ ìƒì„¸ ì •ë³´ ë¡œê¹…
      if (error instanceof Error) {
        console.error('Error details:', {
          name: error.name,
          message: error.message,
          stack: error.stack?.slice(0, 500),
        });
      }

      return new Response(
        JSON.stringify({
          success: false,
          error: 'AI processing failed',
          message:
            error instanceof Error ? error.message : 'Unknown error occurred',
        }),
        {
          status: 500,
          headers: { 'Content-Type': 'application/json' },
        }
      );
    }
  })
);

// ============================================================================
// ğŸ“Š Architecture Note (2025-12-17)
// ============================================================================
//
// All LangGraph agents now run exclusively on Cloud Run ai-engine:
// - Supervisor (Groq Llama-8b): Intent classification & routing
// - NLQ Agent (Gemini Flash): Server metrics queries
// - Analyst Agent (Gemini Pro): Pattern analysis & anomaly detection
// - Reporter Agent (Llama 70b): Incident reports & RAG
//
// Vercel LangGraph code removed to reduce bundle size (~2MB) and
// simplify architecture. This proxy forwards all requests to Cloud Run.
//
// ============================================================================
