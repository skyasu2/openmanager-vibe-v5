/**
 * LangGraph Multi-Agent Supervisor API
 *
 * @endpoint POST /api/ai/supervisor
 *
 * Architecture:
 * - createSupervisor (@langchain/langgraph-supervisor): Automatic agent routing
 * - createReactAgent (@langchain/langgraph/prebuilt): Tool-equipped workers
 *
 * Agents:
 * - Supervisor (Groq Llama-8b): Intent classification & routing
 * - NLQ Agent (Gemini Flash): Server metrics queries
 * - Analyst Agent (Gemini Pro): Pattern analysis & anomaly detection
 * - Reporter Agent (Llama 70b): Incident reports & RAG
 */

import type { NextRequest } from 'next/server';
import { z } from 'zod';
import { withAuth } from '@/lib/auth/api-auth';
import {
  isCloudRunEnabled,
  proxyStreamToCloudRun,
  proxyToCloudRun,
} from '@/lib/cloud-run/proxy';
import {
  createSupervisorStreamResponse,
  executeSupervisor,
} from '@/services/langgraph/multi-agent-supervisor';
import { quickFilter, quickSanitize } from './security';

// Allow streaming responses up to 60 seconds (Vercel Hobby/Pro max duration)
export const maxDuration = 60;

// ============================================================================
// ğŸ“‹ Request Schema (Zod Validation)
// ============================================================================

// AI SDK v5 UIMessage 'parts' í¬ë§·
const textPartSchema = z.object({
  type: z.literal('text'),
  text: z.string(),
});

const partSchema = z.discriminatedUnion('type', [
  textPartSchema,
  // ë‹¤ë¥¸ part íƒ€ì…ë“¤ (tool-invocation, tool-result ë“±)ì€ ë¬´ì‹œ
  z
    .object({ type: z.literal('tool-invocation') })
    .passthrough(),
  z.object({ type: z.literal('tool-result') }).passthrough(),
  z.object({ type: z.literal('file') }).passthrough(),
  z.object({ type: z.literal('reasoning') }).passthrough(),
]);

// í•˜ì´ë¸Œë¦¬ë“œ ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ: AI SDK v5 (parts) + ë ˆê±°ì‹œ (content) ëª¨ë‘ ì§€ì›
const messageSchema = z.object({
  id: z.string().optional(),
  role: z.enum(['user', 'assistant', 'system']),
  // AI SDK v5: parts ë°°ì—´ (UIMessage í¬ë§·)
  parts: z.array(partSchema).optional(),
  // ë ˆê±°ì‹œ: content ë¬¸ìì—´
  content: z.string().optional(),
  // ì¶”ê°€ ë©”íƒ€ë°ì´í„° í—ˆìš©
  createdAt: z.union([z.string(), z.date()]).optional(),
});

const requestSchema = z.object({
  messages: z.array(messageSchema).min(1).max(50),
  sessionId: z.string().optional(),
});

// ============================================================================
// ğŸ”§ Utility: UIMessageì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
// ============================================================================

/**
 * AI SDK v5 UIMessage ë˜ëŠ” ë ˆê±°ì‹œ ë©”ì‹œì§€ì—ì„œ í…ìŠ¤íŠ¸ ì½˜í…ì¸  ì¶”ì¶œ
 */
function extractTextFromMessage(
  message: z.infer<typeof messageSchema>
): string {
  // 1. AI SDK v5 parts ë°°ì—´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  if (message.parts && Array.isArray(message.parts)) {
    const textParts = message.parts
      .filter(
        (part): part is z.infer<typeof textPartSchema> => part.type === 'text'
      )
      .map((part) => part.text);
    if (textParts.length > 0) {
      return textParts.join('\n');
    }
  }

  // 2. ë ˆê±°ì‹œ content í•„ë“œ ì‚¬ìš©
  if (typeof message.content === 'string') {
    return message.content;
  }

  return '';
}

// ============================================================================
// ğŸ§  Main Handler - LangGraph Multi-Agent System
// ============================================================================

export const POST = withAuth(async (req: NextRequest) => {
  try {
    // 1. Zod ìŠ¤í‚¤ë§ˆ ê²€ì¦
    const body = await req.json();
    const parseResult = requestSchema.safeParse(body);

    if (!parseResult.success) {
      console.warn(
        'âš ï¸ [Unified-Stream] Invalid payload:',
        parseResult.error.issues
      );
      return new Response(
        JSON.stringify({
          success: false,
          error: 'Invalid request payload',
          details: parseResult.error.issues.map((i) => i.message).join(', '),
        }),
        {
          status: 400,
          headers: { 'Content-Type': 'application/json' },
        }
      );
    }

    const { messages, sessionId: clientSessionId } = parseResult.data;

    // 2. ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ + ì…ë ¥ ì •ì œ
    const lastMessage =
      messages.length > 0 ? messages[messages.length - 1] : null;
    const rawQuery = lastMessage
      ? extractTextFromMessage(lastMessage)
      : 'System status check';

    // ë¹ˆ ì¿¼ë¦¬ ë°©ì–´
    if (!rawQuery || rawQuery.trim() === '') {
      return new Response(
        JSON.stringify({
          success: false,
          error: 'Empty query',
          message: 'ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.',
        }),
        {
          status: 400,
          headers: { 'Content-Type': 'application/json' },
        }
      );
    }

    const userQuery = quickSanitize(rawQuery);

    // 2. ì„¸ì…˜ ID ìƒì„±/ì‚¬ìš©
    const sessionId = clientSessionId || `session_${Date.now()}`;

    console.log(`ğŸš€ [Supervisor] Query: "${userQuery.slice(0, 50)}..."`);
    console.log(`ğŸ“¡ [Supervisor] Session: ${sessionId}`);

    // 3. ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì—¬ë¶€ í™•ì¸
    // AI SDK v5 DefaultChatTransportëŠ” */* ë˜ëŠ” ë‹¤ì–‘í•œ Accept í—¤ë”ë¥¼ ë³´ëƒ„
    // supervisor ì—”ë“œí¬ì¸íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
    // ëª…ì‹œì ìœ¼ë¡œ application/jsonë§Œ ìš”ì²­í•˜ëŠ” ê²½ìš°ì—ë§Œ JSON ì‘ë‹µ
    const acceptHeader = req.headers.get('accept') || '';
    const wantsJsonOnly = acceptHeader === 'application/json';
    const wantsStream = !wantsJsonOnly;

    // 4. Cloud Run í”„ë¡ì‹œ ëª¨ë“œ (CLOUD_RUN_ENABLED=true)
    if (isCloudRunEnabled()) {
      console.log('â˜ï¸ [Supervisor] Using Cloud Run backend');

      if (wantsStream) {
        // Cloud Run ìŠ¤íŠ¸ë¦¬ë° í”„ë¡ì‹œ
        const cloudStream = await proxyStreamToCloudRun({
          path: '/api/ai/supervisor',
          body: { messages, sessionId },
        });

        if (cloudStream) {
          return new Response(cloudStream, {
            headers: {
              'Content-Type': 'text/plain; charset=utf-8',
              'Cache-Control': 'no-cache',
              Connection: 'keep-alive',
              'X-Session-Id': sessionId,
              'X-Backend': 'cloud-run',
            },
          });
        }
        // Cloud Run ì‹¤íŒ¨ ì‹œ ë¡œì»¬ë¡œ í´ë°±
        console.warn('âš ï¸ Cloud Run stream failed, falling back to local');
      } else {
        // Cloud Run ë‹¨ì¼ ì‘ë‹µ í”„ë¡ì‹œ
        const proxyResult = await proxyToCloudRun({
          path: '/api/ai/supervisor',
          body: { messages, sessionId },
        });

        if (proxyResult.success && proxyResult.data) {
          return Response.json({
            ...proxyResult.data,
            _backend: 'cloud-run',
          });
        }
        // Cloud Run ì‹¤íŒ¨ ì‹œ ë¡œì»¬ë¡œ í´ë°±
        console.warn('âš ï¸ Cloud Run request failed, falling back to local');
      }
    }

    // 5. ë¡œì»¬ ëª¨ë“œ (Next.js ë‚´ì¥ LangGraph Multi-Agent Supervisor)
    if (wantsStream) {
      // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (LangGraph createSupervisor + streamEvents ì‚¬ìš©)
      try {
        const stream = await createSupervisorStreamResponse(
          userQuery,
          sessionId
        );

        return new Response(stream, {
          headers: {
            'Content-Type': 'text/event-stream; charset=utf-8',
            'Cache-Control': 'no-cache, no-transform',
            Connection: 'keep-alive',
            'X-Vercel-AI-Data-Stream': 'v1',
            'X-Session-Id': sessionId,
            'X-Backend': 'vercel-supervisor',
          },
        });
      } catch (streamError) {
        console.error('âŒ Streaming Error:', streamError);
        // ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨ ì‹œ ë‹¨ì¼ ì‘ë‹µìœ¼ë¡œ í´ë°±
        const result = await executeSupervisor(userQuery, { sessionId });
        return new Response(result.response, {
          status: 200,
          headers: {
            'Content-Type': 'text/plain; charset=utf-8',
            'X-Session-Id': sessionId,
            'X-Backend': 'vercel-supervisor',
          },
        });
      }
    } else {
      // ë‹¨ì¼ ì‘ë‹µ (invoke ì‚¬ìš©)
      const result = await executeSupervisor(userQuery, { sessionId });

      return Response.json({
        success: true,
        response: quickFilter(result.response),
        sessionId: result.sessionId,
        _backend: 'vercel-supervisor',
      });
    }
  } catch (error) {
    console.error('âŒ AI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹¤íŒ¨:', error);

    // ì—ëŸ¬ ìƒì„¸ ì •ë³´ ë¡œê¹…
    if (error instanceof Error) {
      console.error('Error details:', {
        name: error.name,
        message: error.message,
        stack: error.stack?.slice(0, 500),
      });
    }

    return new Response(
      JSON.stringify({
        success: false,
        error: 'AI processing failed',
        message:
          error instanceof Error ? error.message : 'Unknown error occurred',
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' },
      }
    );
  }
});

// ============================================================================
// ğŸ“Š Legacy Tools Reference (Now integrated in LangGraph Agents)
// ============================================================================
//
// The following tools have been migrated to LangGraph agents:
//
// 1. getServerMetrics -> NLQ Agent (nlq-agent.ts)
//    - Queries server CPU/memory/disk status from scenario data
//
// 2. searchKnowledgeBase -> Reporter Agent (reporter-agent.ts)
//    - RAG search using Supabase pgvector (384 dimensions)
//
// 3. analyzePattern -> Analyst Agent (analyst-agent.ts)
//    - Pattern matching for system performance queries
//
// 4. recommendCommands -> Reporter Agent (reporter-agent.ts)
//    - CLI command recommendations based on keywords
//
// ============================================================================
