/**
 * Cloud Run AI Supervisor Proxy
 *
 * @endpoint POST /api/ai/supervisor
 *
 * Architecture:
 * - Primary: Cloud Run ai-engine (Multi-Agent System)
 * - Fallback: Simple error response
 * - All AI processing handled by Cloud Run
 *
 * Changes (2025-12-22 v5.83.9):
 * - Added normalizeMessagesForCloudRun(): AI SDK v5 parts[] â†’ Cloud Run content ë³€í™˜
 * - Added sessionId query parameter ì§€ì› (TextStreamChatTransport í˜¸í™˜)
 */

import type { NextRequest } from 'next/server';
import { NextResponse } from 'next/server';
import { z } from 'zod';
import { executeWithCircuitBreakerAndFallback } from '@/lib/ai/circuit-breaker';
import { createFallbackResponse } from '@/lib/ai/fallback/ai-fallback-handler';
import {
  extractLastUserQuery,
  type HybridMessage,
  normalizeMessagesForCloudRun,
} from '@/lib/ai/utils/message-normalizer';
import { calculateDynamicTimeout } from '@/lib/ai/utils/query-complexity';
import { isCloudRunEnabled, proxyToCloudRun } from '@/lib/ai-proxy/proxy';
import { withAuth } from '@/lib/auth/api-auth';
import { rateLimiters, withRateLimit } from '@/lib/security/rate-limiter';
import { quickSanitize } from './security';

// ============================================================================
// ğŸ”§ Stream Transformer: Vercel Data Stream Protocol â†’ Plain Text
// ============================================================================
// Cloud Runì´ ë°˜í™˜í•˜ëŠ” Data Stream Protocolì„ íŒŒì‹±í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
//
// @see https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol
// ============================================================================

/**
 * Vercel AI SDK Data Stream Protocol ìƒìˆ˜
 *
 * @warning ì´ í”„ë¡œí† ì½œì€ Vercel AI SDK ë²„ì „ì— ì˜ì¡´í•©ë‹ˆë‹¤.
 *          SDK ì—…ê·¸ë ˆì´ë“œ ì‹œ í˜¸í™˜ì„± í™•ì¸ í•„ìš”
 *
 * @see https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol
 */
const DATA_STREAM_PREFIXES = {
  TEXT: '0', // í…ìŠ¤íŠ¸ ì½˜í…ì¸  (ì£¼ìš”)
  DATA: '2', // JSON ë°ì´í„° ë°°ì—´
  ERROR: '3', // ì—ëŸ¬ ë©”ì‹œì§€
  ANNOTATION: '8', // ë©”ì‹œì§€ ì£¼ì„
  FINISH: 'd', // ì™„ë£Œ ì‹ í˜¸
  START: 'e', // ì‹œì‘ ì‹ í˜¸
} as const;

/**
 * Data Stream Protocol ë¼ì¸ íŒŒì‹± ì •ê·œì‹
 *
 * @pattern ^(prefix):(content)$
 * - prefix: ìˆ«ì ë˜ëŠ” ì•ŒíŒŒë²³ í•œ ê¸€ì
 * - content: JSON ë¬¸ìì—´ ë˜ëŠ” ê°ì²´
 *
 * @fragility ì´ ì •ê·œì‹ì€ SDK í”„ë¡œí† ì½œ ë³€ê²½ì— ì·¨ì•½í•©ë‹ˆë‹¤.
 *            SDK ë²„ì „ ì—…ê·¸ë ˆì´ë“œ ì‹œ ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸ í•„ìš”
 */
const DATA_STREAM_LINE_REGEX = /^([0-9a-z]):(.*)$/;

/**
 * Data Stream Protocolì„ Plain Textë¡œ ë³€í™˜í•˜ëŠ” TransformStream
 *
 * @description
 * Cloud Runì´ ë°˜í™˜í•˜ëŠ” `0:"í…ìŠ¤íŠ¸"` í˜•ì‹ì„ íŒŒì‹±í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
 * TextStreamChatTransportì™€ í•¨ê»˜ ì‚¬ìš©ë©ë‹ˆë‹¤.
 *
 * @example
 * Input:  0:"Hello "\n0:"World"\nd:{"finishReason":"stop"}
 * Output: Hello World
 *
 * @warning
 * - Vercel AI SDK v5 Data Stream Protocolì— ì˜ì¡´
 * - Cloud Run ì‘ë‹µ í˜•ì‹ ë³€ê²½ ì‹œ íŒŒì‹± ì‹¤íŒ¨ ê°€ëŠ¥
 * - ì¥ê¸°ì ìœ¼ë¡œ SDKì˜ ê³µì‹ íŒŒì„œ ì‚¬ìš© ê¶Œì¥
 */
// NOTE: Reserved for future streaming implementation
function _createDataStreamParserTransform(): TransformStream<
  Uint8Array,
  Uint8Array
> {
  const decoder = new TextDecoder();
  const encoder = new TextEncoder();
  let buffer = '';

  /**
   * JSON ë¬¸ìì—´ ì•ˆì „í•˜ê²Œ íŒŒì‹±
   */
  const safeJsonParse = (str: string): unknown => {
    try {
      return JSON.parse(str);
    } catch {
      return null;
    }
  };

  /**
   * í…ìŠ¤íŠ¸ ì½˜í…ì¸  ì¶”ì¶œ (prefix: 0)
   */
  const extractTextContent = (content: string): string | null => {
    const parsed = safeJsonParse(content);
    if (typeof parsed === 'string') {
      return parsed;
    }
    // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ raw content ë°˜í™˜ (fallback)
    if (content.startsWith('"') && content.endsWith('"')) {
      return content.slice(1, -1);
    }
    return null;
  };

  /**
   * ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ (prefix: 3)
   */
  const extractErrorMessage = (content: string): string => {
    const parsed = safeJsonParse(content);

    if (typeof parsed === 'string') {
      // ì¤‘ì²©ëœ JSON ì—ëŸ¬ ì²˜ë¦¬
      const innerParsed = safeJsonParse(parsed);
      if (
        innerParsed &&
        typeof innerParsed === 'object' &&
        'error' in innerParsed
      ) {
        const errorObj = innerParsed as { error?: { message?: string } };
        return errorObj.error?.message || parsed;
      }
      return parsed;
    }

    if (parsed && typeof parsed === 'object' && 'message' in parsed) {
      return (parsed as { message: string }).message;
    }

    return content;
  };

  return new TransformStream({
    transform(chunk, controller) {
      buffer += decoder.decode(chunk, { stream: true });

      const lines = buffer.split('\n');
      buffer = lines.pop() || ''; // ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ë¼ì¸ì€ ë²„í¼ì— ìœ ì§€

      for (const line of lines) {
        const trimmed = line.trim();
        if (!trimmed) continue;

        const match = trimmed.match(DATA_STREAM_LINE_REGEX);
        if (!match?.[1] || match[2] === undefined) continue;

        const prefix = match[1];
        const content = match[2];

        switch (prefix) {
          case DATA_STREAM_PREFIXES.TEXT: {
            const text = extractTextContent(content);
            if (text) {
              controller.enqueue(encoder.encode(text));
            }
            break;
          }

          case DATA_STREAM_PREFIXES.ERROR: {
            const errorMsg = extractErrorMessage(content);
            controller.enqueue(encoder.encode(`\n\nâš ï¸ AI ì˜¤ë¥˜: ${errorMsg}`));
            break;
          }

          // DATA, ANNOTATION, FINISH, START: ë©”íƒ€ë°ì´í„°ëŠ” ë¬´ì‹œ
          // í•„ìš” ì‹œ ì—¬ê¸°ì— ì¶”ê°€ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥
        }
      }
    },

    flush(controller) {
      // ë²„í¼ì— ë‚¨ì€ ë¶ˆì™„ì „í•œ ë¼ì¸ ì²˜ë¦¬
      if (buffer.trim()) {
        const match = buffer.trim().match(DATA_STREAM_LINE_REGEX);
        if (match?.[1] === DATA_STREAM_PREFIXES.TEXT && match[2]) {
          const text = extractTextContent(match[2]);
          if (text) {
            controller.enqueue(encoder.encode(text));
          }
        }
      }
    },
  });
}

// Allow streaming responses up to 120 seconds (Vercel Pro: max 300s)
// Note: Increased from 60s to handle complex NLQ queries with tool calls
// Supervisor â†’ Agent â†’ Tool â†’ Verifier pipeline can take 60-90s
export const maxDuration = 120;

// ============================================================================
// ğŸ“‹ Request Schema (Zod Validation)
// ============================================================================

// AI SDK v5 UIMessage 'parts' í¬ë§·
const textPartSchema = z.object({
  type: z.literal('text'),
  text: z.string(),
});

const partSchema = z.discriminatedUnion('type', [
  textPartSchema,
  // ë‹¤ë¥¸ part íƒ€ì…ë“¤ (tool-invocation, tool-result ë“±)ì€ ë¬´ì‹œ
  z
    .object({ type: z.literal('tool-invocation') })
    .passthrough(),
  z.object({ type: z.literal('tool-result') }).passthrough(),
  z.object({ type: z.literal('file') }).passthrough(),
  z.object({ type: z.literal('reasoning') }).passthrough(),
]);

// í•˜ì´ë¸Œë¦¬ë“œ ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ: AI SDK v5 (parts) + ë ˆê±°ì‹œ (content) ëª¨ë‘ ì§€ì›
const messageSchema = z.object({
  id: z.string().optional(),
  role: z.enum(['user', 'assistant', 'system']),
  // AI SDK v5: parts ë°°ì—´ (UIMessage í¬ë§·)
  parts: z.array(partSchema).optional(),
  // ë ˆê±°ì‹œ: content ë¬¸ìì—´
  content: z.string().optional(),
  // ì¶”ê°€ ë©”íƒ€ë°ì´í„° í—ˆìš©
  createdAt: z.union([z.string(), z.date()]).optional(),
});

const requestSchema = z.object({
  messages: z.array(messageSchema).min(1).max(50),
  sessionId: z.string().optional(),
});

// ============================================================================
// ğŸ”§ Utility: ë©”ì‹œì§€ ì •ê·œí™” (ì¤‘ì•™í™”ë¨)
// ============================================================================
// @see /src/lib/ai/utils/message-normalizer.ts
// - extractTextFromHybridMessage(): í…ìŠ¤íŠ¸ ì¶”ì¶œ
// - normalizeMessagesForCloudRun(): Cloud Run í˜•ì‹ ë³€í™˜
// - extractLastUserQuery(): ë§ˆì§€ë§‰ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ
// ============================================================================

// ============================================================================
// ğŸ§  Main Handler - Cloud Run Multi-Agent System
// ============================================================================

export const POST = withRateLimit(
  rateLimiters.aiAnalysis,
  withAuth(async (req: NextRequest) => {
    try {
      // 1. Zod ìŠ¤í‚¤ë§ˆ ê²€ì¦
      const body = await req.json();
      const parseResult = requestSchema.safeParse(body);

      if (!parseResult.success) {
        console.warn(
          'âš ï¸ [Supervisor] Invalid payload:',
          parseResult.error.issues
        );
        return NextResponse.json(
          {
            success: false,
            error: 'Invalid request payload',
            details: parseResult.error.issues.map((i) => i.message).join(', '),
          },
          { status: 400 }
        );
      }

      const { messages, sessionId: bodySessionId } = parseResult.data;

      // ====================================================================
      // sessionId ì¶”ì¶œ (2026-01-01 v5.84.0 ê°œì„ )
      // ====================================================================
      // AI SDK v5 DefaultChatTransportëŠ” body/headers ëª¨ë‘ ì§€ì›
      // ìš°ì„ ìˆœìœ„: Header > Body > Query Param (ë ˆê±°ì‹œ í˜¸í™˜)
      // ====================================================================
      const url = new URL(req.url);
      const headerSessionId = req.headers.get('X-Session-Id');
      const querySessionId = url.searchParams.get('sessionId');
      const clientSessionId =
        headerSessionId || bodySessionId || querySessionId;

      // 2. ë§ˆì§€ë§‰ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ì¶œ + ì…ë ¥ ì •ì œ (ì¤‘ì•™í™”ëœ ìœ í‹¸ë¦¬í‹° ì‚¬ìš©)
      const rawQuery =
        extractLastUserQuery(messages as HybridMessage[]) ||
        'System status check';

      // ë¹ˆ ì¿¼ë¦¬ ë°©ì–´
      if (!rawQuery || rawQuery.trim() === '') {
        return NextResponse.json(
          {
            success: false,
            error: 'Empty query',
            message: 'ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.',
          },
          { status: 400 }
        );
      }

      const userQuery = quickSanitize(rawQuery);

      // 2. ì„¸ì…˜ ID ìƒì„±/ì‚¬ìš©
      const sessionId = clientSessionId || `session_${Date.now()}`;

      // 3. ë™ì  íƒ€ì„ì•„ì›ƒ ê³„ì‚° (2025-12-30 ì¶”ê°€)
      const dynamicTimeout = calculateDynamicTimeout(userQuery, {
        messageCount: messages.length,
        minTimeout: 15000, // ìµœì†Œ 15ì´ˆ
        maxTimeout: 120000, // ìµœëŒ€ 120ì´ˆ
      });

      console.log(`ğŸš€ [Supervisor] Query: "${userQuery.slice(0, 50)}..."`);
      console.log(`ğŸ“¡ [Supervisor] Session: ${sessionId}`);
      console.log(`â±ï¸ [Supervisor] Dynamic timeout: ${dynamicTimeout}ms`);

      // 3. ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì—¬ë¶€ í™•ì¸
      // AI SDK v5 DefaultChatTransportëŠ” */* ë˜ëŠ” ë‹¤ì–‘í•œ Accept í—¤ë”ë¥¼ ë³´ëƒ„
      // supervisor ì—”ë“œí¬ì¸íŠ¸ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
      // ëª…ì‹œì ìœ¼ë¡œ application/jsonë§Œ ìš”ì²­í•˜ëŠ” ê²½ìš°ì—ë§Œ JSON ì‘ë‹µ
      const acceptHeader = req.headers.get('accept') || '';
      const wantsJsonOnly = acceptHeader === 'application/json';
      const wantsStream = !wantsJsonOnly;

      // 4. Cloud Run í”„ë¡ì‹œ ëª¨ë“œ (Primary - CLOUD_RUN_ENABLED=true)
      if (isCloudRunEnabled()) {
        console.log('â˜ï¸ [Supervisor] Using Cloud Run backend');

        // AI SDK v5 parts í˜•ì‹ â†’ Cloud Run content í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”
        const normalizedMessages = normalizeMessagesForCloudRun(messages);
        console.log(
          `ğŸ“ [Supervisor] Normalized ${messages.length} messages â†’ ${normalizedMessages.length} for Cloud Run`
        );

        if (wantsStream) {
          // ================================================================
          // ğŸ”§ Cloud Run JSON ì‘ë‹µ ì²˜ë¦¬ (2025-12-30 Circuit Breaker + Fallback)
          // ================================================================
          // Cloud Runì€ í˜„ì¬ JSON ì‘ë‹µì„ ë°˜í™˜í•¨ (ìŠ¤íŠ¸ë¦¬ë° ë¯¸êµ¬í˜„)
          // JSON ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ plain textë¡œ ë°˜í™˜
          // Circuit Breaker + Fallbackìœ¼ë¡œ ì¥ì•  ëŒ€ì‘
          // ================================================================
          const result = await executeWithCircuitBreakerAndFallback<
            NextResponse<unknown>
          >(
            'cloud-run-supervisor-stream',
            // Primary: Cloud Run í˜¸ì¶œ
            async () => {
              const proxyResult = await proxyToCloudRun({
                path: '/api/ai/supervisor',
                body: { messages: normalizedMessages, sessionId },
                timeout: dynamicTimeout,
              });

              if (!proxyResult.success || !proxyResult.data) {
                throw new Error(
                  proxyResult.error ?? 'Cloud Run request failed'
                );
              }

              const data = proxyResult.data as {
                success?: boolean;
                response?: string;
                error?: string;
              };

              if (data.success && data.response) {
                // ================================================================
                // ğŸ”§ Data Stream Protocol í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (AI SDK v5 í˜¸í™˜)
                // useChat í›…ì´ íŒŒì‹±í•  ìˆ˜ ìˆë„ë¡ í‘œì¤€ í”„ë¡œí† ì½œ ì‚¬ìš©
                // @see https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol
                // ================================================================
                const dataStreamResponse = [
                  `0:${JSON.stringify(data.response)}`,
                  'd:{"finishReason":"stop","usage":{"promptTokens":0,"completionTokens":0}}',
                  '', // ë§ˆì§€ë§‰ ì¤„ë°”ê¿ˆ
                ].join('\n');

                return new NextResponse(dataStreamResponse, {
                  headers: {
                    'Content-Type': 'text/plain; charset=utf-8',
                    'Cache-Control': 'no-cache',
                    'X-Session-Id': sessionId,
                    'X-Backend': 'cloud-run',
                    'X-Stream-Protocol': 'data-stream-v1',
                  },
                });
              } else if (data.error) {
                // ì—ëŸ¬ë„ Data Stream Protocol í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
                const errorMessage = `âš ï¸ AI ì˜¤ë¥˜: ${data.error}`;
                const errorStreamResponse = [
                  `0:${JSON.stringify(errorMessage)}`,
                  'd:{"finishReason":"error","usage":{"promptTokens":0,"completionTokens":0}}',
                  '',
                ].join('\n');

                return new NextResponse(errorStreamResponse, {
                  headers: {
                    'Content-Type': 'text/plain; charset=utf-8',
                    'X-Session-Id': sessionId,
                    'X-Backend': 'cloud-run',
                    'X-Stream-Protocol': 'data-stream-v1',
                  },
                });
              }

              throw new Error('Invalid response from Cloud Run');
            },
            // Fallback: ë¡œì»¬ í´ë°± ì‘ë‹µ (Data Stream Protocol)
            () => {
              const fallback = createFallbackResponse('supervisor', {
                query: userQuery,
              });
              const fallbackText = fallback.data?.response ?? fallback.message;
              const fallbackStreamResponse = [
                `0:${JSON.stringify(fallbackText)}`,
                'd:{"finishReason":"stop","usage":{"promptTokens":0,"completionTokens":0}}',
                '',
              ].join('\n');

              return new NextResponse(fallbackStreamResponse, {
                headers: {
                  'Content-Type': 'text/plain; charset=utf-8',
                  'X-Session-Id': sessionId,
                  'X-Backend': 'fallback',
                  'X-Fallback-Response': 'true',
                  'X-Retry-After': '30000',
                  'X-Stream-Protocol': 'data-stream-v1',
                },
              });
            }
          );

          // í´ë°± ì‚¬ìš© ì‹œ ë¡œê¹…
          if (result.source === 'fallback') {
            console.log('âš ï¸ [Supervisor] Using fallback response (stream mode)');
          }

          return result.data;
        } else {
          // Cloud Run ë‹¨ì¼ ì‘ë‹µ í”„ë¡ì‹œ (Circuit Breaker + Fallback)
          const result = await executeWithCircuitBreakerAndFallback<
            Record<string, unknown>
          >(
            'cloud-run-supervisor-json',
            // Primary: Cloud Run í˜¸ì¶œ
            async () => {
              const proxyResult = await proxyToCloudRun({
                path: '/api/ai/supervisor',
                body: { messages: normalizedMessages, sessionId },
                timeout: dynamicTimeout,
              });

              if (!proxyResult.success || !proxyResult.data) {
                throw new Error(
                  proxyResult.error ?? 'Cloud Run request failed'
                );
              }

              return {
                ...(proxyResult.data as Record<string, unknown>),
                _backend: 'cloud-run',
              };
            },
            // Fallback: ë¡œì»¬ í´ë°± ì‘ë‹µ
            () =>
              ({
                ...createFallbackResponse('supervisor', { query: userQuery }),
                sessionId,
                _backend: 'fallback',
              }) as Record<string, unknown>
          );

          // í´ë°± ì‚¬ìš© ì‹œ í—¤ë” ì¶”ê°€
          if (result.source === 'fallback') {
            console.log('âš ï¸ [Supervisor] Using fallback response (json mode)');
            return NextResponse.json(result.data, {
              headers: {
                'X-Session-Id': sessionId,
                'X-Fallback-Response': 'true',
                'X-Retry-After': '30000',
              },
            });
          }

          return NextResponse.json(result.data, {
            headers: { 'X-Session-Id': sessionId },
          });
        }
      }

      // 5. Fallback: Cloud Run ë¹„í™œì„±í™” ì‹œ í´ë°± ì‘ë‹µ
      console.warn('âš ï¸ [Supervisor] Cloud Run disabled, returning fallback');
      const fallback = createFallbackResponse('supervisor', {
        query: userQuery,
      });

      return NextResponse.json(
        {
          ...fallback,
          sessionId,
          _backend: 'fallback',
        },
        {
          headers: {
            'X-Session-Id': sessionId,
            'Retry-After': '30',
          },
        }
      );
    } catch (error) {
      console.error('âŒ AI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹¤íŒ¨:', error);

      // ì—ëŸ¬ ìƒì„¸ ì •ë³´ ë¡œê¹…
      if (error instanceof Error) {
        console.error('Error details:', {
          name: error.name,
          message: error.message,
          stack: error.stack?.slice(0, 500),
        });

        // Circuit Breaker ì—ëŸ¬ ì²˜ë¦¬
        if (error.message.includes('ì¼ì‹œì ìœ¼ë¡œ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤')) {
          // Circuit Breakerê°€ ì—´ë¦° ìƒíƒœ - Retry-After í—¤ë” ì¶”ê°€
          const retryMatch = error.message.match(/(\d+)ì´ˆ í›„/);
          const retryAfter = retryMatch?.[1] ?? '60';

          return NextResponse.json(
            {
              success: false,
              error: 'AI service circuit open',
              message: error.message,
              retryAfter: parseInt(retryAfter, 10),
            },
            {
              status: 503,
              headers: {
                'Retry-After': retryAfter,
              },
            }
          );
        }

        // íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ ì²˜ë¦¬
        if (
          error.message.includes('timeout') ||
          error.message.includes('TIMEOUT')
        ) {
          return NextResponse.json(
            {
              success: false,
              error: 'Request timeout',
              message:
                'AI ë¶„ì„ì´ ì‹œê°„ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ì‹œë„í•´ì£¼ì„¸ìš”.',
            },
            { status: 504 }
          );
        }
      }

      return NextResponse.json(
        {
          success: false,
          error: 'AI processing failed',
          message:
            error instanceof Error ? error.message : 'Unknown error occurred',
        },
        { status: 500 }
      );
    }
  })
);

// ============================================================================
// ğŸ“Š Architecture Note
// ============================================================================
//
// All AI agents run on Cloud Run ai-engine:
// - Supervisor (Groq Llama-8b): Intent classification & routing
// - NLQ Agent (Groq Llama-70b): Server metrics queries
// - Analyst Agent (Mistral): Pattern analysis & anomaly detection
// - Reporter Agent (Cerebras): Incident reports & RAG
//
// This proxy forwards all requests to Cloud Run.
//
// ============================================================================
