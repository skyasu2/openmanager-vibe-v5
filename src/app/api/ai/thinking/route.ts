/**
 * ğŸ§  AI ì‚¬ê³  ê³¼ì • API ì—”ë“œí¬ì¸íŠ¸
 *
 * ì‹¤ì‹œê°„ AI ì‚¬ê³  ê³¼ì • ì‹œê°í™”ë¥¼ ìœ„í•œ API
 * - POST: ìƒˆë¡œìš´ ì‚¬ê³  ì„¸ì…˜ ì‹œì‘
 * - GET: ì‚¬ê³  ê³¼ì • ìƒíƒœ ì¡°íšŒ
 */

import { NextRequest, NextResponse } from 'next/server';
import { ThinkingProcessor } from '@/modules/ai-agent/core/ThinkingProcessor';
import { LangGraphThinkingProcessor } from '@/modules/ai-agent/core/LangGraphThinkingProcessor';
import { RealTimeAILogCollector } from '@/services/ai/logging/RealTimeAILogCollector';

const thinkingProcessor = new ThinkingProcessor();
const langGraphProcessor = LangGraphThinkingProcessor.getInstance();
const logCollector = RealTimeAILogCollector.getInstance();

/**
 * ğŸ§  ì‚¬ê³  ê³¼ì • ìƒíƒœ ì¡°íšŒ (GET)
 */
export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const sessionId = searchParams.get('sessionId');
    const mode = searchParams.get('mode') || 'basic';

    if (sessionId) {
      // íŠ¹ì • ì„¸ì…˜ì˜ ì‚¬ê³  ê³¼ì • ì¡°íšŒ
      const session = thinkingProcessor.getThinkingSession(sessionId);
      const langGraphFlow = langGraphProcessor.getThinkingFlow(sessionId);

      return NextResponse.json({
        success: true,
        data: {
          session,
          langGraphFlow,
          isActive: session?.status === 'thinking',
          logs: logCollector.getRecentLogs(10),
        },
      });
    } else {
      // ì „ì²´ ì‚¬ê³  ê³¼ì • í†µê³„
      const stats = thinkingProcessor.getThinkingStats();
      const activeSessions = thinkingProcessor.getActiveThinkingSessions();

      return NextResponse.json({
        success: true,
        data: {
          stats,
          activeSessions: activeSessions.length,
          activeSessionIds: activeSessions.map(s => s.sessionId),
          systemStatus: {
            thinking: activeSessions.length > 0,
            totalProcessors: 2, // ThinkingProcessor + LangGraphThinkingProcessor
            mode: mode,
          },
        },
      });
    }
  } catch (error) {
    console.error('âŒ AI ì‚¬ê³  ê³¼ì • ì¡°íšŒ ì‹¤íŒ¨:', error);
    return NextResponse.json(
      {
        success: false,
        error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜',
      },
      { status: 500 }
    );
  }
}

/**
 * ğŸ§  ìƒˆë¡œìš´ ì‚¬ê³  ì„¸ì…˜ ì‹œì‘ (POST)
 */
export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const {
      query,
      mode = 'basic',
      useAdvanced = false,
      enableRealTimeLogs = true,
    } = body;

    if (!query) {
      return NextResponse.json(
        { success: false, error: 'ì§ˆì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤' },
        { status: 400 }
      );
    }

    // ì‚¬ê³  ì„¸ì…˜ ì‹œì‘
    const queryId = `query_${Date.now()}_${Math.random().toString(36).substring(2, 15)}`;
    const sessionId = `session_${Date.now()}_${Math.random().toString(36).substring(2, 15)}`;

    // ê¸°ë³¸ ì‚¬ê³  í”„ë¡œì„¸ì„œ ì‹œì‘
    const thinkingSessionId = thinkingProcessor.startThinking(
      queryId,
      query,
      mode
    );

    // ê³ ê¸‰ ëª¨ë“œì¸ ê²½ìš° LangGraph í”„ë¡œì„¸ì„œë„ ì‹œì‘
    let langGraphQueryId = null;
    if (useAdvanced) {
      langGraphQueryId = langGraphProcessor.startThinking(
        sessionId,
        query,
        mode
      );
    }

    // ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì§‘ ì‹œì‘
    if (enableRealTimeLogs) {
      logCollector.startProcess(sessionId, 'ai-thinking', query);
    }

    // ì‹œë®¬ë ˆì´ì…˜ëœ ì‚¬ê³  ê³¼ì • ë‹¨ê³„ë“¤ ì¶”ê°€
    setTimeout(() => {
      thinkingProcessor.addThinkingStep(
        thinkingSessionId,
        'analysis',
        'ì§ˆì˜ ë¶„ì„',
        'ì‚¬ìš©ì ì§ˆì˜ì˜ ì˜ë„ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.'
      );
    }, 100);

    setTimeout(() => {
      thinkingProcessor.addThinkingStep(
        thinkingSessionId,
        'classification',
        'ì—”ì§„ ì„ íƒ',
        'AI ì—”ì§„ë“¤ ì¤‘ ìµœì ì˜ ì¡°í•©ì„ ì„ íƒí•©ë‹ˆë‹¤.'
      );
    }, 500);

    setTimeout(() => {
      thinkingProcessor.addThinkingStep(
        thinkingSessionId,
        'processing',
        'ë³‘ë ¬ ì¶”ë¡ ',
        'ì„ íƒëœ ì—”ì§„ë“¤ì´ ë³‘ë ¬ë¡œ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.'
      );
    }, 1000);

    setTimeout(() => {
      thinkingProcessor.addThinkingStep(
        thinkingSessionId,
        'generation',
        'ì‘ë‹µ ìƒì„±',
        'ì¶”ë¡  ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.'
      );
    }, 2000);

    setTimeout(() => {
      thinkingProcessor.completeThinking(thinkingSessionId, {
        answer: 'ì‚¬ê³  ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
        confidence: 0.95,
        totalSteps: 4,
      });

      if (enableRealTimeLogs) {
        logCollector.stopProcess(sessionId);
      }
    }, 3000);

    return NextResponse.json({
      success: true,
      data: {
        sessionId,
        thinkingSessionId,
        langGraphQueryId,
        query,
        mode,
        useAdvanced,
        estimatedDuration: 3000,
        message: 'ğŸ§  AI ì‚¬ê³  ê³¼ì •ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤',
        endpoints: {
          status: `/api/ai/thinking?sessionId=${sessionId}`,
          stream: `/api/ai/thinking/stream?sessionId=${sessionId}`,
        },
      },
    });
  } catch (error) {
    console.error('âŒ AI ì‚¬ê³  ì„¸ì…˜ ì‹œì‘ ì‹¤íŒ¨:', error);
    return NextResponse.json(
      {
        success: false,
        error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜',
      },
      { status: 500 }
    );
  }
}
