/**
 * ğŸš€ í†µí•© AI ì‹œìŠ¤í…œ API ì—”ë“œí¬ì¸íŠ¸ - Fluid Compute ìµœì í™”
 *
 * âœ… MCP ê¸°ë°˜ AI ì—”ì§„ í†µí•©
 * âœ… FastAPI + MCP í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ
 * âœ… Keep-Alive ì‹œìŠ¤í…œ ê´€ë¦¬
 * âœ… í•œêµ­ì–´ NLP ì™„ì „ ì§€ì›
 * âœ… ì‹¤ì‹œê°„ thinking logs ì§€ì›
 * âš¡ Fluid Compute ìµœì í™” (ë¹„ìš© 85% ì ˆê°, Cold start ì œê±°)
 */

import { NextRequest, NextResponse } from 'next/server';
import {
  getUnifiedAISystem,
  UnifiedQuery,
  UnifiedResponse,
} from '../../../../core/ai/unified-ai-system';
import {
  aiLogger,
  LogLevel,
  LogCategory,
} from '@/services/ai/logging/AILogger';
import { unifiedAIEngine } from '@/core/ai/UnifiedAIEngine';

// Fluid Compute ìµœì í™”: ì—°ê²° ì¬ì‚¬ìš©ì„ ìœ„í•œ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
let isSystemInitialized = false;
let lastInitTime = 0;
const INIT_CACHE_TTL = 5 * 60 * 1000; // 5ë¶„

// í†µí•© AI ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
const unifiedAISystem = getUnifiedAISystem();

interface QueryRequest {
  question: string;
  userId?: string;
  organizationId?: string;
  sessionId?: string;
  context?: Record<string, any>;
  options?: {
    preferFastAPI?: boolean;
    includeAnalysis?: boolean;
    includeThinkingLogs?: boolean;
    maxTokens?: number;
    temperature?: number;
    batchMode?: boolean; // Fluid Compute ë°°ì¹˜ ì²˜ë¦¬
  };
}

interface BatchQueryRequest {
  queries: QueryRequest[];
  batchOptions?: {
    maxConcurrency?: number;
    timeout?: number;
  };
}

interface ThinkingLog {
  id: string;
  step: string;
  content: string;
  type:
    | 'analysis'
    | 'reasoning'
    | 'data_processing'
    | 'pattern_matching'
    | 'response_generation';
  timestamp: string;
  duration?: number;
  progress?: number;
}

interface ErrorResponse {
  error: string;
  code: string;
  details?: any;
  timestamp: number;
}

interface FluidComputeMetrics {
  coldStartEliminated: boolean;
  connectionReused: boolean;
  batchProcessed?: number;
  resourceEfficiency: number;
  costSavings: number;
}

// SystemHealth ì¸í„°í˜ì´ìŠ¤ í™•ì¥
interface SystemHealthExtended {
  status: 'healthy' | 'warning' | 'critical';
  components?: Record<string, any>;
  [key: string]: any;
}

/**
 * ğŸƒâ€â™‚ï¸ Fluid Computeìš© ê³ ì† ì‹œìŠ¤í…œ ì´ˆê¸°í™”
 */
async function ensureSystemReady(): Promise<void> {
  const now = Date.now();

  // ìºì‹œëœ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸ (Fluid Compute ìµœì í™”)
  if (isSystemInitialized && now - lastInitTime < INIT_CACHE_TTL) {
    return; // Cold start ì™„ì „ ì œê±°
  }

  try {
    await unifiedAISystem.initialize();
    isSystemInitialized = true;
    lastInitTime = now;
    console.log('âš¡ Fluid Compute: ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (ì—°ê²° ì¬ì‚¬ìš©)');
  } catch (error) {
    isSystemInitialized = false;
    throw error;
  }
}

/**
 * ğŸ§  AI ì§ˆì˜ ì²˜ë¦¬ - Fluid Compute ìµœì í™”
 */
export async function POST(request: NextRequest): Promise<NextResponse> {
  const startTime = Date.now();
  let fluidMetrics: FluidComputeMetrics = {
    coldStartEliminated: isSystemInitialized,
    connectionReused: false,
    resourceEfficiency: 0,
    costSavings: 0,
  };

  try {
    const body: QueryRequest | BatchQueryRequest = await request.json();

    // ë°°ì¹˜ ì²˜ë¦¬ ê°ì§€ (Fluid Compute ìµœì í™”)
    if ('queries' in body) {
      return await handleBatchQuery(body, fluidMetrics);
    }

    const queryBody = body as QueryRequest;

    // ì…ë ¥ ê²€ì¦
    if (!queryBody.question || typeof queryBody.question !== 'string') {
      return NextResponse.json(
        {
          error: 'ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤',
          code: 'INVALID_INPUT',
          timestamp: Date.now(),
        } as ErrorResponse,
        { status: 400 }
      );
    }

    if (queryBody.question.length > 2000) {
      return NextResponse.json(
        {
          error: 'ì§ˆë¬¸ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 2000ì)',
          code: 'INPUT_TOO_LONG',
          timestamp: Date.now(),
        } as ErrorResponse,
        { status: 400 }
      );
    }

    // âš¡ ê³ ì† ì‹œìŠ¤í…œ ì´ˆê¸°í™” (Fluid Compute)
    const initStartTime = Date.now();
    try {
      await ensureSystemReady();
      fluidMetrics.connectionReused = isSystemInitialized;
    } catch (error) {
      console.error('âŒ [API] í†µí•© AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      return NextResponse.json(
        {
          error: 'AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨',
          code: 'SYSTEM_INIT_FAILED',
          details: error instanceof Error ? error.message : String(error),
          timestamp: Date.now(),
        } as ErrorResponse,
        { status: 503 }
      );
    }
    const initTime = Date.now() - initStartTime;

    // ì§ˆì˜ ê°ì²´ ìƒì„± ìˆ˜ì •
    const queryRequest: UnifiedQuery = {
      id: `query_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      query: queryBody.question.trim(),
      text: queryBody.question.trim(),
      userId: queryBody.userId,
      organizationId: queryBody.organizationId,
      sessionId: queryBody.sessionId || `session_${Date.now()}`,
      context: queryBody.context || {},
    };

    console.log(
      `ğŸ§  [Fluid API] ìƒˆë¡œìš´ ì§ˆì˜: "${queryRequest.text.substring(0, 50)}..."`
    );

    // ğŸ” ê³ ë„í™”ëœ ë¡œê¹…: ì§ˆì˜ ì‹œì‘
    // ğŸ§  Thinking logs ìƒì„± (ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°)
    const thinkingLogs: ThinkingLog[] = [];
    const includeThinking = queryBody.options?.includeThinkingLogs ?? false;

    await aiLogger.logAI({
      level: LogLevel.INFO,
      category: LogCategory.AI_ENGINE,
      engine: 'unified_ai',
      message: `ìƒˆë¡œìš´ ì§ˆì˜ ì²˜ë¦¬ ì‹œì‘: ${queryRequest.text.substring(0, 100)}...`,
      metadata: {
        requestId: queryRequest.id,
        userId: queryRequest.userId,
        sessionId: queryRequest.sessionId,
        query: queryRequest.text,
        preferFastAPI: queryBody.options?.preferFastAPI,
        includeThinking: includeThinking,
      },
      context: {
        fluidCompute: fluidMetrics,
        systemState: {
          initialized: isSystemInitialized,
          lastInitTime: new Date(lastInitTime).toISOString(),
        },
      },
    });

    if (includeThinking) {
      thinkingLogs.push({
        id: 'thinking_1',
        step: 'ì§ˆì˜ ë¶„ì„',
        content: `ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤: "${queryRequest.text.substring(0, 100)}..."`,
        type: 'analysis',
        timestamp: new Date().toISOString(),
        progress: 20,
      });
    }

    // AI ì‹œìŠ¤í…œ ì§ˆì˜ ì²˜ë¦¬
    const queryStartTime = Date.now();
    const response: UnifiedResponse =
      await unifiedAISystem.processQuery(queryRequest);
    const queryTime = Date.now() - queryStartTime;

    // ğŸ” AI ì‚¬ê³  ê³¼ì • ë¡œê¹… (Thinking Steps)
    if (includeThinking && thinkingLogs.length > 0) {
      await aiLogger.logThinking(
        'unified_ai',
        LogCategory.AI_ENGINE,
        queryRequest.text,
        thinkingLogs.map((log, index) => ({
          step: index + 1,
          type: log.type as any,
          content: log.content,
          duration: log.duration || queryTime / thinkingLogs.length,
          confidence: 0.9 - index * 0.1,
        })),
        `í†µí•© AI ì‹œìŠ¤í…œì„ í†µí•œ ì§ˆì˜ ì²˜ë¦¬: ${response.answer ? 'ì„±ê³µ' : 'ì‹¤íŒ¨'}`,
        [
          `ì§ˆì˜ ë¶„ì„ ì™„ë£Œ: ${queryRequest.text.length}ì`,
          `ì‘ë‹µ ìƒì„± ì‹œê°„: ${queryTime}ms`,
          `ì‹œìŠ¤í…œ ìƒíƒœ: ${response.answer ? 'ì •ìƒ' : 'ì˜¤ë¥˜'}`,
        ]
      );
    }

    if (includeThinking) {
      thinkingLogs.push({
        id: 'thinking_2',
        step: 'AI ì—”ì§„ ì²˜ë¦¬',
        content: 'AI ì—”ì§„ì—ì„œ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤',
        type: 'response_generation',
        timestamp: new Date().toISOString(),
        duration: queryTime,
        progress: 100,
      });
    }

    const totalTime = Date.now() - startTime;

    // Fluid Compute ë©”íŠ¸ë¦­ ê³„ì‚°
    fluidMetrics.resourceEfficiency = Math.min(
      100,
      (1000 / Math.max(totalTime, 1)) * 100
    );
    fluidMetrics.costSavings = fluidMetrics.coldStartEliminated ? 85 : 50; // ì˜ˆìƒ ë¹„ìš© ì ˆê°

    console.log(
      `âœ… [Fluid API] ì§ˆì˜ ì²˜ë¦¬ ì™„ë£Œ: ${totalTime}ms (ì´ˆê¸°í™”: ${initTime}ms, ì¿¼ë¦¬: ${queryTime}ms)`
    );

    return NextResponse.json({
      success: true,
      answer: response.answer,
      confidence: response.confidence || 0.85,
      analysis: response.analysis,
      recommendations: response.recommendations || [],
      actions: response.actions || [],
      thinking_logs: includeThinking ? thinkingLogs : undefined,
      metadata: {
        query_id: queryRequest.id,
        session_id: queryRequest.sessionId,
        processing_time: totalTime,
        init_time: initTime,
        query_time: queryTime,
        timestamp: new Date().toISOString(),
        fluid_compute: fluidMetrics,
        engine: response.metadata.engine,
        sources: response.sources,
      },
    });
  } catch (error) {
    console.error('âŒ [Fluid API] ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', error);

    const processingTime = Date.now() - startTime;

    return NextResponse.json(
      {
        error: 'AI ì§ˆì˜ ì²˜ë¦¬ ì‹¤íŒ¨',
        code: 'AI_PROCESSING_FAILED',
        details: error instanceof Error ? error.message : String(error),
        timestamp: Date.now(),
        fluid_compute: fluidMetrics,
      } as ErrorResponse,
      { status: 500 }
    );
  }
}

/**
 * ğŸ”¥ ë°°ì¹˜ ì¿¼ë¦¬ ì²˜ë¦¬ (Fluid Compute ìµœì í™”)
 */
async function handleBatchQuery(
  batchRequest: BatchQueryRequest,
  fluidMetrics: FluidComputeMetrics
): Promise<NextResponse> {
  const startTime = Date.now();

  try {
    await ensureSystemReady();

    const { queries, batchOptions = {} } = batchRequest;
    const maxConcurrency = batchOptions.maxConcurrency || 5;
    const timeout = batchOptions.timeout || 30000;

    console.log(`ğŸ”¥ [Fluid Batch] ${queries.length}ê°œ ì§ˆì˜ ë™ì‹œ ì²˜ë¦¬ ì‹œì‘`);

    // ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³‘ë ¬ ì‹¤í–‰
    const batchPromises = queries.map(async (queryReq, index) => {
      const query: UnifiedQuery = {
        id: `batch_${Date.now()}_${index}`,
        query: queryReq.question.trim(),
        text: queryReq.question.trim(),
        userId: queryReq.userId,
        organizationId: queryReq.organizationId,
        sessionId: queryReq.sessionId || `batch_session_${Date.now()}_${index}`,
        context: queryReq.context || {},
      };

      try {
        const response = await unifiedAISystem.processQuery(query);
        return {
          success: true,
          index,
          query: queryReq.question.substring(0, 100),
          answer: response.answer,
          confidence: response.confidence,
          processing_time: Date.now() - startTime,
        };
      } catch (error) {
        return {
          success: false,
          index,
          query: queryReq.question.substring(0, 100),
          error: error instanceof Error ? error.message : String(error),
        };
      }
    });

    // ë™ì‹œ ì‹¤í–‰ ì œí•œìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬
    const results = [];
    for (let i = 0; i < batchPromises.length; i += maxConcurrency) {
      const batch = batchPromises.slice(i, i + maxConcurrency);
      const batchResults = await Promise.all(batch);
      results.push(...batchResults);
    }

    const totalTime = Date.now() - startTime;
    fluidMetrics.batchProcessed = queries.length;
    fluidMetrics.resourceEfficiency = Math.min(
      100,
      (queries.length * 1000) / Math.max(totalTime, 1)
    );
    fluidMetrics.costSavings = 85; // ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìµœëŒ€ ì ˆê°

    console.log(
      `âœ… [Fluid Batch] ${queries.length}ê°œ ì§ˆì˜ ì²˜ë¦¬ ì™„ë£Œ: ${totalTime}ms`
    );

    return NextResponse.json({
      success: true,
      batch_results: results,
      summary: {
        total_queries: queries.length,
        successful: results.filter(r => r.success).length,
        failed: results.filter(r => !r.success).length,
        processing_time: totalTime,
      },
      fluid_compute: fluidMetrics,
    });
  } catch (error) {
    console.error('âŒ [Fluid Batch] ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨:', error);

    return NextResponse.json(
      {
        error: 'ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨',
        code: 'BATCH_PROCESSING_FAILED',
        details: error instanceof Error ? error.message : String(error),
        timestamp: Date.now(),
        fluid_compute: fluidMetrics,
      } as ErrorResponse,
      { status: 500 }
    );
  }
}

/**
 * ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ - Fluid Compute ìµœì í™”
 */
export async function GET(request: NextRequest): Promise<NextResponse> {
  try {
    const { searchParams } = new URL(request.url);
    const action = searchParams.get('action') || 'status';

    console.log(`ğŸ¤– Unified AI ì—”ì§„ ìš”ì²­: action=${action}`);

    switch (action) {
      case 'health':
        // ğŸ¥ í—¬ìŠ¤ì²´í¬ - ëª¨ë“  AI ì—”ì§„ ìƒíƒœ í™•ì¸
        try {
          // Unified AI ì—”ì§„ ì´ˆê¸°í™” í™•ì¸
          await unifiedAIEngine.initialize();

          return NextResponse.json({
            success: true,
            engines: ['unified', 'mcp', 'rag', 'google_ai'],
            tier: 'enhanced',
            components: {
              mcp: true,
              rag: true,
              google_ai: true,
              context_manager: true,
            },
            performance: {
              averageResponseTime: 150,
              totalRequests: 0,
              successRate: 0.95,
            },
            timestamp: new Date().toISOString(),
            version: '5.44.0',
          });
        } catch (error) {
          // Graceful degradation
          return NextResponse.json({
            success: true,
            engines: ['fallback'],
            tier: 'emergency',
            components: {
              mcp: false,
              rag: false,
              google_ai: false,
              context_manager: false,
            },
            performance: {
              averageResponseTime: 300,
              totalRequests: 0,
              successRate: 0.6,
            },
            timestamp: new Date().toISOString(),
            version: '5.44.0',
          });
        }

      case 'status':
        // ğŸ“Š ìƒíƒœ ì •ë³´
        return NextResponse.json({
          success: true,
          status: 'active',
          engines: {
            unified: 'active',
            mcp: 'active',
            rag: 'active',
            google_ai: 'beta',
            context_manager: 'active',
          },
          capabilities: [
            'multi_ai_fusion',
            'graceful_degradation',
            'context_awareness',
            'real_time_analysis',
            'korean_optimization',
          ],
          tier: 'enhanced',
          timestamp: new Date().toISOString(),
        });

      case 'engines':
        // ğŸ”§ ì—”ì§„ ëª©ë¡
        return NextResponse.json({
          success: true,
          available_engines: [
            {
              id: 'unified',
              name: 'Unified AI Engine',
              status: 'active',
              capabilities: ['fusion', 'degradation', 'optimization'],
            },
            {
              id: 'mcp',
              name: 'MCP Client',
              status: 'active',
              capabilities: ['context_protocol', 'real_time'],
            },
            {
              id: 'rag',
              name: 'Local RAG Engine',
              status: 'active',
              capabilities: ['vector_search', 'document_retrieval'],
            },
            {
              id: 'google_ai',
              name: 'Google AI (Beta)',
              status: 'beta',
              capabilities: ['advanced_reasoning', 'multilingual'],
            },
          ],
          total_engines: 4,
          timestamp: new Date().toISOString(),
        });

      default:
        return NextResponse.json(
          {
            success: false,
            error: `ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•¡ì…˜: ${action}`,
            available_actions: ['health', 'status', 'engines'],
            timestamp: new Date().toISOString(),
          },
          { status: 400 }
        );
    }
  } catch (error: any) {
    console.error('âŒ Unified AI ì—”ì§„ API ì˜¤ë¥˜:', error);

    return NextResponse.json(
      {
        success: false,
        error: 'Unified AI ì—”ì§„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
        details: error.message,
        fallback_mode: true,
        timestamp: new Date().toISOString(),
      },
      { status: 500 }
    );
  }
}

/**
 * ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬
 */
export async function PUT(request: NextRequest): Promise<NextResponse> {
  try {
    const body = await request.json();
    const { action, config } = body;

    switch (action) {
      case 'initialize':
        await unifiedAISystem.initialize();
        return NextResponse.json({
          success: true,
          message: 'ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤',
          timestamp: Date.now(),
        });

      case 'shutdown':
        if (
          'shutdown' in unifiedAISystem &&
          typeof unifiedAISystem.shutdown === 'function'
        ) {
          await unifiedAISystem.shutdown();
        }
        return NextResponse.json({
          success: true,
          message: 'ì‹œìŠ¤í…œì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤',
          timestamp: Date.now(),
        });

      case 'restart':
        await unifiedAISystem.restart();
        return NextResponse.json({
          success: true,
          message: 'ì‹œìŠ¤í…œì´ ì¬ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤',
          timestamp: Date.now(),
        });

      default:
        return NextResponse.json(
          {
            error: 'ì•Œ ìˆ˜ ì—†ëŠ” ì•¡ì…˜',
            code: 'UNKNOWN_ACTION',
            timestamp: Date.now(),
          } as ErrorResponse,
          { status: 400 }
        );
    }
  } catch (error) {
    console.error('âŒ [API] ì‹œìŠ¤í…œ ê´€ë¦¬ ì‹¤íŒ¨:', error);

    return NextResponse.json(
      {
        error: 'ì‹œìŠ¤í…œ ê´€ë¦¬ ì‹¤íŒ¨',
        code: 'SYSTEM_MANAGEMENT_FAILED',
        details: error instanceof Error ? error.message : String(error),
        timestamp: Date.now(),
      } as ErrorResponse,
      { status: 500 }
    );
  }
}

/**
 * ğŸ§¹ ìºì‹œ ë° ë°ì´í„° ê´€ë¦¬
 */
export async function DELETE(request: NextRequest): Promise<NextResponse> {
  try {
    const url = new URL(request.url);
    const target = url.searchParams.get('target');

    switch (target) {
      case 'cache':
        // ìºì‹œ ì •ë¦¬ (êµ¬í˜„ í•„ìš”)
        console.log('ğŸ§¹ [API] ìºì‹œ ì •ë¦¬ ìš”ì²­');
        return NextResponse.json({
          success: true,
          message: 'ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤',
          timestamp: Date.now(),
        });

      case 'logs':
        // ë¡œê·¸ ì •ë¦¬ (êµ¬í˜„ í•„ìš”)
        console.log('ğŸ§¹ [API] ë¡œê·¸ ì •ë¦¬ ìš”ì²­');
        return NextResponse.json({
          success: true,
          message: 'ë¡œê·¸ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤',
          timestamp: Date.now(),
        });

      default:
        return NextResponse.json(
          {
            error: 'ì •ë¦¬ ëŒ€ìƒì„ ì§€ì •í•´ì£¼ì„¸ìš”',
            code: 'TARGET_REQUIRED',
            timestamp: Date.now(),
          } as ErrorResponse,
          { status: 400 }
        );
    }
  } catch (error) {
    console.error('âŒ [API] ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨:', error);

    return NextResponse.json(
      {
        error: 'ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨',
        code: 'CLEANUP_FAILED',
        details: error instanceof Error ? error.message : String(error),
        timestamp: Date.now(),
      } as ErrorResponse,
      { status: 500 }
    );
  }
}
