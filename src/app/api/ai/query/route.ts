/**
 * ğŸ¤– AI í†µí•© ì¿¼ë¦¬ API v2.0 (Non-Streaming JSON)
 *
 * 4-ëª¨ë¸ ë¼ìš°íŒ… ì•„í‚¤í…ì²˜:
 * 1. Router (8B): llama-3.1-8b-instantë¡œ ë¹ ë¥¸ ë³µì¡ë„ ë¶„ë¥˜
 * 2. Simple (1-3): Gemini 2.5 Flash â†’ Llama 8B í´ë°±
 * 3. Complex (4-5): Gemini 2.5 Pro â†’ Llama 70B í´ë°±
 *
 * POST /api/ai/query
 */

import { google } from '@ai-sdk/google';
import { groq } from '@ai-sdk/groq';
import { generateText, tool } from 'ai';
import type { NextRequest } from 'next/server';
import { z } from 'zod';
import {
  checkGoogleAIRateLimit,
  getGoogleAIKey,
} from '@/lib/ai/google-ai-manager';
import {
  checkGroqAIRateLimit,
  type GroqModel,
  isGroqAIAvailable,
} from '@/lib/ai/groq-ai-manager';
import { classifyQuery } from '@/lib/ai/query-classifier';
import { withAuth } from '@/lib/auth/api-auth';
import { createClient } from '@/lib/supabase/server';
import { SupabaseRAGEngine } from '@/services/ai/supabase-rag-engine';
import { loadHourlyScenarioData } from '@/services/scenario/scenario-loader';

// ìµœëŒ€ ì‹¤í–‰ ì‹œê°„: 30ì´ˆ
export const maxDuration = 30;

// ============================================================================
// Tools (unified-streamê³¼ ë™ì¼)
// ============================================================================

const callUnifiedProcessor = tool({
  description:
    'ë³µì¡í•œ ë¶„ì„ ìš”ì²­ì„ í†µí•© AI í”„ë¡œì„¸ì„œë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (GCP Cloud Functions)',
  inputSchema: z.object({
    query: z.string().describe('ì‚¬ìš©ì ì§ˆë¬¸'),
    processors: z
      .array(z.string())
      .describe(
        'ì‹¤í–‰í•  í”„ë¡œì„¸ì„œ ëª©ë¡ (korean_nlp, ml_analytics, server_analyzer)'
      ),
  }),
  execute: async ({
    query,
    processors,
  }: {
    query: string;
    processors: string[];
  }) => {
    try {
      const gcpEndpoint =
        process.env.NEXT_PUBLIC_GCP_UNIFIED_PROCESSOR_ENDPOINT;
      if (!gcpEndpoint) {
        throw new Error(
          'NEXT_PUBLIC_GCP_UNIFIED_PROCESSOR_ENDPOINT is not configured'
        );
      }

      const allServers = await loadHourlyScenarioData();
      const serverIds = allServers.map((s) => s.id);

      const response = await fetch(gcpEndpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query,
          context: {
            server_ids: serverIds,
            timestamp: new Date().toISOString(),
          },
          processors,
          options: { ml_model: 'anomaly_detection' },
        }),
        signal: AbortSignal.timeout(15000),
      });

      if (!response.ok) {
        throw new Error(`Unified Processor API error: ${response.status}`);
      }

      const result = await response.json();
      return {
        success: true,
        data: result.data,
        timestamp: new Date().toISOString(),
        _source: 'GCP Unified AI Processor',
        _performance: result.performance,
      };
    } catch (error) {
      console.error('âŒ Unified Processor í˜¸ì¶œ ì‹¤íŒ¨:', error);
      return {
        success: false,
        error: 'í†µí•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        _fallback_needed: true,
      };
    }
  },
});

const getServerMetrics = tool({
  description:
    'ì„œë²„ CPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜)',
  inputSchema: z.object({
    serverId: z.string().optional().describe('ì¡°íšŒí•  ì„œë²„ ID (ì„ íƒ)'),
    metric: z
      .enum(['cpu', 'memory', 'disk', 'all'])
      .describe('ì¡°íšŒí•  ë©”íŠ¸ë¦­ íƒ€ì…'),
  }),
  execute: async ({
    serverId,
    metric: _metric,
  }: {
    serverId?: string;
    metric: 'cpu' | 'memory' | 'disk' | 'all';
  }) => {
    const allServers = await loadHourlyScenarioData();
    const target = serverId
      ? allServers.find((s) => s.id === serverId)
      : allServers;

    const servers = Array.isArray(target)
      ? target
      : target
        ? [target]
        : allServers;

    return {
      success: true,
      servers: servers.map((s) => ({
        id: s.id,
        name: s.name,
        status: s.status,
        cpu: s.cpu,
        memory: s.memory,
        disk: s.disk,
      })),
      summary: {
        total: servers.length,
        alertCount: servers.filter(
          (s) => s.status === 'warning' || s.status === 'critical'
        ).length,
      },
      timestamp: new Date().toISOString(),
      _dataSource: 'scenario-loader',
    };
  },
});

const searchKnowledgeBase = tool({
  description: 'ê³¼ê±° ì¥ì•  ì´ë ¥ ë° í•´ê²° ë°©ë²•ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤ (Real RAG)',
  inputSchema: z.object({
    query: z.string().describe('ê²€ìƒ‰ ì¿¼ë¦¬'),
  }),
  execute: async ({ query }: { query: string }) => {
    try {
      const supabase = await createClient();
      const ragEngine = new SupabaseRAGEngine(supabase);

      const searchResult = await ragEngine.searchHybrid(query, {
        maxResults: 3,
        enableKeywordFallback: true,
      });

      if (!searchResult.success || searchResult.results.length === 0) {
        return {
          success: false,
          message: 'ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        };
      }

      return {
        success: true,
        results: searchResult.results.map((r) => ({
          content: r.content,
          similarity: r.similarity,
        })),
        _source: 'Supabase pgvector',
      };
    } catch (error) {
      console.error('âŒ RAG ê²€ìƒ‰ ì‹¤íŒ¨:', error);
      return { success: false, error: 'ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜' };
    }
  },
});

const analyzePattern = tool({
  description:
    'ì‚¬ìš©ì ì§ˆë¬¸ì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì¦‰ê°ì ì¸ ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤ (Offline)',
  inputSchema: z.object({
    query: z.string().describe('ë¶„ì„í•  ì‚¬ìš©ì ì§ˆë¬¸'),
  }),
  execute: async ({ query }: { query: string }) => {
    const patterns: string[] = [];
    const q = query.toLowerCase();

    if (/cpu|í”„ë¡œì„¸ì„œ|ì„±ëŠ¥/i.test(q)) patterns.push('system_performance');
    if (/ë©”ëª¨ë¦¬|ram|memory/i.test(q)) patterns.push('memory_status');
    if (/ë””ìŠ¤í¬|ì €ì¥ì†Œ|ìš©ëŸ‰/i.test(q)) patterns.push('storage_info');
    if (/ì„œë²„|ì‹œìŠ¤í…œ|ìƒíƒœ/i.test(q)) patterns.push('server_status');

    if (patterns.length === 0) {
      return { success: false, message: 'ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ ì—†ìŒ' };
    }

    return {
      success: true,
      patterns,
      detectedIntent: patterns[0],
      _mode: 'offline-pattern-match',
    };
  },
});

const recommendCommands = tool({
  description: 'ì‚¬ìš©ì ì§ˆë¬¸ì— ì í•©í•œ CLI ëª…ë ¹ì–´ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤ (Offline)',
  inputSchema: z.object({
    keywords: z.array(z.string()).describe('ì§ˆë¬¸ì—ì„œ ì¶”ì¶œí•œ í•µì‹¬ í‚¤ì›Œë“œ'),
  }),
  execute: async ({ keywords }: { keywords: string[] }) => {
    const recommendations = [
      {
        keywords: ['ì„œë²„', 'ëª©ë¡', 'ì¡°íšŒ'],
        command: 'list servers',
        description: 'ì„œë²„ ëª©ë¡ ì¡°íšŒ',
      },
      {
        keywords: ['ìƒíƒœ', 'ì²´í¬', 'í™•ì¸'],
        command: 'status check',
        description: 'ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€',
      },
      {
        keywords: ['ë¡œê·¸', 'ë¶„ì„', 'ì—ëŸ¬'],
        command: 'analyze logs',
        description: 'ë¡œê·¸ ë¶„ì„',
      },
    ];

    const matched = recommendations.filter((rec) =>
      keywords.some((k) =>
        rec.keywords.some((rk) => rk.includes(k) || k.includes(rk))
      )
    );

    return {
      success: true,
      recommendations:
        matched.length > 0 ? matched : recommendations.slice(0, 2),
      _mode: 'offline-command-recommendation',
    };
  },
});

const analyzeRequest = tool({
  description: 'ì§ˆë¬¸ì˜ ì˜ë„ì™€ ë³µì¡ë„ë¥¼ í•œ ë²ˆì— ë¶„ì„í•©ë‹ˆë‹¤ (Thinking Step)',
  inputSchema: z.object({
    query: z.string().describe('ì‚¬ìš©ì ì§ˆë¬¸'),
  }),
  execute: async ({ query }: { query: string }) => {
    const lowerQuery = query.toLowerCase();
    let intent = 'general';
    let complexity = 1;

    if (
      lowerQuery.includes('cpu') ||
      lowerQuery.includes('ë©”ëª¨ë¦¬') ||
      lowerQuery.includes('ìƒíƒœ')
    ) {
      intent = 'monitoring';
      complexity = 2;
    } else if (
      lowerQuery.includes('ì¥ì• ') ||
      lowerQuery.includes('ì›ì¸') ||
      lowerQuery.includes('ë¶„ì„')
    ) {
      intent = 'analysis';
      complexity = 4;
    } else if (lowerQuery.includes('ì¶”ì²œ') || lowerQuery.includes('ë°©ë²•')) {
      intent = 'guide';
      complexity = 3;
    }

    const recommendation =
      complexity >= 3
        ? 'unified-processor'
        : complexity >= 2
          ? 'rag-search'
          : 'offline-tool';

    return {
      intent,
      complexity,
      recommendation,
      reasoning: `ì˜ë„: ${intent}, ë³µì¡ë„: ${complexity} -> ì „ëµ: ${recommendation}`,
    };
  },
});

// ============================================================================
// Request/Response Types
// ============================================================================

interface QueryRequest {
  query: string;
  context?: string;
  temperature?: number;
  maxTokens?: number;
  includeThinking?: boolean;
  metadata?: {
    totalServers?: number;
    onlineServers?: number;
    warningServers?: number;
    criticalServers?: number;
    avgCpu?: number;
    avgMemory?: number;
    timestamp?: string;
  };
}

// ============================================================================
// Model Configuration (4-Model Architecture)
// ============================================================================

/**
 * ëª¨ë¸ ì„ íƒ ê²°ê³¼
 */
interface ModelSelection {
  primary: ReturnType<typeof google> | ReturnType<typeof groq>;
  fallback: ReturnType<typeof groq> | null;
  primaryName: string;
  fallbackName: string | null;
  isComplex: boolean;
}

/**
 * ë³µì¡ë„ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ
 * - Simple (1-3): Flash ê³„ì—´ (ë¹ ë¥¸ ì‘ë‹µ)
 * - Complex (4-5): Pro ê³„ì—´ (ê¹Šì€ ë¶„ì„)
 */
function selectModels(complexity: number): ModelSelection {
  const isComplex = complexity >= 4;

  const googleApiKey = getGoogleAIKey();
  const googleRateCheck = checkGoogleAIRateLimit();
  const groqAvailable = isGroqAIAvailable();
  const groqRateCheck = checkGroqAIRateLimit();

  const googleAvailable = googleApiKey && googleRateCheck.allowed;
  const groqAllowed = groqAvailable && groqRateCheck.allowed;

  // Complex (4-5): Pro ëª¨ë¸
  if (isComplex) {
    if (googleAvailable) {
      return {
        primary: google('gemini-2.5-pro'),
        fallback: groqAllowed ? groq('llama-3.3-70b-versatile') : null,
        primaryName: 'gemini-2.5-pro',
        fallbackName: groqAllowed ? 'llama-3.3-70b-versatile' : null,
        isComplex: true,
      };
    }
    // Google ë¶ˆê°€ â†’ Groq 70B ì‚¬ìš©
    if (groqAllowed) {
      return {
        primary: groq('llama-3.3-70b-versatile'),
        fallback: null,
        primaryName: 'llama-3.3-70b-versatile',
        fallbackName: null,
        isComplex: true,
      };
    }
  }

  // Simple (1-3): Flash ëª¨ë¸
  if (googleAvailable) {
    return {
      primary: google('gemini-2.5-flash'),
      fallback: groqAllowed ? groq('llama-3.1-8b-instant') : null,
      primaryName: 'gemini-2.5-flash',
      fallbackName: groqAllowed ? 'llama-3.1-8b-instant' : null,
      isComplex: false,
    };
  }
  // Google ë¶ˆê°€ â†’ Groq 8B ì‚¬ìš©
  if (groqAllowed) {
    return {
      primary: groq('llama-3.1-8b-instant'),
      fallback: null,
      primaryName: 'llama-3.1-8b-instant',
      fallbackName: null,
      isComplex: false,
    };
  }

  // ëª¨ë“  AI ì‚¬ìš© ë¶ˆê°€
  throw new Error('AI APIê°€ ëª¨ë‘ ì‚¬ìš© ë¶ˆê°€í•©ë‹ˆë‹¤ (Google AI, Groq)');
}

// ============================================================================
// POST Handler (4-Model Routing Architecture)
// ============================================================================

export const POST = withAuth(async (req: NextRequest) => {
  const startTime = Date.now();

  try {
    const body: QueryRequest = await req.json();
    const { query, metadata, includeThinking = false } = body;

    if (!query || typeof query !== 'string') {
      return Response.json(
        { error: 'query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤' },
        { status: 400 }
      );
    }

    // ============================================================
    // Step 1: Router (8B) - ë¹ ë¥¸ ë³µì¡ë„ ë¶„ë¥˜
    // ============================================================
    const classification = await classifyQuery(query);
    const { complexity, intent, reasoning: routingReason } = classification;

    console.log(
      `ğŸ“¡ [AI Router] Intent: ${intent}, Complexity: ${complexity}/5, Reason: ${routingReason}`
    );

    // ============================================================
    // Step 2: Model Selection (4-Model Architecture)
    // ============================================================
    let modelSelection: ModelSelection;
    try {
      modelSelection = selectModels(complexity);
    } catch (error) {
      return Response.json(
        {
          error:
            error instanceof Error
              ? error.message
              : 'AI ëª¨ë¸ ì„ íƒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ',
        },
        { status: 500 }
      );
    }

    const { primary, fallback, primaryName, fallbackName, isComplex } =
      modelSelection;

    // ============================================================
    // Step 3: System Prompt êµ¬ì„±
    // ============================================================
    const systemPrompt = `ë‹¹ì‹ ì€ **OpenManager Vibe**ì˜ **AI ì–´ì‹œìŠ¤í„´íŠ¸**ì…ë‹ˆë‹¤.
í˜„ì¬ ëª¨ë“œ: ${isComplex ? 'ğŸ§  Deep Reasoning (Pro)' : 'âš¡ Fast Response (Flash)'}
ì§ˆë¬¸ ì˜ë„: ${intent} (ë³µì¡ë„: ${complexity}/5)

**í˜„ì¬ ëŒ€ì‹œë³´ë“œ ì»¨í…ìŠ¤íŠ¸:**
${
  metadata
    ? `- ì´ ì„œë²„: ${metadata.totalServers || 0}ê°œ
- ì •ìƒ ì„œë²„: ${metadata.onlineServers || 0}ê°œ
- ê²½ê³  ì„œë²„: ${metadata.warningServers || 0}ê°œ
- ì‹¬ê° ì„œë²„: ${metadata.criticalServers || 0}ê°œ
- í‰ê·  CPU: ${metadata.avgCpu || 0}%
- í‰ê·  ë©”ëª¨ë¦¬: ${metadata.avgMemory || 0}%`
    : 'ë©”íƒ€ë°ì´í„° ì—†ìŒ'
}

**ğŸš¨ ì²˜ë¦¬ ì „ëµ (4-Model Routing)**
- ë³µì¡ë„ 1-2: ë‹¨ìˆœ ì¡°íšŒ â†’ \`analyzePattern\`, \`recommendCommands\`
- ë³µì¡ë„ 3: ì§€ì‹ ê¸°ë°˜ â†’ \`searchKnowledgeBase\`
- ë³µì¡ë„ 4-5: ì‹¬ì¸µ ë¶„ì„ â†’ \`callUnifiedProcessor\`

í•­ìƒ íŒ©íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ê³ , ë¶ˆí™•ì‹¤í•  ê²½ìš° ì†”ì§íˆ ëª¨ë¥¸ë‹¤ê³  í•˜ì‹­ì‹œì˜¤.
í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤.`;

    // ============================================================
    // Step 4: Primary Model ì‹¤í–‰
    // ============================================================
    let responseText = '';
    let usedEngine = primaryName;
    let fallbackUsed = false;
    const thinkingSteps: string[] = [];

    if (includeThinking) {
      thinkingSteps.push(`ğŸ” Router: ${intent} (ë³µì¡ë„ ${complexity}/5)`);
      thinkingSteps.push(`ğŸ¯ ì„ íƒëœ ëª¨ë¸: ${primaryName}`);
    }

    const tools = {
      analyzeRequest,
      callUnifiedProcessor,
      getServerMetrics,
      searchKnowledgeBase,
      analyzePattern,
      recommendCommands,
    };

    try {
      const result = await generateText({
        model: primary,
        messages: [{ role: 'user', content: query }],
        tools,
        system: systemPrompt,
        maxOutputTokens: isComplex ? 4096 : 2048,
        temperature: isComplex ? 0.7 : 0.5,
      });

      responseText = result.text || 'ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';

      // Tool calls ê¸°ë¡
      if (includeThinking && result.toolCalls && result.toolCalls.length > 0) {
        for (const toolCall of result.toolCalls) {
          const toolArgs = 'args' in toolCall ? toolCall.args : {};
          thinkingSteps.push(
            `ğŸ”§ ${toolCall.toolName}: ${JSON.stringify(toolArgs)}`
          );
        }
      }

      // ì‚¬ìš©ëŸ‰ ê¸°ë¡
      if (includeThinking && result.usage) {
        thinkingSteps.push(
          `ğŸ“Š í† í°: ${result.usage.totalTokens} (input: ${result.usage.inputTokens}, output: ${result.usage.outputTokens})`
        );
      }
    } catch (primaryError) {
      console.warn(
        `âš ï¸ Primary Model (${primaryName}) ì‹¤íŒ¨:`,
        primaryError instanceof Error ? primaryError.message : primaryError
      );

      // ============================================================
      // Step 5: Fallback Model ì‹¤í–‰
      // ============================================================
      if (fallback && fallbackName) {
        console.log(`ğŸ”„ Fallback ì „í™˜: ${primaryName} â†’ ${fallbackName}`);

        if (includeThinking) {
          thinkingSteps.push(`âš ï¸ ${primaryName} ì‹¤íŒ¨ â†’ ${fallbackName} ì „í™˜`);
        }

        try {
          const fallbackResult = await generateText({
            model: fallback,
            messages: [{ role: 'user', content: query }],
            tools,
            system: systemPrompt + '\n(Note: Fallback model active)',
            maxOutputTokens: isComplex ? 4096 : 2048,
            temperature: isComplex ? 0.7 : 0.5,
          });

          responseText = fallbackResult.text || 'ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';
          usedEngine = fallbackName;
          fallbackUsed = true;

          // Tool calls ê¸°ë¡
          if (
            includeThinking &&
            fallbackResult.toolCalls &&
            fallbackResult.toolCalls.length > 0
          ) {
            for (const toolCall of fallbackResult.toolCalls) {
              const toolArgs = 'args' in toolCall ? toolCall.args : {};
              thinkingSteps.push(
                `ğŸ”§ ${toolCall.toolName}: ${JSON.stringify(toolArgs)}`
              );
            }
          }
        } catch (fallbackError) {
          console.error('âŒ Fallback Modelë„ ì‹¤íŒ¨:', fallbackError);
          throw primaryError; // ì›ë˜ ì˜¤ë¥˜ ì „íŒŒ
        }
      } else {
        throw primaryError;
      }
    }

    const responseTime = Date.now() - startTime;

    // ============================================================
    // Step 6: ì‘ë‹µ ë°˜í™˜
    // ============================================================
    return Response.json({
      response: responseText,
      thinkingSteps,
      engine: usedEngine,
      routing: {
        complexity,
        intent,
        reason: routingReason,
        isComplex,
      },
      fallbackUsed,
      fallbackReason: fallbackUsed
        ? `${primaryName} ì‹¤íŒ¨ â†’ ${fallbackName}`
        : undefined,
      responseTime,
      confidence: fallbackUsed ? 0.8 : isComplex ? 0.9 : 0.85,
      timestamp: new Date().toISOString(),
    });
  } catch (error) {
    console.error('âŒ AI ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨:', error);

    const responseTime = Date.now() - startTime;

    return Response.json(
      {
        error: 'AI ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        response:
          'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
        engine: 'error-fallback',
        responseTime,
        timestamp: new Date().toISOString(),
      },
      { status: 500 }
    );
  }
});
