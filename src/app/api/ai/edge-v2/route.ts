/**
 * ğŸš€ Edge AI API Route v2 - Google AI Only
 *
 * ìˆœìˆ˜ Google AI APIë§Œ ì‚¬ìš©
 * - êµ¬ê¸€ AI ëª¨ë“œ ì „ìš© ì—”ë“œí¬ì¸íŠ¸
 * - RAGë‚˜ ë‹¤ë¥¸ ì„œë¹„ìŠ¤ ì‚¬ìš© ì•ˆí•¨
 * - ë¹ ë¥´ê³  ì§ì ‘ì ì¸ Google AI í˜¸ì¶œ
 */

import { NextRequest, NextResponse } from 'next/server';
import { getGoogleAIModel } from '@/lib/ai/google-ai-client';
import { supabaseRealtimeAdapter } from '@/services/ai/adapters/service-adapters';
import debug from '@/utils/debug';

// Edge Runtime ì„¤ì •
// Edge Runtime ì œê±° - ì•ˆì •ì„± ìš°ì„  (AI êµì°¨ ê²€ì¦ ê²°ê³¼)
export const preferredRegion = 'icn1'; // ì„œìš¸
export const dynamic = 'force-dynamic';
export const revalidate = 0;

// ìš”ì²­ ì œí•œ (ë¬´ë£Œ í‹°ì–´ ë³´í˜¸)
const RATE_LIMIT = {
  windowMs: 60 * 1000, // 1ë¶„
  maxRequests: 10,
};

// ë©”ëª¨ë¦¬ ë‚´ ë ˆì´íŠ¸ ë¦¬ë¯¸í„° (Edge Runtime í˜¸í™˜)
const requestCounts = new Map<string, { count: number; resetTime: number }>();

export async function POST(req: NextRequest) {
  try {
    // 1. ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… (ë¬´ë£Œ í‹°ì–´ ë³´í˜¸)
    const clientIp = req.headers.get('x-forwarded-for') || 'anonymous';
    const now = Date.now();

    const clientData = requestCounts.get(clientIp) || {
      count: 0,
      resetTime: now + RATE_LIMIT.windowMs,
    };

    if (now > clientData.resetTime) {
      clientData.count = 0;
      clientData.resetTime = now + RATE_LIMIT.windowMs;
    }

    if (clientData.count >= RATE_LIMIT.maxRequests) {
      return NextResponse.json(
        { error: 'Too many requests. Please try again later.' },
        { status: 429 }
      );
    }

    clientData.count++;
    requestCounts.set(clientIp, clientData);

    // 2. ìš”ì²­ íŒŒì‹±
    const body = await req.json();
    const { query, userId, sessionId } = body;

    if (!query) {
      return NextResponse.json({ error: 'Query is required' }, { status: 400 });
    }

    const sessionIdString = sessionId || crypto.randomUUID();
    const startTime = Date.now();

    // 3. ìƒê°ì¤‘ ìƒíƒœ ì‹œì‘ (ë¹„ë™ê¸°)
    const thinkingPromise = supabaseRealtimeAdapter
      .addThinkingStep(
        sessionIdString,
        {
          step: 'Google AI ì²˜ë¦¬ ì‹œì‘',
          description: query.substring(0, 100),
          status: 'processing',
          timestamp: Date.now(),
        },
        userId
      )
      .catch(debug.warn);

    // 4. Google AI ì§ì ‘ í˜¸ì¶œ
    const generativeModel = getGoogleAIModel('gemini-1.5-flash');
    
    const result = await generativeModel.generateContent({
      contents: [{ role: 'user', parts: [{ text: query }] }],
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 1000,
        topK: 40,
        topP: 0.95,
      },
    });

    const response = result.response;
    const text = response.text();
    const processingTime = Date.now() - startTime;

    // 5. í†µí•© ì‘ë‹µ í¬ë§· (ê¸°ì¡´ í˜•ì‹ ìœ ì§€)
    const unifiedResponse = {
      success: true,
      response: text,
      engine: 'google-ai',
      confidence: 0.9,
      metadata: {
        model: 'gemini-1.5-flash',
        processingTime,
        actualTokens: response.usageMetadata?.totalTokenCount || 0,
        promptTokens: response.usageMetadata?.promptTokenCount || 0,
        completionTokens: response.usageMetadata?.candidatesTokenCount || 0,
      },
      processing: {
        totalTime: processingTime,
        services: ['google-ai'],
        cacheHit: false,
      },
      timestamp: new Date().toISOString(),
    };

    // 6. ìƒê°ì¤‘ ìƒíƒœ ì™„ë£Œ (ë¹„ë™ê¸°)
    thinkingPromise.then(() =>
      supabaseRealtimeAdapter
        .addThinkingStep(
          sessionIdString,
          {
            step: 'Google AI ì²˜ë¦¬ ì™„ë£Œ',
            status: 'completed',
            timestamp: Date.now(),
            duration: processingTime,
          },
          userId
        )
        .catch(debug.warn)
    );

    // 7. ì‘ë‹µ ë°˜í™˜
    const headers = new Headers({
      'Content-Type': 'application/json',
      'X-Processing-Time': `${processingTime}ms`,
      'X-AI-Engine': 'google-ai',
      'Cache-Control': 'no-cache', // Google AIëŠ” ìºì‹± ì•ˆí•¨
    });

    return NextResponse.json(unifiedResponse, { headers });
  } catch (error) {
    debug.error('Google AI API Error:', error);

    // ì—ëŸ¬ ì‘ë‹µ
    return NextResponse.json(
      {
        success: false,
        error: 'Google AI request failed',
        message: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date().toISOString(),
      },
      { status: 500 }
    );
  }
}

// GET ìš”ì²­: API ìƒíƒœ ë° ì •ë³´ ì œê³µ
export function GET(_req: NextRequest) {
  return NextResponse.json({
    status: 'active',
    version: 'v2-google-ai',
    description: 'Edge AI API v2 - ìˆœìˆ˜ Google AI ì „ìš©',
    runtime: 'nodejs',
    region: 'icn1 (Seoul)',
    features: {
      aiEngine: 'ìˆœìˆ˜ Google AI (Gemini Pro)',
      realtime: 'Supabase Realtime ê¸°ë°˜ ìƒê°ì¤‘ ìƒíƒœ',
      rateLimit: 'ë¬´ë£Œ í‹°ì–´ ë³´í˜¸ (10req/min)',
      noRAG: 'RAGë‚˜ ë‹¤ë¥¸ ì„œë¹„ìŠ¤ ì‚¬ìš© ì•ˆí•¨',
    },
    services: [
      'google-ai-only'
    ],
    usage: {
      method: 'POST',
      contentType: 'application/json',
      body: {
        query: 'string (required) - ì²˜ë¦¬í•  ì§ˆì˜',
        userId: 'string (optional) - ì‚¬ìš©ì ID',
        sessionId: 'string (optional) - ì„¸ì…˜ ID (ìë™ ìƒì„±)',
      },
    },
    aiModel: {
      provider: 'Google AI',
      model: 'gemini-1.5-flash',
      temperature: 0.7,
      maxTokens: 1000,
      constraints: 'Google AI ë¬´ë£Œ í•œë„ (1,000 ìš”ì²­/ì¼)',
    },
    timestamp: new Date().toISOString(),
  });
}

// OPTIONS ìš”ì²­ ì²˜ë¦¬ (CORS)
export function OPTIONS(_req: NextRequest) {
  return new NextResponse(null, {
    status: 200,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

// ì£¼ê¸°ì  ë©”ëª¨ë¦¬ ì •ë¦¬ (5ë¶„ë§ˆë‹¤)
setInterval(
  () => {
    const now = Date.now();
    for (const [ip, data] of requestCounts.entries()) {
      if (now > data.resetTime + RATE_LIMIT.windowMs) {
        requestCounts.delete(ip);
      }
    }
  },
  5 * 60 * 1000
);
