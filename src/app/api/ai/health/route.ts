import { NextResponse } from 'next/server';
import { postgresVectorDB } from '@/services/ai/postgres-vector-db';

/**
 * ğŸ“¡ AI Health Endpoint
 * GET /api/ai/health
 * -------------------------
 * MCP Remote / RAG / Google AI ìƒíƒœë¥¼ ì¢…í•© ë°˜í™˜ (TensorFlow ì§€ì› ì¤‘ë‹¨)
 */

async function getMcpHealth() {
  const MCP_URL =
    process.env.MCP_REMOTE_URL ||
    process.env.MCP_LOCAL_URL ||
    'http://localhost:3100';
  try {
    const res = await fetch(`${MCP_URL}/health`, { next: { revalidate: 0 } });
    if (!res.ok) throw new Error('Bad status');
    const data = await res.json();
    return { status: 'online', latency: data.latency ?? null };
  } catch (e) {
    return { status: 'offline' };
  }
}

async function getTensorFlowHealth() {
  // TensorFlow.js ì§€ì›ì´ v5.43.0ì—ì„œ ì¤‘ë‹¨ë¨
  return {
    status: 'deprecated',
    reason: 'removed_in_v5.43.0',
    message:
      'TensorFlow.js ì§€ì›ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. lightweight-ml-engineì„ ì‚¬ìš©í•˜ì„¸ìš”.',
  };
}

export async function GET() {
  // MCP
  const mcp = await getMcpHealth();

  // RAG / pgvector
  const ragStatus =
    process.env.RAG_FORCE_MEMORY === 'true'
      ? { status: 'memory_mode', documents: 3 }
      : { status: 'pgvector_ready' };

  // TensorFlow (ì•ˆì „í•œ ìƒíƒœ ì²´í¬ë§Œ)
  const tensorflow = await getTensorFlowHealth();

  // Google AI
  const googleAi = process.env.GOOGLE_AI_API_KEY
    ? { status: 'ready', model: 'gemini-pro' }
    : { status: 'no_api_key' };

  return NextResponse.json({
    mcp,
    rag: ragStatus,
    tensorflow,
    google_ai: googleAi,
    timestamp: new Date().toISOString(),
    overall_status: 'healthy',
  });
}
