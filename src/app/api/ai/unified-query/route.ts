/**
 * ğŸ¤– í†µí•© AI ì¿¼ë¦¬ API - Edge Runtime ìµœì í™” ë²„ì „
 * Vercel Pro/Hobby í”Œëœ ì§€ì›
 */

import { detectEnvironment } from '@/config/environment';
import { EdgeLogger } from '@/lib/edge-runtime-utils';
import { GCPRealDataService } from '@/services/gcp/GCPRealDataService';
import { NextRequest, NextResponse } from 'next/server';

// ğŸš¨ ì‘ê¸‰ ì¡°ì¹˜: Edge Runtime ë¹„í™œì„±í™” (Vercel Pro ì‚¬ìš©ëŸ‰ ìœ„ê¸°)
// export const runtime = 'edge'; // DISABLED - ì‚¬ìš©ëŸ‰ ê¸‰ì¦ ì›ì¸
export const runtime = 'nodejs';
export const preferredRegion = ['icn1', 'hnd1', 'sin1']; // ì•„ì‹œì•„ ì§€ì—­ ìµœì í™”

// Vercel í”Œëœë³„ ì œí•œì‚¬í•­
const VERCEL_OPTIMIZATION = {
  hobby: {
    maxExecutionTime: 10000, // 10ì´ˆ
    maxConcurrentRequests: 10,
    enableAdvancedFeatures: false,
    ragTimeout: 5000,
    koreanNLPTimeout: 3000,
  },
  pro: {
    maxExecutionTime: 15000, // 15ì´ˆ
    maxConcurrentRequests: 100,
    enableAdvancedFeatures: true,
    ragTimeout: 10000,
    koreanNLPTimeout: 8000,
  },
} as const;

const logger = EdgeLogger.getInstance();

export async function POST(request: NextRequest) {
  const startTime = Date.now();

  // Vercel í”Œëœ ê°ì§€ ë° ì„¤ì •
  const isProPlan =
    process.env.VERCEL_PLAN === 'pro' || process.env.NODE_ENV === 'development';
  const config = isProPlan
    ? VERCEL_OPTIMIZATION.pro
    : VERCEL_OPTIMIZATION.hobby;

  // Edge Runtime íƒ€ì„ì•„ì›ƒ ì„¤ì •
  const controller = new AbortController();
  const timeoutId = setTimeout(
    () => controller.abort(),
    config.maxExecutionTime
  );

  try {
    const { query, options } = await request.json();

    if (!query || typeof query !== 'string') {
      clearTimeout(timeoutId);
      return NextResponse.json(
        {
          success: false,
          error: 'Invalid query parameter',
          message: 'queryëŠ” í•„ìˆ˜ ë¬¸ìì—´ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤',
          timestamp: new Date().toISOString(),
        },
        { status: 400 }
      );
    }

    const env = detectEnvironment();

    // ï¿½ï¿½ Vercel í™˜ê²½: GCP ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ AI ì‘ë‹µ
    if (env.IS_VERCEL) {
      console.log('ğŸŒ Vercel AI ì¿¼ë¦¬:', query);

      const gcpService = GCPRealDataService.getInstance();
      const serverData = await gcpService.getRealServerMetrics();

      // ê°„ë‹¨í•œ AI ì‘ë‹µ ìƒì„± (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ AI ì—”ì§„ ì‚¬ìš©)
      const aiResponse = generateAIResponse(query, serverData.data);

      return NextResponse.json({
        success: true,
        query,
        response: aiResponse,
        dataSource: 'gcp-real-data',
        serverCount: serverData.totalServers,
        timestamp: new Date().toISOString(),
        environment: 'vercel',
      });
    }

    // ğŸ  ë¡œì»¬ í™˜ê²½: ëª©ì—… ë°ì´í„° ê¸°ë°˜ AI ì‘ë‹µ
    console.log('ğŸ  ë¡œì»¬ AI ì¿¼ë¦¬:', query);

    const mockResponse = generateMockAIResponse(query);

    return NextResponse.json({
      success: true,
      query,
      response: mockResponse,
      dataSource: 'mock-data',
      timestamp: new Date().toISOString(),
      environment: 'local',
    });
  } catch (error) {
    clearTimeout(timeoutId);

    console.error('âŒ í†µí•© AI ì¿¼ë¦¬ ì˜¤ë¥˜:', error);

    return NextResponse.json(
      {
        success: false,
        error: 'Internal server error',
        message: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date().toISOString(),
      },
      { status: 500 }
    );
  }
}

export async function GET(request: NextRequest) {
  return NextResponse.json({
    service: 'Unified AI Query API - Edge Runtime',
    status: 'ready',
    version: '5.44.3-edge',
    runtime: 'edge',
    regions: ['icn1', 'hnd1', 'sin1'],
    capabilities: {
      hobby: {
        maxExecutionTime: '10s',
        modes: ['LOCAL'],
        features: ['basic-ai', 'local-rag'],
      },
      pro: {
        maxExecutionTime: '15s',
        modes: ['LOCAL', 'GOOGLE_ONLY'],
        features: [
          'advanced-ai',
          'google-ai',
          'mcp-integration',
          'enhanced-rag',
        ],
      },
    },
    currentPlan: process.env.VERCEL_PLAN || 'development',
    timestamp: new Date().toISOString(),
  });
}

// ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
function generateSessionId(): string {
  return `edge_${Date.now()}_${Math.random().toString(36).substr(2, 6)}`;
}

function formatUnifiedResponse(result: any, isProPlan: boolean) {
  if (!result) {
    return {
      response: generateFallbackResponse(isProPlan),
      confidence: 0.3,
      enginePath: ['fallback'],
      processingTime: 0,
      fallbacksUsed: 1,
    };
  }

  let formattedResponse = result.response || 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';

  // Pro í”Œëœ ë©”íƒ€ë°ì´í„° ì¶”ê°€
  if (isProPlan && result.metadata) {
    if (result.metadata.confidence > 0.8) {
      formattedResponse += `\n\nğŸ¯ **ê³ í’ˆì§ˆ ë¶„ì„** (ì‹ ë¢°ë„: ${Math.round(result.metadata.confidence * 100)}%)`;
    }
    if (result.metadata.ragUsed) {
      formattedResponse += `\nğŸ“š **RAG ì—”ì§„ í™œìš©** - ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ì •í™•í•œ ì‘ë‹µ`;
    }
    if (result.metadata.mcpContextUsed) {
      formattedResponse += `\nğŸ”— **ì‹¤ì‹œê°„ ì»¨í…ìŠ¤íŠ¸** - MCP íŒŒì¼ì‹œìŠ¤í…œ ì—°ë™`;
    }
  }

  return {
    response: formattedResponse,
    confidence: result.confidence || 0.5,
    enginePath: result.enginePath || ['unknown'],
    processingTime: result.processingTime || 0,
    fallbacksUsed: result.fallbacksUsed || 0,
  };
}

function generateTimeoutResponse(isProPlan: boolean): string {
  if (isProPlan) {
    return `â±ï¸ **Pro í”Œëœ - ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼**

ìš”ì²­ì´ ë³µì¡í•˜ì—¬ 15ì´ˆ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.

**ìµœì í™” ì œì•ˆ:**
â€¢ ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ì„¸ë¶„í™”
â€¢ ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì´ìš©
â€¢ ë°°ì¹˜ ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš° ë³„ë„ ë¬¸ì˜

Edge Runtimeì—ì„œ ìµœëŒ€ ì„±ëŠ¥ìœ¼ë¡œ ì²˜ë¦¬í–ˆì§€ë§Œ ì‹œê°„ì´ ë¶€ì¡±í–ˆìŠµë‹ˆë‹¤.`;
  } else {
    return `â±ï¸ **Hobby í”Œëœ - ì²˜ë¦¬ ì‹œê°„ ì œí•œ**

10ì´ˆ ì²˜ë¦¬ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.

**ê¶Œì¥ì‚¬í•­:**
â€¢ ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„
â€¢ Pro í”Œëœ ì—…ê·¸ë ˆì´ë“œì‹œ 15ì´ˆ+ ì²˜ë¦¬ ì‹œê°„
â€¢ ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì€ ê³„ì† ì´ìš© ê°€ëŠ¥

í˜„ì¬ ì œí•œëœ ëª¨ë“œì—ì„œë„ ê¸°ë³¸ ì„œë¹„ìŠ¤ëŠ” ì œê³µë©ë‹ˆë‹¤.`;
  }
}

function generateFallbackResponse(isProPlan: boolean): string {
  if (isProPlan) {
    return `ğŸ”§ **Pro í”Œëœ - ì‹œìŠ¤í…œ ë³µêµ¬ ì¤‘**

AI ì‹œìŠ¤í…œì´ ì¼ì‹œì ìœ¼ë¡œ ì œí•œëœ ëª¨ë“œë¡œ ìš´ì˜ ì¤‘ì…ë‹ˆë‹¤.

**ì´ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥:**
â€¢ ì‹¤ì‹œê°„ ì„œë²„ ëª¨ë‹ˆí„°ë§
â€¢ ê¸°ë³¸ ì„±ëŠ¥ ë¶„ì„
â€¢ ëŒ€ì‹œë³´ë“œ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ

ì‹œìŠ¤í…œì´ ì™„ì „íˆ ë³µêµ¬ë˜ë©´ ê³ ê¸‰ AI ê¸°ëŠ¥ì„ ë‹¤ì‹œ ì´ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`;
  } else {
    return `ğŸ”§ **Hobby í”Œëœ - ê¸°ë³¸ ëª¨ë“œ**

í˜„ì¬ ê¸°ë³¸ ê¸°ëŠ¥ë§Œ ì œê³µë©ë‹ˆë‹¤.

**ì´ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥:**
â€¢ ì„œë²„ ìƒíƒœ í™•ì¸
â€¢ ê¸°ë³¸ ëª¨ë‹ˆí„°ë§
â€¢ ë‹¨ìˆœ ì§ˆì˜ ì‘ë‹µ

Pro í”Œëœ ì—…ê·¸ë ˆì´ë“œì‹œ ê³ ê¸‰ AI ê¸°ëŠ¥ê³¼ ë” ê¸´ ì²˜ë¦¬ ì‹œê°„ì„ ì´ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`;
  }
}

/**
 * ğŸ¤– GCP ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ AI ì‘ë‹µ ìƒì„±
 */
function generateAIResponse(query: string, serverData: any[]): string {
  const lowerQuery = query.toLowerCase();

  if (lowerQuery.includes('ì„œë²„') || lowerQuery.includes('server')) {
    const totalServers = serverData.length;
    const healthyServers = serverData.filter(
      s => s.status === 'healthy'
    ).length;
    const criticalServers = serverData.filter(
      s => s.status === 'critical'
    ).length;

    return `í˜„ì¬ GCPì—ì„œ ${totalServers}ê°œì˜ ì„œë²„ê°€ ìš´ì˜ ì¤‘ì…ë‹ˆë‹¤. ì •ìƒ ìƒíƒœ: ${healthyServers}ê°œ, ìœ„í—˜ ìƒíƒœ: ${criticalServers}ê°œì…ë‹ˆë‹¤.`;
  }

  if (
    lowerQuery.includes('cpu') ||
    lowerQuery.includes('ë©”ëª¨ë¦¬') ||
    lowerQuery.includes('memory')
  ) {
    const avgCpu =
      serverData.reduce((sum, s) => sum + (s.metrics?.cpu?.usage || 0), 0) /
      serverData.length;
    const avgMemory =
      serverData.reduce((sum, s) => sum + (s.metrics?.memory?.usage || 0), 0) /
      serverData.length;

    return `í‰ê·  CPU ì‚¬ìš©ë¥ : ${avgCpu.toFixed(1)}%, í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : ${avgMemory.toFixed(1)}%ì…ë‹ˆë‹¤.`;
  }

  return `GCP ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ "${query}"ì— ëŒ€í•œ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ì´ ${serverData.length}ê°œ ì„œë²„ì˜ ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.`;
}

/**
 * ğŸ  ëª©ì—… ë°ì´í„° ê¸°ë°˜ AI ì‘ë‹µ ìƒì„±
 */
function generateMockAIResponse(query: string): string {
  const lowerQuery = query.toLowerCase();

  if (lowerQuery.includes('ì„œë²„') || lowerQuery.includes('server')) {
    return 'ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œ ëª©ì—… ì„œë²„ ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” GCP ì‹¤ì œ ë°ì´í„°ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.';
  }

  if (
    lowerQuery.includes('cpu') ||
    lowerQuery.includes('ë©”ëª¨ë¦¬') ||
    lowerQuery.includes('memory')
  ) {
    return 'ëª©ì—… í™˜ê²½ì—ì„œ ì‹œë®¬ë ˆì´ì…˜ëœ CPU ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.';
  }

  return `ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œ "${query}"ì— ëŒ€í•œ ëª©ì—… ì‘ë‹µì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. Vercel ë°°í¬ ì‹œ GCP ì‹¤ì œ ë°ì´í„°ê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.`;
}
