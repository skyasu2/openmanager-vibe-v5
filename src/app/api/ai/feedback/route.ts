export const maxDuration = 10; // Vercel Pro Tier (ê²½ëŸ‰ ì—”ë“œí¬ì¸íŠ¸)

import type { NextRequest } from 'next/server';
import { NextResponse } from 'next/server';
import { z } from 'zod';
import { aiLogger } from '@/lib/logger';
import { rateLimiters, withRateLimit } from '@/lib/security/rate-limiter';

/**
 * AI í”¼ë“œë°± API ì—”ë“œí¬ì¸íŠ¸
 *
 * POST /api/ai/feedback
 *
 * ì‚¬ìš©ì í”¼ë“œë°± (ğŸ‘/ğŸ‘)ì„ ìˆ˜ì§‘í•˜ì—¬ AI í’ˆì§ˆ ê°œì„ ì— í™œìš©
 *
 * @version 1.1.0 - Rate Limiting ì¶”ê°€ (2026-01-03)
 * @version 1.2.0 - Zod ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì¶”ê°€
 */

const FeedbackRequestSchema = z.object({
  messageId: z.string().min(1),
  type: z.enum(['positive', 'negative']),
  timestamp: z.string().optional(),
  sessionId: z.string().optional(),
  traceId: z.string().optional(),
});

interface FeedbackLog {
  messageId: string;
  type: 'positive' | 'negative';
  timestamp: string;
  userAgent?: string;
}

// ë©”ëª¨ë¦¬ ë‚´ í”¼ë“œë°± ì €ì¥ì†Œ (MVP - ì¶”í›„ DB ì—°ë™)
const feedbackStore: FeedbackLog[] = [];

async function handlePOST(request: NextRequest) {
  try {
    const rawBody = await request.json();
    const parsed = FeedbackRequestSchema.safeParse(rawBody);

    if (!parsed.success) {
      return NextResponse.json(
        {
          error: 'Validation failed',
          details: parsed.error.flatten().fieldErrors,
        },
        { status: 400 }
      );
    }

    const body = parsed.data;

    const feedbackLog: FeedbackLog = {
      messageId: body.messageId,
      type: body.type,
      timestamp: body.timestamp || new Date().toISOString(),
      userAgent: request.headers.get('user-agent') || undefined,
    };

    // í”¼ë“œë°± ì €ì¥ (ë©”ëª¨ë¦¬)
    feedbackStore.push(feedbackLog);

    // ë¡œê·¸ ì¶œë ¥ (ê°œë°œ/ë””ë²„ê¹…ìš©)
    aiLogger.info('Feedback received', feedbackLog);

    // ìµœê·¼ 100ê°œë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
    if (feedbackStore.length > 100) {
      feedbackStore.shift();
    }

    // Forward to Cloud Run Langfuse if traceId is present
    let langfuseStatus: 'skipped' | 'success' | 'error' = 'skipped';
    if (
      body.traceId &&
      process.env.CLOUD_RUN_AI_URL &&
      process.env.CLOUD_RUN_API_SECRET
    ) {
      try {
        const res = await fetch(
          `${process.env.CLOUD_RUN_AI_URL}/api/ai/feedback`,
          {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'X-API-Key': process.env.CLOUD_RUN_API_SECRET,
            },
            body: JSON.stringify({
              traceId: body.traceId,
              score: body.type,
            }),
            signal: AbortSignal.timeout(5000),
          }
        );
        langfuseStatus = res.ok ? 'success' : 'error';
        if (!res.ok) {
          aiLogger.error(
            `Cloud Run feedback proxy failed: ${res.status} ${res.statusText}`
          );
        }
      } catch (err) {
        langfuseStatus = 'error';
        aiLogger.error('Failed to forward feedback to Cloud Run', err);
      }
    }

    return NextResponse.json({
      success: true,
      message: 'Feedback recorded',
      feedbackId: `fb_${Date.now()}`,
      langfuseStatus,
    });
  } catch (error) {
    aiLogger.error('Feedback processing failed', error);
    return NextResponse.json(
      { error: 'Failed to process feedback' },
      { status: 500 }
    );
  }
}

// Rate Limiting ì ìš© (ë¶„ë‹¹ 20íšŒ)
export const POST = withRateLimit(rateLimiters.default, handlePOST);

// GET: í”¼ë“œë°± í†µê³„ ì¡°íšŒ (ê´€ë¦¬ììš©)
async function handleGET(_request: NextRequest) {
  const stats = {
    total: feedbackStore.length,
    positive: feedbackStore.filter((f) => f.type === 'positive').length,
    negative: feedbackStore.filter((f) => f.type === 'negative').length,
    recentFeedback: feedbackStore.slice(-10),
  };

  return NextResponse.json(stats);
}

// Rate Limiting ì ìš©
export const GET = withRateLimit(rateLimiters.default, handleGET);
