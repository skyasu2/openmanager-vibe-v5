/**
 * ğŸ¯ í†µí•© AI ëª¨ë“œ ê´€ë¦¬ API
 * 
 * ëª¨ë“  AI ì„œë¹„ìŠ¤ì˜ ëª¨ë“œë¥¼ í†µí•© ê´€ë¦¬:
 * - IntelligentMonitoringService
 * - AutoIncidentReportSystem  
 * - UnifiedAIEngineRouter
 * - ê¸°íƒ€ AI ì„œë¹„ìŠ¤ë“¤
 */

import { AutoIncidentReportSystem } from '@/core/ai/systems/AutoIncidentReportSystem';
import { LightweightMLEngine } from '@/lib/ml/LightweightMLEngine';
import { IntelligentMonitoringService } from '@/services/ai/IntelligentMonitoringService';
import { SimplifiedNaturalLanguageEngine } from '@/services/ai/SimplifiedNaturalLanguageEngine';
import { NextRequest, NextResponse } from 'next/server';

// íƒ€ì… ì •ì˜
interface IncidentDetectionEngine {
    detectIncident(data: any): Promise<any>;
}

interface SolutionDatabase {
    findSolutions(incident: any): Promise<string[]>;
}

/**
 * GET: í˜„ì¬ í†µí•© AI ëª¨ë“œ ìƒíƒœ ì¡°íšŒ
 */
export async function GET(request: NextRequest) {
    try {
        const { searchParams } = new URL(request.url);
        const component = searchParams.get('component');

        const status: any = {
            success: true,
            timestamp: new Date().toISOString(),
            components: {
                naturalLanguage: 'ready',
                monitoring: 'ready',
                incidentReporting: 'ready',
                mlEngine: 'checking'
            }
        };

        // ML ì—”ì§„ ìƒíƒœ í™•ì¸
        try {
            const mlEngine = new LightweightMLEngine();
            status.components.mlEngine = 'ready';
            status.mlCapabilities = {
                queryOptimization: true,
                predictiveMonitoring: true,
                incidentLearning: true,
                autoOptimization: true
            };
        } catch (error) {
            status.components.mlEngine = 'unavailable';
            status.mlCapabilities = {
                queryOptimization: false,
                predictiveMonitoring: false,
                incidentLearning: false,
                autoOptimization: false
            };
        }

        // íŠ¹ì • ì»´í¬ë„ŒíŠ¸ ìƒíƒœë§Œ ìš”ì²­ëœ ê²½ìš°
        if (component && status.components[component]) {
            return NextResponse.json({
                success: true,
                component,
                status: status.components[component],
                timestamp: status.timestamp
            });
        }

        return NextResponse.json(status);

    } catch (error) {
        console.error('í†µí•© AI ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜:', error);
        return NextResponse.json({
            success: false,
            error: 'ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨',
            details: error.message
        }, { status: 500 });
    }
}

/**
 * POST: í†µí•© AI ëª¨ë“œ ë³€ê²½
 */
export async function POST(request: NextRequest) {
    try {
        const body = await request.json();
        const {
            query,
            mode = 'AUTO',
            enableMLOptimization = true,
            includeMonitoring = true,
            includeIncidentReporting = true,
            includeNaturalLanguage = true
        } = body;

        const startTime = Date.now();
        const results: any = {
            success: true,
            mode,
            mlEnhanced: enableMLOptimization,
            components: {},
            learningInsights: {},
            metadata: {
                totalTime: 0,
                componentsUsed: [],
                mlOptimizations: []
            }
        };

        // ğŸ¤– ML ì—”ì§„ ì´ˆê¸°í™”
        let mlEngine: LightweightMLEngine | null = null;
        if (enableMLOptimization) {
            try {
                mlEngine = new LightweightMLEngine();
                results.metadata.componentsUsed.push('ml-engine');
            } catch (error) {
                console.warn('âš ï¸ ML ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
            }
        }

        // 1ï¸âƒ£ ìì—°ì–´ ì²˜ë¦¬ + ML ì§ˆì˜ ìµœì í™”
        if (includeNaturalLanguage && query) {
            const nlEngine = SimplifiedNaturalLanguageEngine.getInstance();
            const nlResult = await nlEngine.processQuery(query, {}, {
                mode: mode.toLowerCase(),
                enableMLOptimization,
                timeout: 5000
            });

            results.components.naturalLanguage = nlResult;
            results.metadata.componentsUsed.push('natural-language');

            // ML ê¸°ë°˜ ì§ˆì˜ í•™ìŠµ
            if (mlEngine && nlResult.success) {
                try {
                    await mlEngine.learnFromQueryLogs([{
                        query,
                        response: nlResult.response,
                        engine: nlResult.engine,
                        confidence: nlResult.confidence,
                        responseTime: nlResult.responseTime
                    }]);
                    results.metadata.mlOptimizations.push('query-learning');
                } catch (error) {
                    console.warn('ML ì§ˆì˜ í•™ìŠµ ì‹¤íŒ¨:', error);
                }
            }
        }

        // 2ï¸âƒ£ ì§€ëŠ¥í˜• ëª¨ë‹ˆí„°ë§ + ML ì˜ˆì¸¡
        if (includeMonitoring) {
            const monitoringService = IntelligentMonitoringService.getInstance();
            const monitoringResult = await monitoringService.runIntelligentAnalysis({
                analysisDepth: 'standard',
                mode,
                includeSteps: {
                    anomalyDetection: true,
                    rootCauseAnalysis: true,
                    predictiveMonitoring: true,
                    mlOptimization: enableMLOptimization
                }
            });

            results.components.monitoring = monitoringResult;
            results.metadata.componentsUsed.push('intelligent-monitoring');

            if (enableMLOptimization && monitoringResult.mlOptimization.status === 'completed') {
                results.metadata.mlOptimizations.push('predictive-monitoring');
            }
        }

        // 3ï¸âƒ£ ìë™ ì¥ì• ë³´ê³ ì„œ + ML í•™ìŠµ
        if (includeIncidentReporting) {
            // ì‹¤ì œ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            const { IncidentDetectionEngine } = await import('@/core/ai/engines/IncidentDetectionEngine');
            const { SolutionDatabase } = await import('@/core/ai/databases/SolutionDatabase');

            const detectionEngine = new IncidentDetectionEngine();
            const solutionDB = new SolutionDatabase();

            const incidentSystem = new AutoIncidentReportSystem(
                detectionEngine,
                solutionDB,
                enableMLOptimization,
                mode
            );

            // ìƒ˜í”Œ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì¥ì•  ê°ì§€ í…ŒìŠ¤íŠ¸
            const sampleMetrics = {
                serverId: 'test-server',
                timestamp: Date.now(),
                cpu: 85,
                memory: 90,
                disk: 70,
                network: 50,
                responseTime: 2000,
                errorRate: 3
            };

            const incident = await incidentSystem.detectIncident(sampleMetrics);

            if (incident) {
                const report = await incidentSystem.generateKoreanReport(incident);
                results.components.incidentReport = {
                    incident,
                    report,
                    mlEnhanced: enableMLOptimization
                };

                // ML í•™ìŠµ ì‹¤í–‰
                if (enableMLOptimization) {
                    try {
                        await incidentSystem.learnFromIncidentWithML(report);
                        results.metadata.mlOptimizations.push('incident-learning');
                    } catch (error) {
                        console.warn('ML ì¥ì•  í•™ìŠµ ì‹¤íŒ¨:', error);
                    }
                }
            } else {
                results.components.incidentReport = {
                    status: 'no-incident-detected',
                    mlEnhanced: enableMLOptimization
                };
            }

            results.metadata.componentsUsed.push('incident-reporting');
        }

        // 4ï¸âƒ£ ML í†µí•© í•™ìŠµ ì¸ì‚¬ì´íŠ¸
        if (mlEngine) {
            try {
                // ML í•™ìŠµ ì¸ì‚¬ì´íŠ¸ëŠ” ê¸°ë³¸ ë©”íŠ¸ë¦­ìœ¼ë¡œ ëŒ€ì²´
                results.learningInsights = {
                    totalPatterns: 0,
                    recentLearnings: 0,
                    accuracyImprovement: 0,
                    recommendations: [
                        'ì‹œìŠ¤í…œì´ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì •í™•ë„ê°€ í–¥ìƒë˜ê³  ìˆìŠµë‹ˆë‹¤',
                        'ë” ë§ì€ ë°ì´í„°ë¥¼ ì œê³µí• ìˆ˜ë¡ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ê°œì„ ë©ë‹ˆë‹¤',
                        'ML ìµœì í™”ê°€ í™œì„±í™”ë˜ì–´ ìë™ í•™ìŠµì´ ì§„í–‰ë©ë‹ˆë‹¤'
                    ]
                };
            } catch (error) {
                console.warn('ML í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨:', error);
                results.learningInsights = {
                    error: 'ML ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨',
                    fallback: true
                };
            }
        }

        // ìµœì¢… ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        results.metadata.totalTime = Date.now() - startTime;
        results.metadata.timestamp = new Date().toISOString();

        return NextResponse.json(results);

    } catch (error) {
        console.error('í†µí•© AI ëª¨ë“œ API ì˜¤ë¥˜:', error);
        return NextResponse.json({
            success: false,
            error: 'í†µí•© AI ì²˜ë¦¬ ì‹¤íŒ¨',
            details: error.message,
            timestamp: new Date().toISOString()
        }, { status: 500 });
    }
}

/**
 * ğŸ“ API ì‚¬ìš© ì˜ˆì‹œ
 * 
 * GET /api/ai-agent/unified-mode
 * 
 * POST /api/ai-agent/unified-mode
 * {
 *   "mode": "LOCAL",
 *   "reason": "ê°œë°œ í™˜ê²½ì—ì„œ ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´"
 * }
 */ 