/**
 * ğŸ—ï¸ Infrastructure Layer - ì„œë²„ ë©”íŠ¸ë¦­ API
 *
 * ì—­í• : ì‹¤ì œ ì„œë²„ ì¸í”„ë¼ ëŒ€ì²´
 * - 15ëŒ€ ê°€ìƒ ì„œë²„ = ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½
 * - í‘œì¤€ Prometheus ë©”íŠ¸ë¦­ í˜•ì‹ 100% ì¤€ìˆ˜
 * - í•œêµ­ ì‹œê°„(KST) ê¸°ì¤€ ê³ ì • ë°ì´í„° ì œê³µ
 * - Single Source of Truth: MetricsProvider
 */

import type { NextRequest } from 'next/server';
import { NextResponse } from 'next/server';
import { getMockSystem } from '@/__mocks__/data';
import { metricsProvider } from '@/services/metrics/MetricsProvider';
import debug from '@/utils/debug';

// ğŸ”’ íƒ€ì… ì•ˆì „ì„±ì„ ìœ„í•œ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
interface ServerMetrics {
  id: string;
  role: string;
  environment: string;
  cpu_usage: number;
  memory_usage: number;
  disk_usage: number;
  network_in: number;
  network_out: number;
  response_time: number;
  status: string;
  uptime: number;
  alerts?: unknown[];
}

interface PrometheusMetricResult {
  metric: {
    __name__: string;
    instance: string;
    job: string;
    environment: string;
    status?: string;
  };
  value: [number, string];
}

/**
 * @deprecated ì†Œë¹„ì 0ê°œ í™•ì¸ë¨ - /api/metrics/current ì‚¬ìš© ê¶Œì¥
 * í‘œì¤€ Prometheus /metrics ì—”ë“œí¬ì¸íŠ¸ (ë ˆê±°ì‹œ)
 */
export function GET() {
  try {
    // ğŸ¯ MetricsProviderë¥¼ í†µí•œ ê³ ì • ë°ì´í„° (KST ì‹œê°„ ê¸°ì¤€)
    const summary = metricsProvider.getSystemSummary();
    const metrics = {
      totalServers: summary.totalServers,
      onlineServers: summary.onlineServers,
      warningServers: summary.warningServers,
      offlineServers: summary.criticalServers, // criticalì„ offlineìœ¼ë¡œ ë§¤í•‘
      averageCpu: Math.round(summary.averageCpu),
      averageMemory: Math.round(summary.averageMemory),
      averageDisk: Math.round(summary.averageDisk),
      totalAlerts: summary.warningServers + summary.criticalServers,
      timestamp: summary.timestamp,
    };

    // ğŸ“Š DASHBOARD: 5ë¶„ TTL, SWR ë¹„í™œì„±í™” (ëª©ì—… ë©”íŠ¸ë¦­ ìµœì í™”)
    // ë©”íŠ¸ë¦­ì€ 5ë¶„ ìºì‹œë¡œ ì¶©ë¶„, SWR ë¶ˆí•„ìš”
    return NextResponse.json(metrics, {
      headers: {
        'Content-Type': 'application/json',
        'Cache-Control':
          'public, max-age=600, s-maxage=600, stale-while-revalidate=60',
        'CDN-Cache-Control': 'public, s-maxage=600',
        'Vercel-CDN-Cache-Control': 'public, s-maxage=600',
      },
    });
  } catch (error) {
    debug.error('âŒ Failed to fetch metrics:', error);

    return NextResponse.json(
      {
        error: 'Failed to fetch metrics',
        details: error instanceof Error ? error.message : 'Unknown error',
      },
      { status: 500 }
    );
  }
}

/**
 * ğŸ“Š ì„œë²„ ë°ì´í„°ë¥¼ í‘œì¤€ Prometheus í˜•ì‹ìœ¼ë¡œ ë³€í™˜
 */
function _convertToPrometheusFormat(servers: ServerMetrics[]): string {
  const timestamp = Math.floor(Date.now() / 1000);
  let output = '';

  // OpenManager Infrastructure Layer ë©”íƒ€ ì •ë³´
  output += '# OpenManager Vibe v5 - Infrastructure Layer\n';
  output += `# Generated at: ${new Date().toISOString()}\n`;
  output += `# Total servers: ${servers.length}\n`;
  output += '# Data generator: v3.0.0 (Completely Independent)\n';
  output += '\n';

  // CPU ì‚¬ìš©ë¥  ë©”íŠ¸ë¦­
  output += '# HELP cpu_usage_percent Current CPU usage percentage\n';
  output += '# TYPE cpu_usage_percent gauge\n';
  servers.forEach((server) => {
    output += `cpu_usage_percent{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1"} ${server.cpu_usage} ${timestamp}\n`;
  });
  output += '\n';

  // ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë©”íŠ¸ë¦­
  output += '# HELP memory_usage_percent Current memory usage percentage\n';
  output += '# TYPE memory_usage_percent gauge\n';
  servers.forEach((server) => {
    output += `memory_usage_percent{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1"} ${server.memory_usage} ${timestamp}\n`;
  });
  output += '\n';

  // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë°”ì´íŠ¸)
  output += '# HELP memory_usage_bytes Current memory usage in bytes\n';
  output += '# TYPE memory_usage_bytes gauge\n';
  servers.forEach((server) => {
    const memoryBytes = Math.round((server.memory_usage / 100) * 17179869184); // 16GB ì„œë²„ ê°€ì •
    output += `memory_usage_bytes{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1"} ${memoryBytes} ${timestamp}\n`;
  });
  output += '\n';

  // ë””ìŠ¤í¬ ì‚¬ìš©ë¥  ë©”íŠ¸ë¦­
  output += '# HELP disk_usage_percent Current disk usage percentage\n';
  output += '# TYPE disk_usage_percent gauge\n';
  servers.forEach((server) => {
    output += `disk_usage_percent{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1"} ${server.disk_usage} ${timestamp}\n`;
  });
  output += '\n';

  // ë„¤íŠ¸ì›Œí¬ ì…ë ¥ ë©”íŠ¸ë¦­
  output +=
    '# HELP network_receive_bytes_total Total bytes received over network\n';
  output += '# TYPE network_receive_bytes_total counter\n';
  servers.forEach((server) => {
    const networkBytes = Math.round(server.network_in * 1024 * 1024); // MB to bytes
    output += `network_receive_bytes_total{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1"} ${networkBytes} ${timestamp}\n`;
  });
  output += '\n';

  // ë„¤íŠ¸ì›Œí¬ ì¶œë ¥ ë©”íŠ¸ë¦­
  output +=
    '# HELP network_transmit_bytes_total Total bytes transmitted over network\n';
  output += '# TYPE network_transmit_bytes_total counter\n';
  servers.forEach((server) => {
    const networkBytes = Math.round(server.network_out * 1024 * 1024); // MB to bytes
    output += `network_transmit_bytes_total{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1"} ${networkBytes} ${timestamp}\n`;
  });
  output += '\n';

  // ì‘ë‹µ ì‹œê°„ ë©”íŠ¸ë¦­
  output += '# HELP http_request_duration_seconds HTTP request latency\n';
  output += '# TYPE http_request_duration_seconds gauge\n';
  servers.forEach((server) => {
    const responseTimeSeconds = server.response_time / 1000; // ms to seconds
    output += `http_request_duration_seconds{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1"} ${responseTimeSeconds} ${timestamp}\n`;
  });
  output += '\n';

  // ì„œë²„ ìƒíƒœ ë©”íŠ¸ë¦­ (0=maintenance, 1=warning, 2=normal, 3=critical)
  output += '# HELP server_status Current server status\n';
  output += '# TYPE server_status gauge\n';
  servers.forEach((server) => {
    let statusValue = 2; // normal
    if (server.status === 'critical') statusValue = 3;
    else if (server.status === 'warning') statusValue = 1;
    else if (server.status === 'maintenance') statusValue = 0;

    output += `server_status{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1",status="${server.status}"} ${statusValue} ${timestamp}\n`;
  });
  output += '\n';

  // ì—…íƒ€ì„ ë©”íŠ¸ë¦­
  output += '# HELP node_uptime_seconds Total uptime in seconds\n';
  output += '# TYPE node_uptime_seconds counter\n';
  servers.forEach((server) => {
    output += `node_uptime_seconds{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1"} ${server.uptime} ${timestamp}\n`;
  });
  output += '\n';

  // ì•Œë¦¼ ìˆ˜ ë©”íŠ¸ë¦­
  output += '# HELP server_alerts_total Total number of active alerts\n';
  output += '# TYPE server_alerts_total gauge\n';
  servers.forEach((server) => {
    const alertCount = server.alerts ? server.alerts.length : 0;
    output += `server_alerts_total{instance="${server.id}",job="${server.role}",environment="${server.environment}",datacenter="dc1"} ${alertCount} ${timestamp}\n`;
  });
  output += '\n';

  // ì¸í”„ë¼ ìˆ˜ì¤€ ë©”íŠ¸ë¦­ ì¶”ê°€
  output +=
    '# HELP openmanager_infrastructure_servers_total Total number of servers in infrastructure\n';
  output += '# TYPE openmanager_infrastructure_servers_total gauge\n';
  output += `openmanager_infrastructure_servers_total{datacenter="dc1",environment="production"} ${servers.length} ${timestamp}\n`;
  output += '\n';

  // ì¸í”„ë¼ ê±´ê°•ë„ ë©”íŠ¸ë¦­
  const healthyServers = servers.filter(
    (s: ServerMetrics) => s.status === 'online'
  ).length;
  const healthPercentage = (healthyServers / servers.length) * 100;

  output +=
    '# HELP openmanager_infrastructure_health_percent Infrastructure health percentage\n';
  output += '# TYPE openmanager_infrastructure_health_percent gauge\n';
  output += `openmanager_infrastructure_health_percent{datacenter="dc1",environment="production"} ${healthPercentage.toFixed(2)} ${timestamp}\n`;
  output += '\n';

  // ë°ì´í„° ìƒì„±ê¸° ìì²´ ë©”íŠ¸ë¦­
  output +=
    '# HELP openmanager_generator_version Data generator version info\n';
  output += '# TYPE openmanager_generator_version gauge\n';
  output += `openmanager_generator_version{version="3.0.0",component="infrastructure"} 1 ${timestamp}\n`;
  output += '\n';

  output +=
    '# HELP openmanager_generator_uptime_seconds Data generator uptime\n';
  output += '# TYPE openmanager_generator_uptime_seconds counter\n';
  const generatorUptime = Math.floor(Date.now() / 1000); // í˜„ì¬ ì‹œê°„ì„ ì—…íƒ€ì„ìœ¼ë¡œ ì‚¬ìš©
  output += `openmanager_generator_uptime_seconds{component="infrastructure"} ${generatorUptime} ${timestamp}\n`;

  return output;
}

/**
 * ğŸ” Prometheus ì¿¼ë¦¬ API (PromQL í˜¸í™˜)
 */
export async function POST(request: NextRequest) {
  try {
    const { query, time, timeout: _timeout } = await request.json();

    // PromQL ì¿¼ë¦¬ íŒŒì‹± ë° ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
    const result = await executePromQLQuery(query, time);

    return NextResponse.json({
      status: 'success',
      data: {
        resultType: 'vector',
        result: result,
      },
    });
  } catch (error) {
    debug.error('âŒ PromQL ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨:', error);
    return NextResponse.json(
      {
        status: 'error',
        error: 'Query execution failed',
        errorType: 'bad_data',
      },
      { status: 400 }
    );
  }
}

/**
 * ğŸ“Š PromQL ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
 */
async function executePromQLQuery(
  query: string,
  time?: number
): Promise<PrometheusMetricResult[]> {
  const mockSystem = getMockSystem();
  const servers = mockSystem.getServers();

  // ê°„ë‹¨í•œ PromQL ì¿¼ë¦¬ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ íŒŒì„œê°€ í•„ìš”)
  if (query.includes('cpu_usage_percent')) {
    return servers.map((server) => ({
      metric: {
        __name__: 'cpu_usage_percent',
        instance: server.id,
        job: server.role || 'unknown',
        environment: server.environment || 'production',
      },
      value: [
        time || Math.floor(Date.now() / 1000),
        (server.cpu || 0).toString(),
      ],
    }));
  }

  if (query.includes('memory_usage_percent')) {
    return servers.map((server) => ({
      metric: {
        __name__: 'memory_usage_percent',
        instance: server.id,
        job: server.role || 'unknown',
        environment: server.environment || 'production',
      },
      value: [
        time || Math.floor(Date.now() / 1000),
        (server.memory || 0).toString(),
      ],
    }));
  }

  if (query.includes('server_status')) {
    return servers.map((server) => {
      let statusValue = 2; // normal/healthy
      if (server.status === 'offline') statusValue = 3;
      else if (server.status === 'online') statusValue = 2;
      else statusValue = 1; // any other status (warning, etc.)

      return {
        metric: {
          __name__: 'server_status',
          instance: server.id,
          job: server.role || 'unknown',
          environment: server.environment || 'production',
          status: server.status || 'unknown',
        },
        value: [time || Math.floor(Date.now() / 1000), statusValue.toString()],
      };
    });
  }

  // ê¸°ë³¸ì ìœ¼ë¡œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
  return [];
}
