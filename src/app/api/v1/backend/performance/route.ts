/**
 * ğŸš€ ë°±ì—”ë“œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ API
 * 
 * ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œ, ë©”ëª¨ë¦¬ ìƒíƒœ, Python ë¸Œë¦¿ì§€ ìƒíƒœ ëª¨ë‹ˆí„°ë§
 */
import { NextRequest, NextResponse } from 'next/server';
import { memoryManager } from '@/utils/MemoryManager';
import { PythonMLBridge } from '@/services/python-bridge/ml-bridge';

// Python ë¸Œë¦¿ì§€ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
let pythonBridge: PythonMLBridge | null = null;
function getPythonBridge(): PythonMLBridge {
  if (!pythonBridge) {
    pythonBridge = new PythonMLBridge(process.env.FASTAPI_BASE_URL || 'https://openmanager-ai-engine.onrender.com');
  }
  return pythonBridge;
}

/**
 * ğŸ“Š GET - ì „ì²´ ë°±ì—”ë“œ ì„±ëŠ¥ ìƒíƒœ ì¡°íšŒ
 */
export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const metric = searchParams.get('metric');
    const action = searchParams.get('action');

    // íŠ¹ì • ì•¡ì…˜ ì²˜ë¦¬
    if (action) {
      return handlePerformanceAction(action);
    }

    // íŠ¹ì • ë©”íŠ¸ë¦­ ì¡°íšŒ
    if (metric) {
      return getSpecificMetric(metric);
    }

    // ì „ì²´ ì„±ëŠ¥ ìƒíƒœ ì¡°íšŒ
    const performanceData = await getOverallPerformance();
    
    return NextResponse.json({
      success: true,
      timestamp: new Date().toISOString(),
      performance: performanceData
    });

  } catch (error: any) {
    console.error('âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜:', error);
    return NextResponse.json({
      success: false,
      error: error.message,
      timestamp: new Date().toISOString()
    }, { status: 500 });
  }
}

/**
 * ğŸ”§ POST - ì„±ëŠ¥ ìµœì í™” ì•¡ì…˜ ì‹¤í–‰
 */
export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { action, parameters } = body;

    console.log(`ğŸ”§ ì„±ëŠ¥ ìµœì í™” ì•¡ì…˜ ì‹¤í–‰: ${action}`);

    let result;
    switch (action) {
      case 'cleanup_memory':
        result = await performMemoryCleanup();
        break;
        
      case 'reset_python_bridge':
        result = await resetPythonBridge();
        break;
        
      case 'optimize_cache':
        result = await optimizeCache(parameters);
        break;
        
      case 'emergency_cleanup':
        result = await performEmergencyCleanup();
        break;
        
      case 'warmup_python':
        result = await warmupPython();
        break;
        
      default:
        throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•¡ì…˜: ${action}`);
    }

    return NextResponse.json({
      success: true,
      action,
      result,
      timestamp: new Date().toISOString()
    });

  } catch (error: any) {
    console.error('âŒ ì„±ëŠ¥ ìµœì í™” ì‹¤í–‰ ì˜¤ë¥˜:', error);
    return NextResponse.json({
      success: false,
      error: error.message,
      timestamp: new Date().toISOString()
    }, { status: 500 });
  }
}

/**
 * ğŸ“Š ì „ì²´ ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
 */
async function getOverallPerformance() {
  const startTime = Date.now();
  
  // ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´
  const memoryUsage = process.memoryUsage();
  const memoryStatus = memoryManager.getStatus();
  
  // Python ë¸Œë¦¿ì§€ ìƒíƒœ
  const bridge = getPythonBridge();
  const bridgeMetrics = bridge.getMetrics();
  const pythonHealth = await bridge.healthCheck();
  
  // CPU ì •ë³´ (Node.js cpuUsage)
  const cpuUsage = process.cpuUsage();
  
  // ì—…íƒ€ì„ ë° ë²„ì „ ì •ë³´
  const uptime = process.uptime();
  const nodeVersion = process.version;
  
  const collectTime = Date.now() - startTime;

  return {
    system: {
      uptime: Math.floor(uptime),
      nodeVersion,
      platform: process.platform,
      arch: process.arch,
      pid: process.pid
    },
    memory: {
      current: {
        rss: Math.round(memoryUsage.rss / 1024 / 1024),
        heapTotal: Math.round(memoryUsage.heapTotal / 1024 / 1024),
        heapUsed: Math.round(memoryUsage.heapUsed / 1024 / 1024),
        external: Math.round(memoryUsage.external / 1024 / 1024),
        arrayBuffers: Math.round(memoryUsage.arrayBuffers / 1024 / 1024)
      },
      monitoring: memoryStatus.monitor,
      pools: memoryStatus.pools
    },
    pythonBridge: {
      health: pythonHealth,
      metrics: bridgeMetrics,
      status: pythonHealth ? 'healthy' : 'unhealthy'
    },
    cpu: {
      user: Math.round(cpuUsage.user / 1000), // ë§ˆì´í¬ë¡œì´ˆ â†’ ë°€ë¦¬ì´ˆ
      system: Math.round(cpuUsage.system / 1000)
    },
    performance: {
      dataCollectionTime: collectTime,
      responseTime: Date.now()
    }
  };
}

/**
 * ğŸ¯ íŠ¹ì • ë©”íŠ¸ë¦­ ì¡°íšŒ
 */
async function getSpecificMetric(metric: string) {
  const startTime = Date.now();
  
  switch (metric) {
    case 'memory':
      return NextResponse.json({
        metric: 'memory',
        data: memoryManager.getStatus(),
        collectionTime: Date.now() - startTime
      });
      
    case 'python':
      const bridge = getPythonBridge();
      const health = await bridge.healthCheck();
      return NextResponse.json({
        metric: 'python',
        data: {
          health,
          metrics: bridge.getMetrics(),
          url: process.env.FASTAPI_BASE_URL || 'https://openmanager-ai-engine.onrender.com'
        },
        collectionTime: Date.now() - startTime
      });
      
    case 'cpu':
      const cpuUsage = process.cpuUsage();
      return NextResponse.json({
        metric: 'cpu',
        data: {
          user: Math.round(cpuUsage.user / 1000),
          system: Math.round(cpuUsage.system / 1000),
          uptime: Math.floor(process.uptime())
        },
        collectionTime: Date.now() - startTime
      });
      
    default:
      throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ë©”íŠ¸ë¦­: ${metric}`);
  }
}

/**
 * âš¡ ì„±ëŠ¥ ì•¡ì…˜ ì²˜ë¦¬
 */
async function handlePerformanceAction(action: string) {
  switch (action) {
    case 'health':
      const health = await getHealthStatus();
      return NextResponse.json({
        success: true,
        health,
        timestamp: new Date().toISOString()
      });
      
    case 'memory_stats':
      const memStats = memoryManager.getStatus();
      return NextResponse.json({
        success: true,
        memory: memStats,
        timestamp: new Date().toISOString()
      });
      
    case 'python_status':
      const bridge = getPythonBridge();
      const pythonHealth = await bridge.healthCheck();
      const pythonMetrics = bridge.getMetrics();
      
      return NextResponse.json({
        success: true,
        python: {
          health: pythonHealth,
          metrics: pythonMetrics,
          url: process.env.FASTAPI_BASE_URL
        },
        timestamp: new Date().toISOString()
      });
      
    default:
      throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•¡ì…˜: ${action}`);
  }
}

/**
 * ğŸ¥ í—¬ìŠ¤ ìƒíƒœ í™•ì¸
 */
async function getHealthStatus() {
  const memoryUsage = process.memoryUsage();
  const memoryThreshold = 512 * 1024 * 1024; // 512MB
  const bridge = getPythonBridge();
  const pythonHealth = await bridge.healthCheck();
  
  const status = {
    overall: 'healthy' as 'healthy' | 'warning' | 'critical',
    components: {
      memory: {
        status: 'healthy' as 'healthy' | 'warning' | 'critical',
        usage: Math.round(memoryUsage.heapUsed / 1024 / 1024),
        threshold: Math.round(memoryThreshold / 1024 / 1024)
      },
      python: {
        status: pythonHealth ? 'healthy' : 'critical' as 'healthy' | 'warning' | 'critical',
        connected: pythonHealth
      },
      uptime: {
        status: 'healthy' as 'healthy' | 'warning' | 'critical',
        seconds: Math.floor(process.uptime())
      }
    }
  };

  // ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
  if (memoryUsage.heapUsed > memoryThreshold * 0.8) {
    status.components.memory.status = 'warning';
    status.overall = 'warning';
  }
  if (memoryUsage.heapUsed > memoryThreshold) {
    status.components.memory.status = 'critical';
    status.overall = 'critical';
  }

  // Python ì—°ê²° ìƒíƒœ í™•ì¸
  if (!pythonHealth) {
    status.overall = status.overall === 'critical' ? 'critical' : 'warning';
  }

  return status;
}

/**
 * ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤í–‰
 */
async function performMemoryCleanup() {
  const beforeMemory = process.memoryUsage();
  console.log('ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘...');
  
  // ê°ì²´ í’€ ì •ë¦¬
  memoryManager.cleanup();
  
  // ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ (ê°€ëŠ¥í•œ ê²½ìš°)
  if (global.gc) {
    global.gc();
  }
  
  // ì •ë¦¬ í›„ ë©”ëª¨ë¦¬ ìƒíƒœ
  await new Promise(resolve => setTimeout(resolve, 1000)); // 1ì´ˆ ëŒ€ê¸°
  const afterMemory = process.memoryUsage();
  
  const result = {
    before: {
      heapUsed: Math.round(beforeMemory.heapUsed / 1024 / 1024),
      rss: Math.round(beforeMemory.rss / 1024 / 1024)
    },
    after: {
      heapUsed: Math.round(afterMemory.heapUsed / 1024 / 1024),
      rss: Math.round(afterMemory.rss / 1024 / 1024)
    },
    freed: {
      heap: Math.round((beforeMemory.heapUsed - afterMemory.heapUsed) / 1024 / 1024),
      rss: Math.round((beforeMemory.rss - afterMemory.rss) / 1024 / 1024)
    },
    gcAvailable: !!global.gc
  };
  
  console.log('âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ:', result);
  return result;
}

/**
 * ğŸ”„ Python ë¸Œë¦¿ì§€ ë¦¬ì…‹
 */
async function resetPythonBridge() {
  console.log('ğŸ”„ Python ë¸Œë¦¿ì§€ ë¦¬ì…‹ ì‹œì‘...');
  
  // ê¸°ì¡´ ë¸Œë¦¿ì§€ ì •ë¦¬
  pythonBridge = null;
  
  // ìƒˆ ë¸Œë¦¿ì§€ ìƒì„± ë° í—¬ìŠ¤ì²´í¬
  const newBridge = getPythonBridge();
  const health = await newBridge.healthCheck();
  
  const result = {
    reset: true,
    health,
    url: process.env.FASTAPI_BASE_URL,
    timestamp: new Date().toISOString()
  };
  
  console.log('âœ… Python ë¸Œë¦¿ì§€ ë¦¬ì…‹ ì™„ë£Œ:', result);
  return result;
}

/**
 * âš¡ ìºì‹œ ìµœì í™”
 */
async function optimizeCache(parameters: any = {}) {
  console.log('âš¡ ìºì‹œ ìµœì í™” ì‹œì‘...');
  
  const bridge = getPythonBridge();
  const beforeMetrics = bridge.getMetrics();
  
  // ìºì‹œ ì •ë¦¬ (ë¸Œë¦¿ì§€ ë‚´ë¶€ì—ì„œ ìˆ˜í–‰)
  bridge.clearCache();
  
  const afterMetrics = bridge.getMetrics();
  
  const result = {
    cacheClearedSize: beforeMetrics.cacheSize,
    optimizationComplete: true,
    parameters,
    metrics: {
      before: beforeMetrics,
      after: afterMetrics
    }
  };
  
  console.log('âœ… ìºì‹œ ìµœì í™” ì™„ë£Œ:', result);
  return result;
}

/**
 * ğŸš¨ ì‘ê¸‰ ì •ë¦¬
 */
async function performEmergencyCleanup() {
  console.log('ğŸš¨ ì‘ê¸‰ ì •ë¦¬ ì‹œì‘...');
  
  const beforeMemory = process.memoryUsage();
  
  // ì‘ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬
  memoryManager.emergencyCleanup();
  
  // Python ë¸Œë¦¿ì§€ ë¦¬ì…‹
  pythonBridge = null;
  
  // ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
  if (global.gc) {
    global.gc();
  }
  
  await new Promise(resolve => setTimeout(resolve, 2000)); // 2ì´ˆ ëŒ€ê¸°
  const afterMemory = process.memoryUsage();
  
  const result = {
    emergency: true,
    actions: ['memory_cleanup', 'python_bridge_reset', 'garbage_collection'],
    memoryFreed: Math.round((beforeMemory.heapUsed - afterMemory.heapUsed) / 1024 / 1024),
    timestamp: new Date().toISOString()
  };
  
  console.log('âœ… ì‘ê¸‰ ì •ë¦¬ ì™„ë£Œ:', result);
  return result;
}

/**
 * ğŸ”¥ Python ì„œë¹„ìŠ¤ ì›œì—…
 */
async function warmupPython() {
  console.log('ğŸ”¥ Python ì„œë¹„ìŠ¤ ì›œì—… ì‹œì‘...');
  
  const bridge = getPythonBridge();
  const startTime = Date.now();
  
  try {
    // í—¬ìŠ¤ì²´í¬ë¡œ ì›œì—…
    const health = await bridge.healthCheck();
    
    if (health) {
      // ê°„ë‹¨í•œ ë¶„ì„ ìš”ì²­ìœ¼ë¡œ ì™„ì „ ì›œì—…
      await bridge.call('statistical_analysis', {
        data: [1, 2, 3, 4, 5],
        warmup: true
      });
    }
    
    const warmupTime = Date.now() - startTime;
    
    const result = {
      success: health,
      warmupTime,
      pythonHealth: health,
      url: process.env.FASTAPI_BASE_URL
    };
    
    console.log('âœ… Python ì›œì—… ì™„ë£Œ:', result);
    return result;
    
  } catch (error: any) {
    const warmupTime = Date.now() - startTime;
    
    const result = {
      success: false,
      error: error.message,
      warmupTime,
      fallbackAvailable: true
    };
    
    console.log('âŒ Python ì›œì—… ì‹¤íŒ¨:', result);
    return result;
  }
} 