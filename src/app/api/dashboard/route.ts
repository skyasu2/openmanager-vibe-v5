/**
 * ðŸ“Š ëŒ€ì‹œë³´ë“œ API - Enhanced (Prometheus ì œê±°ë¨)
 *
 * ì‹¤ì‹œê°„ ì„œë²„ ë©”íŠ¸ë¦­ê³¼ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì œê³µí•˜ëŠ” í†µí•© API
 *
 * @author OpenManager Team
 * @version 5.12.0
 */

import { NextRequest, NextResponse } from 'next/server';
import { unifiedMetricsManager } from '@/services/UnifiedMetricsManager';
import type { EnhancedServerMetrics } from '@/types/server';

export async function GET(request: NextRequest) {
  const startTime = Date.now();

  try {
    const { searchParams } = new URL(request.url);
    const includeHistory = searchParams.get('include_history') === 'true';
    const format = searchParams.get('format') || 'dashboard';

    console.log(
      `ðŸ“Š ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìš”ì²­: format=${format}, history=${includeHistory}`
    );

    // 1. í†µí•© ë©”íŠ¸ë¦­ ê´€ë¦¬ìž ìƒíƒœ í™•ì¸
    const managerStatus = unifiedMetricsManager.getStatus();
    if (!managerStatus.isRunning) {
      console.log('âš ï¸ í†µí•© ë©”íŠ¸ë¦­ ê´€ë¦¬ìžê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ. ì‹œìž‘ ì‹œë„...');
      await unifiedMetricsManager.start();
      await new Promise(resolve => setTimeout(resolve, 100));
    }

    // 2. ì„œë²„ ë°ì´í„° ì¡°íšŒ
    const servers: any[] = unifiedMetricsManager.getServers();
    console.log(`ðŸ“Š ì´ ${servers.length}ê°œ ì„œë²„ì—ì„œ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±`);

    // 3. ì„œë²„ ìƒíƒœ ë¶„ì„
    const statusDistribution = analyzeServerStatus(servers);
    const environmentStats = analyzeByEnvironment(servers);
    const roleStats = analyzeByRole(servers);
    const performanceMetrics = calculatePerformanceMetrics(servers);
    const resourceUtilization = calculateResourceUtilization(servers);
    const alertsSummary = analyzeAlerts(servers);
    const topServers = getTopResourceConsumers(servers);

    // 4. ëŒ€ì‹œë³´ë“œ ë°ì´í„° êµ¬ì„±
    const dashboardData = {
      // ðŸ–¥ï¸ ì„œë²„ ì›ë³¸ ë°ì´í„°
      servers: servers,

      // ðŸ“Š ì „ì²´ í˜„í™© ìš”ì•½
      overview: {
        total_servers: servers.length,
        healthy_servers: statusDistribution.healthy,
        warning_servers: statusDistribution.warning,
        critical_servers: statusDistribution.critical,
        health_score: calculateHealthScore(statusDistribution),
        system_availability: calculateSystemAvailability(servers),
        active_incidents: alertsSummary.total_alerts,
        last_updated: new Date().toISOString(),
        system_running: managerStatus.isRunning,
      },

      // ðŸ—ï¸ í™˜ê²½ë³„ í˜„í™©
      environment_stats: environmentStats,

      // ðŸ”§ ì—­í• ë³„ í˜„í™©
      role_stats: roleStats,

      // ðŸ“ˆ ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œ
      performance_metrics: performanceMetrics,

      // ðŸ’¾ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
      resource_utilization: resourceUtilization,

      // ðŸš¨ ì•Œë¦¼ í˜„í™©
      alerts_summary: alertsSummary,

      // ðŸ” ìƒìœ„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ì„œë²„
      top_resource_consumers: topServers,

      // ðŸ“Š íŒ¨í„´ ë¶„ì„
      pattern_analysis: analyzePatterns(servers),

      // ðŸŽ¯ ìƒê´€ê´€ê³„ ë©”íŠ¸ë¦­
      correlation_insights: analyzeCorrelations(servers),

      // ðŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„
      trends: analyzeTrends(servers),

      // ðŸ’¡ ê¶Œìž¥ì‚¬í•­
      recommendations: generateRecommendations(servers, alertsSummary),

      // ðŸ”„ í˜¸í™˜ì„±ì„ ìœ„í•œ ì¤‘ì²© êµ¬ì¡°
      data: {
        servers: servers,
        overview: {
          total_servers: servers.length,
          healthy_servers: statusDistribution.healthy,
          warning_servers: statusDistribution.warning,
          critical_servers: statusDistribution.critical,
        },
      },
    };

    // 5. ížˆìŠ¤í† ë¦¬ ë°ì´í„° ì¶”ê°€ (ìš”ì²­ì‹œ)
    if (includeHistory) {
      (dashboardData as any).historical_data =
        generateHistoricalSummary(servers);
    }

    // 6. ë©”íƒ€ë°ì´í„° ì¶”ê°€
    const response = {
      meta: {
        request_info: {
          format,
          include_history: includeHistory,
          processing_time_ms: Date.now() - startTime,
          timestamp: new Date().toISOString(),
        },
        system_info: managerStatus,
        data_freshness: {
          last_system_update: managerStatus.isRunning ? 'real-time' : 'static',
          cache_ttl_seconds: 30,
          refresh_recommended: true,
        },
      },
      data: dashboardData,
    };

    return NextResponse.json(response, {
      headers: {
        'X-Total-Servers': servers.length.toString(),
        'X-Health-Score': calculateHealthScore(statusDistribution).toString(),
        'X-Active-Alerts': alertsSummary.total_alerts.toString(),
        'X-Processing-Time-Ms': (Date.now() - startTime).toString(),
        'Cache-Control': 'no-cache, must-revalidate',
        'X-Refresh-Interval': '30',
      },
    });
  } catch (error) {
    console.error('âŒ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨:', error);

    return NextResponse.json(
      {
        success: false,
        error: 'Dashboard data generation failed',
        message:
          error instanceof Error
            ? error.message
            : 'ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
        timestamp: new Date().toISOString(),
      },
      { status: 500 }
    );
  }
}

// ðŸ”§ ë¶„ì„ í•¨ìˆ˜ë“¤
function analyzeServerStatus(servers: any[]) {
  return {
    healthy: servers.filter(s => s.status === 'healthy').length,
    warning: servers.filter(s => s.status === 'warning').length,
    critical: servers.filter(s => s.status === 'critical').length,
  };
}

function analyzeByEnvironment(servers: any[]) {
  const environments = ['production', 'staging', 'development'];
  return environments.map(env => ({
    environment: env,
    total: servers.filter(s => s.environment === env).length,
    healthy: servers.filter(
      s => s.environment === env && s.status === 'healthy'
    ).length,
    warning: servers.filter(
      s => s.environment === env && s.status === 'warning'
    ).length,
    critical: servers.filter(
      s => s.environment === env && s.status === 'critical'
    ).length,
  }));
}

function analyzeByRole(servers: any[]) {
  const roles = ['web', 'api', 'database', 'cache', 'worker'];
  return roles.map(role => ({
    role,
    total: servers.filter(s => s.role === role).length,
    healthy: servers.filter(s => s.role === role && s.status === 'healthy')
      .length,
    warning: servers.filter(s => s.role === role && s.status === 'warning')
      .length,
    critical: servers.filter(s => s.role === role && s.status === 'critical')
      .length,
  }));
}

function calculatePerformanceMetrics(servers: any[]) {
  if (servers.length === 0)
    return { avg_response_time: 0, total_requests: 0, error_rate: 0 };

  const totalResponseTime = servers.reduce(
    (sum, s) => sum + (s.response_time || 0),
    0
  );
  const totalRequests = servers.reduce(
    (sum, s) => sum + (s.http_requests_total || 0),
    0
  );
  const totalErrors = servers.reduce(
    (sum, s) => sum + (s.http_requests_errors_total || 0),
    0
  );

  return {
    avg_response_time: totalResponseTime / servers.length,
    total_requests: totalRequests,
    error_rate: totalRequests > 0 ? (totalErrors / totalRequests) * 100 : 0,
  };
}

function calculateResourceUtilization(servers: any[]) {
  if (servers.length === 0) return { avg_cpu: 0, avg_memory: 0, avg_disk: 0 };

  const totalCpu = servers.reduce(
    (sum, s) => sum + (s.cpu_usage || s.node_cpu_usage_percent || 0),
    0
  );
  const totalMemory = servers.reduce(
    (sum, s) => sum + (s.memory_usage || s.node_memory_usage_percent || 0),
    0
  );
  const totalDisk = servers.reduce(
    (sum, s) => sum + (s.disk_usage || s.node_disk_usage_percent || 0),
    0
  );

  return {
    avg_cpu: totalCpu / servers.length,
    avg_memory: totalMemory / servers.length,
    avg_disk: totalDisk / servers.length,
  };
}

function analyzeAlerts(servers: any[]) {
  const criticalServers = servers.filter(s => s.status === 'critical').length;
  const warningServers = servers.filter(s => s.status === 'warning').length;

  return {
    total_alerts: criticalServers + warningServers,
    critical_alerts: criticalServers,
    warning_alerts: warningServers,
  };
}

function getTopResourceConsumers(servers: any[]) {
  return servers
    .sort(
      (a, b) =>
        (b.cpu_usage || b.node_cpu_usage_percent || 0) -
        (a.cpu_usage || a.node_cpu_usage_percent || 0)
    )
    .slice(0, 5)
    .map(server => ({
      id: server.id,
      hostname: server.hostname,
      cpu_usage: server.cpu_usage || server.node_cpu_usage_percent || 0,
      memory_usage:
        server.memory_usage || server.node_memory_usage_percent || 0,
      status: server.status,
    }));
}

function analyzePatterns(servers: any[]) {
  return {
    high_cpu_pattern: servers.filter(
      s => (s.cpu_usage || s.node_cpu_usage_percent || 0) > 80
    ).length,
    high_memory_pattern: servers.filter(
      s => (s.memory_usage || s.node_memory_usage_percent || 0) > 80
    ).length,
    error_pattern: servers.filter(s => s.status === 'critical').length,
  };
}

function analyzeCorrelations(servers: any[]) {
  return {
    cpu_memory_correlation: 0.75, // ì˜ˆì‹œ ê°’
    response_time_correlation: 0.65,
    error_rate_correlation: 0.45,
  };
}

function analyzeTrends(servers: any[]) {
  return {
    cpu_trend: 'stable',
    memory_trend: 'increasing',
    error_trend: 'decreasing',
  };
}

function generateRecommendations(servers: any[], alertsSummary: any) {
  const recommendations = [];

  if (alertsSummary.critical_alerts > 0) {
    recommendations.push('Critical servers need immediate attention');
  }

  if (alertsSummary.warning_alerts > 5) {
    recommendations.push('Consider scaling resources for warning servers');
  }

  return recommendations;
}

function calculateHealthScore(statusDistribution: any): number {
  const total =
    statusDistribution.healthy +
    statusDistribution.warning +
    statusDistribution.critical;
  if (total === 0) return 100;

  return Math.round((statusDistribution.healthy / total) * 100);
}

function calculateSystemAvailability(servers: any[]): number {
  const healthyServers = servers.filter(s => s.status === 'healthy').length;
  return servers.length > 0
    ? Math.round((healthyServers / servers.length) * 100)
    : 100;
}

function generateHistoricalSummary(servers: any[]) {
  return {
    last_24h: {
      avg_cpu: 45.2,
      avg_memory: 62.1,
      incidents: 2,
    },
    last_7d: {
      avg_cpu: 43.8,
      avg_memory: 58.9,
      incidents: 12,
    },
  };
}
