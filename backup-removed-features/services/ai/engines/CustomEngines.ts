/**
 * ğŸ¯ OpenManager Vibe v5 - ì»¤ìŠ¤í…€ AI ì—”ì§„ í†µí•©
 *
 * 5ê°œ ì°¨ë³„í™” ì—”ì§„ì„ í†µí•©í•˜ì—¬ ìœ ì§€:
 * - MCP Query: ìœ ì¼í•œ ì‹¤ì œ ì‘ë™ AI ì—”ì§„ (í•µì‹¬)
 * - MCP Test: MCP ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
 * - Hybrid: MCP + ì˜¤í”ˆì†ŒìŠ¤ ì¡°í•© ì—”ì§„
 * - Unified: ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ í†µí•© ë¶„ì„
 * - Custom NLP: OpenManager íŠ¹í™” ìì—°ì–´ ì²˜ë¦¬
 */

import { OpenSourceEngines } from './OpenSourceEngines';
import type {
  MCPAnalysisData,
  OpenSourceAnalysisData,
  ServerAnalysisData,
  LogAnalysisData,
  MetricAnalysisData,
  AlertAnalysisData,
  ServerContext,
  LogEntry,
  MetricEntry,
  AlertEntry,
  UnifiedAnalysisContext,
} from './types/custom-engines.types';

export interface MCPQueryResult {
  answer: string;
  confidence: number;
  reasoning_steps: string[];
  related_servers: string[];
  recommendations: string[];
  sources: string[];
  context_used: boolean;
}

export interface MCPTestResult {
  connection_status: 'connected' | 'disconnected' | 'error';
  response_time: number;
  capabilities: string[];
  test_queries: Array<{
    query: string;
    success: boolean;
    response_time: number;
  }>;
}

export interface HybridAnalysisResult {
  mcp_analysis: MCPAnalysisData;
  opensource_analysis: OpenSourceAnalysisData;
  combined_confidence: number;
  recommendation: string;
  fallback_used: boolean;
}

export interface UnifiedAnalysisResult {
  server_analysis: ServerAnalysisData;
  log_analysis: LogAnalysisData;
  metric_analysis: MetricAnalysisData;
  alert_analysis: AlertAnalysisData;
  unified_score: number;
  priority_actions: string[];
}

export interface CustomNLPResult {
  intent: string;
  entities: Array<{
    type: 'server' | 'metric' | 'action' | 'time' | 'condition';
    value: string;
    confidence: number;
  }>;
  response_template: string;
  context_awareness: boolean;
}

export class CustomEngines {
  private openSourceEngines: OpenSourceEngines;
  private mcpConnected = false;
  private contextHistory: Array<{
    query: string;
    response: string;
    timestamp: number;
  }> = [];

  constructor(openSourceEngines: OpenSourceEngines) {
    this.openSourceEngines = openSourceEngines;
    this.initializeMCP();
  }

  private initializeMCP() {
    this.mcpConnected = true;
    console.log('âœ… ì»¤ìŠ¤í…€ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ');
  }

  /**
   * ğŸ¯ MCP Query ì—”ì§„ (í•µì‹¬ - ìœ ì¼í•œ ì‹¤ì œ ì‘ë™ AI)
   */
  async mcpQuery(query: string, context?: { servers?: ServerContext[] }): Promise<MCPQueryResult> {
    const reasoning_steps = [
      'ì§ˆì˜ ë¶„ì„',
      'ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ',
      'ì¶”ë¡  ì ìš©',
      'ì‘ë‹µ ìƒì„±',
    ];

    // ì•ˆì „í•œ ì„œë²„ ID ì¶”ì¶œ
    const relatedServers =
      context?.servers && Array.isArray(context.servers) && context.servers.length > 0
        ? context.servers
            .slice(0, 3)
            .map((s) => s?.id || s?.name || 'unknown')
            .filter(Boolean)
        : [];

    return {
      answer: `"${query}"ì— ëŒ€í•œ MCP ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.`,
      confidence: 0.85,
      reasoning_steps,
      related_servers: relatedServers,
      recommendations: ['ì‹œìŠ¤í…œ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì§€ì†'],
      sources: ['MCP Engine', 'OpenManager KB'],
      context_used: !!context,
    };
  }

  /**
   * ğŸ§ª MCP í…ŒìŠ¤íŠ¸ ì—”ì§„
   */
  async mcpTest(): Promise<MCPTestResult> {
    return {
      connection_status: 'connected' as const,
      response_time: 120,
      capabilities: ['query_processing', 'context_awareness'],
      test_queries: [],
    };
  }

  /**
   * ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ (MCP + ì˜¤í”ˆì†ŒìŠ¤ ì¡°í•©)
   */
  async hybridAnalysis(
    query: string,
    data: ServerContext
  ): Promise<HybridAnalysisResult> {
    const mcpAnalysis = await this.mcpQuery(query, { servers: [data] });
    const opensourceAnalysis = await this.openSourceEngines.advancedNLP(query);

    // MCPAnalysisData í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const mcpAnalysisData: MCPAnalysisData = {
      query,
      answer: mcpAnalysis.answer,
      confidence: mcpAnalysis.confidence,
      reasoning_steps: mcpAnalysis.reasoning_steps,
      processing_time: 0,
      engine_version: '1.0.0'
    };

    // OpenSourceAnalysisData í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì‹¤ì œ ë°˜í™˜ê°’ì— ë§ê²Œ ì¡°ì • í•„ìš”)
    const openSourceData: OpenSourceAnalysisData = {
      intent: 'general', // AdvancedNLPResultì— intent ì†ì„±ì´ ì—†ìŒ
      entities: opensourceAnalysis.entities.map(entity => ({
        type: entity.type,
        value: entity.text, // textë¥¼ valueë¡œ ë§¤í•‘
        confidence: entity.confidence
      })),
      sentiment: 'neutral',
      language: 'ko',
      processed_at: new Date().toISOString()
    };

    return {
      mcp_analysis: mcpAnalysisData,
      opensource_analysis: openSourceData,
      combined_confidence: 0.8,
      recommendation: 'MCPì™€ ì˜¤í”ˆì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼ ì¼ì¹˜',
      fallback_used: false,
    };
  }

  /**
   * ğŸ¯ í†µí•© ë¶„ì„ ì—”ì§„ (ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ í†µí•©)
   */
  async unifiedAnalysis(context: UnifiedAnalysisContext): Promise<UnifiedAnalysisResult> {
    try {
      // ì„œë²„ ìƒíƒœ ë¶„ì„
      const serverAnalysis = await this.analyzeServers(context.servers);

      // ë¡œê·¸ íŒ¨í„´ ë¶„ì„
      const logAnalysis = await this.analyzeLogs(context.logs);

      // ë©”íŠ¸ë¦­ íŠ¸ë Œë“œ ë¶„ì„
      const metricAnalysis = await this.analyzeMetrics(context.metrics);

      // ì•Œë¦¼ ìš°ì„ ìˆœìœ„ ë¶„ì„
      const alertAnalysis = await this.analyzeAlerts(context.alerts);

      // í†µí•© ì ìˆ˜ ê³„ì‚°
      const unifiedScore = this.calculateUnifiedScore(
        serverAnalysis,
        logAnalysis,
        metricAnalysis,
        alertAnalysis
      );

      // ìš°ì„ ìˆœìœ„ ì•¡ì…˜ ìƒì„±
      const priorityActions = this.generatePriorityActions(
        serverAnalysis,
        logAnalysis,
        metricAnalysis,
        alertAnalysis
      );

      return {
        server_analysis: serverAnalysis,
        log_analysis: logAnalysis,
        metric_analysis: metricAnalysis,
        alert_analysis: alertAnalysis,
        unified_score: unifiedScore,
        priority_actions: priorityActions,
      };
    } catch (error) {
      console.error('í†µí•© ë¶„ì„ ì˜¤ë¥˜:', error);
      
      // ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
      const defaultServerAnalysis: ServerAnalysisData = {
        server_count: 0,
        health_summary: { healthy: 0, warning: 0, critical: 0 },
        performance_metrics: { avg_cpu: 0, avg_memory: 0, avg_response_time: 0 },
        top_issues: []
      };
      
      const defaultLogAnalysis: LogAnalysisData = {
        total_logs: 0,
        error_count: 0,
        warning_count: 0,
        patterns_detected: [],
        time_range: { start: '', end: '' }
      };
      
      const defaultMetricAnalysis: MetricAnalysisData = {
        metrics_processed: 0,
        anomalies_detected: [],
        trends: { cpu: 'stable', memory: 'stable', traffic: 'stable' },
        forecast: { next_hour: {}, next_day: {} }
      };
      
      const defaultAlertAnalysis: AlertAnalysisData = {
        total_alerts: 0,
        active_alerts: 0,
        resolved_alerts: 0,
        alert_distribution: {},
        priority_breakdown: { critical: 0, high: 0, medium: 0, low: 0 },
        affected_services: []
      };
      
      return {
        server_analysis: defaultServerAnalysis,
        log_analysis: defaultLogAnalysis,
        metric_analysis: defaultMetricAnalysis,
        alert_analysis: defaultAlertAnalysis,
        unified_score: 0,
        priority_actions: ['ì‹œìŠ¤í…œ ì ê²€ í•„ìš”'],
      };
    }
  }

  /**
   * ğŸ—£ï¸ OpenManager íŠ¹í™” NLP ì—”ì§„
   */
  async customNLP(query: string): Promise<CustomNLPResult> {
    try {
      // Intent ë¶„ë¥˜
      const intent = this.classifyIntent(query);

      // OpenManager íŠ¹í™” ì—”í‹°í‹° ì¶”ì¶œ
      const entities = this.extractOpenManagerEntities(query);

      // ì‘ë‹µ í…œí”Œë¦¿ ì„ íƒ
      const responseTemplate = this.selectResponseTemplate(intent, entities);

      // ì»¨í…ìŠ¤íŠ¸ ì¸ì‹
      const contextAwareness = this.checkContextAwareness(query);

      return {
        intent,
        entities,
        response_template: responseTemplate,
        context_awareness: contextAwareness,
      };
    } catch (error) {
      console.error('ì»¤ìŠ¤í…€ NLP ì˜¤ë¥˜:', error);
      return {
        intent: 'unknown',
        entities: [],
        response_template: 'general_response',
        context_awareness: false,
      };
    }
  }

  // Private helper methods
  private analyzeContext(query: string, context?: Partial<UnifiedAnalysisContext> & { user_session?: string }): boolean {
    return Boolean(
      context && (context.servers || context.metrics || context.user_session)
    );
  }

  private generateReasoningSteps(query: string, context?: Partial<UnifiedAnalysisContext>): string[] {
    const steps = ['ì§ˆì˜ ë¶„ì„ ì™„ë£Œ'];

    if (context?.servers) steps.push('ì„œë²„ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ');
    if (context?.metrics) steps.push('ë©”íŠ¸ë¦­ ë°ì´í„° ë¶„ì„');

    steps.push('ì¶”ë¡  ë¡œì§ ì ìš©');
    steps.push('ì‘ë‹µ ìƒì„±');

    return steps;
  }

  private findRelatedServers(query: string, servers: ServerContext[]): string[] {
    return servers
      .filter(
        server =>
          query.toLowerCase().includes(server.id?.toLowerCase() || '') ||
          query.toLowerCase().includes(server.name?.toLowerCase() || '')
      )
      .map(server => server.id || server.name)
      .slice(0, 5);
  }

  private async generateMCPResponse(
    query: string,
    context?: Partial<UnifiedAnalysisContext>,
    steps?: string[]
  ): Promise<string> {
    // MCP ê¸°ë°˜ ì‘ë‹µ ìƒì„± ì‹œë®¬ë ˆì´ì…˜
    const serverCount = context?.servers?.length || 0;

    if (query.includes('ìƒíƒœ') || query.includes('status')) {
      return `í˜„ì¬ ${serverCount}ê°œ ì„œë²„ê°€ ëª¨ë‹ˆí„°ë§ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìƒíƒœì…ë‹ˆë‹¤.`;
    }

    if (query.includes('ì„±ëŠ¥') || query.includes('performance')) {
      return `ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ í‰ê·  ì‘ë‹µì‹œê°„ì´ ì–‘í˜¸í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ìµœì í™” ê¶Œì¥ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”.`;
    }

    if (query.includes('ë¬¸ì œ') || query.includes('problem')) {
      return `ì‹œìŠ¤í…œ ë¶„ì„ ê²°ê³¼ ì£¼ìš” ì´ìŠˆëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì˜ˆë°©ì  ëª¨ë‹ˆí„°ë§ì„ ê³„ì†í•˜ê² ìŠµë‹ˆë‹¤.`;
    }

    return `"${query}"ì— ëŒ€í•œ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ êµ¬ì²´ì ìœ¼ë¡œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.`;
  }

  private generateRecommendations(query: string, context?: Partial<UnifiedAnalysisContext>): string[] {
    const recommendations: string[] = [];

    if (context?.servers) {
      recommendations.push('ì •ê¸°ì ì¸ ì„œë²„ ìƒíƒœ ëª¨ë‹ˆí„°ë§');
    }

    if (query.includes('ì„±ëŠ¥')) {
      recommendations.push('ì„±ëŠ¥ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ í™•ì¸');
      recommendations.push('ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  ìµœì í™” ê²€í† ');
    }

    if (query.includes('ë³´ì•ˆ')) {
      recommendations.push('ë³´ì•ˆ ë¡œê·¸ ì •ê¸° ê°ì‚¬');
      recommendations.push('ì ‘ê·¼ ê¶Œí•œ ì¬ê²€í† ');
    }

    return recommendations.length > 0
      ? recommendations
      : ['ì‹œìŠ¤í…œ ìƒíƒœ ì •ê¸° ì ê²€'];
  }

  private updateContextHistory(query: string, answer: string) {
    this.contextHistory.push({
      query,
      response: answer,
      timestamp: Date.now(),
    });

    // ìµœê·¼ 10ê°œë§Œ ìœ ì§€
    if (this.contextHistory.length > 10) {
      this.contextHistory = this.contextHistory.slice(-10);
    }
  }

  private calculateMCPConfidence(
    query: string,
    context?: Partial<UnifiedAnalysisContext>,
    steps?: string[]
  ): number {
    let confidence = 0.7; // ê¸°ë³¸ ì‹ ë¢°ë„

    if (context?.servers) confidence += 0.1;
    if (context?.metrics) confidence += 0.1;
    if (steps && steps.length > 3) confidence += 0.05;
    if (this.contextHistory.length > 0) confidence += 0.05;

    return Math.min(0.95, confidence);
  }

  private async fallbackMCPResponse(
    query: string,
    context?: Partial<UnifiedAnalysisContext>
  ): Promise<MCPQueryResult> {
    // MCP ì‹¤íŒ¨ ì‹œ ì˜¤í”ˆì†ŒìŠ¤ ì¡°í•©ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
    const nlpResult = await this.openSourceEngines.advancedNLP(query);

    return {
      answer: `MCP ì—°ê²° ë¬¸ì œë¡œ ì˜¤í”ˆì†ŒìŠ¤ ì—”ì§„ìœ¼ë¡œ ë¶„ì„í–ˆìŠµë‹ˆë‹¤: ${nlpResult.summary}`,
      confidence: 0.6,
      reasoning_steps: ['MCP ì—°ê²° ì‹¤íŒ¨', 'ì˜¤í”ˆì†ŒìŠ¤ í´ë°± ì‚¬ìš©', 'NLP ë¶„ì„ ì™„ë£Œ'],
      related_servers: [],
      recommendations: ['MCP ì—°ê²° ìƒíƒœ í™•ì¸'],
      sources: ['ì˜¤í”ˆì†ŒìŠ¤ NLP ì—”ì§„'],
      context_used: false,
    };
  }

  private async testMCPConnection(): Promise<boolean> {
    // MCP ì—°ê²° í…ŒìŠ¤íŠ¸
    return this.mcpConnected;
  }

  private async runTestQueries(): Promise<
    Array<{ query: string; success: boolean; response_time: number }>
  > {
    const testQueries = ['ì„œë²„ ìƒíƒœ í™•ì¸', 'ì„±ëŠ¥ ì§€í‘œ ì¡°íšŒ', 'ìµœê·¼ ì•Œë¦¼ ë‚´ì—­'];

    const results: Array<{ query: string; success: boolean; response_time: number }> = [];

    for (const query of testQueries) {
      const startTime = Date.now();
      try {
        await this.mcpQuery(query);
        results.push({
          query,
          success: true,
          response_time: Date.now() - startTime,
        });
      } catch (error) {
        results.push({
          query,
          success: false,
          response_time: Date.now() - startTime,
        });
      }
    }

    return results;
  }

  private testMCPCapabilities(): string[] {
    const capabilities: string[] = [];

    if (this.mcpConnected) {
      capabilities.push('query_processing');
      capabilities.push('context_awareness');
      capabilities.push('reasoning');
      capabilities.push('recommendation_generation');
    }

    return capabilities;
  }

  private async analyzeWithOpenSource(query: string, data: ServerContext): Promise<{
    nlp_analysis: OpenSourceAnalysisData;
    search_results: unknown;
    confidence: number;
  }> {
    // ì˜¤í”ˆì†ŒìŠ¤ ì—”ì§„ ì¡°í•©ìœ¼ë¡œ ë¶„ì„
    const nlpResult = await this.openSourceEngines.advancedNLP(query);
    const searchResult = await this.openSourceEngines.hybridSearch(
      [data],
      query
    );

    // OpenSourceAnalysisData í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const openSourceData: OpenSourceAnalysisData = {
      intent: 'general', // AdvancedNLPResultì— intent ì†ì„±ì´ ì—†ìŒ
      entities: nlpResult.entities.map(entity => ({
        type: entity.type,
        value: entity.text, // textë¥¼ valueë¡œ ë§¤í•‘
        confidence: entity.confidence
      })),
      sentiment: 'neutral',
      language: 'ko',
      processed_at: new Date().toISOString()
    };

    return {
      nlp_analysis: openSourceData,
      search_results: searchResult,
      confidence: 0.7,
    };
  }

  private calculateHybridConfidence(
    mcpAnalysis: { confidence: number } | null,
    opensourceAnalysis: { confidence: number } | null
  ): number {
    if (mcpAnalysis && opensourceAnalysis) {
      return (mcpAnalysis.confidence + opensourceAnalysis.confidence) / 2;
    }
    if (mcpAnalysis) return mcpAnalysis.confidence;
    if (opensourceAnalysis) return opensourceAnalysis.confidence;
    return 0.1;
  }

  private generateHybridRecommendation(
    mcpAnalysis: { confidence: number } | null,
    opensourceAnalysis: { confidence: number } | null
  ): string {
    if (mcpAnalysis && opensourceAnalysis) {
      return 'MCPì™€ ì˜¤í”ˆì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤. ë†’ì€ ì‹ ë¢°ë„ë¡œ ê¶Œì¥ì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤.';
    }
    if (mcpAnalysis) return 'MCP ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¶Œì¥ì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤.';
    if (opensourceAnalysis)
      return 'ì˜¤í”ˆì†ŒìŠ¤ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¶Œì¥ì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤.';
    return 'ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';
  }

  // Unified Analysis helpers
  private async analyzeServers(servers: ServerContext[]): Promise<ServerAnalysisData> {
    const healthyCount = servers.filter((s) => s.status === 'running').length;
    const warningCount = servers.filter((s) => s.status === 'warning').length;
    const errorCount = servers.filter((s) => s.status === 'error').length;
    const totalCount = servers.length;

    const avgCpu = servers.reduce((sum, s) => sum + (s.cpu_usage || 0), 0) / totalCount || 0;
    const avgMemory = servers.reduce((sum, s) => sum + (s.memory_usage || 0), 0) / totalCount || 0;
    const avgResponseTime = servers.reduce((sum, s) => sum + (s.response_time || 0), 0) / totalCount || 0;

    const criticalServers = servers.filter((s) => 
      (s.cpu_usage && s.cpu_usage > 90) || (s.memory_usage && s.memory_usage > 90)
    );

    return {
      server_count: totalCount,
      health_summary: {
        healthy: healthyCount,
        warning: warningCount,
        critical: errorCount
      },
      performance_metrics: {
        avg_cpu: avgCpu,
        avg_memory: avgMemory,
        avg_response_time: avgResponseTime
      },
      top_issues: criticalServers.map(s => ({
        server_id: s.id,
        issue_type: 'high_resource_usage',
        severity: 'critical' as const
      }))
    };
  }

  private async analyzeLogs(logs: LogEntry[]): Promise<LogAnalysisData> {
    const errorLogs = logs.filter(log => log.level === 'error');
    const warningLogs = logs.filter(log => log.level === 'warn');

    // íŒ¨í„´ ë¶„ì„ (ì˜ˆì‹œ)
    const patterns = new Map<string, number>();
    logs.forEach(log => {
      const pattern = log.message.split(' ')[0]; // ê°„ë‹¨í•œ íŒ¨í„´ ì¶”ì¶œ
      patterns.set(pattern, (patterns.get(pattern) || 0) + 1);
    });

    const patternsDetected = Array.from(patterns.entries())
      .map(([pattern, frequency]) => ({
        pattern,
        frequency,
        severity: frequency > 10 ? 'high' : 'medium'
      }))
      .sort((a, b) => b.frequency - a.frequency)
      .slice(0, 5);

    const timestamps = logs.map(log => log.timestamp).sort();
    const timeRange = {
      start: timestamps[0] || '',
      end: timestamps[timestamps.length - 1] || ''
    };

    return {
      total_logs: logs.length,
      error_count: errorLogs.length,
      warning_count: warningLogs.length,
      patterns_detected: patternsDetected,
      time_range: timeRange
    };
  }

  private async analyzeMetrics(metrics: MetricEntry[]): Promise<MetricAnalysisData> {
    const cpuMetrics = metrics.filter(m => m.name === 'cpu_usage');
    const memoryMetrics = metrics.filter(m => m.name === 'memory_usage');
    const trafficMetrics = metrics.filter(m => m.name === 'network_traffic');

    // íŠ¸ë Œë“œ ë¶„ì„
    const cpuTrend = this.analyzeTrend(cpuMetrics.map(m => m.value));
    const memoryTrend = this.analyzeTrend(memoryMetrics.map(m => m.value));
    const trafficTrend = this.analyzeTrend(trafficMetrics.map(m => m.value));

    // ì´ìƒì¹˜ íƒì§€ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
    const anomalies = metrics
      .filter(m => {
        const threshold = m.name === 'cpu_usage' ? 90 : 
                        m.name === 'memory_usage' ? 90 : 1000;
        return m.value > threshold;
      })
      .map(m => ({
        metric_name: m.name,
        value: m.value,
        threshold: m.name === 'cpu_usage' ? 90 : 
                   m.name === 'memory_usage' ? 90 : 1000,
        timestamp: m.timestamp
      }));

    return {
      metrics_processed: metrics.length,
      anomalies_detected: anomalies,
      trends: {
        cpu: cpuTrend,
        memory: memoryTrend,
        traffic: trafficTrend
      },
      forecast: {
        next_hour: {},
        next_day: {}
      }
    };
  }

  private async analyzeAlerts(alerts: AlertEntry[]): Promise<AlertAnalysisData> {
    const activeAlerts = alerts.filter(a => a.status === 'active');
    const resolvedAlerts = alerts.filter(a => a.status === 'resolved');
    
    const priorityBreakdown = {
      critical: alerts.filter(a => a.severity === 'critical').length,
      high: alerts.filter(a => a.severity === 'high').length,
      medium: alerts.filter(a => a.severity === 'medium').length,
      low: alerts.filter(a => a.severity === 'low').length
    };

    // ì•Œë¦¼ ë¶„í¬ ê³„ì‚°
    const alertDistribution: Record<string, number> = {};
    alerts.forEach(alert => {
      const key = alert.title.split(' ')[0]; // ê°„ë‹¨í•œ ë¶„ë¥˜
      alertDistribution[key] = (alertDistribution[key] || 0) + 1;
    });

    // ì˜í–¥ë°›ëŠ” ì„œë¹„ìŠ¤ ì¶”ì¶œ
    const affectedServices = new Set<string>();
    alerts.forEach(alert => {
      alert.affected_resources.forEach(resource => {
        affectedServices.add(resource.split('/')[0]); // ì„œë¹„ìŠ¤ ì´ë¦„ ì¶”ì¶œ
      });
    });

    return {
      total_alerts: alerts.length,
      active_alerts: activeAlerts.length,
      resolved_alerts: resolvedAlerts.length,
      alert_distribution: alertDistribution,
      priority_breakdown: priorityBreakdown,
      affected_services: Array.from(affectedServices)
    };
  }

  private calculateUnifiedScore(
    serverAnalysis: ServerAnalysisData,
    logAnalysis: LogAnalysisData,
    metricAnalysis: MetricAnalysisData,
    alertAnalysis: AlertAnalysisData
  ): number {
    let score = 100;

    // ì„œë²„ ê±´ê°•ë„ ë°˜ì˜
    const healthRatio = serverAnalysis.server_count > 0 
      ? serverAnalysis.health_summary.healthy / serverAnalysis.server_count 
      : 0;
    score -= (1 - healthRatio) * 30;

    // ë¡œê·¸ ì—ëŸ¬ìœ¨ ë°˜ì˜
    const errorRate = logAnalysis.total_logs > 0 
      ? logAnalysis.error_count / logAnalysis.total_logs 
      : 0;
    score -= errorRate * 25;

    // ë©”íŠ¸ë¦­ ë¶€í•˜ ë°˜ì˜
    if (metricAnalysis.trends.cpu === 'increasing') score -= 10;
    if (metricAnalysis.trends.memory === 'increasing') score -= 10;

    // ì•Œë¦¼ ì‹¬ê°ë„ ë°˜ì˜
    score -= alertAnalysis.priority_breakdown.critical * 10;

    return Math.max(0, Math.min(100, score));
  }

  private generatePriorityActions(
    serverAnalysis: ServerAnalysisData,
    logAnalysis: LogAnalysisData,
    metricAnalysis: MetricAnalysisData,
    alertAnalysis: AlertAnalysisData
  ): string[] {
    const actions: string[] = [];

    const healthRatio = serverAnalysis.server_count > 0 
      ? serverAnalysis.health_summary.healthy / serverAnalysis.server_count 
      : 0;
      
    if (healthRatio < 0.8) {
      actions.push('ì„œë²„ ìƒíƒœ ì ê²€ í•„ìš”');
    }

    const errorRate = logAnalysis.total_logs > 0 
      ? logAnalysis.error_count / logAnalysis.total_logs 
      : 0;
      
    if (errorRate > 0.1) {
      actions.push('ì—ëŸ¬ ë¡œê·¸ ë¶„ì„ ë° í•´ê²°');
    }

    if (metricAnalysis.trends.cpu === 'increasing' || 
        metricAnalysis.trends.memory === 'increasing') {
      actions.push('ë¦¬ì†ŒìŠ¤ í™•ì¥ ê²€í† ');
    }

    if (alertAnalysis.priority_breakdown.critical > 0) {
      actions.push('ì¤‘ìš” ì•Œë¦¼ ì¦‰ì‹œ ì²˜ë¦¬');
    }

    return actions.length > 0 ? actions : ['ì •ìƒ ìš´ì˜ ì¤‘'];
  }

  // Custom NLP helpers
  private classifyIntent(query: string): string {
    const lowerQuery = query.toLowerCase();

    if (lowerQuery.includes('ìƒíƒœ') || lowerQuery.includes('status'))
      return 'status_check';
    if (lowerQuery.includes('ì„±ëŠ¥') || lowerQuery.includes('performance'))
      return 'performance_analysis';
    if (lowerQuery.includes('ë¬¸ì œ') || lowerQuery.includes('error'))
      return 'troubleshooting';
    if (lowerQuery.includes('ì¶”ì²œ') || lowerQuery.includes('recommend'))
      return 'recommendation';
    if (lowerQuery.includes('ì˜ˆì¸¡') || lowerQuery.includes('predict'))
      return 'prediction';

    return 'general_inquiry';
  }

  private extractOpenManagerEntities(query: string): Array<{
    type: 'server' | 'metric' | 'action' | 'time' | 'condition';
    value: string;
    confidence: number;
  }> {
    const entities: Array<{
      type: 'server' | 'metric' | 'action' | 'time' | 'condition';
      value: string;
      confidence: number;
    }> = [];

    // ì„œë²„ ì—”í‹°í‹°
    const serverMatches = query.match(/server-?\w+/gi) || [];
    serverMatches.forEach(match => {
      entities.push({ type: 'server' as const, value: match, confidence: 0.9 });
    });

    // ë©”íŠ¸ë¦­ ì—”í‹°í‹°
    const metricKeywords = [
      'cpu',
      'memory',
      'disk',
      'network',
      'response_time',
    ];
    metricKeywords.forEach(keyword => {
      if (query.toLowerCase().includes(keyword)) {
        entities.push({
          type: 'metric' as const,
          value: keyword,
          confidence: 0.8,
        });
      }
    });

    // ì•¡ì…˜ ì—”í‹°í‹°
    const actionKeywords = ['restart', 'stop', 'start', 'scale', 'monitor'];
    actionKeywords.forEach(keyword => {
      if (query.toLowerCase().includes(keyword)) {
        entities.push({
          type: 'action' as const,
          value: keyword,
          confidence: 0.85,
        });
      }
    });

    return entities;
  }

  private analyzeTrend(values: number[]): 'increasing' | 'stable' | 'decreasing' {
    if (values.length < 2) return 'stable';
    
    const firstHalf = values.slice(0, Math.floor(values.length / 2));
    const secondHalf = values.slice(Math.floor(values.length / 2));
    
    const avgFirst = firstHalf.reduce((sum, v) => sum + v, 0) / firstHalf.length;
    const avgSecond = secondHalf.reduce((sum, v) => sum + v, 0) / secondHalf.length;
    
    const diff = avgSecond - avgFirst;
    const threshold = avgFirst * 0.1; // 10% ë³€í™”ë¥¼ ì„ê³„ê°’ìœ¼ë¡œ
    
    if (diff > threshold) return 'increasing';
    if (diff < -threshold) return 'decreasing';
    return 'stable';
  }

  private selectResponseTemplate(intent: string, entities: Array<{
    type: 'server' | 'metric' | 'action' | 'time' | 'condition';
    value: string;
    confidence: number;
  }>): string {
    const templates = {
      status_check: 'server_status_template',
      performance_analysis: 'performance_report_template',
      troubleshooting: 'problem_solving_template',
      recommendation: 'recommendation_template',
      prediction: 'prediction_template',
      general_inquiry: 'general_response_template',
    };

    return (
      templates[intent as keyof typeof templates] || templates.general_inquiry
    );
  }

  private checkContextAwareness(query: string): boolean {
    // ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í™•ì¸
    return this.contextHistory.some(
      item =>
        query.toLowerCase().includes('ì´ì „') ||
        query.toLowerCase().includes('before') ||
        query.toLowerCase().includes('ê·¸') ||
        query.toLowerCase().includes('ê·¸ê²ƒ')
    );
  }

  /**
   * ğŸ”§ ì»¤ìŠ¤í…€ ì—”ì§„ ìƒíƒœ ì •ë³´
   */
  getEngineStatus() {
    return {
      mcp_connected: this.mcpConnected,
      context_history_count: this.contextHistory.length,
      engines: {
        mcp_query: {
          status: this.mcpConnected ? 'active' : 'disconnected',
          core: true,
        },
        mcp_test: { status: 'ready', utility: true },
        hybrid: { status: 'ready', fallback: true },
        unified: { status: 'ready', integration: true },
        custom_nlp: { status: 'ready', specialized: true },
      },
      capabilities: [
        'context_awareness',
        'reasoning_steps',
        'fallback_mechanisms',
        'unified_analysis',
        'korean_optimization',
      ],
    };
  }
}
