/**
 * ğŸ§  ê²½ëŸ‰ ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§„ v2.0
 *
 * âœ… Vercel ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ ì™„ì „ í˜¸í™˜
 * âœ… Python ì—†ì´ ìˆœìˆ˜ TypeScript/JavaScript êµ¬í˜„
 * âœ… ìë™ ì¥ì• ë³´ê³ ì„œ í•™ìŠµ ì‹œìŠ¤í…œ
 * âœ… ìì—°ì–´ ì§ˆì˜ ë¡œê·¸ ê¸°ë°˜ í•™ìŠµ
 * âœ… ì‹¤ì‹œê°„ ì„±ëŠ¥ ìµœì í™”
 */

// ê¸°ë³¸ íƒ€ì… ì •ì˜
interface DataPoint {
  features: number[];
  label?: number | string;
  timestamp: number;
  metadata?: Record<string, any>;
}

interface MLModel {
  type: 'regression' | 'classification' | 'clustering' | 'anomaly';
  weights?: number[];
  bias?: number;
  clusters?: number[][];
  threshold?: number;
  accuracy?: number;
  lastTrained: number;
  trainingData: DataPoint[];
}

export interface PredictionResult {
  prediction: number | string;
  confidence: number;
  explanation?: string;
  features: number[];
  timestamp: number;
}

interface LearningConfig {
  learningRate: number;
  maxIterations: number;
  convergenceThreshold: number;
  regularization: number;
  batchSize: number;
  autoRetrain: boolean;
  retrainThreshold: number; // ìƒˆ ë°ì´í„° ê°œìˆ˜
}

// ìˆ˜í•™ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
class MathUtils {
  // ë²¡í„° ë‚´ì 
  static dotProduct(a: number[], b: number[]): number {
    return a.reduce((sum, val, i) => sum + val * (b[i] || 0), 0);
  }

  // ë²¡í„° ì •ê·œí™”
  static normalize(vector: number[]): number[] {
    const magnitude = Math.sqrt(
      vector.reduce((sum, val) => sum + val * val, 0)
    );
    return magnitude === 0 ? vector : vector.map(val => val / magnitude);
  }

  // í‰ê·  ê³„ì‚°
  static mean(values: number[]): number {
    return values.reduce((sum, val) => sum + val, 0) / values.length;
  }

  // í‘œì¤€í¸ì°¨ ê³„ì‚°
  static standardDeviation(values: number[]): number {
    const avg = this.mean(values);
    const squaredDiffs = values.map(val => Math.pow(val - avg, 2));
    return Math.sqrt(this.mean(squaredDiffs));
  }

  // ìœ í´ë¦¬ë“œ ê±°ë¦¬
  static euclideanDistance(a: number[], b: number[]): number {
    return Math.sqrt(
      a.reduce((sum, val, i) => sum + Math.pow(val - (b[i] || 0), 2), 0)
    );
  }

  // ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜
  static sigmoid(x: number): number {
    return 1 / (1 + Math.exp(-Math.max(-500, Math.min(500, x)))); // ì˜¤ë²„í”Œë¡œìš° ë°©ì§€
  }

  // ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜
  static softmax(values: number[]): number[] {
    const maxVal = Math.max(...values);
    const expValues = values.map(val => Math.exp(val - maxVal));
    const sumExp = expValues.reduce((sum, val) => sum + val, 0);
    return expValues.map(val => val / sumExp);
  }
}

// íŠ¹ì„± ì¶”ì¶œê¸°
class FeatureExtractor {
  // ìë™ ì¥ì• ë³´ê³ ì„œì—ì„œ íŠ¹ì„± ì¶”ì¶œ
  static extractIncidentFeatures(incidentData: any): number[] {
    const features: number[] = [];

    // ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±
    const timestamp = new Date(incidentData.timestamp || Date.now()).getTime();
    features.push(timestamp % (24 * 60 * 60 * 1000)); // í•˜ë£¨ ì¤‘ ì‹œê°„
    features.push(new Date(timestamp).getDay()); // ìš”ì¼

    // ì„œë²„ ë©”íŠ¸ë¦­ íŠ¹ì„±
    features.push(incidentData.cpuUsage || 0);
    features.push(incidentData.memoryUsage || 0);
    features.push(incidentData.diskUsage || 0);
    features.push(incidentData.networkLatency || 0);

    // ì—ëŸ¬ ê´€ë ¨ íŠ¹ì„±
    features.push(incidentData.errorCount || 0);
    features.push(incidentData.warningCount || 0);
    features.push(incidentData.responseTime || 0);

    // í…ìŠ¤íŠ¸ íŠ¹ì„± (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
    const description = (incidentData.description || '').toLowerCase();
    features.push(description.includes('memory') ? 1 : 0);
    features.push(description.includes('cpu') ? 1 : 0);
    features.push(description.includes('disk') ? 1 : 0);
    features.push(description.includes('network') ? 1 : 0);
    features.push(description.includes('timeout') ? 1 : 0);
    features.push(description.includes('connection') ? 1 : 0);

    return features;
  }

  // ìì—°ì–´ ì§ˆì˜ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
  static extractQueryFeatures(queryData: any): number[] {
    const features: number[] = [];

    const query = (queryData.query || '').toLowerCase();
    const queryLength = query.length;

    // ê¸°ë³¸ í…ìŠ¤íŠ¸ íŠ¹ì„±
    features.push(queryLength);
    features.push(query.split(' ').length); // ë‹¨ì–´ ìˆ˜
    features.push(query.split('?').length - 1); // ì§ˆë¬¸ ê°œìˆ˜

    // ì¹´í…Œê³ ë¦¬ íŠ¹ì„± (í‚¤ì›Œë“œ ê¸°ë°˜)
    const categories = [
      'status',
      'performance',
      'error',
      'log',
      'system',
      'ai',
      'engine',
      'database',
      'network',
      'memory',
      'cpu',
      'disk',
      'alert',
      'monitoring',
      'analysis',
    ];

    categories.forEach(category => {
      features.push(query.includes(category) ? 1 : 0);
    });

    // ì‹œê°„ ê´€ë ¨ íŠ¹ì„±
    features.push(queryData.responseTime || 0);
    features.push(queryData.success ? 1 : 0);
    features.push(queryData.confidence || 0);

    // ì—”ì§„ ì‚¬ìš© íŠ¹ì„±
    features.push(queryData.engineUsed === 'google-ai' ? 1 : 0);
    features.push(queryData.engineUsed === 'supabase-rag' ? 1 : 0);
    features.push(queryData.engineUsed === 'mcp-context' ? 1 : 0);
    features.push(queryData.fallbackUsed ? 1 : 0);

    return features;
  }

  // ì„±ëŠ¥ ë©”íŠ¸ë¦­ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
  static extractPerformanceFeatures(performanceData: any): number[] {
    const features: number[] = [];

    features.push(performanceData.responseTime || 0);
    features.push(performanceData.successRate || 0);
    features.push(performanceData.errorRate || 0);
    features.push(performanceData.throughput || 0);
    features.push(performanceData.memoryUsage || 0);
    features.push(performanceData.cpuUsage || 0);
    features.push(performanceData.activeConnections || 0);
    features.push(performanceData.queueLength || 0);

    // ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±
    const timestamp = new Date(performanceData.timestamp || Date.now());
    features.push(timestamp.getHours());
    features.push(timestamp.getDay());
    features.push(timestamp.getTime() % (60 * 60 * 1000)); // ì‹œê°„ ë‚´ ë¶„

    return features;
  }
}

// ë©”ì¸ ê²½ëŸ‰ ML ì—”ì§„
export class LightweightMLEngine {
  private models: Map<string, MLModel> = new Map();
  private config: LearningConfig;
  private isTraining: boolean = false;

  constructor(config: Partial<LearningConfig> = {}) {
    this.config = {
      learningRate: 0.01,
      maxIterations: 1000,
      convergenceThreshold: 0.001,
      regularization: 0.01,
      batchSize: 32,
      autoRetrain: true,
      retrainThreshold: 100,
      ...config,
    };
  }

  // ì„ í˜• íšŒê·€ ëª¨ë¸ í›ˆë ¨
  async trainLinearRegression(
    modelName: string,
    trainingData: DataPoint[]
  ): Promise<void> {
    if (trainingData.length === 0) return;

    const features = trainingData.map(d => d.features);
    const labels = trainingData.map(d => Number(d.label) || 0);

    const featureCount = features[0].length;
    let weights = new Array(featureCount).fill(0);
    let bias = 0;

    // ê²½ì‚¬í•˜ê°•ë²•
    for (
      let iteration = 0;
      iteration < this.config.maxIterations;
      iteration++
    ) {
      let totalError = 0;
      const weightGradients = new Array(featureCount).fill(0);
      let biasGradient = 0;

      // ë°°ì¹˜ ì²˜ë¦¬
      for (let i = 0; i < features.length; i++) {
        const prediction = MathUtils.dotProduct(features[i], weights) + bias;
        const error = prediction - labels[i];
        totalError += error * error;

        // ê·¸ë¼ë””ì–¸íŠ¸ ê³„ì‚°
        for (let j = 0; j < featureCount; j++) {
          weightGradients[j] += error * features[i][j];
        }
        biasGradient += error;
      }

      // ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (ì •ê·œí™” í¬í•¨)
      for (let j = 0; j < featureCount; j++) {
        weights[j] -=
          this.config.learningRate *
          (weightGradients[j] / features.length +
            this.config.regularization * weights[j]);
      }
      bias -= this.config.learningRate * (biasGradient / features.length);

      // ìˆ˜ë ´ í™•ì¸
      const avgError = totalError / features.length;
      if (avgError < this.config.convergenceThreshold) {
        console.log(
          `âœ… ëª¨ë¸ ìˆ˜ë ´: ${iteration}íšŒ ë°˜ë³µ, ì˜¤ì°¨: ${avgError.toFixed(6)}`
        );
        break;
      }
    }

    // ì •í™•ë„ ê³„ì‚°
    const predictions = features.map(
      f => MathUtils.dotProduct(f, weights) + bias
    );
    const mse =
      labels.reduce(
        (sum, label, i) => sum + Math.pow(label - predictions[i], 2),
        0
      ) / labels.length;
    const accuracy = Math.max(0, 1 - Math.sqrt(mse) / Math.max(...labels));

    this.models.set(modelName, {
      type: 'regression',
      weights,
      bias,
      accuracy,
      lastTrained: Date.now(),
      trainingData: trainingData.slice(-1000), // ìµœê·¼ 1000ê°œë§Œ ë³´ê´€
    });

    console.log(
      `ğŸ“Š ì„ í˜• íšŒê·€ ëª¨ë¸ '${modelName}' í›ˆë ¨ ì™„ë£Œ - ì •í™•ë„: ${(accuracy * 100).toFixed(2)}%`
    );
  }

  // ë¡œì§€ìŠ¤í‹± íšŒê·€ (ë¶„ë¥˜) ëª¨ë¸ í›ˆë ¨
  async trainLogisticRegression(
    modelName: string,
    trainingData: DataPoint[]
  ): Promise<void> {
    if (trainingData.length === 0) return;

    const features = trainingData.map(d => d.features);
    const labels = trainingData.map(d => Number(d.label) || 0);

    const featureCount = features[0].length;
    let weights = new Array(featureCount).fill(0);
    let bias = 0;

    // ê²½ì‚¬í•˜ê°•ë²• (ë¡œì§€ìŠ¤í‹± íšŒê·€)
    for (
      let iteration = 0;
      iteration < this.config.maxIterations;
      iteration++
    ) {
      const weightGradients = new Array(featureCount).fill(0);
      let biasGradient = 0;

      for (let i = 0; i < features.length; i++) {
        const z = MathUtils.dotProduct(features[i], weights) + bias;
        const prediction = MathUtils.sigmoid(z);
        const error = prediction - labels[i];

        for (let j = 0; j < featureCount; j++) {
          weightGradients[j] += error * features[i][j];
        }
        biasGradient += error;
      }

      // ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
      for (let j = 0; j < featureCount; j++) {
        weights[j] -=
          this.config.learningRate *
          (weightGradients[j] / features.length +
            this.config.regularization * weights[j]);
      }
      bias -= this.config.learningRate * (biasGradient / features.length);
    }

    // ì •í™•ë„ ê³„ì‚°
    const correctPredictions = features.reduce((count, feature, i) => {
      const z = MathUtils.dotProduct(feature, weights) + bias;
      const prediction = MathUtils.sigmoid(z) > 0.5 ? 1 : 0;
      return count + (prediction === labels[i] ? 1 : 0);
    }, 0);
    const accuracy = correctPredictions / features.length;

    this.models.set(modelName, {
      type: 'classification',
      weights,
      bias,
      accuracy,
      lastTrained: Date.now(),
      trainingData: trainingData.slice(-1000),
    });

    console.log(
      `ğŸ¯ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ '${modelName}' í›ˆë ¨ ì™„ë£Œ - ì •í™•ë„: ${(accuracy * 100).toFixed(2)}%`
    );
  }

  // K-Means í´ëŸ¬ìŠ¤í„°ë§
  async trainKMeansClustering(
    modelName: string,
    trainingData: DataPoint[],
    k: number = 3
  ): Promise<void> {
    if (trainingData.length === 0) return;

    const features = trainingData.map(d => d.features);
    const featureCount = features[0].length;

    // ì´ˆê¸° í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  ëœë¤ ì„ íƒ
    let centroids: number[][] = [];
    for (let i = 0; i < k; i++) {
      const randomIndex = Math.floor(Math.random() * features.length);
      centroids.push([...features[randomIndex]]);
    }

    let converged = false;
    let iterations = 0;

    while (!converged && iterations < this.config.maxIterations) {
      // ê° ì ì„ ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹
      const clusters: number[][] = Array(k)
        .fill(null)
        .map((): number[] => []);

      features.forEach((feature, index) => {
        let minDistance = Infinity;
        let closestCluster = 0;

        for (let i = 0; i < k; i++) {
          const distance = MathUtils.euclideanDistance(feature, centroids[i]);
          if (distance < minDistance) {
            minDistance = distance;
            closestCluster = i;
          }
        }

        clusters[closestCluster].push(index);
      });

      // ìƒˆë¡œìš´ ì¤‘ì‹¬ì  ê³„ì‚°
      const newCentroids: number[][] = [];
      let totalMovement = 0;

      for (let i = 0; i < k; i++) {
        if (clusters[i].length === 0) {
          newCentroids.push([...centroids[i]]);
          continue;
        }

        const newCentroid = new Array(featureCount).fill(0);
        clusters[i].forEach(pointIndex => {
          features[pointIndex].forEach((value, featureIndex) => {
            newCentroid[featureIndex] += value;
          });
        });

        newCentroid.forEach((value, index) => {
          newCentroid[index] = value / clusters[i].length;
        });

        totalMovement += MathUtils.euclideanDistance(centroids[i], newCentroid);
        newCentroids.push(newCentroid);
      }

      centroids = newCentroids;
      converged = totalMovement < this.config.convergenceThreshold;
      iterations++;
    }

    this.models.set(modelName, {
      type: 'clustering',
      clusters: centroids,
      lastTrained: Date.now(),
      trainingData: trainingData.slice(-1000),
    });

    console.log(
      `ğŸ” K-Means í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸ '${modelName}' í›ˆë ¨ ì™„ë£Œ - ${iterations}íšŒ ë°˜ë³µ`
    );
  }

  // ì´ìƒ íƒì§€ ëª¨ë¸ í›ˆë ¨ (í†µê³„ ê¸°ë°˜)
  async trainAnomalyDetection(
    modelName: string,
    trainingData: DataPoint[]
  ): Promise<void> {
    if (trainingData.length === 0) return;

    const features = trainingData.map(d => d.features);
    const featureCount = features[0].length;

    // ê° íŠ¹ì„±ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
    const means: number[] = [];
    const stds: number[] = [];

    for (let i = 0; i < featureCount; i++) {
      const featureValues = features.map(f => f[i]);
      means.push(MathUtils.mean(featureValues));
      stds.push(MathUtils.standardDeviation(featureValues));
    }

    // ì„ê³„ê°’ ì„¤ì • (2 í‘œì¤€í¸ì°¨)
    const threshold = 2.0;

    this.models.set(modelName, {
      type: 'anomaly',
      weights: means,
      bias: threshold,
      clusters: [stds], // í‘œì¤€í¸ì°¨ë¥¼ clustersì— ì €ì¥
      lastTrained: Date.now(),
      trainingData: trainingData.slice(-1000),
    });

    console.log(`ğŸš¨ ì´ìƒ íƒì§€ ëª¨ë¸ '${modelName}' í›ˆë ¨ ì™„ë£Œ`);
  }

  // ì˜ˆì¸¡ ìˆ˜í–‰
  async predict(
    modelName: string,
    features: number[]
  ): Promise<PredictionResult | null> {
    const model = this.models.get(modelName);
    if (!model) {
      console.warn(`âš ï¸ ëª¨ë¸ '${modelName}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤`);
      return null;
    }

    let prediction: number | string;
    let confidence: number;
    let explanation: string;

    switch (model.type) {
      case 'regression':
        prediction =
          MathUtils.dotProduct(features, model.weights!) + (model.bias || 0);
        confidence = Math.min(1, model.accuracy || 0.5);
        explanation = `ì„ í˜• íšŒê·€ ì˜ˆì¸¡ê°’: ${prediction.toFixed(2)}`;
        break;

      case 'classification':
        const z =
          MathUtils.dotProduct(features, model.weights!) + (model.bias || 0);
        const probability = MathUtils.sigmoid(z);
        prediction = probability > 0.5 ? 1 : 0;
        confidence = Math.abs(probability - 0.5) * 2;
        explanation = `ë¶„ë¥˜ ê²°ê³¼: ${prediction} (í™•ë¥ : ${(probability * 100).toFixed(1)}%)`;
        break;

      case 'clustering':
        let minDistance = Infinity;
        let closestCluster = 0;

        model.clusters!.forEach((centroid, index) => {
          const distance = MathUtils.euclideanDistance(features, centroid);
          if (distance < minDistance) {
            minDistance = distance;
            closestCluster = index;
          }
        });

        prediction = closestCluster;
        confidence = Math.max(0, 1 - minDistance / 10); // ê±°ë¦¬ ê¸°ë°˜ ì‹ ë¢°ë„
        explanation = `í´ëŸ¬ìŠ¤í„° ${closestCluster} (ê±°ë¦¬: ${minDistance.toFixed(2)})`;
        break;

      case 'anomaly':
        const means = model.weights!;
        const stds = model.clusters![0];
        const threshold = model.bias!;

        let anomalyScore = 0;
        for (let i = 0; i < features.length; i++) {
          const zScore = Math.abs((features[i] - means[i]) / (stds[i] || 1));
          anomalyScore = Math.max(anomalyScore, zScore);
        }

        prediction = anomalyScore > threshold ? 1 : 0; // 1: ì´ìƒ, 0: ì •ìƒ
        confidence = Math.min(1, anomalyScore / threshold);
        explanation = `ì´ìƒ ì ìˆ˜: ${anomalyScore.toFixed(2)} (ì„ê³„ê°’: ${threshold})`;
        break;

      default:
        return null;
    }

    return {
      prediction,
      confidence,
      explanation,
      features,
      timestamp: Date.now(),
    };
  }

  // ìë™ ì¥ì• ë³´ê³ ì„œ í•™ìŠµ
  async learnFromIncidentReports(incidentReports: any[]): Promise<void> {
    console.log(
      `ğŸ“š ìë™ ì¥ì• ë³´ê³ ì„œ í•™ìŠµ ì‹œì‘: ${incidentReports.length}ê°œ ë³´ê³ ì„œ`
    );

    // íŠ¹ì„± ì¶”ì¶œ
    const trainingData: DataPoint[] = incidentReports.map(report => ({
      features: FeatureExtractor.extractIncidentFeatures(report),
      label: report.severity || report.priority || 1, // ì‹¬ê°ë„ë¥¼ ë¼ë²¨ë¡œ ì‚¬ìš©
      timestamp: new Date(report.timestamp || Date.now()).getTime(),
      metadata: { reportId: report.id, type: 'incident' },
    }));

    // ì—¬ëŸ¬ ëª¨ë¸ í›ˆë ¨
    await this.trainLinearRegression(
      'incident-severity-predictor',
      trainingData
    );
    await this.trainKMeansClustering('incident-clustering', trainingData, 3);
    await this.trainAnomalyDetection('incident-anomaly-detector', trainingData);

    console.log('âœ… ìë™ ì¥ì• ë³´ê³ ì„œ í•™ìŠµ ì™„ë£Œ');
  }

  // ìì—°ì–´ ì§ˆì˜ ë¡œê·¸ í•™ìŠµ
  async learnFromQueryLogs(queryLogs: any[]): Promise<void> {
    console.log(`ğŸ“š ìì—°ì–´ ì§ˆì˜ ë¡œê·¸ í•™ìŠµ ì‹œì‘: ${queryLogs.length}ê°œ ë¡œê·¸`);

    // íŠ¹ì„± ì¶”ì¶œ
    const trainingData: DataPoint[] = queryLogs.map(log => ({
      features: FeatureExtractor.extractQueryFeatures(log),
      label: log.responseTime || log.success ? 1 : 0,
      timestamp: new Date(log.timestamp || Date.now()).getTime(),
      metadata: { queryId: log.id, type: 'query' },
    }));

    // ì‘ë‹µ ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸
    const responseTimeData = trainingData.map(d => ({
      ...d,
      label: d.metadata?.responseTime || 1000,
    }));
    await this.trainLinearRegression(
      'query-response-time-predictor',
      responseTimeData
    );

    // ì„±ê³µë¥  ì˜ˆì¸¡ ëª¨ë¸
    const successData = trainingData.map(d => ({
      ...d,
      label: d.metadata?.success ? 1 : 0,
    }));
    await this.trainLogisticRegression('query-success-predictor', successData);

    // ì§ˆì˜ í´ëŸ¬ìŠ¤í„°ë§
    await this.trainKMeansClustering('query-clustering', trainingData, 5);

    console.log('âœ… ìì—°ì–´ ì§ˆì˜ ë¡œê·¸ í•™ìŠµ ì™„ë£Œ');
  }

  // ì„±ëŠ¥ ë°ì´í„° í•™ìŠµ
  async learnFromPerformanceData(performanceData: any[]): Promise<void> {
    console.log(`ğŸ“š ì„±ëŠ¥ ë°ì´í„° í•™ìŠµ ì‹œì‘: ${performanceData.length}ê°œ ë°ì´í„°`);

    const trainingData: DataPoint[] = performanceData.map(data => ({
      features: FeatureExtractor.extractPerformanceFeatures(data),
      label: data.responseTime || 0,
      timestamp: new Date(data.timestamp || Date.now()).getTime(),
      metadata: { type: 'performance' },
    }));

    // ì„±ëŠ¥ ì˜ˆì¸¡ ëª¨ë¸ë“¤
    await this.trainLinearRegression('performance-predictor', trainingData);
    await this.trainAnomalyDetection(
      'performance-anomaly-detector',
      trainingData
    );

    console.log('âœ… ì„±ëŠ¥ ë°ì´í„° í•™ìŠµ ì™„ë£Œ');
  }

  // ëª¨ë¸ ìƒíƒœ ì¡°íšŒ
  getModelStatus(): Record<string, any> {
    const status: Record<string, any> = {};

    this.models.forEach((model, name) => {
      status[name] = {
        type: model.type,
        accuracy: model.accuracy,
        lastTrained: new Date(model.lastTrained).toISOString(),
        trainingDataSize: model.trainingData.length,
        isReady: true,
      };
    });

    return status;
  }

  // ëª¨ë¸ ì €ì¥ (JSON í˜•íƒœ)
  exportModels(): string {
    const exportData = {
      models: Object.fromEntries(this.models),
      config: this.config,
      exportTime: new Date().toISOString(),
    };

    return JSON.stringify(exportData, null, 2);
  }

  // ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
  importModels(data: string): void {
    try {
      const importData = JSON.parse(data);

      if (importData.models) {
        this.models = new Map(Object.entries(importData.models));
      }

      if (importData.config) {
        this.config = { ...this.config, ...importData.config };
      }

      console.log(`âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ: ${this.models.size}ê°œ ëª¨ë¸`);
    } catch (error) {
      console.error('âŒ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:', error);
    }
  }

  // ìë™ ì¬í›ˆë ¨ í™•ì¸
  async checkAutoRetrain(): Promise<void> {
    if (!this.config.autoRetrain || this.isTraining) return;

    for (const [modelName, model] of this.models) {
      if (model.trainingData.length >= this.config.retrainThreshold) {
        console.log(`ğŸ”„ ëª¨ë¸ '${modelName}' ìë™ ì¬í›ˆë ¨ ì‹œì‘`);
        this.isTraining = true;

        try {
          switch (model.type) {
            case 'regression':
              await this.trainLinearRegression(modelName, model.trainingData);
              break;
            case 'classification':
              await this.trainLogisticRegression(modelName, model.trainingData);
              break;
            case 'clustering':
              await this.trainKMeansClustering(modelName, model.trainingData);
              break;
            case 'anomaly':
              await this.trainAnomalyDetection(modelName, model.trainingData);
              break;
          }
        } finally {
          this.isTraining = false;
        }
      }
    }
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
let mlEngineInstance: LightweightMLEngine | null = null;

export function getLightweightMLEngine(): LightweightMLEngine {
  if (!mlEngineInstance) {
    mlEngineInstance = new LightweightMLEngine({
      learningRate: 0.01,
      maxIterations: 500, // Vercel í™˜ê²½ì—ì„œ ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•´ ì¤„ì„
      convergenceThreshold: 0.001,
      regularization: 0.01,
      batchSize: 16,
      autoRetrain: true,
      retrainThreshold: 50,
    });
  }
  return mlEngineInstance;
}

export default LightweightMLEngine;
